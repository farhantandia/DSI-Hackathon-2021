{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interracial-rough",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "36FGnZpmKNg6lOTmOclq",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passive-offense",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "oxFZckY4dsi0LXBNC2s9",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-edgar",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jhqIeFVN8A69sjCWq1Cw",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "# Read Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "standing-inventory",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Xb8qNpcCpVWnbFCObkIG",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "YtgnLLJztCASmQSf9tvE",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e69e9384_2020-10-06_13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e6992c7c_2020-10-02_17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e69ef474_2020-09-13_19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69c5fd4_2020-10-10_15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e6992134_2020-09-12_11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71331</th>\n",
       "      <td>2e69eea5c_2020-11-09_10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71332</th>\n",
       "      <td>2e69c5944_2020-10-27_12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71333</th>\n",
       "      <td>2e69f2cd4_2020-11-07_14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71334</th>\n",
       "      <td>2e68e64e4_2020-09-23_9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71335</th>\n",
       "      <td>2e68e6084_2020-10-18_12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71336 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids  Labels\n",
       "0      2e69e9384_2020-10-06_13    True\n",
       "1      2e6992c7c_2020-10-02_17    True\n",
       "2      2e69ef474_2020-09-13_19    True\n",
       "3      2e69c5fd4_2020-10-10_15    True\n",
       "4      2e6992134_2020-09-12_11    True\n",
       "...                        ...     ...\n",
       "71331  2e69eea5c_2020-11-09_10   False\n",
       "71332  2e69c5944_2020-10-27_12    True\n",
       "71333  2e69f2cd4_2020-11-07_14    True\n",
       "71334   2e68e64e4_2020-09-23_9   False\n",
       "71335  2e68e6084_2020-10-18_12   False\n",
       "\n",
       "[71336 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data = pd.read_csv('data_train.csv')\n",
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legal-nickname",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "3OtRJWQkoi2kFgrjcrHc",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "LX6ipBTWxxCJAOpHTZ0g",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6992a84_2020-11-25_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e68e62f4_2020-11-29_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e68e81a4_2020-11-27_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69eec04_2020-11-24_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e698e4a4_2020-11-27_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2e68dd414_2020-11-26_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2e698541c_2020-11-24_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2e69e8e0c_2020-11-24_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2e699a1cc_2020-11-24_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2e698d804_2020-11-25_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids\n",
       "0      2e6992a84_2020-11-25_18\n",
       "1      2e68e62f4_2020-11-29_20\n",
       "2      2e68e81a4_2020-11-27_10\n",
       "3       2e69eec04_2020-11-24_7\n",
       "4       2e698e4a4_2020-11-27_8\n",
       "...                        ...\n",
       "13836   2e68dd414_2020-11-26_5\n",
       "13837  2e698541c_2020-11-24_22\n",
       "13838  2e69e8e0c_2020-11-24_10\n",
       "13839  2e699a1cc_2020-11-24_18\n",
       "13840  2e698d804_2020-11-25_19\n",
       "\n",
       "[13841 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_data = pd.read_csv('data_test.csv')\n",
    "all_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-network",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "igMJ5VYoiZBIBaeHNps4",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "# Cleaning Alerts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comfortable-documentation",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "F554DsvO08vyiXDZ9kSW",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "all_alerts_data = pd.read_csv('alerts.csv')\n",
    "alerts_data = all_alerts_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unavailable-uganda",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "ifrx4rEyXrltY57m2NJt",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "ThIDKYiLj59lYvgQ2lQe",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>s2id_15</th>\n",
       "      <th>s2token_15</th>\n",
       "      <th>road_type</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>magvar</th>\n",
       "      <th>reliability</th>\n",
       "      <th>report_description</th>\n",
       "      <th>report_rating</th>\n",
       "      <th>confidence</th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>report_by_municipality_user</th>\n",
       "      <th>n_thumbs_up</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177876895</td>\n",
       "      <td>1603331480000</td>\n",
       "      <td>3344466888162803712</td>\n",
       "      <td>2e69eeea4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Depok</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.788545</td>\n",
       "      <td>-6.359846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179156987</td>\n",
       "      <td>1604487892000</td>\n",
       "      <td>3344463130066419712</td>\n",
       "      <td>2e69eb7f4</td>\n",
       "      <td>6</td>\n",
       "      <td>N8 Jalan Raya Bogor</td>\n",
       "      <td>Depok</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_HEAVY_TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.867141</td>\n",
       "      <td>-6.383855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181688703</td>\n",
       "      <td>1605666614000</td>\n",
       "      <td>3344367648648462336</td>\n",
       "      <td>2e6994a84</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bekasi</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.921974</td>\n",
       "      <td>-6.379087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173055165</td>\n",
       "      <td>1601895721000</td>\n",
       "      <td>3344374458319110144</td>\n",
       "      <td>2e699ad9c</td>\n",
       "      <td>2</td>\n",
       "      <td>Flyover Tegal Gede</td>\n",
       "      <td>Cikarang</td>\n",
       "      <td>319</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>WEATHERHAZARD</td>\n",
       "      <td>HAZARD_ON_ROAD_POT_HOLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.143656</td>\n",
       "      <td>-6.300441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173802602</td>\n",
       "      <td>1602464394000</td>\n",
       "      <td>3344466709921660928</td>\n",
       "      <td>2e69eec0c</td>\n",
       "      <td>2</td>\n",
       "      <td>Tanjakan Kembar</td>\n",
       "      <td>Depok</td>\n",
       "      <td>310</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_HEAVY_TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.793950</td>\n",
       "      <td>-6.365677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800657</th>\n",
       "      <td>171213053</td>\n",
       "      <td>1601258425000</td>\n",
       "      <td>3344175981437911040</td>\n",
       "      <td>2e68e6564</td>\n",
       "      <td>7</td>\n",
       "      <td>Ir Haji Juanda</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.613518</td>\n",
       "      <td>-6.889047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800658</th>\n",
       "      <td>172373573</td>\n",
       "      <td>1601809265000</td>\n",
       "      <td>3344356103776370688</td>\n",
       "      <td>2e698a284</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutiara Gading</td>\n",
       "      <td>Tarumajaya</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_STAND_STILL_TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.004148</td>\n",
       "      <td>-6.162891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800659</th>\n",
       "      <td>166701219</td>\n",
       "      <td>1599012052000</td>\n",
       "      <td>3344175940635721728</td>\n",
       "      <td>2e68e64cc</td>\n",
       "      <td>7</td>\n",
       "      <td>Diponegoro</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.619330</td>\n",
       "      <td>-6.901280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800660</th>\n",
       "      <td>172955801</td>\n",
       "      <td>1602073655000</td>\n",
       "      <td>3344365275679031296</td>\n",
       "      <td>2e69927fc</td>\n",
       "      <td>2</td>\n",
       "      <td>Wibawa Mukti 2</td>\n",
       "      <td>Bekasi</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_HEAVY_TRAFFIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.959589</td>\n",
       "      <td>-6.294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800661</th>\n",
       "      <td>180801479</td>\n",
       "      <td>1605288917000</td>\n",
       "      <td>3344358444533547008</td>\n",
       "      <td>2e698c494</td>\n",
       "      <td>1</td>\n",
       "      <td>Satria Raya</td>\n",
       "      <td>Bekasi</td>\n",
       "      <td>359</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>WEATHERHAZARD</td>\n",
       "      <td>HAZARD_ON_ROAD_POT_HOLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.977909</td>\n",
       "      <td>-6.245801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7800662 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     pub_millis              s2id_15 s2token_15  road_type  \\\n",
       "0        177876895  1603331480000  3344466888162803712  2e69eeea4          1   \n",
       "1        179156987  1604487892000  3344463130066419712  2e69eb7f4          6   \n",
       "2        181688703  1605666614000  3344367648648462336  2e6994a84          7   \n",
       "3        173055165  1601895721000  3344374458319110144  2e699ad9c          2   \n",
       "4        173802602  1602464394000  3344466709921660928  2e69eec0c          2   \n",
       "...            ...            ...                  ...        ...        ...   \n",
       "7800657  171213053  1601258425000  3344175981437911040  2e68e6564          7   \n",
       "7800658  172373573  1601809265000  3344356103776370688  2e698a284          1   \n",
       "7800659  166701219  1599012052000  3344175940635721728  2e68e64cc          7   \n",
       "7800660  172955801  1602073655000  3344365275679031296  2e69927fc          2   \n",
       "7800661  180801479  1605288917000  3344358444533547008  2e698c494          1   \n",
       "\n",
       "                      street        city  magvar  reliability  \\\n",
       "0                        NaN       Depok       0            9   \n",
       "1        N8 Jalan Raya Bogor       Depok     170            7   \n",
       "2                        NaN      Bekasi       0            8   \n",
       "3         Flyover Tegal Gede    Cikarang     319           10   \n",
       "4            Tanjakan Kembar       Depok     310            5   \n",
       "...                      ...         ...     ...          ...   \n",
       "7800657       Ir Haji Juanda     Bandung       0            6   \n",
       "7800658       Mutiara Gading  Tarumajaya     101            5   \n",
       "7800659           Diponegoro     Bandung       0            6   \n",
       "7800660       Wibawa Mukti 2      Bekasi     200            5   \n",
       "7800661          Satria Raya      Bekasi     359            6   \n",
       "\n",
       "         report_description  report_rating  confidence           type  \\\n",
       "0                       NaN              0           1    ROAD_CLOSED   \n",
       "1                       NaN              1           1            JAM   \n",
       "2                       NaN              0           1    ROAD_CLOSED   \n",
       "3                       NaN              5           0  WEATHERHAZARD   \n",
       "4                       NaN              3           0            JAM   \n",
       "...                     ...            ...         ...            ...   \n",
       "7800657                 NaN              0           0    ROAD_CLOSED   \n",
       "7800658                 NaN              3           0            JAM   \n",
       "7800659                 NaN              0           0    ROAD_CLOSED   \n",
       "7800660                 NaN              2           0            JAM   \n",
       "7800661                 NaN              3           0  WEATHERHAZARD   \n",
       "\n",
       "                         subtype  report_by_municipality_user  n_thumbs_up  \\\n",
       "0              ROAD_CLOSED_EVENT                          NaN          NaN   \n",
       "1              JAM_HEAVY_TRAFFIC                          NaN          0.0   \n",
       "2              ROAD_CLOSED_EVENT                          NaN          NaN   \n",
       "3        HAZARD_ON_ROAD_POT_HOLE                          NaN          NaN   \n",
       "4              JAM_HEAVY_TRAFFIC                          NaN          NaN   \n",
       "...                          ...                          ...          ...   \n",
       "7800657        ROAD_CLOSED_EVENT                          NaN          NaN   \n",
       "7800658  JAM_STAND_STILL_TRAFFIC                          NaN          NaN   \n",
       "7800659        ROAD_CLOSED_EVENT                          NaN          0.0   \n",
       "7800660        JAM_HEAVY_TRAFFIC                          NaN          NaN   \n",
       "7800661  HAZARD_ON_ROAD_POT_HOLE                          NaN          NaN   \n",
       "\n",
       "          longitude  latitude  \n",
       "0        106.788545 -6.359846  \n",
       "1        106.867141 -6.383855  \n",
       "2        106.921974 -6.379087  \n",
       "3        107.143656 -6.300441  \n",
       "4        106.793950 -6.365677  \n",
       "...             ...       ...  \n",
       "7800657  107.613518 -6.889047  \n",
       "7800658  107.004148 -6.162891  \n",
       "7800659  107.619330 -6.901280  \n",
       "7800660  106.959589 -6.294933  \n",
       "7800661  106.977909 -6.245801  \n",
       "\n",
       "[7800662 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunrise-sally",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "8uv7b2atow1lOP78ilJ6",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "alerts_data['pub_millis'] = pd.to_datetime(alerts_data['pub_millis'], unit='ms')\n",
    "#add time column\n",
    "alerts_data['pub_time'] = [d.time() for d in alerts_data['pub_millis']]\n",
    "#add date column\n",
    "alerts_data['pub_date'] = [d.date() for d in alerts_data['pub_millis']]\n",
    "#add hour column\n",
    "alerts_data['hour'] = pd.to_datetime(alerts_data['pub_millis']).dt.hour\n",
    "alerts_data['report_description'].value_counts()\n",
    "\n",
    "\n",
    "dropped_columns = [['report_description','report_by_municipality_user','n_thumbs_up']]\n",
    "for col in dropped_columns:\n",
    "    alerts_clean = alerts_data.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "noticed-american",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "oqmwVJXRWJcHc4mujGLB",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pub_millis</th>\n",
       "      <th>s2id_15</th>\n",
       "      <th>s2token_15</th>\n",
       "      <th>road_type</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>magvar</th>\n",
       "      <th>reliability</th>\n",
       "      <th>report_rating</th>\n",
       "      <th>confidence</th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>pub_time</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177876895</td>\n",
       "      <td>2020-10-22 01:51:20</td>\n",
       "      <td>3344466888162803712</td>\n",
       "      <td>2e69eeea4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Depok</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>106.788545</td>\n",
       "      <td>-6.359846</td>\n",
       "      <td>01:51:20</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179156987</td>\n",
       "      <td>2020-11-04 11:04:52</td>\n",
       "      <td>3344463130066419712</td>\n",
       "      <td>2e69eb7f4</td>\n",
       "      <td>6</td>\n",
       "      <td>N8 Jalan Raya Bogor</td>\n",
       "      <td>Depok</td>\n",
       "      <td>170</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_HEAVY_TRAFFIC</td>\n",
       "      <td>106.867141</td>\n",
       "      <td>-6.383855</td>\n",
       "      <td>11:04:52</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181688703</td>\n",
       "      <td>2020-11-18 02:30:14</td>\n",
       "      <td>3344367648648462336</td>\n",
       "      <td>2e6994a84</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bekasi</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>106.921974</td>\n",
       "      <td>-6.379087</td>\n",
       "      <td>02:30:14</td>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173055165</td>\n",
       "      <td>2020-10-05 11:02:01</td>\n",
       "      <td>3344374458319110144</td>\n",
       "      <td>2e699ad9c</td>\n",
       "      <td>2</td>\n",
       "      <td>Flyover Tegal Gede</td>\n",
       "      <td>Cikarang</td>\n",
       "      <td>319</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>WEATHERHAZARD</td>\n",
       "      <td>HAZARD_ON_ROAD_POT_HOLE</td>\n",
       "      <td>107.143656</td>\n",
       "      <td>-6.300441</td>\n",
       "      <td>11:02:01</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173802602</td>\n",
       "      <td>2020-10-12 00:59:54</td>\n",
       "      <td>3344466709921660928</td>\n",
       "      <td>2e69eec0c</td>\n",
       "      <td>2</td>\n",
       "      <td>Tanjakan Kembar</td>\n",
       "      <td>Depok</td>\n",
       "      <td>310</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_HEAVY_TRAFFIC</td>\n",
       "      <td>106.793950</td>\n",
       "      <td>-6.365677</td>\n",
       "      <td>00:59:54</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800657</th>\n",
       "      <td>171213053</td>\n",
       "      <td>2020-09-28 02:00:25</td>\n",
       "      <td>3344175981437911040</td>\n",
       "      <td>2e68e6564</td>\n",
       "      <td>7</td>\n",
       "      <td>Ir Haji Juanda</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>107.613518</td>\n",
       "      <td>-6.889047</td>\n",
       "      <td>02:00:25</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800658</th>\n",
       "      <td>172373573</td>\n",
       "      <td>2020-10-04 11:01:05</td>\n",
       "      <td>3344356103776370688</td>\n",
       "      <td>2e698a284</td>\n",
       "      <td>1</td>\n",
       "      <td>Mutiara Gading</td>\n",
       "      <td>Tarumajaya</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_STAND_STILL_TRAFFIC</td>\n",
       "      <td>107.004148</td>\n",
       "      <td>-6.162891</td>\n",
       "      <td>11:01:05</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800659</th>\n",
       "      <td>166701219</td>\n",
       "      <td>2020-09-02 02:00:52</td>\n",
       "      <td>3344175940635721728</td>\n",
       "      <td>2e68e64cc</td>\n",
       "      <td>7</td>\n",
       "      <td>Diponegoro</td>\n",
       "      <td>Bandung</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ROAD_CLOSED</td>\n",
       "      <td>ROAD_CLOSED_EVENT</td>\n",
       "      <td>107.619330</td>\n",
       "      <td>-6.901280</td>\n",
       "      <td>02:00:52</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800660</th>\n",
       "      <td>172955801</td>\n",
       "      <td>2020-10-07 12:27:35</td>\n",
       "      <td>3344365275679031296</td>\n",
       "      <td>2e69927fc</td>\n",
       "      <td>2</td>\n",
       "      <td>Wibawa Mukti 2</td>\n",
       "      <td>Bekasi</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>JAM</td>\n",
       "      <td>JAM_HEAVY_TRAFFIC</td>\n",
       "      <td>106.959589</td>\n",
       "      <td>-6.294933</td>\n",
       "      <td>12:27:35</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800661</th>\n",
       "      <td>180801479</td>\n",
       "      <td>2020-11-13 17:35:17</td>\n",
       "      <td>3344358444533547008</td>\n",
       "      <td>2e698c494</td>\n",
       "      <td>1</td>\n",
       "      <td>Satria Raya</td>\n",
       "      <td>Bekasi</td>\n",
       "      <td>359</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>WEATHERHAZARD</td>\n",
       "      <td>HAZARD_ON_ROAD_POT_HOLE</td>\n",
       "      <td>106.977909</td>\n",
       "      <td>-6.245801</td>\n",
       "      <td>17:35:17</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7800662 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id          pub_millis              s2id_15 s2token_15  \\\n",
       "0        177876895 2020-10-22 01:51:20  3344466888162803712  2e69eeea4   \n",
       "1        179156987 2020-11-04 11:04:52  3344463130066419712  2e69eb7f4   \n",
       "2        181688703 2020-11-18 02:30:14  3344367648648462336  2e6994a84   \n",
       "3        173055165 2020-10-05 11:02:01  3344374458319110144  2e699ad9c   \n",
       "4        173802602 2020-10-12 00:59:54  3344466709921660928  2e69eec0c   \n",
       "...            ...                 ...                  ...        ...   \n",
       "7800657  171213053 2020-09-28 02:00:25  3344175981437911040  2e68e6564   \n",
       "7800658  172373573 2020-10-04 11:01:05  3344356103776370688  2e698a284   \n",
       "7800659  166701219 2020-09-02 02:00:52  3344175940635721728  2e68e64cc   \n",
       "7800660  172955801 2020-10-07 12:27:35  3344365275679031296  2e69927fc   \n",
       "7800661  180801479 2020-11-13 17:35:17  3344358444533547008  2e698c494   \n",
       "\n",
       "         road_type               street        city  magvar  reliability  \\\n",
       "0                1                  NaN       Depok       0            9   \n",
       "1                6  N8 Jalan Raya Bogor       Depok     170            7   \n",
       "2                7                  NaN      Bekasi       0            8   \n",
       "3                2   Flyover Tegal Gede    Cikarang     319           10   \n",
       "4                2      Tanjakan Kembar       Depok     310            5   \n",
       "...            ...                  ...         ...     ...          ...   \n",
       "7800657          7       Ir Haji Juanda     Bandung       0            6   \n",
       "7800658          1       Mutiara Gading  Tarumajaya     101            5   \n",
       "7800659          7           Diponegoro     Bandung       0            6   \n",
       "7800660          2       Wibawa Mukti 2      Bekasi     200            5   \n",
       "7800661          1          Satria Raya      Bekasi     359            6   \n",
       "\n",
       "         report_rating  confidence           type                  subtype  \\\n",
       "0                    0           1    ROAD_CLOSED        ROAD_CLOSED_EVENT   \n",
       "1                    1           1            JAM        JAM_HEAVY_TRAFFIC   \n",
       "2                    0           1    ROAD_CLOSED        ROAD_CLOSED_EVENT   \n",
       "3                    5           0  WEATHERHAZARD  HAZARD_ON_ROAD_POT_HOLE   \n",
       "4                    3           0            JAM        JAM_HEAVY_TRAFFIC   \n",
       "...                ...         ...            ...                      ...   \n",
       "7800657              0           0    ROAD_CLOSED        ROAD_CLOSED_EVENT   \n",
       "7800658              3           0            JAM  JAM_STAND_STILL_TRAFFIC   \n",
       "7800659              0           0    ROAD_CLOSED        ROAD_CLOSED_EVENT   \n",
       "7800660              2           0            JAM        JAM_HEAVY_TRAFFIC   \n",
       "7800661              3           0  WEATHERHAZARD  HAZARD_ON_ROAD_POT_HOLE   \n",
       "\n",
       "          longitude  latitude  pub_time    pub_date  hour  \n",
       "0        106.788545 -6.359846  01:51:20  2020-10-22     1  \n",
       "1        106.867141 -6.383855  11:04:52  2020-11-04    11  \n",
       "2        106.921974 -6.379087  02:30:14  2020-11-18     2  \n",
       "3        107.143656 -6.300441  11:02:01  2020-10-05    11  \n",
       "4        106.793950 -6.365677  00:59:54  2020-10-12     0  \n",
       "...             ...       ...       ...         ...   ...  \n",
       "7800657  107.613518 -6.889047  02:00:25  2020-09-28     2  \n",
       "7800658  107.004148 -6.162891  11:01:05  2020-10-04    11  \n",
       "7800659  107.619330 -6.901280  02:00:52  2020-09-02     2  \n",
       "7800660  106.959589 -6.294933  12:27:35  2020-10-07    12  \n",
       "7800661  106.977909 -6.245801  17:35:17  2020-11-13    17  \n",
       "\n",
       "[7800662 rows x 18 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alerts_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-british",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "oMAEKsLBz3ZjFN7E1V00",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "# Features Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "round-afghanistan",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Fzdjub7imLwwEgDkQMV8",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "all_train_data['Labels']=encoder.fit_transform(all_train_data['Labels'])\n",
    "all_train_data[['s2token_15','pub_date','hour']] = all_train_data['Ids'].str.split('_',expand=True)\n",
    "all_test_data[['s2token_15','pub_date','hour']] = all_test_data['Ids'].str.split('_',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developed-finnish",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "7u5sjWtCH7kBkxGjkEdM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "56v0jHwcOvQ6xPDZgUmI",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "      <th>s2token_15</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e69e9384_2020-10-06_13</td>\n",
       "      <td>1</td>\n",
       "      <td>2e69e9384</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e6992c7c_2020-10-02_17</td>\n",
       "      <td>1</td>\n",
       "      <td>2e6992c7c</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e69ef474_2020-09-13_19</td>\n",
       "      <td>1</td>\n",
       "      <td>2e69ef474</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69c5fd4_2020-10-10_15</td>\n",
       "      <td>1</td>\n",
       "      <td>2e69c5fd4</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e6992134_2020-09-12_11</td>\n",
       "      <td>1</td>\n",
       "      <td>2e6992134</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71331</th>\n",
       "      <td>2e69eea5c_2020-11-09_10</td>\n",
       "      <td>0</td>\n",
       "      <td>2e69eea5c</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71332</th>\n",
       "      <td>2e69c5944_2020-10-27_12</td>\n",
       "      <td>1</td>\n",
       "      <td>2e69c5944</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71333</th>\n",
       "      <td>2e69f2cd4_2020-11-07_14</td>\n",
       "      <td>1</td>\n",
       "      <td>2e69f2cd4</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71334</th>\n",
       "      <td>2e68e64e4_2020-09-23_9</td>\n",
       "      <td>0</td>\n",
       "      <td>2e68e64e4</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71335</th>\n",
       "      <td>2e68e6084_2020-10-18_12</td>\n",
       "      <td>0</td>\n",
       "      <td>2e68e6084</td>\n",
       "      <td>2020-10-18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71336 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids  Labels s2token_15    pub_date hour\n",
       "0      2e69e9384_2020-10-06_13       1  2e69e9384  2020-10-06   13\n",
       "1      2e6992c7c_2020-10-02_17       1  2e6992c7c  2020-10-02   17\n",
       "2      2e69ef474_2020-09-13_19       1  2e69ef474  2020-09-13   19\n",
       "3      2e69c5fd4_2020-10-10_15       1  2e69c5fd4  2020-10-10   15\n",
       "4      2e6992134_2020-09-12_11       1  2e6992134  2020-09-12   11\n",
       "...                        ...     ...        ...         ...  ...\n",
       "71331  2e69eea5c_2020-11-09_10       0  2e69eea5c  2020-11-09   10\n",
       "71332  2e69c5944_2020-10-27_12       1  2e69c5944  2020-10-27   12\n",
       "71333  2e69f2cd4_2020-11-07_14       1  2e69f2cd4  2020-11-07   14\n",
       "71334   2e68e64e4_2020-09-23_9       0  2e68e64e4  2020-09-23    9\n",
       "71335  2e68e6084_2020-10-18_12       0  2e68e6084  2020-10-18   12\n",
       "\n",
       "[71336 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-pulse",
   "metadata": {},
   "source": [
    "# See how imbalance the label is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "working-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47183 24153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hutom\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Target variable count')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=all_train_data['Labels'].value_counts().values\n",
    "print(x)\n",
    "sns.barplot([1,0],x)\n",
    "plt.title('Target variable count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conceptual-vanilla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "# WARNING! THIS CAN DAMAGE THE DATA \n",
    "def reduce_mem_usage2(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "radical-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.72 MB\n",
      "Memory usage after optimization is: 3.34 MB\n",
      "Decreased by -22.6%\n",
      "Memory usage of dataframe is 0.42 MB\n",
      "Memory usage after optimization is: 0.77 MB\n",
      "Decreased by -81.7%\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_train_data = reduce_mem_usage2(all_train_data)\n",
    "all_test_data = reduce_mem_usage2(all_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "narrow-yemen",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "QgHQPZn5R0hos14i0Kvq",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "all_train_data['pub_date'] = pd.to_datetime(all_train_data['pub_date'], errors='coerce')\n",
    "all_train_data['day'] = all_train_data['pub_date'].dt.day_name() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "powerful-breakfast",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "EDKsJkZLC84IOA4gRoFS",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "all_test_data['pub_date'] = pd.to_datetime(all_test_data['pub_date'], errors='coerce')\n",
    "all_test_data['day'] = all_test_data['pub_date'].dt.day_name() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stable-investment",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Sqv9C9dkEE6aOG1dxsF1",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "import s2cell\n",
    "all_train_data['latitude']=all_train_data['s2token_15'].apply (lambda row: s2cell.token_to_lat_lon(row)[0])\n",
    "all_train_data['longitude']=all_train_data['s2token_15'].apply (lambda row: s2cell.token_to_lat_lon(row)[1])\n",
    "\n",
    "all_test_data['latitude']=all_test_data['s2token_15'].apply (lambda row: s2cell.token_to_lat_lon(row)[0])\n",
    "all_test_data['longitude']=all_test_data['s2token_15'].apply (lambda row: s2cell.token_to_lat_lon(row)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "immediate-spirit",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "eF2LrIYyWvZ9kl5C4BDi",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "all_train_data['Labels']=pd.to_numeric(all_train_data['Labels'])\n",
    "all_train_data['hour']=pd.to_numeric(all_train_data['hour'])\n",
    "all_test_data['hour']=pd.to_numeric(all_test_data['hour'])\n",
    "y_train_all = all_train_data['Labels']\n",
    "all_train_data['day']=encoder.fit_transform(all_train_data['day'])\n",
    "all_test_data['day']=encoder.fit_transform(all_test_data['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "british-design",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "eutLtsHVSRbjWow0SWy9",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "dropped_columns = ['Labels','Ids','pub_date','s2token_15']\n",
    "for col in dropped_columns:\n",
    "    all_train_data = all_train_data.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mental-intellectual",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "TKcHUI3DsQd48bqzhW5h",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "dropped_columns_test = ['Ids','pub_date','s2token_15']\n",
    "\n",
    "for col in dropped_columns_test:\n",
    "    all_test_data = all_test_data.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "jewish-palestinian",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "bN7Gflgc6tXpay6hG6Nr",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "RRzXwyMjmnAKPRSDY1Us",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71336 entries, 0 to 71335\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   hour       71336 non-null  int64   \n",
      " 1   day        71336 non-null  int32   \n",
      " 2   latitude   71336 non-null  category\n",
      " 3   longitude  71336 non-null  float64 \n",
      "dtypes: category(1), float64(1), int32(1), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "all_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "practical-albany",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Sfm0BSuNzCJhVvmukEpE",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "epYfXsjG0mTx9lZo4MwT",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13841 entries, 0 to 13840\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   hour       13841 non-null  int64   \n",
      " 1   day        13841 non-null  int32   \n",
      " 2   latitude   13841 non-null  category\n",
      " 3   longitude  13841 non-null  float64 \n",
      "dtypes: category(1), float64(1), int32(1), int64(1)\n",
      "memory usage: 377.3 KB\n"
     ]
    }
   ],
   "source": [
    "all_test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elementary-disposal",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "2vQxHAaDi5rDuZeVaZiA",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "lOydtIcGmSvqQfItkIYQ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Labels, dtype: int8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "international-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data[\"longitude\"] = all_train_data[\"longitude\"].astype(\"float64\")\n",
    "all_train_data[\"latitude\"] = all_train_data[\"latitude\"].astype(\"float64\")\n",
    "all_test_data[\"longitude\"] = all_test_data[\"longitude\"].astype(\"float64\")\n",
    "all_test_data[\"latitude\"] = all_test_data[\"latitude\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-refund",
   "metadata": {},
   "source": [
    "<div align='left'><font size='4' color='#229954'>Splitting to train and validation</font></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-defeat",
   "metadata": {},
   "source": [
    "- We will now split the train dataset into train and validation set.\n",
    "- We will keeep 20% of data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "enclosed-royalty",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "dehqnrrxep599gXaCuys",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "# X_train_, X_test_, y_train_, y_test_ = train_test_split(all_train_data,y_train_all, test_size=0.2, random_state=38)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-concern",
   "metadata": {},
   "source": [
    "\n",
    "## [Resampling](#5)<a id=\"5\"></a> <br>\n",
    "\n",
    "A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling).\n",
    "\n",
    "![](https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-graham",
   "metadata": {},
   "source": [
    "## [Resampling Techniques using sklearn](#6)<a id=\"6\"></a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-brazilian",
   "metadata": {},
   "source": [
    "<div align='left'><font size='4' color=' #6c3483'> 1.Oversample minority class </font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-librarian",
   "metadata": {},
   "source": [
    "Oversampling can be defined as adding more copies of the minority class. Oversampling can be a good choice when you don’t have a ton of data to work with.\n",
    "\n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hourly-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# X=pd.concat([X_train_,y_train_],axis=1)\n",
    "\n",
    "\n",
    "# not_jam=X[X.Labels==0]\n",
    "# jam=X[X.Labels==1]\n",
    "\n",
    "# # upsample minority\n",
    "# jam_upsampled = resample(jam,\n",
    "#                           replace=True, # sample with replacement\n",
    "#                           n_samples=len(not_jam), # match number in majority class\n",
    "#                           random_state=27) # reproducible results\n",
    "\n",
    "# # combine majority and upsampled minority\n",
    "# upsampled = pd.concat([not_jam, jam_upsampled])\n",
    "\n",
    "# # check new class counts\n",
    "# upsampled.Labels.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "damaged-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=upsampled.Labels.value_counts()\n",
    "# sns.barplot(y=y,x=[0,1])\n",
    "# plt.title('upsampled data class count')\n",
    "# plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "spoken-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "specialized-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled[\"longitude\"] = upsampled[\"longitude\"].astype(\"float64\")\n",
    "# upsampled[\"latitude\"] = upsampled[\"latitude\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "absolute-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "approved-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split new upsampled Dataset\n",
    "# y_train_all = upsampled['Labels']\n",
    "# dropped_columns = ['Labels']\n",
    "# for col in dropped_columns:\n",
    "#     all_train_data = upsampled.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "oriental-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_test_data[\"longitude\"] = all_test_data[\"longitude\"].astype(\"float64\")\n",
    "# all_test_data[\"latitude\"] = all_test_data[\"latitude\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "durable-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-azerbaijan",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "fZJEV9tVePl7HJgrs8if",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    },
    "papermill": {
     "duration": 0.030123,
     "end_time": "2020-12-10T13:19:40.765736",
     "exception": false,
     "start_time": "2020-12-10T13:19:40.735613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unlikely-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(all_train_data,y_train_all, test_size=0.2, random_state=38)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "novel-composite",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "adKL10sTjCZjF8B3Ysvs",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "model = CatBoostClassifier(iterations=5000, learning_rate=0.01, l2_leaf_reg=3.5,colsample_bylevel= 0.09890530836500062,\n",
    "                           depth= 4, boosting_type= \"Plain\",  eval_metric='Logloss',use_best_model=True,\n",
    "                           random_seed=42,bootstrap_type= \"Bayesian\", bagging_temperature= 3.1351041422561403)\n",
    "cate_features_index = np.where(X_train_.dtypes != float)[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dying-vertical",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "35fJy1NYpcjF3XIPerVM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "lyiASAWUpiIlRpVNTIcQ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6920868\ttest: 0.6920508\tbest: 0.6920508 (0)\ttotal: 66.6ms\tremaining: 5m 32s\n",
      "1:\tlearn: 0.6910479\ttest: 0.6909762\tbest: 0.6909762 (1)\ttotal: 77.8ms\tremaining: 3m 14s\n",
      "2:\tlearn: 0.6895588\ttest: 0.6894083\tbest: 0.6894083 (2)\ttotal: 100ms\tremaining: 2m 46s\n",
      "3:\tlearn: 0.6885618\ttest: 0.6883762\tbest: 0.6883762 (3)\ttotal: 111ms\tremaining: 2m 18s\n",
      "4:\tlearn: 0.6869989\ttest: 0.6867512\tbest: 0.6867512 (4)\ttotal: 137ms\tremaining: 2m 16s\n",
      "5:\tlearn: 0.6859943\ttest: 0.6857206\tbest: 0.6857206 (5)\ttotal: 156ms\tremaining: 2m 10s\n",
      "6:\tlearn: 0.6850566\ttest: 0.6847488\tbest: 0.6847488 (6)\ttotal: 168ms\tremaining: 1m 59s\n",
      "7:\tlearn: 0.6841379\ttest: 0.6837964\tbest: 0.6837964 (7)\ttotal: 179ms\tremaining: 1m 51s\n",
      "8:\tlearn: 0.6829735\ttest: 0.6825339\tbest: 0.6825339 (8)\ttotal: 193ms\tremaining: 1m 47s\n",
      "9:\tlearn: 0.6820920\ttest: 0.6816200\tbest: 0.6816200 (9)\ttotal: 205ms\tremaining: 1m 42s\n",
      "10:\tlearn: 0.6812285\ttest: 0.6807243\tbest: 0.6807243 (10)\ttotal: 216ms\tremaining: 1m 37s\n",
      "11:\tlearn: 0.6803364\ttest: 0.6798085\tbest: 0.6798085 (11)\ttotal: 230ms\tremaining: 1m 35s\n",
      "12:\tlearn: 0.6793175\ttest: 0.6787609\tbest: 0.6787609 (12)\ttotal: 250ms\tremaining: 1m 35s\n",
      "13:\tlearn: 0.6782114\ttest: 0.6775941\tbest: 0.6775941 (13)\ttotal: 265ms\tremaining: 1m 34s\n",
      "14:\tlearn: 0.6772377\ttest: 0.6766182\tbest: 0.6766182 (14)\ttotal: 289ms\tremaining: 1m 36s\n",
      "15:\tlearn: 0.6764592\ttest: 0.6758091\tbest: 0.6758091 (15)\ttotal: 301ms\tremaining: 1m 33s\n",
      "16:\tlearn: 0.6756965\ttest: 0.6750162\tbest: 0.6750162 (16)\ttotal: 311ms\tremaining: 1m 31s\n",
      "17:\tlearn: 0.6748618\ttest: 0.6741547\tbest: 0.6741547 (17)\ttotal: 325ms\tremaining: 1m 29s\n",
      "18:\tlearn: 0.6741299\ttest: 0.6733931\tbest: 0.6733931 (18)\ttotal: 336ms\tremaining: 1m 27s\n",
      "19:\tlearn: 0.6734128\ttest: 0.6726467\tbest: 0.6726467 (19)\ttotal: 346ms\tremaining: 1m 26s\n",
      "20:\tlearn: 0.6727103\ttest: 0.6719151\tbest: 0.6719151 (20)\ttotal: 357ms\tremaining: 1m 24s\n",
      "21:\tlearn: 0.6719490\ttest: 0.6711330\tbest: 0.6711330 (21)\ttotal: 369ms\tremaining: 1m 23s\n",
      "22:\tlearn: 0.6711800\ttest: 0.6703400\tbest: 0.6703400 (22)\ttotal: 384ms\tremaining: 1m 23s\n",
      "23:\tlearn: 0.6699816\ttest: 0.6690751\tbest: 0.6690751 (23)\ttotal: 409ms\tremaining: 1m 24s\n",
      "24:\tlearn: 0.6693350\ttest: 0.6684005\tbest: 0.6684005 (24)\ttotal: 419ms\tremaining: 1m 23s\n",
      "25:\tlearn: 0.6687015\ttest: 0.6677392\tbest: 0.6677392 (25)\ttotal: 430ms\tremaining: 1m 22s\n",
      "26:\tlearn: 0.6680809\ttest: 0.6670911\tbest: 0.6670911 (26)\ttotal: 441ms\tremaining: 1m 21s\n",
      "27:\tlearn: 0.6669449\ttest: 0.6658836\tbest: 0.6658836 (27)\ttotal: 460ms\tremaining: 1m 21s\n",
      "28:\tlearn: 0.6660845\ttest: 0.6649657\tbest: 0.6649657 (28)\ttotal: 472ms\tremaining: 1m 20s\n",
      "29:\tlearn: 0.6655012\ttest: 0.6643557\tbest: 0.6643557 (29)\ttotal: 482ms\tremaining: 1m 19s\n",
      "30:\tlearn: 0.6649297\ttest: 0.6637579\tbest: 0.6637579 (30)\ttotal: 494ms\tremaining: 1m 19s\n",
      "31:\tlearn: 0.6643698\ttest: 0.6631719\tbest: 0.6631719 (31)\ttotal: 504ms\tremaining: 1m 18s\n",
      "32:\tlearn: 0.6636981\ttest: 0.6624834\tbest: 0.6624834 (32)\ttotal: 520ms\tremaining: 1m 18s\n",
      "33:\tlearn: 0.6631609\ttest: 0.6619206\tbest: 0.6619206 (33)\ttotal: 532ms\tremaining: 1m 17s\n",
      "34:\tlearn: 0.6623659\ttest: 0.6610726\tbest: 0.6610726 (34)\ttotal: 545ms\tremaining: 1m 17s\n",
      "35:\tlearn: 0.6618086\ttest: 0.6604975\tbest: 0.6604975 (35)\ttotal: 558ms\tremaining: 1m 16s\n",
      "36:\tlearn: 0.6613038\ttest: 0.6599677\tbest: 0.6599677 (36)\ttotal: 569ms\tremaining: 1m 16s\n",
      "37:\tlearn: 0.6608092\ttest: 0.6594485\tbest: 0.6594485 (37)\ttotal: 579ms\tremaining: 1m 15s\n",
      "38:\tlearn: 0.6600251\ttest: 0.6586190\tbest: 0.6586190 (38)\ttotal: 595ms\tremaining: 1m 15s\n",
      "39:\tlearn: 0.6595054\ttest: 0.6580760\tbest: 0.6580760 (39)\ttotal: 608ms\tremaining: 1m 15s\n",
      "40:\tlearn: 0.6588149\ttest: 0.6573144\tbest: 0.6573144 (40)\ttotal: 624ms\tremaining: 1m 15s\n",
      "41:\tlearn: 0.6583597\ttest: 0.6568360\tbest: 0.6568360 (41)\ttotal: 636ms\tremaining: 1m 15s\n",
      "42:\tlearn: 0.6579139\ttest: 0.6563671\tbest: 0.6563671 (42)\ttotal: 649ms\tremaining: 1m 14s\n",
      "43:\tlearn: 0.6574770\ttest: 0.6559075\tbest: 0.6559075 (43)\ttotal: 663ms\tremaining: 1m 14s\n",
      "44:\tlearn: 0.6569700\ttest: 0.6553843\tbest: 0.6553843 (44)\ttotal: 681ms\tremaining: 1m 14s\n",
      "45:\tlearn: 0.6565509\ttest: 0.6549428\tbest: 0.6549428 (45)\ttotal: 694ms\tremaining: 1m 14s\n",
      "46:\tlearn: 0.6561402\ttest: 0.6545100\tbest: 0.6545100 (46)\ttotal: 707ms\tremaining: 1m 14s\n",
      "47:\tlearn: 0.6557379\ttest: 0.6540857\tbest: 0.6540857 (47)\ttotal: 722ms\tremaining: 1m 14s\n",
      "48:\tlearn: 0.6552618\ttest: 0.6535996\tbest: 0.6535996 (48)\ttotal: 738ms\tremaining: 1m 14s\n",
      "49:\tlearn: 0.6548758\ttest: 0.6531921\tbest: 0.6531921 (49)\ttotal: 748ms\tremaining: 1m 14s\n",
      "50:\tlearn: 0.6542260\ttest: 0.6524898\tbest: 0.6524898 (50)\ttotal: 767ms\tremaining: 1m 14s\n",
      "51:\tlearn: 0.6536075\ttest: 0.6518240\tbest: 0.6518240 (51)\ttotal: 780ms\tremaining: 1m 14s\n",
      "52:\tlearn: 0.6528940\ttest: 0.6510596\tbest: 0.6510596 (52)\ttotal: 799ms\tremaining: 1m 14s\n",
      "53:\tlearn: 0.6525387\ttest: 0.6506839\tbest: 0.6506839 (53)\ttotal: 810ms\tremaining: 1m 14s\n",
      "54:\tlearn: 0.6521479\ttest: 0.6502736\tbest: 0.6502736 (54)\ttotal: 822ms\tremaining: 1m 13s\n",
      "55:\tlearn: 0.6517451\ttest: 0.6498529\tbest: 0.6498529 (55)\ttotal: 835ms\tremaining: 1m 13s\n",
      "56:\tlearn: 0.6514112\ttest: 0.6494991\tbest: 0.6494991 (56)\ttotal: 845ms\tremaining: 1m 13s\n",
      "57:\tlearn: 0.6510282\ttest: 0.6491099\tbest: 0.6491099 (57)\ttotal: 858ms\tremaining: 1m 13s\n",
      "58:\tlearn: 0.6505744\ttest: 0.6485914\tbest: 0.6485914 (58)\ttotal: 872ms\tremaining: 1m 12s\n",
      "59:\tlearn: 0.6502189\ttest: 0.6482176\tbest: 0.6482176 (59)\ttotal: 885ms\tremaining: 1m 12s\n",
      "60:\tlearn: 0.6499115\ttest: 0.6478913\tbest: 0.6478913 (60)\ttotal: 895ms\tremaining: 1m 12s\n",
      "61:\tlearn: 0.6495516\ttest: 0.6475140\tbest: 0.6475140 (61)\ttotal: 910ms\tremaining: 1m 12s\n",
      "62:\tlearn: 0.6492566\ttest: 0.6472004\tbest: 0.6472004 (62)\ttotal: 921ms\tremaining: 1m 12s\n",
      "63:\tlearn: 0.6487448\ttest: 0.6466406\tbest: 0.6466406 (63)\ttotal: 934ms\tremaining: 1m 12s\n",
      "64:\tlearn: 0.6480432\ttest: 0.6458954\tbest: 0.6458954 (64)\ttotal: 959ms\tremaining: 1m 12s\n",
      "65:\tlearn: 0.6477659\ttest: 0.6456004\tbest: 0.6456004 (65)\ttotal: 970ms\tremaining: 1m 12s\n",
      "66:\tlearn: 0.6474943\ttest: 0.6453111\tbest: 0.6453111 (66)\ttotal: 981ms\tremaining: 1m 12s\n",
      "67:\tlearn: 0.6472281\ttest: 0.6450276\tbest: 0.6450276 (67)\ttotal: 995ms\tremaining: 1m 12s\n",
      "68:\tlearn: 0.6469674\ttest: 0.6447496\tbest: 0.6447496 (68)\ttotal: 1s\tremaining: 1m 11s\n",
      "69:\tlearn: 0.6467119\ttest: 0.6444770\tbest: 0.6444770 (69)\ttotal: 1.02s\tremaining: 1m 11s\n",
      "70:\tlearn: 0.6464616\ttest: 0.6442098\tbest: 0.6442098 (70)\ttotal: 1.03s\tremaining: 1m 11s\n",
      "71:\tlearn: 0.6462164\ttest: 0.6439479\tbest: 0.6439479 (71)\ttotal: 1.04s\tremaining: 1m 11s\n",
      "72:\tlearn: 0.6459762\ttest: 0.6436910\tbest: 0.6436910 (72)\ttotal: 1.05s\tremaining: 1m 11s\n",
      "73:\tlearn: 0.6457408\ttest: 0.6434393\tbest: 0.6434393 (73)\ttotal: 1.07s\tremaining: 1m 11s\n",
      "74:\tlearn: 0.6452838\ttest: 0.6429410\tbest: 0.6429410 (74)\ttotal: 1.08s\tremaining: 1m 11s\n",
      "75:\tlearn: 0.6449933\ttest: 0.6426362\tbest: 0.6426362 (75)\ttotal: 1.09s\tremaining: 1m 10s\n",
      "76:\tlearn: 0.6447720\ttest: 0.6423990\tbest: 0.6423990 (76)\ttotal: 1.11s\tremaining: 1m 10s\n",
      "77:\tlearn: 0.6444920\ttest: 0.6421049\tbest: 0.6421049 (77)\ttotal: 1.12s\tremaining: 1m 10s\n",
      "78:\tlearn: 0.6442797\ttest: 0.6418770\tbest: 0.6418770 (78)\ttotal: 1.13s\tremaining: 1m 10s\n",
      "79:\tlearn: 0.6438295\ttest: 0.6413686\tbest: 0.6413686 (79)\ttotal: 1.15s\tremaining: 1m 10s\n",
      "80:\tlearn: 0.6434088\ttest: 0.6409086\tbest: 0.6409086 (80)\ttotal: 1.16s\tremaining: 1m 10s\n",
      "81:\tlearn: 0.6427252\ttest: 0.6401563\tbest: 0.6401563 (81)\ttotal: 1.18s\tremaining: 1m 10s\n",
      "82:\tlearn: 0.6425296\ttest: 0.6399459\tbest: 0.6399459 (82)\ttotal: 1.19s\tremaining: 1m 10s\n",
      "83:\tlearn: 0.6423380\ttest: 0.6397397\tbest: 0.6397397 (83)\ttotal: 1.21s\tremaining: 1m 10s\n",
      "84:\tlearn: 0.6421502\ttest: 0.6395374\tbest: 0.6395374 (84)\ttotal: 1.22s\tremaining: 1m 10s\n",
      "85:\tlearn: 0.6419663\ttest: 0.6393391\tbest: 0.6393391 (85)\ttotal: 1.23s\tremaining: 1m 10s\n",
      "86:\tlearn: 0.6417860\ttest: 0.6391446\tbest: 0.6391446 (86)\ttotal: 1.24s\tremaining: 1m 10s\n",
      "87:\tlearn: 0.6416094\ttest: 0.6389540\tbest: 0.6389540 (87)\ttotal: 1.25s\tremaining: 1m 9s\n",
      "88:\tlearn: 0.6413816\ttest: 0.6387166\tbest: 0.6387166 (88)\ttotal: 1.27s\tremaining: 1m 9s\n",
      "89:\tlearn: 0.6411508\ttest: 0.6384796\tbest: 0.6384796 (89)\ttotal: 1.29s\tremaining: 1m 10s\n",
      "90:\tlearn: 0.6405818\ttest: 0.6378679\tbest: 0.6378679 (90)\ttotal: 1.31s\tremaining: 1m 10s\n",
      "91:\tlearn: 0.6403814\ttest: 0.6376548\tbest: 0.6376548 (91)\ttotal: 1.32s\tremaining: 1m 10s\n",
      "92:\tlearn: 0.6402221\ttest: 0.6374821\tbest: 0.6374821 (92)\ttotal: 1.33s\tremaining: 1m 10s\n",
      "93:\tlearn: 0.6400660\ttest: 0.6373127\tbest: 0.6373127 (93)\ttotal: 1.34s\tremaining: 1m 10s\n",
      "94:\tlearn: 0.6399130\ttest: 0.6371466\tbest: 0.6371466 (94)\ttotal: 1.35s\tremaining: 1m 9s\n",
      "95:\tlearn: 0.6397632\ttest: 0.6369837\tbest: 0.6369837 (95)\ttotal: 1.36s\tremaining: 1m 9s\n",
      "96:\tlearn: 0.6396163\ttest: 0.6368240\tbest: 0.6368240 (96)\ttotal: 1.37s\tremaining: 1m 9s\n",
      "97:\tlearn: 0.6394725\ttest: 0.6366674\tbest: 0.6366674 (97)\ttotal: 1.39s\tremaining: 1m 9s\n",
      "98:\tlearn: 0.6391294\ttest: 0.6362883\tbest: 0.6362883 (98)\ttotal: 1.4s\tremaining: 1m 9s\n",
      "99:\tlearn: 0.6387907\ttest: 0.6358951\tbest: 0.6358951 (99)\ttotal: 1.41s\tremaining: 1m 9s\n",
      "100:\tlearn: 0.6386136\ttest: 0.6357157\tbest: 0.6357157 (100)\ttotal: 1.43s\tremaining: 1m 9s\n",
      "101:\tlearn: 0.6384812\ttest: 0.6355712\tbest: 0.6355712 (101)\ttotal: 1.44s\tremaining: 1m 9s\n",
      "102:\tlearn: 0.6383515\ttest: 0.6354296\tbest: 0.6354296 (102)\ttotal: 1.45s\tremaining: 1m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103:\tlearn: 0.6382244\ttest: 0.6352906\tbest: 0.6352906 (103)\ttotal: 1.46s\tremaining: 1m 8s\n",
      "104:\tlearn: 0.6380999\ttest: 0.6351543\tbest: 0.6351543 (104)\ttotal: 1.47s\tremaining: 1m 8s\n",
      "105:\tlearn: 0.6379779\ttest: 0.6350207\tbest: 0.6350207 (105)\ttotal: 1.49s\tremaining: 1m 8s\n",
      "106:\tlearn: 0.6378583\ttest: 0.6348896\tbest: 0.6348896 (106)\ttotal: 1.5s\tremaining: 1m 8s\n",
      "107:\tlearn: 0.6373770\ttest: 0.6343664\tbest: 0.6343664 (107)\ttotal: 1.52s\tremaining: 1m 8s\n",
      "108:\tlearn: 0.6372621\ttest: 0.6342402\tbest: 0.6342402 (108)\ttotal: 1.53s\tremaining: 1m 8s\n",
      "109:\tlearn: 0.6371496\ttest: 0.6341165\tbest: 0.6341165 (109)\ttotal: 1.54s\tremaining: 1m 8s\n",
      "110:\tlearn: 0.6370393\ttest: 0.6339952\tbest: 0.6339952 (110)\ttotal: 1.55s\tremaining: 1m 8s\n",
      "111:\tlearn: 0.6368882\ttest: 0.6338325\tbest: 0.6338325 (111)\ttotal: 1.57s\tremaining: 1m 8s\n",
      "112:\tlearn: 0.6367237\ttest: 0.6336624\tbest: 0.6336624 (112)\ttotal: 1.59s\tremaining: 1m 8s\n",
      "113:\tlearn: 0.6365381\ttest: 0.6334841\tbest: 0.6334841 (113)\ttotal: 1.6s\tremaining: 1m 8s\n",
      "114:\tlearn: 0.6364366\ttest: 0.6333719\tbest: 0.6333719 (114)\ttotal: 1.61s\tremaining: 1m 8s\n",
      "115:\tlearn: 0.6363371\ttest: 0.6332619\tbest: 0.6332619 (115)\ttotal: 1.63s\tremaining: 1m 8s\n",
      "116:\tlearn: 0.6359203\ttest: 0.6327909\tbest: 0.6327909 (116)\ttotal: 1.65s\tremaining: 1m 8s\n",
      "117:\tlearn: 0.6358249\ttest: 0.6326851\tbest: 0.6326851 (117)\ttotal: 1.66s\tremaining: 1m 8s\n",
      "118:\tlearn: 0.6357313\ttest: 0.6325813\tbest: 0.6325813 (118)\ttotal: 1.67s\tremaining: 1m 8s\n",
      "119:\tlearn: 0.6356396\ttest: 0.6324795\tbest: 0.6324795 (119)\ttotal: 1.68s\tremaining: 1m 8s\n",
      "120:\tlearn: 0.6355498\ttest: 0.6323797\tbest: 0.6323797 (120)\ttotal: 1.7s\tremaining: 1m 8s\n",
      "121:\tlearn: 0.6354262\ttest: 0.6322470\tbest: 0.6322470 (121)\ttotal: 1.71s\tremaining: 1m 8s\n",
      "122:\tlearn: 0.6353400\ttest: 0.6321509\tbest: 0.6321509 (122)\ttotal: 1.72s\tremaining: 1m 8s\n",
      "123:\tlearn: 0.6352555\ttest: 0.6320567\tbest: 0.6320567 (123)\ttotal: 1.73s\tremaining: 1m 8s\n",
      "124:\tlearn: 0.6351727\ttest: 0.6319643\tbest: 0.6319643 (124)\ttotal: 1.75s\tremaining: 1m 8s\n",
      "125:\tlearn: 0.6350803\ttest: 0.6318600\tbest: 0.6318600 (125)\ttotal: 1.77s\tremaining: 1m 8s\n",
      "126:\tlearn: 0.6350008\ttest: 0.6317711\tbest: 0.6317711 (126)\ttotal: 1.78s\tremaining: 1m 8s\n",
      "127:\tlearn: 0.6349230\ttest: 0.6316839\tbest: 0.6316839 (127)\ttotal: 1.8s\tremaining: 1m 8s\n",
      "128:\tlearn: 0.6346601\ttest: 0.6313893\tbest: 0.6313893 (128)\ttotal: 1.81s\tremaining: 1m 8s\n",
      "129:\tlearn: 0.6345854\ttest: 0.6313055\tbest: 0.6313055 (129)\ttotal: 1.83s\tremaining: 1m 8s\n",
      "130:\tlearn: 0.6344775\ttest: 0.6311893\tbest: 0.6311893 (130)\ttotal: 1.85s\tremaining: 1m 8s\n",
      "131:\tlearn: 0.6344057\ttest: 0.6311086\tbest: 0.6311086 (131)\ttotal: 1.86s\tremaining: 1m 8s\n",
      "132:\tlearn: 0.6343355\ttest: 0.6310294\tbest: 0.6310294 (132)\ttotal: 1.88s\tremaining: 1m 8s\n",
      "133:\tlearn: 0.6342666\ttest: 0.6309518\tbest: 0.6309518 (133)\ttotal: 1.89s\tremaining: 1m 8s\n",
      "134:\tlearn: 0.6341991\ttest: 0.6308756\tbest: 0.6308756 (134)\ttotal: 1.9s\tremaining: 1m 8s\n",
      "135:\tlearn: 0.6341330\ttest: 0.6308009\tbest: 0.6308009 (135)\ttotal: 1.92s\tremaining: 1m 8s\n",
      "136:\tlearn: 0.6340682\ttest: 0.6307276\tbest: 0.6307276 (136)\ttotal: 1.93s\tremaining: 1m 8s\n",
      "137:\tlearn: 0.6340048\ttest: 0.6306557\tbest: 0.6306557 (137)\ttotal: 1.94s\tremaining: 1m 8s\n",
      "138:\tlearn: 0.6339426\ttest: 0.6305851\tbest: 0.6305851 (138)\ttotal: 1.96s\tremaining: 1m 8s\n",
      "139:\tlearn: 0.6338816\ttest: 0.6305159\tbest: 0.6305159 (139)\ttotal: 1.97s\tremaining: 1m 8s\n",
      "140:\tlearn: 0.6336466\ttest: 0.6302490\tbest: 0.6302490 (140)\ttotal: 1.98s\tremaining: 1m 8s\n",
      "141:\tlearn: 0.6334085\ttest: 0.6299798\tbest: 0.6299798 (141)\ttotal: 2s\tremaining: 1m 8s\n",
      "142:\tlearn: 0.6331957\ttest: 0.6297408\tbest: 0.6297408 (142)\ttotal: 2.01s\tremaining: 1m 8s\n",
      "143:\tlearn: 0.6328885\ttest: 0.6293861\tbest: 0.6293861 (143)\ttotal: 2.04s\tremaining: 1m 8s\n",
      "144:\tlearn: 0.6328336\ttest: 0.6293235\tbest: 0.6293235 (144)\ttotal: 2.06s\tremaining: 1m 8s\n",
      "145:\tlearn: 0.6327798\ttest: 0.6292621\tbest: 0.6292621 (145)\ttotal: 2.07s\tremaining: 1m 8s\n",
      "146:\tlearn: 0.6327271\ttest: 0.6292018\tbest: 0.6292018 (146)\ttotal: 2.08s\tremaining: 1m 8s\n",
      "147:\tlearn: 0.6326452\ttest: 0.6291176\tbest: 0.6291176 (147)\ttotal: 2.1s\tremaining: 1m 8s\n",
      "148:\tlearn: 0.6325409\ttest: 0.6290105\tbest: 0.6290105 (148)\ttotal: 2.11s\tremaining: 1m 8s\n",
      "149:\tlearn: 0.6324914\ttest: 0.6289536\tbest: 0.6289536 (149)\ttotal: 2.12s\tremaining: 1m 8s\n",
      "150:\tlearn: 0.6324428\ttest: 0.6288978\tbest: 0.6288978 (150)\ttotal: 2.14s\tremaining: 1m 8s\n",
      "151:\tlearn: 0.6323952\ttest: 0.6288430\tbest: 0.6288430 (151)\ttotal: 2.15s\tremaining: 1m 8s\n",
      "152:\tlearn: 0.6323486\ttest: 0.6287893\tbest: 0.6287893 (152)\ttotal: 2.16s\tremaining: 1m 8s\n",
      "153:\tlearn: 0.6323029\ttest: 0.6287365\tbest: 0.6287365 (153)\ttotal: 2.17s\tremaining: 1m 8s\n",
      "154:\tlearn: 0.6322581\ttest: 0.6286848\tbest: 0.6286848 (154)\ttotal: 2.18s\tremaining: 1m 8s\n",
      "155:\tlearn: 0.6322143\ttest: 0.6286340\tbest: 0.6286340 (155)\ttotal: 2.19s\tremaining: 1m 8s\n",
      "156:\tlearn: 0.6321713\ttest: 0.6285842\tbest: 0.6285842 (156)\ttotal: 2.21s\tremaining: 1m 8s\n",
      "157:\tlearn: 0.6321291\ttest: 0.6285353\tbest: 0.6285353 (157)\ttotal: 2.22s\tremaining: 1m 7s\n",
      "158:\tlearn: 0.6320879\ttest: 0.6284873\tbest: 0.6284873 (158)\ttotal: 2.23s\tremaining: 1m 7s\n",
      "159:\tlearn: 0.6320474\ttest: 0.6284403\tbest: 0.6284403 (159)\ttotal: 2.24s\tremaining: 1m 7s\n",
      "160:\tlearn: 0.6320078\ttest: 0.6283941\tbest: 0.6283941 (160)\ttotal: 2.25s\tremaining: 1m 7s\n",
      "161:\tlearn: 0.6319689\ttest: 0.6283487\tbest: 0.6283487 (161)\ttotal: 2.26s\tremaining: 1m 7s\n",
      "162:\tlearn: 0.6319309\ttest: 0.6283042\tbest: 0.6283042 (162)\ttotal: 2.28s\tremaining: 1m 7s\n",
      "163:\tlearn: 0.6318199\ttest: 0.6281884\tbest: 0.6281884 (163)\ttotal: 2.29s\tremaining: 1m 7s\n",
      "164:\tlearn: 0.6317834\ttest: 0.6281456\tbest: 0.6281456 (164)\ttotal: 2.31s\tremaining: 1m 7s\n",
      "165:\tlearn: 0.6317476\ttest: 0.6281036\tbest: 0.6281036 (165)\ttotal: 2.32s\tremaining: 1m 7s\n",
      "166:\tlearn: 0.6317126\ttest: 0.6280623\tbest: 0.6280623 (166)\ttotal: 2.33s\tremaining: 1m 7s\n",
      "167:\tlearn: 0.6316051\ttest: 0.6279580\tbest: 0.6279580 (167)\ttotal: 2.35s\tremaining: 1m 7s\n",
      "168:\tlearn: 0.6314032\ttest: 0.6277293\tbest: 0.6277293 (168)\ttotal: 2.36s\tremaining: 1m 7s\n",
      "169:\tlearn: 0.6312948\ttest: 0.6276207\tbest: 0.6276207 (169)\ttotal: 2.38s\tremaining: 1m 7s\n",
      "170:\tlearn: 0.6312626\ttest: 0.6275825\tbest: 0.6275825 (170)\ttotal: 2.4s\tremaining: 1m 7s\n",
      "171:\tlearn: 0.6312310\ttest: 0.6275450\tbest: 0.6275450 (171)\ttotal: 2.41s\tremaining: 1m 7s\n",
      "172:\tlearn: 0.6311624\ttest: 0.6274806\tbest: 0.6274806 (172)\ttotal: 2.42s\tremaining: 1m 7s\n",
      "173:\tlearn: 0.6311321\ttest: 0.6274445\tbest: 0.6274445 (173)\ttotal: 2.43s\tremaining: 1m 7s\n",
      "174:\tlearn: 0.6310734\ttest: 0.6273851\tbest: 0.6273851 (174)\ttotal: 2.45s\tremaining: 1m 7s\n",
      "175:\tlearn: 0.6310132\ttest: 0.6273199\tbest: 0.6273199 (175)\ttotal: 2.46s\tremaining: 1m 7s\n",
      "176:\tlearn: 0.6309847\ttest: 0.6272858\tbest: 0.6272858 (176)\ttotal: 2.47s\tremaining: 1m 7s\n",
      "177:\tlearn: 0.6309214\ttest: 0.6272165\tbest: 0.6272165 (177)\ttotal: 2.49s\tremaining: 1m 7s\n",
      "178:\tlearn: 0.6308507\ttest: 0.6271379\tbest: 0.6271379 (178)\ttotal: 2.5s\tremaining: 1m 7s\n",
      "179:\tlearn: 0.6308239\ttest: 0.6271057\tbest: 0.6271057 (179)\ttotal: 2.52s\tremaining: 1m 7s\n",
      "180:\tlearn: 0.6307976\ttest: 0.6270740\tbest: 0.6270740 (180)\ttotal: 2.53s\tremaining: 1m 7s\n",
      "181:\tlearn: 0.6307718\ttest: 0.6270429\tbest: 0.6270429 (181)\ttotal: 2.54s\tremaining: 1m 7s\n",
      "182:\tlearn: 0.6307465\ttest: 0.6270124\tbest: 0.6270124 (182)\ttotal: 2.55s\tremaining: 1m 7s\n",
      "183:\tlearn: 0.6307218\ttest: 0.6269825\tbest: 0.6269825 (183)\ttotal: 2.56s\tremaining: 1m 7s\n",
      "184:\tlearn: 0.6306975\ttest: 0.6269531\tbest: 0.6269531 (184)\ttotal: 2.58s\tremaining: 1m 7s\n",
      "185:\tlearn: 0.6306738\ttest: 0.6269242\tbest: 0.6269242 (185)\ttotal: 2.59s\tremaining: 1m 7s\n",
      "186:\tlearn: 0.6306505\ttest: 0.6268959\tbest: 0.6268959 (186)\ttotal: 2.6s\tremaining: 1m 7s\n",
      "187:\tlearn: 0.6306276\ttest: 0.6268680\tbest: 0.6268680 (187)\ttotal: 2.62s\tremaining: 1m 6s\n",
      "188:\tlearn: 0.6305714\ttest: 0.6268159\tbest: 0.6268159 (188)\ttotal: 2.63s\tremaining: 1m 6s\n",
      "189:\tlearn: 0.6305495\ttest: 0.6267891\tbest: 0.6267891 (189)\ttotal: 2.65s\tremaining: 1m 6s\n",
      "190:\tlearn: 0.6303359\ttest: 0.6265499\tbest: 0.6265499 (190)\ttotal: 2.66s\tremaining: 1m 7s\n",
      "191:\tlearn: 0.6303149\ttest: 0.6265241\tbest: 0.6265241 (191)\ttotal: 2.67s\tremaining: 1m 6s\n",
      "192:\tlearn: 0.6302943\ttest: 0.6264987\tbest: 0.6264987 (192)\ttotal: 2.69s\tremaining: 1m 6s\n",
      "193:\tlearn: 0.6299642\ttest: 0.6261304\tbest: 0.6261304 (193)\ttotal: 2.71s\tremaining: 1m 7s\n",
      "194:\tlearn: 0.6299445\ttest: 0.6261059\tbest: 0.6261059 (194)\ttotal: 2.72s\tremaining: 1m 7s\n",
      "195:\tlearn: 0.6298721\ttest: 0.6260319\tbest: 0.6260319 (195)\ttotal: 2.73s\tremaining: 1m 7s\n",
      "196:\tlearn: 0.6298531\ttest: 0.6260083\tbest: 0.6260083 (196)\ttotal: 2.75s\tremaining: 1m 6s\n",
      "197:\tlearn: 0.6296840\ttest: 0.6258531\tbest: 0.6258531 (197)\ttotal: 2.77s\tremaining: 1m 7s\n",
      "198:\tlearn: 0.6296658\ttest: 0.6258304\tbest: 0.6258304 (198)\ttotal: 2.78s\tremaining: 1m 7s\n",
      "199:\tlearn: 0.6296480\ttest: 0.6258082\tbest: 0.6258082 (199)\ttotal: 2.79s\tremaining: 1m 7s\n",
      "200:\tlearn: 0.6296305\ttest: 0.6257863\tbest: 0.6257863 (200)\ttotal: 2.8s\tremaining: 1m 6s\n",
      "201:\tlearn: 0.6296133\ttest: 0.6257649\tbest: 0.6257649 (201)\ttotal: 2.81s\tremaining: 1m 6s\n",
      "202:\tlearn: 0.6295965\ttest: 0.6257438\tbest: 0.6257438 (202)\ttotal: 2.83s\tremaining: 1m 6s\n",
      "203:\tlearn: 0.6292019\ttest: 0.6253272\tbest: 0.6253272 (203)\ttotal: 2.85s\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204:\tlearn: 0.6291857\ttest: 0.6253068\tbest: 0.6253068 (204)\ttotal: 2.86s\tremaining: 1m 6s\n",
      "205:\tlearn: 0.6287908\ttest: 0.6248776\tbest: 0.6248776 (205)\ttotal: 2.88s\tremaining: 1m 7s\n",
      "206:\tlearn: 0.6287752\ttest: 0.6248579\tbest: 0.6248579 (206)\ttotal: 2.89s\tremaining: 1m 6s\n",
      "207:\tlearn: 0.6287269\ttest: 0.6248101\tbest: 0.6248101 (207)\ttotal: 2.9s\tremaining: 1m 6s\n",
      "208:\tlearn: 0.6286832\ttest: 0.6247631\tbest: 0.6247631 (208)\ttotal: 2.92s\tremaining: 1m 6s\n",
      "209:\tlearn: 0.6286209\ttest: 0.6246992\tbest: 0.6246992 (209)\ttotal: 2.94s\tremaining: 1m 6s\n",
      "210:\tlearn: 0.6286066\ttest: 0.6246809\tbest: 0.6246809 (210)\ttotal: 2.95s\tremaining: 1m 6s\n",
      "211:\tlearn: 0.6285925\ttest: 0.6246629\tbest: 0.6246629 (211)\ttotal: 2.96s\tremaining: 1m 6s\n",
      "212:\tlearn: 0.6285788\ttest: 0.6246453\tbest: 0.6246453 (212)\ttotal: 2.98s\tremaining: 1m 6s\n",
      "213:\tlearn: 0.6285077\ttest: 0.6245685\tbest: 0.6245685 (213)\ttotal: 3s\tremaining: 1m 7s\n",
      "214:\tlearn: 0.6284945\ttest: 0.6245514\tbest: 0.6245514 (214)\ttotal: 3.01s\tremaining: 1m 7s\n",
      "215:\tlearn: 0.6284815\ttest: 0.6245347\tbest: 0.6245347 (215)\ttotal: 3.03s\tremaining: 1m 7s\n",
      "216:\tlearn: 0.6284688\ttest: 0.6245183\tbest: 0.6245183 (216)\ttotal: 3.04s\tremaining: 1m 7s\n",
      "217:\tlearn: 0.6284564\ttest: 0.6245022\tbest: 0.6245022 (217)\ttotal: 3.06s\tremaining: 1m 7s\n",
      "218:\tlearn: 0.6284442\ttest: 0.6244864\tbest: 0.6244864 (218)\ttotal: 3.07s\tremaining: 1m 6s\n",
      "219:\tlearn: 0.6284322\ttest: 0.6244708\tbest: 0.6244708 (219)\ttotal: 3.08s\tremaining: 1m 6s\n",
      "220:\tlearn: 0.6281341\ttest: 0.6241366\tbest: 0.6241366 (220)\ttotal: 3.1s\tremaining: 1m 7s\n",
      "221:\tlearn: 0.6281226\ttest: 0.6241216\tbest: 0.6241216 (221)\ttotal: 3.11s\tremaining: 1m 7s\n",
      "222:\tlearn: 0.6281114\ttest: 0.6241068\tbest: 0.6241068 (222)\ttotal: 3.13s\tremaining: 1m 6s\n",
      "223:\tlearn: 0.6281003\ttest: 0.6240923\tbest: 0.6240923 (223)\ttotal: 3.14s\tremaining: 1m 6s\n",
      "224:\tlearn: 0.6280437\ttest: 0.6240345\tbest: 0.6240345 (224)\ttotal: 3.15s\tremaining: 1m 6s\n",
      "225:\tlearn: 0.6280331\ttest: 0.6240205\tbest: 0.6240205 (225)\ttotal: 3.17s\tremaining: 1m 6s\n",
      "226:\tlearn: 0.6278841\ttest: 0.6238472\tbest: 0.6238472 (226)\ttotal: 3.18s\tremaining: 1m 6s\n",
      "227:\tlearn: 0.6276184\ttest: 0.6235565\tbest: 0.6235565 (227)\ttotal: 3.2s\tremaining: 1m 7s\n",
      "228:\tlearn: 0.6276084\ttest: 0.6235432\tbest: 0.6235432 (228)\ttotal: 3.22s\tremaining: 1m 7s\n",
      "229:\tlearn: 0.6275986\ttest: 0.6235302\tbest: 0.6235302 (229)\ttotal: 3.23s\tremaining: 1m 6s\n",
      "230:\tlearn: 0.6275891\ttest: 0.6235174\tbest: 0.6235174 (230)\ttotal: 3.24s\tremaining: 1m 6s\n",
      "231:\tlearn: 0.6275797\ttest: 0.6235049\tbest: 0.6235049 (231)\ttotal: 3.25s\tremaining: 1m 6s\n",
      "232:\tlearn: 0.6274309\ttest: 0.6233340\tbest: 0.6233340 (232)\ttotal: 3.27s\tremaining: 1m 6s\n",
      "233:\tlearn: 0.6274219\ttest: 0.6233219\tbest: 0.6233219 (233)\ttotal: 3.28s\tremaining: 1m 6s\n",
      "234:\tlearn: 0.6274131\ttest: 0.6233100\tbest: 0.6233100 (234)\ttotal: 3.29s\tremaining: 1m 6s\n",
      "235:\tlearn: 0.6274044\ttest: 0.6232983\tbest: 0.6232983 (235)\ttotal: 3.3s\tremaining: 1m 6s\n",
      "236:\tlearn: 0.6273960\ttest: 0.6232868\tbest: 0.6232868 (236)\ttotal: 3.32s\tremaining: 1m 6s\n",
      "237:\tlearn: 0.6273877\ttest: 0.6232755\tbest: 0.6232755 (237)\ttotal: 3.33s\tremaining: 1m 6s\n",
      "238:\tlearn: 0.6273795\ttest: 0.6232644\tbest: 0.6232644 (238)\ttotal: 3.34s\tremaining: 1m 6s\n",
      "239:\tlearn: 0.6273716\ttest: 0.6232535\tbest: 0.6232535 (239)\ttotal: 3.35s\tremaining: 1m 6s\n",
      "240:\tlearn: 0.6273638\ttest: 0.6232428\tbest: 0.6232428 (240)\ttotal: 3.37s\tremaining: 1m 6s\n",
      "241:\tlearn: 0.6270133\ttest: 0.6228342\tbest: 0.6228342 (241)\ttotal: 3.39s\tremaining: 1m 6s\n",
      "242:\tlearn: 0.6269673\ttest: 0.6227891\tbest: 0.6227891 (242)\ttotal: 3.41s\tremaining: 1m 6s\n",
      "243:\tlearn: 0.6269600\ttest: 0.6227789\tbest: 0.6227789 (243)\ttotal: 3.42s\tremaining: 1m 6s\n",
      "244:\tlearn: 0.6269527\ttest: 0.6227689\tbest: 0.6227689 (244)\ttotal: 3.43s\tremaining: 1m 6s\n",
      "245:\tlearn: 0.6269457\ttest: 0.6227591\tbest: 0.6227591 (245)\ttotal: 3.44s\tremaining: 1m 6s\n",
      "246:\tlearn: 0.6269387\ttest: 0.6227494\tbest: 0.6227494 (246)\ttotal: 3.45s\tremaining: 1m 6s\n",
      "247:\tlearn: 0.6268993\ttest: 0.6227176\tbest: 0.6227176 (247)\ttotal: 3.47s\tremaining: 1m 6s\n",
      "248:\tlearn: 0.6267592\ttest: 0.6225558\tbest: 0.6225558 (248)\ttotal: 3.48s\tremaining: 1m 6s\n",
      "249:\tlearn: 0.6267527\ttest: 0.6225466\tbest: 0.6225466 (249)\ttotal: 3.49s\tremaining: 1m 6s\n",
      "250:\tlearn: 0.6267211\ttest: 0.6225168\tbest: 0.6225168 (250)\ttotal: 3.51s\tremaining: 1m 6s\n",
      "251:\tlearn: 0.6267149\ttest: 0.6225080\tbest: 0.6225080 (251)\ttotal: 3.52s\tremaining: 1m 6s\n",
      "252:\tlearn: 0.6267088\ttest: 0.6224993\tbest: 0.6224993 (252)\ttotal: 3.53s\tremaining: 1m 6s\n",
      "253:\tlearn: 0.6267028\ttest: 0.6224907\tbest: 0.6224907 (253)\ttotal: 3.54s\tremaining: 1m 6s\n",
      "254:\tlearn: 0.6266969\ttest: 0.6224823\tbest: 0.6224823 (254)\ttotal: 3.56s\tremaining: 1m 6s\n",
      "255:\tlearn: 0.6264167\ttest: 0.6221685\tbest: 0.6221685 (255)\ttotal: 3.57s\tremaining: 1m 6s\n",
      "256:\tlearn: 0.6262827\ttest: 0.6220126\tbest: 0.6220126 (256)\ttotal: 3.59s\tremaining: 1m 6s\n",
      "257:\tlearn: 0.6261594\ttest: 0.6218655\tbest: 0.6218655 (257)\ttotal: 3.6s\tremaining: 1m 6s\n",
      "258:\tlearn: 0.6261539\ttest: 0.6218576\tbest: 0.6218576 (258)\ttotal: 3.62s\tremaining: 1m 6s\n",
      "259:\tlearn: 0.6260300\ttest: 0.6217134\tbest: 0.6217134 (259)\ttotal: 3.63s\tremaining: 1m 6s\n",
      "260:\tlearn: 0.6260248\ttest: 0.6217058\tbest: 0.6217058 (260)\ttotal: 3.65s\tremaining: 1m 6s\n",
      "261:\tlearn: 0.6260197\ttest: 0.6216983\tbest: 0.6216983 (261)\ttotal: 3.66s\tremaining: 1m 6s\n",
      "262:\tlearn: 0.6260031\ttest: 0.6216759\tbest: 0.6216759 (262)\ttotal: 3.67s\tremaining: 1m 6s\n",
      "263:\tlearn: 0.6259982\ttest: 0.6216687\tbest: 0.6216687 (263)\ttotal: 3.68s\tremaining: 1m 6s\n",
      "264:\tlearn: 0.6259599\ttest: 0.6216286\tbest: 0.6216286 (264)\ttotal: 3.69s\tremaining: 1m 6s\n",
      "265:\tlearn: 0.6259551\ttest: 0.6216216\tbest: 0.6216216 (265)\ttotal: 3.7s\tremaining: 1m 5s\n",
      "266:\tlearn: 0.6259505\ttest: 0.6216147\tbest: 0.6216147 (266)\ttotal: 3.71s\tremaining: 1m 5s\n",
      "267:\tlearn: 0.6258769\ttest: 0.6215554\tbest: 0.6215554 (267)\ttotal: 3.73s\tremaining: 1m 5s\n",
      "268:\tlearn: 0.6258725\ttest: 0.6215488\tbest: 0.6215488 (268)\ttotal: 3.74s\tremaining: 1m 5s\n",
      "269:\tlearn: 0.6258682\ttest: 0.6215423\tbest: 0.6215423 (269)\ttotal: 3.75s\tremaining: 1m 5s\n",
      "270:\tlearn: 0.6257469\ttest: 0.6214151\tbest: 0.6214151 (270)\ttotal: 3.77s\tremaining: 1m 5s\n",
      "271:\tlearn: 0.6257428\ttest: 0.6214089\tbest: 0.6214089 (271)\ttotal: 3.78s\tremaining: 1m 5s\n",
      "272:\tlearn: 0.6257387\ttest: 0.6214027\tbest: 0.6214027 (272)\ttotal: 3.79s\tremaining: 1m 5s\n",
      "273:\tlearn: 0.6254567\ttest: 0.6211241\tbest: 0.6211241 (273)\ttotal: 3.81s\tremaining: 1m 5s\n",
      "274:\tlearn: 0.6254528\ttest: 0.6211181\tbest: 0.6211181 (274)\ttotal: 3.82s\tremaining: 1m 5s\n",
      "275:\tlearn: 0.6254490\ttest: 0.6211123\tbest: 0.6211123 (275)\ttotal: 3.83s\tremaining: 1m 5s\n",
      "276:\tlearn: 0.6252746\ttest: 0.6209201\tbest: 0.6209201 (276)\ttotal: 3.86s\tremaining: 1m 5s\n",
      "277:\tlearn: 0.6252709\ttest: 0.6209144\tbest: 0.6209144 (277)\ttotal: 3.87s\tremaining: 1m 5s\n",
      "278:\tlearn: 0.6249457\ttest: 0.6205483\tbest: 0.6205483 (278)\ttotal: 3.9s\tremaining: 1m 5s\n",
      "279:\tlearn: 0.6249422\ttest: 0.6205428\tbest: 0.6205428 (279)\ttotal: 3.91s\tremaining: 1m 5s\n",
      "280:\tlearn: 0.6249387\ttest: 0.6205374\tbest: 0.6205374 (280)\ttotal: 3.92s\tremaining: 1m 5s\n",
      "281:\tlearn: 0.6249353\ttest: 0.6205321\tbest: 0.6205321 (281)\ttotal: 3.93s\tremaining: 1m 5s\n",
      "282:\tlearn: 0.6249320\ttest: 0.6205269\tbest: 0.6205269 (282)\ttotal: 3.94s\tremaining: 1m 5s\n",
      "283:\tlearn: 0.6249287\ttest: 0.6205218\tbest: 0.6205218 (283)\ttotal: 3.95s\tremaining: 1m 5s\n",
      "284:\tlearn: 0.6248174\ttest: 0.6203901\tbest: 0.6203901 (284)\ttotal: 3.97s\tremaining: 1m 5s\n",
      "285:\tlearn: 0.6247421\ttest: 0.6202919\tbest: 0.6202919 (285)\ttotal: 3.99s\tremaining: 1m 5s\n",
      "286:\tlearn: 0.6244302\ttest: 0.6199647\tbest: 0.6199647 (286)\ttotal: 4.01s\tremaining: 1m 5s\n",
      "287:\tlearn: 0.6244272\ttest: 0.6199599\tbest: 0.6199599 (287)\ttotal: 4.02s\tremaining: 1m 5s\n",
      "288:\tlearn: 0.6244242\ttest: 0.6199552\tbest: 0.6199552 (288)\ttotal: 4.04s\tremaining: 1m 5s\n",
      "289:\tlearn: 0.6242971\ttest: 0.6198078\tbest: 0.6198078 (289)\ttotal: 4.05s\tremaining: 1m 5s\n",
      "290:\tlearn: 0.6242943\ttest: 0.6198033\tbest: 0.6198033 (290)\ttotal: 4.07s\tremaining: 1m 5s\n",
      "291:\tlearn: 0.6242915\ttest: 0.6197988\tbest: 0.6197988 (291)\ttotal: 4.09s\tremaining: 1m 5s\n",
      "292:\tlearn: 0.6240802\ttest: 0.6195593\tbest: 0.6195593 (292)\ttotal: 4.11s\tremaining: 1m 6s\n",
      "293:\tlearn: 0.6240364\ttest: 0.6195198\tbest: 0.6195198 (293)\ttotal: 4.13s\tremaining: 1m 6s\n",
      "294:\tlearn: 0.6239372\ttest: 0.6194109\tbest: 0.6194109 (294)\ttotal: 4.16s\tremaining: 1m 6s\n",
      "295:\tlearn: 0.6239346\ttest: 0.6194067\tbest: 0.6194067 (295)\ttotal: 4.17s\tremaining: 1m 6s\n",
      "296:\tlearn: 0.6239061\ttest: 0.6193868\tbest: 0.6193868 (296)\ttotal: 4.19s\tremaining: 1m 6s\n",
      "297:\tlearn: 0.6239036\ttest: 0.6193828\tbest: 0.6193828 (297)\ttotal: 4.2s\tremaining: 1m 6s\n",
      "298:\tlearn: 0.6239012\ttest: 0.6193788\tbest: 0.6193788 (298)\ttotal: 4.21s\tremaining: 1m 6s\n",
      "299:\tlearn: 0.6238989\ttest: 0.6193749\tbest: 0.6193749 (299)\ttotal: 4.23s\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300:\tlearn: 0.6237813\ttest: 0.6192303\tbest: 0.6192303 (300)\ttotal: 4.25s\tremaining: 1m 6s\n",
      "301:\tlearn: 0.6237790\ttest: 0.6192265\tbest: 0.6192265 (301)\ttotal: 4.26s\tremaining: 1m 6s\n",
      "302:\tlearn: 0.6237768\ttest: 0.6192228\tbest: 0.6192228 (302)\ttotal: 4.27s\tremaining: 1m 6s\n",
      "303:\tlearn: 0.6237746\ttest: 0.6192191\tbest: 0.6192191 (303)\ttotal: 4.29s\tremaining: 1m 6s\n",
      "304:\tlearn: 0.6237725\ttest: 0.6192156\tbest: 0.6192156 (304)\ttotal: 4.3s\tremaining: 1m 6s\n",
      "305:\tlearn: 0.6237704\ttest: 0.6192120\tbest: 0.6192120 (305)\ttotal: 4.31s\tremaining: 1m 6s\n",
      "306:\tlearn: 0.6237684\ttest: 0.6192085\tbest: 0.6192085 (306)\ttotal: 4.33s\tremaining: 1m 6s\n",
      "307:\tlearn: 0.6237664\ttest: 0.6192051\tbest: 0.6192051 (307)\ttotal: 4.34s\tremaining: 1m 6s\n",
      "308:\tlearn: 0.6237644\ttest: 0.6192017\tbest: 0.6192017 (308)\ttotal: 4.35s\tremaining: 1m 6s\n",
      "309:\tlearn: 0.6237339\ttest: 0.6191708\tbest: 0.6191708 (309)\ttotal: 4.37s\tremaining: 1m 6s\n",
      "310:\tlearn: 0.6237320\ttest: 0.6191675\tbest: 0.6191675 (310)\ttotal: 4.38s\tremaining: 1m 6s\n",
      "311:\tlearn: 0.6237302\ttest: 0.6191643\tbest: 0.6191643 (311)\ttotal: 4.39s\tremaining: 1m 6s\n",
      "312:\tlearn: 0.6237284\ttest: 0.6191611\tbest: 0.6191611 (312)\ttotal: 4.41s\tremaining: 1m 5s\n",
      "313:\tlearn: 0.6237266\ttest: 0.6191580\tbest: 0.6191580 (313)\ttotal: 4.42s\tremaining: 1m 5s\n",
      "314:\tlearn: 0.6237248\ttest: 0.6191549\tbest: 0.6191549 (314)\ttotal: 4.43s\tremaining: 1m 5s\n",
      "315:\tlearn: 0.6237231\ttest: 0.6191519\tbest: 0.6191519 (315)\ttotal: 4.44s\tremaining: 1m 5s\n",
      "316:\tlearn: 0.6237215\ttest: 0.6191490\tbest: 0.6191490 (316)\ttotal: 4.45s\tremaining: 1m 5s\n",
      "317:\tlearn: 0.6237198\ttest: 0.6191460\tbest: 0.6191460 (317)\ttotal: 4.46s\tremaining: 1m 5s\n",
      "318:\tlearn: 0.6235539\ttest: 0.6189817\tbest: 0.6189817 (318)\ttotal: 4.48s\tremaining: 1m 5s\n",
      "319:\tlearn: 0.6235523\ttest: 0.6189789\tbest: 0.6189789 (319)\ttotal: 4.49s\tremaining: 1m 5s\n",
      "320:\tlearn: 0.6235508\ttest: 0.6189761\tbest: 0.6189761 (320)\ttotal: 4.5s\tremaining: 1m 5s\n",
      "321:\tlearn: 0.6235281\ttest: 0.6189604\tbest: 0.6189604 (321)\ttotal: 4.51s\tremaining: 1m 5s\n",
      "322:\tlearn: 0.6234234\ttest: 0.6188415\tbest: 0.6188415 (322)\ttotal: 4.54s\tremaining: 1m 5s\n",
      "323:\tlearn: 0.6234220\ttest: 0.6188389\tbest: 0.6188389 (323)\ttotal: 4.55s\tremaining: 1m 5s\n",
      "324:\tlearn: 0.6231451\ttest: 0.6185132\tbest: 0.6185132 (324)\ttotal: 4.57s\tremaining: 1m 5s\n",
      "325:\tlearn: 0.6228520\ttest: 0.6182050\tbest: 0.6182050 (325)\ttotal: 4.6s\tremaining: 1m 5s\n",
      "326:\tlearn: 0.6227565\ttest: 0.6180927\tbest: 0.6180927 (326)\ttotal: 4.61s\tremaining: 1m 5s\n",
      "327:\tlearn: 0.6227552\ttest: 0.6180902\tbest: 0.6180902 (327)\ttotal: 4.63s\tremaining: 1m 5s\n",
      "328:\tlearn: 0.6226617\ttest: 0.6179799\tbest: 0.6179799 (328)\ttotal: 4.64s\tremaining: 1m 5s\n",
      "329:\tlearn: 0.6226604\ttest: 0.6179775\tbest: 0.6179775 (329)\ttotal: 4.66s\tremaining: 1m 5s\n",
      "330:\tlearn: 0.6226591\ttest: 0.6179751\tbest: 0.6179751 (330)\ttotal: 4.67s\tremaining: 1m 5s\n",
      "331:\tlearn: 0.6224873\ttest: 0.6177836\tbest: 0.6177836 (331)\ttotal: 4.68s\tremaining: 1m 5s\n",
      "332:\tlearn: 0.6224861\ttest: 0.6177813\tbest: 0.6177813 (332)\ttotal: 4.7s\tremaining: 1m 5s\n",
      "333:\tlearn: 0.6224527\ttest: 0.6177486\tbest: 0.6177486 (333)\ttotal: 4.71s\tremaining: 1m 5s\n",
      "334:\tlearn: 0.6224409\ttest: 0.6177384\tbest: 0.6177384 (334)\ttotal: 4.72s\tremaining: 1m 5s\n",
      "335:\tlearn: 0.6224397\ttest: 0.6177362\tbest: 0.6177362 (335)\ttotal: 4.74s\tremaining: 1m 5s\n",
      "336:\tlearn: 0.6224386\ttest: 0.6177340\tbest: 0.6177340 (336)\ttotal: 4.75s\tremaining: 1m 5s\n",
      "337:\tlearn: 0.6224375\ttest: 0.6177319\tbest: 0.6177319 (337)\ttotal: 4.76s\tremaining: 1m 5s\n",
      "338:\tlearn: 0.6224364\ttest: 0.6177298\tbest: 0.6177298 (338)\ttotal: 4.77s\tremaining: 1m 5s\n",
      "339:\tlearn: 0.6220611\ttest: 0.6173867\tbest: 0.6173867 (339)\ttotal: 4.79s\tremaining: 1m 5s\n",
      "340:\tlearn: 0.6219736\ttest: 0.6172832\tbest: 0.6172832 (340)\ttotal: 4.81s\tremaining: 1m 5s\n",
      "341:\tlearn: 0.6219726\ttest: 0.6172812\tbest: 0.6172812 (341)\ttotal: 4.82s\tremaining: 1m 5s\n",
      "342:\tlearn: 0.6219716\ttest: 0.6172792\tbest: 0.6172792 (342)\ttotal: 4.83s\tremaining: 1m 5s\n",
      "343:\tlearn: 0.6219706\ttest: 0.6172772\tbest: 0.6172772 (343)\ttotal: 4.84s\tremaining: 1m 5s\n",
      "344:\tlearn: 0.6217186\ttest: 0.6170003\tbest: 0.6170003 (344)\ttotal: 4.86s\tremaining: 1m 5s\n",
      "345:\tlearn: 0.6216403\ttest: 0.6169141\tbest: 0.6169141 (345)\ttotal: 4.88s\tremaining: 1m 5s\n",
      "346:\tlearn: 0.6216394\ttest: 0.6169122\tbest: 0.6169122 (346)\ttotal: 4.89s\tremaining: 1m 5s\n",
      "347:\tlearn: 0.6216385\ttest: 0.6169104\tbest: 0.6169104 (347)\ttotal: 4.9s\tremaining: 1m 5s\n",
      "348:\tlearn: 0.6216376\ttest: 0.6169086\tbest: 0.6169086 (348)\ttotal: 4.91s\tremaining: 1m 5s\n",
      "349:\tlearn: 0.6216367\ttest: 0.6169068\tbest: 0.6169068 (349)\ttotal: 4.92s\tremaining: 1m 5s\n",
      "350:\tlearn: 0.6215543\ttest: 0.6168094\tbest: 0.6168094 (350)\ttotal: 4.94s\tremaining: 1m 5s\n",
      "351:\tlearn: 0.6215379\ttest: 0.6167952\tbest: 0.6167952 (351)\ttotal: 4.95s\tremaining: 1m 5s\n",
      "352:\tlearn: 0.6214569\ttest: 0.6166983\tbest: 0.6166983 (352)\ttotal: 4.97s\tremaining: 1m 5s\n",
      "353:\tlearn: 0.6214560\ttest: 0.6166966\tbest: 0.6166966 (353)\ttotal: 4.98s\tremaining: 1m 5s\n",
      "354:\tlearn: 0.6212062\ttest: 0.6164219\tbest: 0.6164219 (354)\ttotal: 5s\tremaining: 1m 5s\n",
      "355:\tlearn: 0.6212054\ttest: 0.6164203\tbest: 0.6164203 (355)\ttotal: 5.01s\tremaining: 1m 5s\n",
      "356:\tlearn: 0.6209724\ttest: 0.6161318\tbest: 0.6161318 (356)\ttotal: 5.04s\tremaining: 1m 5s\n",
      "357:\tlearn: 0.6209717\ttest: 0.6161302\tbest: 0.6161302 (357)\ttotal: 5.05s\tremaining: 1m 5s\n",
      "358:\tlearn: 0.6208164\ttest: 0.6159517\tbest: 0.6159517 (358)\ttotal: 5.07s\tremaining: 1m 5s\n",
      "359:\tlearn: 0.6207974\ttest: 0.6159386\tbest: 0.6159386 (359)\ttotal: 5.08s\tremaining: 1m 5s\n",
      "360:\tlearn: 0.6207967\ttest: 0.6159370\tbest: 0.6159370 (360)\ttotal: 5.09s\tremaining: 1m 5s\n",
      "361:\tlearn: 0.6205582\ttest: 0.6156730\tbest: 0.6156730 (361)\ttotal: 5.12s\tremaining: 1m 5s\n",
      "362:\tlearn: 0.6205575\ttest: 0.6156715\tbest: 0.6156715 (362)\ttotal: 5.13s\tremaining: 1m 5s\n",
      "363:\tlearn: 0.6204901\ttest: 0.6155875\tbest: 0.6155875 (363)\ttotal: 5.14s\tremaining: 1m 5s\n",
      "364:\tlearn: 0.6204894\ttest: 0.6155861\tbest: 0.6155861 (364)\ttotal: 5.15s\tremaining: 1m 5s\n",
      "365:\tlearn: 0.6204888\ttest: 0.6155847\tbest: 0.6155847 (365)\ttotal: 5.16s\tremaining: 1m 5s\n",
      "366:\tlearn: 0.6204881\ttest: 0.6155833\tbest: 0.6155833 (366)\ttotal: 5.17s\tremaining: 1m 5s\n",
      "367:\tlearn: 0.6202245\ttest: 0.6153046\tbest: 0.6153046 (367)\ttotal: 5.2s\tremaining: 1m 5s\n",
      "368:\tlearn: 0.6202239\ttest: 0.6153032\tbest: 0.6153032 (368)\ttotal: 5.22s\tremaining: 1m 5s\n",
      "369:\tlearn: 0.6202233\ttest: 0.6153018\tbest: 0.6153018 (369)\ttotal: 5.23s\tremaining: 1m 5s\n",
      "370:\tlearn: 0.6202026\ttest: 0.6152809\tbest: 0.6152809 (370)\ttotal: 5.25s\tremaining: 1m 5s\n",
      "371:\tlearn: 0.6202020\ttest: 0.6152796\tbest: 0.6152796 (371)\ttotal: 5.26s\tremaining: 1m 5s\n",
      "372:\tlearn: 0.6201817\ttest: 0.6152591\tbest: 0.6152591 (372)\ttotal: 5.28s\tremaining: 1m 5s\n",
      "373:\tlearn: 0.6199189\ttest: 0.6149938\tbest: 0.6149938 (373)\ttotal: 5.3s\tremaining: 1m 5s\n",
      "374:\tlearn: 0.6198999\ttest: 0.6149776\tbest: 0.6149776 (374)\ttotal: 5.32s\tremaining: 1m 5s\n",
      "375:\tlearn: 0.6198993\ttest: 0.6149763\tbest: 0.6149763 (375)\ttotal: 5.33s\tremaining: 1m 5s\n",
      "376:\tlearn: 0.6198988\ttest: 0.6149750\tbest: 0.6149750 (376)\ttotal: 5.34s\tremaining: 1m 5s\n",
      "377:\tlearn: 0.6198982\ttest: 0.6149738\tbest: 0.6149738 (377)\ttotal: 5.35s\tremaining: 1m 5s\n",
      "378:\tlearn: 0.6198977\ttest: 0.6149726\tbest: 0.6149726 (378)\ttotal: 5.37s\tremaining: 1m 5s\n",
      "379:\tlearn: 0.6198972\ttest: 0.6149714\tbest: 0.6149714 (379)\ttotal: 5.38s\tremaining: 1m 5s\n",
      "380:\tlearn: 0.6198027\ttest: 0.6148732\tbest: 0.6148732 (380)\ttotal: 5.39s\tremaining: 1m 5s\n",
      "381:\tlearn: 0.6198022\ttest: 0.6148721\tbest: 0.6148721 (381)\ttotal: 5.41s\tremaining: 1m 5s\n",
      "382:\tlearn: 0.6198018\ttest: 0.6148709\tbest: 0.6148709 (382)\ttotal: 5.42s\tremaining: 1m 5s\n",
      "383:\tlearn: 0.6198013\ttest: 0.6148698\tbest: 0.6148698 (383)\ttotal: 5.43s\tremaining: 1m 5s\n",
      "384:\tlearn: 0.6197902\ttest: 0.6148549\tbest: 0.6148549 (384)\ttotal: 5.44s\tremaining: 1m 5s\n",
      "385:\tlearn: 0.6197898\ttest: 0.6148538\tbest: 0.6148538 (385)\ttotal: 5.45s\tremaining: 1m 5s\n",
      "386:\tlearn: 0.6197893\ttest: 0.6148528\tbest: 0.6148528 (386)\ttotal: 5.46s\tremaining: 1m 5s\n",
      "387:\tlearn: 0.6197620\ttest: 0.6148265\tbest: 0.6148265 (387)\ttotal: 5.48s\tremaining: 1m 5s\n",
      "388:\tlearn: 0.6197616\ttest: 0.6148254\tbest: 0.6148254 (388)\ttotal: 5.49s\tremaining: 1m 5s\n",
      "389:\tlearn: 0.6197612\ttest: 0.6148244\tbest: 0.6148244 (389)\ttotal: 5.5s\tremaining: 1m 4s\n",
      "390:\tlearn: 0.6197608\ttest: 0.6148234\tbest: 0.6148234 (390)\ttotal: 5.51s\tremaining: 1m 4s\n",
      "391:\tlearn: 0.6197415\ttest: 0.6148039\tbest: 0.6148039 (391)\ttotal: 5.53s\tremaining: 1m 4s\n",
      "392:\tlearn: 0.6197148\ttest: 0.6147782\tbest: 0.6147782 (392)\ttotal: 5.54s\tremaining: 1m 4s\n",
      "393:\tlearn: 0.6197144\ttest: 0.6147772\tbest: 0.6147772 (393)\ttotal: 5.55s\tremaining: 1m 4s\n",
      "394:\tlearn: 0.6197140\ttest: 0.6147762\tbest: 0.6147762 (394)\ttotal: 5.56s\tremaining: 1m 4s\n",
      "395:\tlearn: 0.6197137\ttest: 0.6147753\tbest: 0.6147753 (395)\ttotal: 5.57s\tremaining: 1m 4s\n",
      "396:\tlearn: 0.6197133\ttest: 0.6147744\tbest: 0.6147744 (396)\ttotal: 5.58s\tremaining: 1m 4s\n",
      "397:\tlearn: 0.6197129\ttest: 0.6147734\tbest: 0.6147734 (397)\ttotal: 5.59s\tremaining: 1m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398:\tlearn: 0.6197126\ttest: 0.6147725\tbest: 0.6147725 (398)\ttotal: 5.6s\tremaining: 1m 4s\n",
      "399:\tlearn: 0.6196505\ttest: 0.6147059\tbest: 0.6147059 (399)\ttotal: 5.62s\tremaining: 1m 4s\n",
      "400:\tlearn: 0.6196501\ttest: 0.6147050\tbest: 0.6147050 (400)\ttotal: 5.64s\tremaining: 1m 4s\n",
      "401:\tlearn: 0.6195885\ttest: 0.6146278\tbest: 0.6146278 (401)\ttotal: 5.65s\tremaining: 1m 4s\n",
      "402:\tlearn: 0.6195882\ttest: 0.6146269\tbest: 0.6146269 (402)\ttotal: 5.66s\tremaining: 1m 4s\n",
      "403:\tlearn: 0.6195226\ttest: 0.6145483\tbest: 0.6145483 (403)\ttotal: 5.68s\tremaining: 1m 4s\n",
      "404:\tlearn: 0.6194170\ttest: 0.6144386\tbest: 0.6144386 (404)\ttotal: 5.7s\tremaining: 1m 4s\n",
      "405:\tlearn: 0.6194167\ttest: 0.6144378\tbest: 0.6144378 (405)\ttotal: 5.71s\tremaining: 1m 4s\n",
      "406:\tlearn: 0.6194164\ttest: 0.6144369\tbest: 0.6144369 (406)\ttotal: 5.72s\tremaining: 1m 4s\n",
      "407:\tlearn: 0.6194028\ttest: 0.6144254\tbest: 0.6144254 (407)\ttotal: 5.74s\tremaining: 1m 4s\n",
      "408:\tlearn: 0.6194026\ttest: 0.6144246\tbest: 0.6144246 (408)\ttotal: 5.75s\tremaining: 1m 4s\n",
      "409:\tlearn: 0.6194023\ttest: 0.6144239\tbest: 0.6144239 (409)\ttotal: 5.76s\tremaining: 1m 4s\n",
      "410:\tlearn: 0.6194020\ttest: 0.6144231\tbest: 0.6144231 (410)\ttotal: 5.77s\tremaining: 1m 4s\n",
      "411:\tlearn: 0.6193797\ttest: 0.6144030\tbest: 0.6144030 (411)\ttotal: 5.78s\tremaining: 1m 4s\n",
      "412:\tlearn: 0.6193738\ttest: 0.6143969\tbest: 0.6143969 (412)\ttotal: 5.79s\tremaining: 1m 4s\n",
      "413:\tlearn: 0.6193735\ttest: 0.6143961\tbest: 0.6143961 (413)\ttotal: 5.81s\tremaining: 1m 4s\n",
      "414:\tlearn: 0.6192559\ttest: 0.6142591\tbest: 0.6142591 (414)\ttotal: 5.83s\tremaining: 1m 4s\n",
      "415:\tlearn: 0.6191766\ttest: 0.6141671\tbest: 0.6141671 (415)\ttotal: 5.84s\tremaining: 1m 4s\n",
      "416:\tlearn: 0.6191708\ttest: 0.6141617\tbest: 0.6141617 (416)\ttotal: 5.86s\tremaining: 1m 4s\n",
      "417:\tlearn: 0.6191706\ttest: 0.6141610\tbest: 0.6141610 (417)\ttotal: 5.87s\tremaining: 1m 4s\n",
      "418:\tlearn: 0.6191703\ttest: 0.6141603\tbest: 0.6141603 (418)\ttotal: 5.88s\tremaining: 1m 4s\n",
      "419:\tlearn: 0.6191701\ttest: 0.6141596\tbest: 0.6141596 (419)\ttotal: 5.89s\tremaining: 1m 4s\n",
      "420:\tlearn: 0.6191144\ttest: 0.6140975\tbest: 0.6140975 (420)\ttotal: 5.9s\tremaining: 1m 4s\n",
      "421:\tlearn: 0.6189323\ttest: 0.6138915\tbest: 0.6138915 (421)\ttotal: 5.92s\tremaining: 1m 4s\n",
      "422:\tlearn: 0.6189321\ttest: 0.6138909\tbest: 0.6138909 (422)\ttotal: 5.93s\tremaining: 1m 4s\n",
      "423:\tlearn: 0.6189319\ttest: 0.6138902\tbest: 0.6138902 (423)\ttotal: 5.95s\tremaining: 1m 4s\n",
      "424:\tlearn: 0.6189317\ttest: 0.6138896\tbest: 0.6138896 (424)\ttotal: 5.96s\tremaining: 1m 4s\n",
      "425:\tlearn: 0.6189315\ttest: 0.6138890\tbest: 0.6138890 (425)\ttotal: 5.97s\tremaining: 1m 4s\n",
      "426:\tlearn: 0.6189313\ttest: 0.6138883\tbest: 0.6138883 (426)\ttotal: 5.98s\tremaining: 1m 4s\n",
      "427:\tlearn: 0.6188730\ttest: 0.6138171\tbest: 0.6138171 (427)\ttotal: 6s\tremaining: 1m 4s\n",
      "428:\tlearn: 0.6188728\ttest: 0.6138165\tbest: 0.6138165 (428)\ttotal: 6.01s\tremaining: 1m 4s\n",
      "429:\tlearn: 0.6188726\ttest: 0.6138159\tbest: 0.6138159 (429)\ttotal: 6.03s\tremaining: 1m 4s\n",
      "430:\tlearn: 0.6187717\ttest: 0.6136862\tbest: 0.6136862 (430)\ttotal: 6.04s\tremaining: 1m 4s\n",
      "431:\tlearn: 0.6187715\ttest: 0.6136856\tbest: 0.6136856 (431)\ttotal: 6.06s\tremaining: 1m 4s\n",
      "432:\tlearn: 0.6186576\ttest: 0.6135669\tbest: 0.6135669 (432)\ttotal: 6.08s\tremaining: 1m 4s\n",
      "433:\tlearn: 0.6186574\ttest: 0.6135663\tbest: 0.6135663 (433)\ttotal: 6.09s\tremaining: 1m 4s\n",
      "434:\tlearn: 0.6186022\ttest: 0.6134993\tbest: 0.6134993 (434)\ttotal: 6.11s\tremaining: 1m 4s\n",
      "435:\tlearn: 0.6186020\ttest: 0.6134987\tbest: 0.6134987 (435)\ttotal: 6.12s\tremaining: 1m 4s\n",
      "436:\tlearn: 0.6186019\ttest: 0.6134982\tbest: 0.6134982 (436)\ttotal: 6.13s\tremaining: 1m 4s\n",
      "437:\tlearn: 0.6186017\ttest: 0.6134977\tbest: 0.6134977 (437)\ttotal: 6.14s\tremaining: 1m 3s\n",
      "438:\tlearn: 0.6186016\ttest: 0.6134971\tbest: 0.6134971 (438)\ttotal: 6.16s\tremaining: 1m 3s\n",
      "439:\tlearn: 0.6183991\ttest: 0.6132671\tbest: 0.6132671 (439)\ttotal: 6.17s\tremaining: 1m 4s\n",
      "440:\tlearn: 0.6183990\ttest: 0.6132666\tbest: 0.6132666 (440)\ttotal: 6.19s\tremaining: 1m 3s\n",
      "441:\tlearn: 0.6183988\ttest: 0.6132661\tbest: 0.6132661 (441)\ttotal: 6.2s\tremaining: 1m 3s\n",
      "442:\tlearn: 0.6183987\ttest: 0.6132656\tbest: 0.6132656 (442)\ttotal: 6.21s\tremaining: 1m 3s\n",
      "443:\tlearn: 0.6183985\ttest: 0.6132651\tbest: 0.6132651 (443)\ttotal: 6.23s\tremaining: 1m 3s\n",
      "444:\tlearn: 0.6183984\ttest: 0.6132646\tbest: 0.6132646 (444)\ttotal: 6.24s\tremaining: 1m 3s\n",
      "445:\tlearn: 0.6183982\ttest: 0.6132641\tbest: 0.6132641 (445)\ttotal: 6.25s\tremaining: 1m 3s\n",
      "446:\tlearn: 0.6183981\ttest: 0.6132636\tbest: 0.6132636 (446)\ttotal: 6.26s\tremaining: 1m 3s\n",
      "447:\tlearn: 0.6183123\ttest: 0.6131656\tbest: 0.6131656 (447)\ttotal: 6.28s\tremaining: 1m 3s\n",
      "448:\tlearn: 0.6183122\ttest: 0.6131652\tbest: 0.6131652 (448)\ttotal: 6.3s\tremaining: 1m 3s\n",
      "449:\tlearn: 0.6183121\ttest: 0.6131647\tbest: 0.6131647 (449)\ttotal: 6.31s\tremaining: 1m 3s\n",
      "450:\tlearn: 0.6182707\ttest: 0.6131081\tbest: 0.6131081 (450)\ttotal: 6.32s\tremaining: 1m 3s\n",
      "451:\tlearn: 0.6182706\ttest: 0.6131076\tbest: 0.6131076 (451)\ttotal: 6.33s\tremaining: 1m 3s\n",
      "452:\tlearn: 0.6182705\ttest: 0.6131072\tbest: 0.6131072 (452)\ttotal: 6.35s\tremaining: 1m 3s\n",
      "453:\tlearn: 0.6182704\ttest: 0.6131068\tbest: 0.6131068 (453)\ttotal: 6.37s\tremaining: 1m 3s\n",
      "454:\tlearn: 0.6182702\ttest: 0.6131063\tbest: 0.6131063 (454)\ttotal: 6.38s\tremaining: 1m 3s\n",
      "455:\tlearn: 0.6182538\ttest: 0.6130928\tbest: 0.6130928 (455)\ttotal: 6.39s\tremaining: 1m 3s\n",
      "456:\tlearn: 0.6182537\ttest: 0.6130924\tbest: 0.6130924 (456)\ttotal: 6.41s\tremaining: 1m 3s\n",
      "457:\tlearn: 0.6182536\ttest: 0.6130919\tbest: 0.6130919 (457)\ttotal: 6.42s\tremaining: 1m 3s\n",
      "458:\tlearn: 0.6182535\ttest: 0.6130915\tbest: 0.6130915 (458)\ttotal: 6.44s\tremaining: 1m 3s\n",
      "459:\tlearn: 0.6180989\ttest: 0.6129088\tbest: 0.6129088 (459)\ttotal: 6.46s\tremaining: 1m 3s\n",
      "460:\tlearn: 0.6180813\ttest: 0.6128930\tbest: 0.6128930 (460)\ttotal: 6.48s\tremaining: 1m 3s\n",
      "461:\tlearn: 0.6180312\ttest: 0.6128317\tbest: 0.6128317 (461)\ttotal: 6.5s\tremaining: 1m 3s\n",
      "462:\tlearn: 0.6180311\ttest: 0.6128313\tbest: 0.6128313 (462)\ttotal: 6.51s\tremaining: 1m 3s\n",
      "463:\tlearn: 0.6180231\ttest: 0.6128247\tbest: 0.6128247 (463)\ttotal: 6.52s\tremaining: 1m 3s\n",
      "464:\tlearn: 0.6180230\ttest: 0.6128243\tbest: 0.6128243 (464)\ttotal: 6.54s\tremaining: 1m 3s\n",
      "465:\tlearn: 0.6180229\ttest: 0.6128239\tbest: 0.6128239 (465)\ttotal: 6.54s\tremaining: 1m 3s\n",
      "466:\tlearn: 0.6180229\ttest: 0.6128235\tbest: 0.6128235 (466)\ttotal: 6.56s\tremaining: 1m 3s\n",
      "467:\tlearn: 0.6180228\ttest: 0.6128232\tbest: 0.6128232 (467)\ttotal: 6.57s\tremaining: 1m 3s\n",
      "468:\tlearn: 0.6180227\ttest: 0.6128228\tbest: 0.6128228 (468)\ttotal: 6.58s\tremaining: 1m 3s\n",
      "469:\tlearn: 0.6180226\ttest: 0.6128225\tbest: 0.6128225 (469)\ttotal: 6.59s\tremaining: 1m 3s\n",
      "470:\tlearn: 0.6180070\ttest: 0.6128097\tbest: 0.6128097 (470)\ttotal: 6.61s\tremaining: 1m 3s\n",
      "471:\tlearn: 0.6180069\ttest: 0.6128093\tbest: 0.6128093 (471)\ttotal: 6.62s\tremaining: 1m 3s\n",
      "472:\tlearn: 0.6180068\ttest: 0.6128090\tbest: 0.6128090 (472)\ttotal: 6.63s\tremaining: 1m 3s\n",
      "473:\tlearn: 0.6180067\ttest: 0.6128086\tbest: 0.6128086 (473)\ttotal: 6.64s\tremaining: 1m 3s\n",
      "474:\tlearn: 0.6180066\ttest: 0.6128083\tbest: 0.6128083 (474)\ttotal: 6.65s\tremaining: 1m 3s\n",
      "475:\tlearn: 0.6179689\ttest: 0.6127550\tbest: 0.6127550 (475)\ttotal: 6.67s\tremaining: 1m 3s\n",
      "476:\tlearn: 0.6179526\ttest: 0.6127388\tbest: 0.6127388 (476)\ttotal: 6.69s\tremaining: 1m 3s\n",
      "477:\tlearn: 0.6179303\ttest: 0.6127178\tbest: 0.6127178 (477)\ttotal: 6.7s\tremaining: 1m 3s\n",
      "478:\tlearn: 0.6179302\ttest: 0.6127175\tbest: 0.6127175 (478)\ttotal: 6.71s\tremaining: 1m 3s\n",
      "479:\tlearn: 0.6179301\ttest: 0.6127172\tbest: 0.6127172 (479)\ttotal: 6.72s\tremaining: 1m 3s\n",
      "480:\tlearn: 0.6179301\ttest: 0.6127168\tbest: 0.6127168 (480)\ttotal: 6.73s\tremaining: 1m 3s\n",
      "481:\tlearn: 0.6179300\ttest: 0.6127165\tbest: 0.6127165 (481)\ttotal: 6.74s\tremaining: 1m 3s\n",
      "482:\tlearn: 0.6179299\ttest: 0.6127162\tbest: 0.6127162 (482)\ttotal: 6.76s\tremaining: 1m 3s\n",
      "483:\tlearn: 0.6179299\ttest: 0.6127159\tbest: 0.6127159 (483)\ttotal: 6.77s\tremaining: 1m 3s\n",
      "484:\tlearn: 0.6178369\ttest: 0.6126363\tbest: 0.6126363 (484)\ttotal: 6.79s\tremaining: 1m 3s\n",
      "485:\tlearn: 0.6178368\ttest: 0.6126360\tbest: 0.6126360 (485)\ttotal: 6.8s\tremaining: 1m 3s\n",
      "486:\tlearn: 0.6178088\ttest: 0.6126061\tbest: 0.6126061 (486)\ttotal: 6.82s\tremaining: 1m 3s\n",
      "487:\tlearn: 0.6178088\ttest: 0.6126058\tbest: 0.6126058 (487)\ttotal: 6.83s\tremaining: 1m 3s\n",
      "488:\tlearn: 0.6177978\ttest: 0.6125993\tbest: 0.6125993 (488)\ttotal: 6.85s\tremaining: 1m 3s\n",
      "489:\tlearn: 0.6177977\ttest: 0.6125990\tbest: 0.6125990 (489)\ttotal: 6.86s\tremaining: 1m 3s\n",
      "490:\tlearn: 0.6177977\ttest: 0.6125987\tbest: 0.6125987 (490)\ttotal: 6.87s\tremaining: 1m 3s\n",
      "491:\tlearn: 0.6177976\ttest: 0.6125985\tbest: 0.6125985 (491)\ttotal: 6.88s\tremaining: 1m 3s\n",
      "492:\tlearn: 0.6177976\ttest: 0.6125982\tbest: 0.6125982 (492)\ttotal: 6.89s\tremaining: 1m 3s\n",
      "493:\tlearn: 0.6177975\ttest: 0.6125980\tbest: 0.6125980 (493)\ttotal: 6.9s\tremaining: 1m 2s\n",
      "494:\tlearn: 0.6177975\ttest: 0.6125977\tbest: 0.6125977 (494)\ttotal: 6.92s\tremaining: 1m 2s\n",
      "495:\tlearn: 0.6177974\ttest: 0.6125974\tbest: 0.6125974 (495)\ttotal: 6.93s\tremaining: 1m 2s\n",
      "496:\tlearn: 0.6177974\ttest: 0.6125972\tbest: 0.6125972 (496)\ttotal: 6.94s\tremaining: 1m 2s\n",
      "497:\tlearn: 0.6177973\ttest: 0.6125970\tbest: 0.6125970 (497)\ttotal: 6.95s\tremaining: 1m 2s\n",
      "498:\tlearn: 0.6177818\ttest: 0.6125816\tbest: 0.6125816 (498)\ttotal: 6.97s\tremaining: 1m 2s\n",
      "499:\tlearn: 0.6177818\ttest: 0.6125814\tbest: 0.6125814 (499)\ttotal: 6.98s\tremaining: 1m 2s\n",
      "500:\tlearn: 0.6177817\ttest: 0.6125811\tbest: 0.6125811 (500)\ttotal: 7s\tremaining: 1m 2s\n",
      "501:\tlearn: 0.6177817\ttest: 0.6125809\tbest: 0.6125809 (501)\ttotal: 7.01s\tremaining: 1m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502:\tlearn: 0.6177816\ttest: 0.6125807\tbest: 0.6125807 (502)\ttotal: 7.02s\tremaining: 1m 2s\n",
      "503:\tlearn: 0.6177751\ttest: 0.6125763\tbest: 0.6125763 (503)\ttotal: 7.03s\tremaining: 1m 2s\n",
      "504:\tlearn: 0.6177751\ttest: 0.6125760\tbest: 0.6125760 (504)\ttotal: 7.04s\tremaining: 1m 2s\n",
      "505:\tlearn: 0.6177749\ttest: 0.6125756\tbest: 0.6125756 (505)\ttotal: 7.06s\tremaining: 1m 2s\n",
      "506:\tlearn: 0.6177749\ttest: 0.6125754\tbest: 0.6125754 (506)\ttotal: 7.07s\tremaining: 1m 2s\n",
      "507:\tlearn: 0.6177749\ttest: 0.6125752\tbest: 0.6125752 (507)\ttotal: 7.08s\tremaining: 1m 2s\n",
      "508:\tlearn: 0.6177748\ttest: 0.6125750\tbest: 0.6125750 (508)\ttotal: 7.1s\tremaining: 1m 2s\n",
      "509:\tlearn: 0.6177748\ttest: 0.6125748\tbest: 0.6125748 (509)\ttotal: 7.11s\tremaining: 1m 2s\n",
      "510:\tlearn: 0.6177748\ttest: 0.6125745\tbest: 0.6125745 (510)\ttotal: 7.12s\tremaining: 1m 2s\n",
      "511:\tlearn: 0.6177675\ttest: 0.6125693\tbest: 0.6125693 (511)\ttotal: 7.14s\tremaining: 1m 2s\n",
      "512:\tlearn: 0.6177582\ttest: 0.6125621\tbest: 0.6125621 (512)\ttotal: 7.15s\tremaining: 1m 2s\n",
      "513:\tlearn: 0.6177582\ttest: 0.6125619\tbest: 0.6125619 (513)\ttotal: 7.16s\tremaining: 1m 2s\n",
      "514:\tlearn: 0.6177581\ttest: 0.6125617\tbest: 0.6125617 (514)\ttotal: 7.17s\tremaining: 1m 2s\n",
      "515:\tlearn: 0.6177000\ttest: 0.6124880\tbest: 0.6124880 (515)\ttotal: 7.2s\tremaining: 1m 2s\n",
      "516:\tlearn: 0.6176999\ttest: 0.6124878\tbest: 0.6124878 (516)\ttotal: 7.21s\tremaining: 1m 2s\n",
      "517:\tlearn: 0.6176857\ttest: 0.6124765\tbest: 0.6124765 (517)\ttotal: 7.22s\tremaining: 1m 2s\n",
      "518:\tlearn: 0.6176122\ttest: 0.6124003\tbest: 0.6124003 (518)\ttotal: 7.24s\tremaining: 1m 2s\n",
      "519:\tlearn: 0.6176122\ttest: 0.6124001\tbest: 0.6124001 (519)\ttotal: 7.25s\tremaining: 1m 2s\n",
      "520:\tlearn: 0.6176122\ttest: 0.6123999\tbest: 0.6123999 (520)\ttotal: 7.26s\tremaining: 1m 2s\n",
      "521:\tlearn: 0.6175911\ttest: 0.6123770\tbest: 0.6123770 (521)\ttotal: 7.29s\tremaining: 1m 2s\n",
      "522:\tlearn: 0.6175911\ttest: 0.6123769\tbest: 0.6123769 (522)\ttotal: 7.3s\tremaining: 1m 2s\n",
      "523:\tlearn: 0.6175911\ttest: 0.6123767\tbest: 0.6123767 (523)\ttotal: 7.31s\tremaining: 1m 2s\n",
      "524:\tlearn: 0.6175910\ttest: 0.6123765\tbest: 0.6123765 (524)\ttotal: 7.32s\tremaining: 1m 2s\n",
      "525:\tlearn: 0.6175910\ttest: 0.6123763\tbest: 0.6123763 (525)\ttotal: 7.33s\tremaining: 1m 2s\n",
      "526:\tlearn: 0.6175236\ttest: 0.6122929\tbest: 0.6122929 (526)\ttotal: 7.35s\tremaining: 1m 2s\n",
      "527:\tlearn: 0.6175235\ttest: 0.6122927\tbest: 0.6122927 (527)\ttotal: 7.36s\tremaining: 1m 2s\n",
      "528:\tlearn: 0.6175235\ttest: 0.6122925\tbest: 0.6122925 (528)\ttotal: 7.37s\tremaining: 1m 2s\n",
      "529:\tlearn: 0.6175235\ttest: 0.6122924\tbest: 0.6122924 (529)\ttotal: 7.38s\tremaining: 1m 2s\n",
      "530:\tlearn: 0.6174654\ttest: 0.6122435\tbest: 0.6122435 (530)\ttotal: 7.4s\tremaining: 1m 2s\n",
      "531:\tlearn: 0.6174654\ttest: 0.6122434\tbest: 0.6122434 (531)\ttotal: 7.41s\tremaining: 1m 2s\n",
      "532:\tlearn: 0.6174654\ttest: 0.6122432\tbest: 0.6122432 (532)\ttotal: 7.42s\tremaining: 1m 2s\n",
      "533:\tlearn: 0.6174606\ttest: 0.6122386\tbest: 0.6122386 (533)\ttotal: 7.43s\tremaining: 1m 2s\n",
      "534:\tlearn: 0.6174606\ttest: 0.6122384\tbest: 0.6122384 (534)\ttotal: 7.44s\tremaining: 1m 2s\n",
      "535:\tlearn: 0.6173137\ttest: 0.6120963\tbest: 0.6120963 (535)\ttotal: 7.46s\tremaining: 1m 2s\n",
      "536:\tlearn: 0.6173136\ttest: 0.6120961\tbest: 0.6120961 (536)\ttotal: 7.47s\tremaining: 1m 2s\n",
      "537:\tlearn: 0.6173136\ttest: 0.6120960\tbest: 0.6120960 (537)\ttotal: 7.49s\tremaining: 1m 2s\n",
      "538:\tlearn: 0.6173136\ttest: 0.6120958\tbest: 0.6120958 (538)\ttotal: 7.5s\tremaining: 1m 2s\n",
      "539:\tlearn: 0.6173136\ttest: 0.6120957\tbest: 0.6120957 (539)\ttotal: 7.52s\tremaining: 1m 2s\n",
      "540:\tlearn: 0.6173136\ttest: 0.6120955\tbest: 0.6120955 (540)\ttotal: 7.53s\tremaining: 1m 2s\n",
      "541:\tlearn: 0.6173136\ttest: 0.6120954\tbest: 0.6120954 (541)\ttotal: 7.54s\tremaining: 1m 2s\n",
      "542:\tlearn: 0.6173135\ttest: 0.6120953\tbest: 0.6120953 (542)\ttotal: 7.55s\tremaining: 1m 2s\n",
      "543:\tlearn: 0.6173135\ttest: 0.6120951\tbest: 0.6120951 (543)\ttotal: 7.57s\tremaining: 1m 1s\n",
      "544:\tlearn: 0.6173071\ttest: 0.6120906\tbest: 0.6120906 (544)\ttotal: 7.58s\tremaining: 1m 2s\n",
      "545:\tlearn: 0.6173071\ttest: 0.6120905\tbest: 0.6120905 (545)\ttotal: 7.6s\tremaining: 1m 1s\n",
      "546:\tlearn: 0.6173071\ttest: 0.6120903\tbest: 0.6120903 (546)\ttotal: 7.61s\tremaining: 1m 1s\n",
      "547:\tlearn: 0.6173071\ttest: 0.6120902\tbest: 0.6120902 (547)\ttotal: 7.62s\tremaining: 1m 1s\n",
      "548:\tlearn: 0.6173070\ttest: 0.6120901\tbest: 0.6120901 (548)\ttotal: 7.63s\tremaining: 1m 1s\n",
      "549:\tlearn: 0.6173070\ttest: 0.6120899\tbest: 0.6120899 (549)\ttotal: 7.64s\tremaining: 1m 1s\n",
      "550:\tlearn: 0.6173070\ttest: 0.6120898\tbest: 0.6120898 (550)\ttotal: 7.66s\tremaining: 1m 1s\n",
      "551:\tlearn: 0.6173070\ttest: 0.6120897\tbest: 0.6120897 (551)\ttotal: 7.67s\tremaining: 1m 1s\n",
      "552:\tlearn: 0.6173070\ttest: 0.6120896\tbest: 0.6120896 (552)\ttotal: 7.68s\tremaining: 1m 1s\n",
      "553:\tlearn: 0.6173070\ttest: 0.6120894\tbest: 0.6120894 (553)\ttotal: 7.7s\tremaining: 1m 1s\n",
      "554:\tlearn: 0.6173070\ttest: 0.6120893\tbest: 0.6120893 (554)\ttotal: 7.71s\tremaining: 1m 1s\n",
      "555:\tlearn: 0.6173069\ttest: 0.6120892\tbest: 0.6120892 (555)\ttotal: 7.72s\tremaining: 1m 1s\n",
      "556:\tlearn: 0.6172618\ttest: 0.6120407\tbest: 0.6120407 (556)\ttotal: 7.74s\tremaining: 1m 1s\n",
      "557:\tlearn: 0.6172618\ttest: 0.6120406\tbest: 0.6120406 (557)\ttotal: 7.75s\tremaining: 1m 1s\n",
      "558:\tlearn: 0.6172618\ttest: 0.6120404\tbest: 0.6120404 (558)\ttotal: 7.76s\tremaining: 1m 1s\n",
      "559:\tlearn: 0.6172618\ttest: 0.6120403\tbest: 0.6120403 (559)\ttotal: 7.77s\tremaining: 1m 1s\n",
      "560:\tlearn: 0.6172618\ttest: 0.6120402\tbest: 0.6120402 (560)\ttotal: 7.78s\tremaining: 1m 1s\n",
      "561:\tlearn: 0.6172423\ttest: 0.6120268\tbest: 0.6120268 (561)\ttotal: 7.8s\tremaining: 1m 1s\n",
      "562:\tlearn: 0.6172423\ttest: 0.6120267\tbest: 0.6120267 (562)\ttotal: 7.82s\tremaining: 1m 1s\n",
      "563:\tlearn: 0.6172422\ttest: 0.6120266\tbest: 0.6120266 (563)\ttotal: 7.83s\tremaining: 1m 1s\n",
      "564:\tlearn: 0.6172422\ttest: 0.6120265\tbest: 0.6120265 (564)\ttotal: 7.83s\tremaining: 1m 1s\n",
      "565:\tlearn: 0.6172422\ttest: 0.6120264\tbest: 0.6120264 (565)\ttotal: 7.85s\tremaining: 1m 1s\n",
      "566:\tlearn: 0.6172422\ttest: 0.6120263\tbest: 0.6120263 (566)\ttotal: 7.86s\tremaining: 1m 1s\n",
      "567:\tlearn: 0.6172319\ttest: 0.6120204\tbest: 0.6120204 (567)\ttotal: 7.87s\tremaining: 1m 1s\n",
      "568:\tlearn: 0.6172319\ttest: 0.6120203\tbest: 0.6120203 (568)\ttotal: 7.88s\tremaining: 1m 1s\n",
      "569:\tlearn: 0.6172319\ttest: 0.6120202\tbest: 0.6120202 (569)\ttotal: 7.9s\tremaining: 1m 1s\n",
      "570:\tlearn: 0.6172014\ttest: 0.6119945\tbest: 0.6119945 (570)\ttotal: 7.92s\tremaining: 1m 1s\n",
      "571:\tlearn: 0.6171073\ttest: 0.6118963\tbest: 0.6118963 (571)\ttotal: 7.96s\tremaining: 1m 1s\n",
      "572:\tlearn: 0.6171073\ttest: 0.6118962\tbest: 0.6118962 (572)\ttotal: 7.97s\tremaining: 1m 1s\n",
      "573:\tlearn: 0.6171073\ttest: 0.6118961\tbest: 0.6118961 (573)\ttotal: 7.98s\tremaining: 1m 1s\n",
      "574:\tlearn: 0.6171073\ttest: 0.6118960\tbest: 0.6118960 (574)\ttotal: 7.99s\tremaining: 1m 1s\n",
      "575:\tlearn: 0.6170499\ttest: 0.6118299\tbest: 0.6118299 (575)\ttotal: 8.02s\tremaining: 1m 1s\n",
      "576:\tlearn: 0.6170281\ttest: 0.6118038\tbest: 0.6118038 (576)\ttotal: 8.03s\tremaining: 1m 1s\n",
      "577:\tlearn: 0.6170086\ttest: 0.6117856\tbest: 0.6117856 (577)\ttotal: 8.05s\tremaining: 1m 1s\n",
      "578:\tlearn: 0.6169548\ttest: 0.6117226\tbest: 0.6117226 (578)\ttotal: 8.07s\tremaining: 1m 1s\n",
      "579:\tlearn: 0.6169548\ttest: 0.6117226\tbest: 0.6117226 (579)\ttotal: 8.08s\tremaining: 1m 1s\n",
      "580:\tlearn: 0.6168069\ttest: 0.6115772\tbest: 0.6115772 (580)\ttotal: 8.1s\tremaining: 1m 1s\n",
      "581:\tlearn: 0.6167864\ttest: 0.6115561\tbest: 0.6115561 (581)\ttotal: 8.12s\tremaining: 1m 1s\n",
      "582:\tlearn: 0.6167741\ttest: 0.6115462\tbest: 0.6115462 (582)\ttotal: 8.13s\tremaining: 1m 1s\n",
      "583:\tlearn: 0.6167741\ttest: 0.6115461\tbest: 0.6115461 (583)\ttotal: 8.14s\tremaining: 1m 1s\n",
      "584:\tlearn: 0.6167741\ttest: 0.6115460\tbest: 0.6115460 (584)\ttotal: 8.16s\tremaining: 1m 1s\n",
      "585:\tlearn: 0.6167465\ttest: 0.6115233\tbest: 0.6115233 (585)\ttotal: 8.18s\tremaining: 1m 1s\n",
      "586:\tlearn: 0.6167465\ttest: 0.6115232\tbest: 0.6115232 (586)\ttotal: 8.19s\tremaining: 1m 1s\n",
      "587:\tlearn: 0.6167465\ttest: 0.6115231\tbest: 0.6115231 (587)\ttotal: 8.2s\tremaining: 1m 1s\n",
      "588:\tlearn: 0.6167129\ttest: 0.6114759\tbest: 0.6114759 (588)\ttotal: 8.21s\tremaining: 1m 1s\n",
      "589:\tlearn: 0.6167129\ttest: 0.6114758\tbest: 0.6114758 (589)\ttotal: 8.23s\tremaining: 1m 1s\n",
      "590:\tlearn: 0.6166464\ttest: 0.6113873\tbest: 0.6113873 (590)\ttotal: 8.25s\tremaining: 1m 1s\n",
      "591:\tlearn: 0.6166464\ttest: 0.6113872\tbest: 0.6113872 (591)\ttotal: 8.26s\tremaining: 1m 1s\n",
      "592:\tlearn: 0.6166464\ttest: 0.6113872\tbest: 0.6113872 (592)\ttotal: 8.27s\tremaining: 1m 1s\n",
      "593:\tlearn: 0.6166464\ttest: 0.6113871\tbest: 0.6113871 (593)\ttotal: 8.28s\tremaining: 1m 1s\n",
      "594:\tlearn: 0.6166464\ttest: 0.6113870\tbest: 0.6113870 (594)\ttotal: 8.29s\tremaining: 1m 1s\n",
      "595:\tlearn: 0.6166464\ttest: 0.6113870\tbest: 0.6113870 (595)\ttotal: 8.3s\tremaining: 1m 1s\n",
      "596:\tlearn: 0.6166463\ttest: 0.6113869\tbest: 0.6113869 (596)\ttotal: 8.31s\tremaining: 1m 1s\n",
      "597:\tlearn: 0.6166463\ttest: 0.6113868\tbest: 0.6113868 (597)\ttotal: 8.33s\tremaining: 1m 1s\n",
      "598:\tlearn: 0.6166463\ttest: 0.6113868\tbest: 0.6113868 (598)\ttotal: 8.34s\tremaining: 1m 1s\n",
      "599:\tlearn: 0.6166463\ttest: 0.6113867\tbest: 0.6113867 (599)\ttotal: 8.35s\tremaining: 1m 1s\n",
      "600:\tlearn: 0.6166463\ttest: 0.6113866\tbest: 0.6113866 (600)\ttotal: 8.36s\tremaining: 1m 1s\n",
      "601:\tlearn: 0.6165914\ttest: 0.6113188\tbest: 0.6113188 (601)\ttotal: 8.38s\tremaining: 1m 1s\n",
      "602:\tlearn: 0.6165292\ttest: 0.6112447\tbest: 0.6112447 (602)\ttotal: 8.4s\tremaining: 1m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603:\tlearn: 0.6165170\ttest: 0.6112390\tbest: 0.6112390 (603)\ttotal: 8.41s\tremaining: 1m 1s\n",
      "604:\tlearn: 0.6164614\ttest: 0.6111997\tbest: 0.6111997 (604)\ttotal: 8.43s\tremaining: 1m 1s\n",
      "605:\tlearn: 0.6164568\ttest: 0.6111969\tbest: 0.6111969 (605)\ttotal: 8.45s\tremaining: 1m 1s\n",
      "606:\tlearn: 0.6164568\ttest: 0.6111969\tbest: 0.6111969 (606)\ttotal: 8.46s\tremaining: 1m 1s\n",
      "607:\tlearn: 0.6164212\ttest: 0.6111561\tbest: 0.6111561 (607)\ttotal: 8.47s\tremaining: 1m 1s\n",
      "608:\tlearn: 0.6164212\ttest: 0.6111560\tbest: 0.6111560 (608)\ttotal: 8.48s\tremaining: 1m 1s\n",
      "609:\tlearn: 0.6164212\ttest: 0.6111560\tbest: 0.6111560 (609)\ttotal: 8.49s\tremaining: 1m 1s\n",
      "610:\tlearn: 0.6164212\ttest: 0.6111559\tbest: 0.6111559 (610)\ttotal: 8.5s\tremaining: 1m 1s\n",
      "611:\tlearn: 0.6163721\ttest: 0.6110998\tbest: 0.6110998 (611)\ttotal: 8.52s\tremaining: 1m 1s\n",
      "612:\tlearn: 0.6163205\ttest: 0.6110357\tbest: 0.6110357 (612)\ttotal: 8.54s\tremaining: 1m 1s\n",
      "613:\tlearn: 0.6163205\ttest: 0.6110357\tbest: 0.6110357 (613)\ttotal: 8.55s\tremaining: 1m 1s\n",
      "614:\tlearn: 0.6163205\ttest: 0.6110356\tbest: 0.6110356 (614)\ttotal: 8.56s\tremaining: 1m 1s\n",
      "615:\tlearn: 0.6163139\ttest: 0.6110297\tbest: 0.6110297 (615)\ttotal: 8.58s\tremaining: 1m 1s\n",
      "616:\tlearn: 0.6162850\ttest: 0.6109871\tbest: 0.6109871 (616)\ttotal: 8.59s\tremaining: 1m 1s\n",
      "617:\tlearn: 0.6162850\ttest: 0.6109871\tbest: 0.6109871 (617)\ttotal: 8.6s\tremaining: 1m 1s\n",
      "618:\tlearn: 0.6162849\ttest: 0.6109870\tbest: 0.6109870 (618)\ttotal: 8.62s\tremaining: 1m\n",
      "619:\tlearn: 0.6162849\ttest: 0.6109870\tbest: 0.6109870 (619)\ttotal: 8.63s\tremaining: 1m\n",
      "620:\tlearn: 0.6162689\ttest: 0.6109743\tbest: 0.6109743 (620)\ttotal: 8.65s\tremaining: 1m\n",
      "621:\tlearn: 0.6162689\ttest: 0.6109743\tbest: 0.6109743 (621)\ttotal: 8.66s\tremaining: 1m\n",
      "622:\tlearn: 0.6162689\ttest: 0.6109742\tbest: 0.6109742 (622)\ttotal: 8.67s\tremaining: 1m\n",
      "623:\tlearn: 0.6162619\ttest: 0.6109669\tbest: 0.6109669 (623)\ttotal: 8.69s\tremaining: 1m\n",
      "624:\tlearn: 0.6162513\ttest: 0.6109583\tbest: 0.6109583 (624)\ttotal: 8.71s\tremaining: 1m\n",
      "625:\tlearn: 0.6162512\ttest: 0.6109583\tbest: 0.6109583 (625)\ttotal: 8.72s\tremaining: 1m\n",
      "626:\tlearn: 0.6162512\ttest: 0.6109582\tbest: 0.6109582 (626)\ttotal: 8.74s\tremaining: 1m\n",
      "627:\tlearn: 0.6162512\ttest: 0.6109582\tbest: 0.6109582 (627)\ttotal: 8.75s\tremaining: 1m\n",
      "628:\tlearn: 0.6162512\ttest: 0.6109581\tbest: 0.6109581 (628)\ttotal: 8.76s\tremaining: 1m\n",
      "629:\tlearn: 0.6161944\ttest: 0.6108985\tbest: 0.6108985 (629)\ttotal: 8.78s\tremaining: 1m\n",
      "630:\tlearn: 0.6161944\ttest: 0.6108985\tbest: 0.6108985 (630)\ttotal: 8.79s\tremaining: 1m\n",
      "631:\tlearn: 0.6161944\ttest: 0.6108985\tbest: 0.6108985 (631)\ttotal: 8.81s\tremaining: 1m\n",
      "632:\tlearn: 0.6161944\ttest: 0.6108984\tbest: 0.6108984 (632)\ttotal: 8.82s\tremaining: 1m\n",
      "633:\tlearn: 0.6161944\ttest: 0.6108984\tbest: 0.6108984 (633)\ttotal: 8.83s\tremaining: 1m\n",
      "634:\tlearn: 0.6161944\ttest: 0.6108983\tbest: 0.6108983 (634)\ttotal: 8.84s\tremaining: 1m\n",
      "635:\tlearn: 0.6161944\ttest: 0.6108983\tbest: 0.6108983 (635)\ttotal: 8.85s\tremaining: 1m\n",
      "636:\tlearn: 0.6161944\ttest: 0.6108983\tbest: 0.6108983 (636)\ttotal: 8.86s\tremaining: 1m\n",
      "637:\tlearn: 0.6161811\ttest: 0.6108879\tbest: 0.6108879 (637)\ttotal: 8.88s\tremaining: 1m\n",
      "638:\tlearn: 0.6161811\ttest: 0.6108879\tbest: 0.6108879 (638)\ttotal: 8.9s\tremaining: 1m\n",
      "639:\tlearn: 0.6161811\ttest: 0.6108879\tbest: 0.6108879 (639)\ttotal: 8.91s\tremaining: 1m\n",
      "640:\tlearn: 0.6161811\ttest: 0.6108878\tbest: 0.6108878 (640)\ttotal: 8.92s\tremaining: 1m\n",
      "641:\tlearn: 0.6161811\ttest: 0.6108878\tbest: 0.6108878 (641)\ttotal: 8.93s\tremaining: 1m\n",
      "642:\tlearn: 0.6161810\ttest: 0.6108877\tbest: 0.6108877 (642)\ttotal: 8.95s\tremaining: 1m\n",
      "643:\tlearn: 0.6161810\ttest: 0.6108877\tbest: 0.6108877 (643)\ttotal: 8.96s\tremaining: 1m\n",
      "644:\tlearn: 0.6161810\ttest: 0.6108877\tbest: 0.6108877 (644)\ttotal: 8.97s\tremaining: 1m\n",
      "645:\tlearn: 0.6161810\ttest: 0.6108876\tbest: 0.6108876 (645)\ttotal: 8.99s\tremaining: 1m\n",
      "646:\tlearn: 0.6161810\ttest: 0.6108876\tbest: 0.6108876 (646)\ttotal: 9.01s\tremaining: 1m\n",
      "647:\tlearn: 0.6161810\ttest: 0.6108876\tbest: 0.6108876 (647)\ttotal: 9.02s\tremaining: 1m\n",
      "648:\tlearn: 0.6161810\ttest: 0.6108875\tbest: 0.6108875 (648)\ttotal: 9.03s\tremaining: 1m\n",
      "649:\tlearn: 0.6161810\ttest: 0.6108875\tbest: 0.6108875 (649)\ttotal: 9.05s\tremaining: 1m\n",
      "650:\tlearn: 0.6161810\ttest: 0.6108875\tbest: 0.6108875 (650)\ttotal: 9.06s\tremaining: 1m\n",
      "651:\tlearn: 0.6161810\ttest: 0.6108874\tbest: 0.6108874 (651)\ttotal: 9.07s\tremaining: 1m\n",
      "652:\tlearn: 0.6161810\ttest: 0.6108874\tbest: 0.6108874 (652)\ttotal: 9.09s\tremaining: 1m\n",
      "653:\tlearn: 0.6161810\ttest: 0.6108874\tbest: 0.6108874 (653)\ttotal: 9.1s\tremaining: 1m\n",
      "654:\tlearn: 0.6161753\ttest: 0.6108821\tbest: 0.6108821 (654)\ttotal: 9.12s\tremaining: 1m\n",
      "655:\tlearn: 0.6161753\ttest: 0.6108821\tbest: 0.6108821 (655)\ttotal: 9.13s\tremaining: 1m\n",
      "656:\tlearn: 0.6161753\ttest: 0.6108820\tbest: 0.6108820 (656)\ttotal: 9.14s\tremaining: 1m\n",
      "657:\tlearn: 0.6161753\ttest: 0.6108820\tbest: 0.6108820 (657)\ttotal: 9.15s\tremaining: 1m\n",
      "658:\tlearn: 0.6161753\ttest: 0.6108820\tbest: 0.6108820 (658)\ttotal: 9.16s\tremaining: 1m\n",
      "659:\tlearn: 0.6161753\ttest: 0.6108819\tbest: 0.6108819 (659)\ttotal: 9.17s\tremaining: 1m\n",
      "660:\tlearn: 0.6161734\ttest: 0.6108773\tbest: 0.6108773 (660)\ttotal: 9.19s\tremaining: 1m\n",
      "661:\tlearn: 0.6161734\ttest: 0.6108773\tbest: 0.6108773 (661)\ttotal: 9.2s\tremaining: 1m\n",
      "662:\tlearn: 0.6161734\ttest: 0.6108773\tbest: 0.6108773 (662)\ttotal: 9.21s\tremaining: 1m\n",
      "663:\tlearn: 0.6161734\ttest: 0.6108772\tbest: 0.6108772 (663)\ttotal: 9.22s\tremaining: 1m\n",
      "664:\tlearn: 0.6161734\ttest: 0.6108772\tbest: 0.6108772 (664)\ttotal: 9.23s\tremaining: 1m\n",
      "665:\tlearn: 0.6161734\ttest: 0.6108772\tbest: 0.6108772 (665)\ttotal: 9.24s\tremaining: 1m\n",
      "666:\tlearn: 0.6161734\ttest: 0.6108772\tbest: 0.6108772 (666)\ttotal: 9.25s\tremaining: 1m\n",
      "667:\tlearn: 0.6161440\ttest: 0.6108349\tbest: 0.6108349 (667)\ttotal: 9.27s\tremaining: 1m\n",
      "668:\tlearn: 0.6161440\ttest: 0.6108349\tbest: 0.6108349 (668)\ttotal: 9.28s\tremaining: 1m\n",
      "669:\tlearn: 0.6161440\ttest: 0.6108348\tbest: 0.6108348 (669)\ttotal: 9.29s\tremaining: 1m\n",
      "670:\tlearn: 0.6161326\ttest: 0.6108258\tbest: 0.6108258 (670)\ttotal: 9.31s\tremaining: 1m\n",
      "671:\tlearn: 0.6161221\ttest: 0.6108174\tbest: 0.6108174 (671)\ttotal: 9.33s\tremaining: 1m\n",
      "672:\tlearn: 0.6161221\ttest: 0.6108174\tbest: 0.6108174 (672)\ttotal: 9.34s\tremaining: 1m\n",
      "673:\tlearn: 0.6161221\ttest: 0.6108174\tbest: 0.6108174 (673)\ttotal: 9.35s\tremaining: 1m\n",
      "674:\tlearn: 0.6161203\ttest: 0.6108171\tbest: 0.6108171 (674)\ttotal: 9.36s\tremaining: 60s\n",
      "675:\tlearn: 0.6161203\ttest: 0.6108171\tbest: 0.6108171 (675)\ttotal: 9.38s\tremaining: 60s\n",
      "676:\tlearn: 0.6161203\ttest: 0.6108170\tbest: 0.6108170 (676)\ttotal: 9.39s\tremaining: 59.9s\n",
      "677:\tlearn: 0.6160052\ttest: 0.6106706\tbest: 0.6106706 (677)\ttotal: 9.4s\tremaining: 59.9s\n",
      "678:\tlearn: 0.6160052\ttest: 0.6106706\tbest: 0.6106706 (678)\ttotal: 9.41s\tremaining: 59.9s\n",
      "679:\tlearn: 0.6160052\ttest: 0.6106706\tbest: 0.6106706 (679)\ttotal: 9.43s\tremaining: 59.9s\n",
      "680:\tlearn: 0.6160052\ttest: 0.6106705\tbest: 0.6106705 (680)\ttotal: 9.44s\tremaining: 59.9s\n",
      "681:\tlearn: 0.6160011\ttest: 0.6106665\tbest: 0.6106665 (681)\ttotal: 9.45s\tremaining: 59.8s\n",
      "682:\tlearn: 0.6160011\ttest: 0.6106665\tbest: 0.6106665 (682)\ttotal: 9.46s\tremaining: 59.8s\n",
      "683:\tlearn: 0.6160011\ttest: 0.6106665\tbest: 0.6106665 (683)\ttotal: 9.47s\tremaining: 59.8s\n",
      "684:\tlearn: 0.6159603\ttest: 0.6106171\tbest: 0.6106171 (684)\ttotal: 9.49s\tremaining: 59.8s\n",
      "685:\tlearn: 0.6159603\ttest: 0.6106171\tbest: 0.6106171 (685)\ttotal: 9.5s\tremaining: 59.7s\n",
      "686:\tlearn: 0.6159603\ttest: 0.6106171\tbest: 0.6106171 (686)\ttotal: 9.51s\tremaining: 59.7s\n",
      "687:\tlearn: 0.6159603\ttest: 0.6106171\tbest: 0.6106171 (687)\ttotal: 9.52s\tremaining: 59.7s\n",
      "688:\tlearn: 0.6159603\ttest: 0.6106170\tbest: 0.6106170 (688)\ttotal: 9.53s\tremaining: 59.6s\n",
      "689:\tlearn: 0.6159603\ttest: 0.6106170\tbest: 0.6106170 (689)\ttotal: 9.54s\tremaining: 59.6s\n",
      "690:\tlearn: 0.6158759\ttest: 0.6105390\tbest: 0.6105390 (690)\ttotal: 9.56s\tremaining: 59.6s\n",
      "691:\tlearn: 0.6158759\ttest: 0.6105390\tbest: 0.6105390 (691)\ttotal: 9.58s\tremaining: 59.6s\n",
      "692:\tlearn: 0.6158759\ttest: 0.6105389\tbest: 0.6105389 (692)\ttotal: 9.59s\tremaining: 59.6s\n",
      "693:\tlearn: 0.6158605\ttest: 0.6105216\tbest: 0.6105216 (693)\ttotal: 9.6s\tremaining: 59.6s\n",
      "694:\tlearn: 0.6157378\ttest: 0.6103793\tbest: 0.6103793 (694)\ttotal: 9.63s\tremaining: 59.6s\n",
      "695:\tlearn: 0.6157378\ttest: 0.6103793\tbest: 0.6103793 (695)\ttotal: 9.64s\tremaining: 59.6s\n",
      "696:\tlearn: 0.6157378\ttest: 0.6103793\tbest: 0.6103793 (696)\ttotal: 9.65s\tremaining: 59.6s\n",
      "697:\tlearn: 0.6157378\ttest: 0.6103792\tbest: 0.6103792 (697)\ttotal: 9.66s\tremaining: 59.5s\n",
      "698:\tlearn: 0.6157378\ttest: 0.6103792\tbest: 0.6103792 (698)\ttotal: 9.67s\tremaining: 59.5s\n",
      "699:\tlearn: 0.6157378\ttest: 0.6103792\tbest: 0.6103792 (699)\ttotal: 9.68s\tremaining: 59.5s\n",
      "700:\tlearn: 0.6157378\ttest: 0.6103792\tbest: 0.6103792 (700)\ttotal: 9.69s\tremaining: 59.4s\n",
      "701:\tlearn: 0.6157378\ttest: 0.6103791\tbest: 0.6103791 (701)\ttotal: 9.7s\tremaining: 59.4s\n",
      "702:\tlearn: 0.6156093\ttest: 0.6102442\tbest: 0.6102442 (702)\ttotal: 9.72s\tremaining: 59.4s\n",
      "703:\tlearn: 0.6156093\ttest: 0.6102442\tbest: 0.6102442 (703)\ttotal: 9.73s\tremaining: 59.4s\n",
      "704:\tlearn: 0.6156093\ttest: 0.6102442\tbest: 0.6102442 (704)\ttotal: 9.74s\tremaining: 59.4s\n",
      "705:\tlearn: 0.6155987\ttest: 0.6102360\tbest: 0.6102360 (705)\ttotal: 9.76s\tremaining: 59.4s\n",
      "706:\tlearn: 0.6155987\ttest: 0.6102360\tbest: 0.6102360 (706)\ttotal: 9.77s\tremaining: 59.3s\n",
      "707:\tlearn: 0.6155565\ttest: 0.6101897\tbest: 0.6101897 (707)\ttotal: 9.79s\tremaining: 59.4s\n",
      "708:\tlearn: 0.6155449\ttest: 0.6101785\tbest: 0.6101785 (708)\ttotal: 9.81s\tremaining: 59.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709:\tlearn: 0.6155160\ttest: 0.6101454\tbest: 0.6101454 (709)\ttotal: 9.83s\tremaining: 59.4s\n",
      "710:\tlearn: 0.6154908\ttest: 0.6101074\tbest: 0.6101074 (710)\ttotal: 9.85s\tremaining: 59.4s\n",
      "711:\tlearn: 0.6154908\ttest: 0.6101074\tbest: 0.6101074 (711)\ttotal: 9.86s\tremaining: 59.4s\n",
      "712:\tlearn: 0.6154592\ttest: 0.6100666\tbest: 0.6100666 (712)\ttotal: 9.88s\tremaining: 59.4s\n",
      "713:\tlearn: 0.6154310\ttest: 0.6100334\tbest: 0.6100334 (713)\ttotal: 9.9s\tremaining: 59.4s\n",
      "714:\tlearn: 0.6154310\ttest: 0.6100334\tbest: 0.6100334 (714)\ttotal: 9.91s\tremaining: 59.4s\n",
      "715:\tlearn: 0.6153596\ttest: 0.6099628\tbest: 0.6099628 (715)\ttotal: 9.94s\tremaining: 59.5s\n",
      "716:\tlearn: 0.6153084\ttest: 0.6099060\tbest: 0.6099060 (716)\ttotal: 9.96s\tremaining: 59.5s\n",
      "717:\tlearn: 0.6153084\ttest: 0.6099060\tbest: 0.6099060 (717)\ttotal: 9.97s\tremaining: 59.5s\n",
      "718:\tlearn: 0.6153084\ttest: 0.6099060\tbest: 0.6099060 (718)\ttotal: 9.99s\tremaining: 59.5s\n",
      "719:\tlearn: 0.6153084\ttest: 0.6099060\tbest: 0.6099060 (719)\ttotal: 10s\tremaining: 59.4s\n",
      "720:\tlearn: 0.6152531\ttest: 0.6098326\tbest: 0.6098326 (720)\ttotal: 10s\tremaining: 59.4s\n",
      "721:\tlearn: 0.6152393\ttest: 0.6098227\tbest: 0.6098227 (721)\ttotal: 10s\tremaining: 59.4s\n",
      "722:\tlearn: 0.6152165\ttest: 0.6097878\tbest: 0.6097878 (722)\ttotal: 10s\tremaining: 59.4s\n",
      "723:\tlearn: 0.6151906\ttest: 0.6097700\tbest: 0.6097700 (723)\ttotal: 10.1s\tremaining: 59.5s\n",
      "724:\tlearn: 0.6151906\ttest: 0.6097700\tbest: 0.6097700 (724)\ttotal: 10.1s\tremaining: 59.4s\n",
      "725:\tlearn: 0.6151580\ttest: 0.6097258\tbest: 0.6097258 (725)\ttotal: 10.1s\tremaining: 59.4s\n",
      "726:\tlearn: 0.6151518\ttest: 0.6097202\tbest: 0.6097202 (726)\ttotal: 10.1s\tremaining: 59.4s\n",
      "727:\tlearn: 0.6150684\ttest: 0.6096468\tbest: 0.6096468 (727)\ttotal: 10.1s\tremaining: 59.5s\n",
      "728:\tlearn: 0.6150684\ttest: 0.6096468\tbest: 0.6096468 (728)\ttotal: 10.1s\tremaining: 59.4s\n",
      "729:\tlearn: 0.6150684\ttest: 0.6096468\tbest: 0.6096468 (729)\ttotal: 10.2s\tremaining: 59.4s\n",
      "730:\tlearn: 0.6150684\ttest: 0.6096468\tbest: 0.6096468 (730)\ttotal: 10.2s\tremaining: 59.4s\n",
      "731:\tlearn: 0.6150455\ttest: 0.6096211\tbest: 0.6096211 (731)\ttotal: 10.2s\tremaining: 59.4s\n",
      "732:\tlearn: 0.6150455\ttest: 0.6096210\tbest: 0.6096210 (732)\ttotal: 10.2s\tremaining: 59.3s\n",
      "733:\tlearn: 0.6150455\ttest: 0.6096210\tbest: 0.6096210 (733)\ttotal: 10.2s\tremaining: 59.3s\n",
      "734:\tlearn: 0.6150455\ttest: 0.6096210\tbest: 0.6096210 (734)\ttotal: 10.2s\tremaining: 59.3s\n",
      "735:\tlearn: 0.6150316\ttest: 0.6096093\tbest: 0.6096093 (735)\ttotal: 10.2s\tremaining: 59.3s\n",
      "736:\tlearn: 0.6150313\ttest: 0.6096084\tbest: 0.6096084 (736)\ttotal: 10.2s\tremaining: 59.3s\n",
      "737:\tlearn: 0.6150313\ttest: 0.6096084\tbest: 0.6096084 (737)\ttotal: 10.3s\tremaining: 59.3s\n",
      "738:\tlearn: 0.6149947\ttest: 0.6095588\tbest: 0.6095588 (738)\ttotal: 10.3s\tremaining: 59.3s\n",
      "739:\tlearn: 0.6149947\ttest: 0.6095587\tbest: 0.6095587 (739)\ttotal: 10.3s\tremaining: 59.3s\n",
      "740:\tlearn: 0.6149947\ttest: 0.6095587\tbest: 0.6095587 (740)\ttotal: 10.3s\tremaining: 59.2s\n",
      "741:\tlearn: 0.6149947\ttest: 0.6095587\tbest: 0.6095587 (741)\ttotal: 10.3s\tremaining: 59.2s\n",
      "742:\tlearn: 0.6149851\ttest: 0.6095459\tbest: 0.6095459 (742)\ttotal: 10.3s\tremaining: 59.2s\n",
      "743:\tlearn: 0.6149593\ttest: 0.6095114\tbest: 0.6095114 (743)\ttotal: 10.3s\tremaining: 59.2s\n",
      "744:\tlearn: 0.6149354\ttest: 0.6094907\tbest: 0.6094907 (744)\ttotal: 10.4s\tremaining: 59.2s\n",
      "745:\tlearn: 0.6149143\ttest: 0.6094579\tbest: 0.6094579 (745)\ttotal: 10.4s\tremaining: 59.2s\n",
      "746:\tlearn: 0.6149143\ttest: 0.6094579\tbest: 0.6094579 (746)\ttotal: 10.4s\tremaining: 59.2s\n",
      "747:\tlearn: 0.6149127\ttest: 0.6094557\tbest: 0.6094557 (747)\ttotal: 10.4s\tremaining: 59.2s\n",
      "748:\tlearn: 0.6149127\ttest: 0.6094556\tbest: 0.6094556 (748)\ttotal: 10.4s\tremaining: 59.2s\n",
      "749:\tlearn: 0.6149127\ttest: 0.6094556\tbest: 0.6094556 (749)\ttotal: 10.4s\tremaining: 59.2s\n",
      "750:\tlearn: 0.6149127\ttest: 0.6094556\tbest: 0.6094556 (750)\ttotal: 10.5s\tremaining: 59.1s\n",
      "751:\tlearn: 0.6149127\ttest: 0.6094556\tbest: 0.6094556 (751)\ttotal: 10.5s\tremaining: 59.1s\n",
      "752:\tlearn: 0.6148849\ttest: 0.6094322\tbest: 0.6094322 (752)\ttotal: 10.5s\tremaining: 59.1s\n",
      "753:\tlearn: 0.6148849\ttest: 0.6094322\tbest: 0.6094322 (753)\ttotal: 10.5s\tremaining: 59.1s\n",
      "754:\tlearn: 0.6148748\ttest: 0.6094253\tbest: 0.6094253 (754)\ttotal: 10.5s\tremaining: 59.1s\n",
      "755:\tlearn: 0.6148621\ttest: 0.6094165\tbest: 0.6094165 (755)\ttotal: 10.5s\tremaining: 59.1s\n",
      "756:\tlearn: 0.6148610\ttest: 0.6094158\tbest: 0.6094158 (756)\ttotal: 10.6s\tremaining: 59.1s\n",
      "757:\tlearn: 0.6148610\ttest: 0.6094158\tbest: 0.6094158 (757)\ttotal: 10.6s\tremaining: 59.1s\n",
      "758:\tlearn: 0.6148472\ttest: 0.6094042\tbest: 0.6094042 (758)\ttotal: 10.6s\tremaining: 59.1s\n",
      "759:\tlearn: 0.6148472\ttest: 0.6094042\tbest: 0.6094042 (759)\ttotal: 10.6s\tremaining: 59.1s\n",
      "760:\tlearn: 0.6148472\ttest: 0.6094042\tbest: 0.6094042 (760)\ttotal: 10.6s\tremaining: 59s\n",
      "761:\tlearn: 0.6148472\ttest: 0.6094042\tbest: 0.6094042 (761)\ttotal: 10.6s\tremaining: 59s\n",
      "762:\tlearn: 0.6148472\ttest: 0.6094042\tbest: 0.6094042 (762)\ttotal: 10.6s\tremaining: 59s\n",
      "763:\tlearn: 0.6148411\ttest: 0.6093981\tbest: 0.6093981 (763)\ttotal: 10.6s\tremaining: 59s\n",
      "764:\tlearn: 0.6148200\ttest: 0.6093724\tbest: 0.6093724 (764)\ttotal: 10.7s\tremaining: 59s\n",
      "765:\tlearn: 0.6147585\ttest: 0.6093039\tbest: 0.6093039 (765)\ttotal: 10.7s\tremaining: 59s\n",
      "766:\tlearn: 0.6147585\ttest: 0.6093039\tbest: 0.6093039 (766)\ttotal: 10.7s\tremaining: 59s\n",
      "767:\tlearn: 0.6147585\ttest: 0.6093039\tbest: 0.6093039 (767)\ttotal: 10.7s\tremaining: 58.9s\n",
      "768:\tlearn: 0.6147488\ttest: 0.6092945\tbest: 0.6092945 (768)\ttotal: 10.7s\tremaining: 58.9s\n",
      "769:\tlearn: 0.6146526\ttest: 0.6092182\tbest: 0.6092182 (769)\ttotal: 10.7s\tremaining: 58.9s\n",
      "770:\tlearn: 0.6146526\ttest: 0.6092182\tbest: 0.6092182 (770)\ttotal: 10.7s\tremaining: 58.9s\n",
      "771:\tlearn: 0.6146387\ttest: 0.6092004\tbest: 0.6092004 (771)\ttotal: 10.8s\tremaining: 58.9s\n",
      "772:\tlearn: 0.6144692\ttest: 0.6090095\tbest: 0.6090095 (772)\ttotal: 10.8s\tremaining: 58.9s\n",
      "773:\tlearn: 0.6144692\ttest: 0.6090095\tbest: 0.6090095 (773)\ttotal: 10.8s\tremaining: 58.9s\n",
      "774:\tlearn: 0.6144692\ttest: 0.6090095\tbest: 0.6090095 (774)\ttotal: 10.8s\tremaining: 58.9s\n",
      "775:\tlearn: 0.6144692\ttest: 0.6090095\tbest: 0.6090095 (775)\ttotal: 10.8s\tremaining: 58.9s\n",
      "776:\tlearn: 0.6144692\ttest: 0.6090095\tbest: 0.6090095 (776)\ttotal: 10.8s\tremaining: 58.8s\n",
      "777:\tlearn: 0.6144692\ttest: 0.6090095\tbest: 0.6090095 (777)\ttotal: 10.8s\tremaining: 58.8s\n",
      "778:\tlearn: 0.6144692\ttest: 0.6090094\tbest: 0.6090094 (778)\ttotal: 10.9s\tremaining: 58.8s\n",
      "779:\tlearn: 0.6144692\ttest: 0.6090094\tbest: 0.6090094 (779)\ttotal: 10.9s\tremaining: 58.8s\n",
      "780:\tlearn: 0.6144691\ttest: 0.6090094\tbest: 0.6090094 (780)\ttotal: 10.9s\tremaining: 58.8s\n",
      "781:\tlearn: 0.6144691\ttest: 0.6090094\tbest: 0.6090094 (781)\ttotal: 10.9s\tremaining: 58.8s\n",
      "782:\tlearn: 0.6144691\ttest: 0.6090094\tbest: 0.6090094 (782)\ttotal: 10.9s\tremaining: 58.7s\n",
      "783:\tlearn: 0.6144691\ttest: 0.6090094\tbest: 0.6090094 (783)\ttotal: 10.9s\tremaining: 58.7s\n",
      "784:\tlearn: 0.6144553\ttest: 0.6089929\tbest: 0.6089929 (784)\ttotal: 10.9s\tremaining: 58.7s\n",
      "785:\tlearn: 0.6144553\ttest: 0.6089929\tbest: 0.6089929 (785)\ttotal: 11s\tremaining: 58.7s\n",
      "786:\tlearn: 0.6144553\ttest: 0.6089929\tbest: 0.6089929 (786)\ttotal: 11s\tremaining: 58.7s\n",
      "787:\tlearn: 0.6144553\ttest: 0.6089929\tbest: 0.6089929 (787)\ttotal: 11s\tremaining: 58.7s\n",
      "788:\tlearn: 0.6144553\ttest: 0.6089929\tbest: 0.6089929 (788)\ttotal: 11s\tremaining: 58.7s\n",
      "789:\tlearn: 0.6144553\ttest: 0.6089929\tbest: 0.6089929 (789)\ttotal: 11s\tremaining: 58.7s\n",
      "790:\tlearn: 0.6144352\ttest: 0.6089701\tbest: 0.6089701 (790)\ttotal: 11s\tremaining: 58.7s\n",
      "791:\tlearn: 0.6144352\ttest: 0.6089701\tbest: 0.6089701 (791)\ttotal: 11s\tremaining: 58.7s\n",
      "792:\tlearn: 0.6144352\ttest: 0.6089701\tbest: 0.6089701 (792)\ttotal: 11.1s\tremaining: 58.7s\n",
      "793:\tlearn: 0.6144352\ttest: 0.6089701\tbest: 0.6089701 (793)\ttotal: 11.1s\tremaining: 58.7s\n",
      "794:\tlearn: 0.6144352\ttest: 0.6089701\tbest: 0.6089701 (794)\ttotal: 11.1s\tremaining: 58.6s\n",
      "795:\tlearn: 0.6144352\ttest: 0.6089701\tbest: 0.6089701 (795)\ttotal: 11.1s\tremaining: 58.6s\n",
      "796:\tlearn: 0.6144108\ttest: 0.6089378\tbest: 0.6089378 (796)\ttotal: 11.1s\tremaining: 58.7s\n",
      "797:\tlearn: 0.6144108\ttest: 0.6089378\tbest: 0.6089378 (797)\ttotal: 11.1s\tremaining: 58.6s\n",
      "798:\tlearn: 0.6144089\ttest: 0.6089338\tbest: 0.6089338 (798)\ttotal: 11.2s\tremaining: 58.6s\n",
      "799:\tlearn: 0.6143683\ttest: 0.6088863\tbest: 0.6088863 (799)\ttotal: 11.2s\tremaining: 58.7s\n",
      "800:\tlearn: 0.6143683\ttest: 0.6088863\tbest: 0.6088863 (800)\ttotal: 11.2s\tremaining: 58.6s\n",
      "801:\tlearn: 0.6143364\ttest: 0.6088507\tbest: 0.6088507 (801)\ttotal: 11.2s\tremaining: 58.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802:\tlearn: 0.6143148\ttest: 0.6088245\tbest: 0.6088245 (802)\ttotal: 11.2s\tremaining: 58.7s\n",
      "803:\tlearn: 0.6143148\ttest: 0.6088245\tbest: 0.6088245 (803)\ttotal: 11.2s\tremaining: 58.6s\n",
      "804:\tlearn: 0.6143148\ttest: 0.6088245\tbest: 0.6088245 (804)\ttotal: 11.2s\tremaining: 58.6s\n",
      "805:\tlearn: 0.6143148\ttest: 0.6088244\tbest: 0.6088244 (805)\ttotal: 11.3s\tremaining: 58.6s\n",
      "806:\tlearn: 0.6143148\ttest: 0.6088244\tbest: 0.6088244 (806)\ttotal: 11.3s\tremaining: 58.6s\n",
      "807:\tlearn: 0.6143024\ttest: 0.6088126\tbest: 0.6088126 (807)\ttotal: 11.3s\tremaining: 58.5s\n",
      "808:\tlearn: 0.6143024\ttest: 0.6088126\tbest: 0.6088126 (808)\ttotal: 11.3s\tremaining: 58.5s\n",
      "809:\tlearn: 0.6143024\ttest: 0.6088126\tbest: 0.6088126 (809)\ttotal: 11.3s\tremaining: 58.5s\n",
      "810:\tlearn: 0.6142828\ttest: 0.6087822\tbest: 0.6087822 (810)\ttotal: 11.3s\tremaining: 58.5s\n",
      "811:\tlearn: 0.6142828\ttest: 0.6087822\tbest: 0.6087822 (811)\ttotal: 11.3s\tremaining: 58.4s\n",
      "812:\tlearn: 0.6142828\ttest: 0.6087822\tbest: 0.6087822 (812)\ttotal: 11.3s\tremaining: 58.4s\n",
      "813:\tlearn: 0.6142828\ttest: 0.6087822\tbest: 0.6087822 (813)\ttotal: 11.4s\tremaining: 58.4s\n",
      "814:\tlearn: 0.6142368\ttest: 0.6087320\tbest: 0.6087320 (814)\ttotal: 11.4s\tremaining: 58.4s\n",
      "815:\tlearn: 0.6142368\ttest: 0.6087320\tbest: 0.6087320 (815)\ttotal: 11.4s\tremaining: 58.4s\n",
      "816:\tlearn: 0.6142359\ttest: 0.6087312\tbest: 0.6087312 (816)\ttotal: 11.4s\tremaining: 58.4s\n",
      "817:\tlearn: 0.6141973\ttest: 0.6086995\tbest: 0.6086995 (817)\ttotal: 11.4s\tremaining: 58.4s\n",
      "818:\tlearn: 0.6141973\ttest: 0.6086995\tbest: 0.6086995 (818)\ttotal: 11.4s\tremaining: 58.3s\n",
      "819:\tlearn: 0.6141888\ttest: 0.6086882\tbest: 0.6086882 (819)\ttotal: 11.4s\tremaining: 58.3s\n",
      "820:\tlearn: 0.6141888\ttest: 0.6086882\tbest: 0.6086882 (820)\ttotal: 11.5s\tremaining: 58.3s\n",
      "821:\tlearn: 0.6141798\ttest: 0.6086795\tbest: 0.6086795 (821)\ttotal: 11.5s\tremaining: 58.3s\n",
      "822:\tlearn: 0.6141679\ttest: 0.6086734\tbest: 0.6086734 (822)\ttotal: 11.5s\tremaining: 58.3s\n",
      "823:\tlearn: 0.6141088\ttest: 0.6086139\tbest: 0.6086139 (823)\ttotal: 11.5s\tremaining: 58.3s\n",
      "824:\tlearn: 0.6140736\ttest: 0.6085896\tbest: 0.6085896 (824)\ttotal: 11.5s\tremaining: 58.3s\n",
      "825:\tlearn: 0.6140537\ttest: 0.6085617\tbest: 0.6085617 (825)\ttotal: 11.5s\tremaining: 58.3s\n",
      "826:\tlearn: 0.6140456\ttest: 0.6085512\tbest: 0.6085512 (826)\ttotal: 11.6s\tremaining: 58.3s\n",
      "827:\tlearn: 0.6140364\ttest: 0.6085449\tbest: 0.6085449 (827)\ttotal: 11.6s\tremaining: 58.3s\n",
      "828:\tlearn: 0.6140160\ttest: 0.6085201\tbest: 0.6085201 (828)\ttotal: 11.6s\tremaining: 58.3s\n",
      "829:\tlearn: 0.6140160\ttest: 0.6085201\tbest: 0.6085201 (829)\ttotal: 11.6s\tremaining: 58.3s\n",
      "830:\tlearn: 0.6140160\ttest: 0.6085201\tbest: 0.6085201 (830)\ttotal: 11.6s\tremaining: 58.2s\n",
      "831:\tlearn: 0.6140128\ttest: 0.6085198\tbest: 0.6085198 (831)\ttotal: 11.6s\tremaining: 58.2s\n",
      "832:\tlearn: 0.6140128\ttest: 0.6085198\tbest: 0.6085198 (832)\ttotal: 11.6s\tremaining: 58.2s\n",
      "833:\tlearn: 0.6140047\ttest: 0.6085089\tbest: 0.6085089 (833)\ttotal: 11.6s\tremaining: 58.2s\n",
      "834:\tlearn: 0.6140047\ttest: 0.6085089\tbest: 0.6085089 (834)\ttotal: 11.7s\tremaining: 58.2s\n",
      "835:\tlearn: 0.6140047\ttest: 0.6085089\tbest: 0.6085089 (835)\ttotal: 11.7s\tremaining: 58.1s\n",
      "836:\tlearn: 0.6139836\ttest: 0.6084803\tbest: 0.6084803 (836)\ttotal: 11.7s\tremaining: 58.1s\n",
      "837:\tlearn: 0.6139836\ttest: 0.6084803\tbest: 0.6084803 (837)\ttotal: 11.7s\tremaining: 58.1s\n",
      "838:\tlearn: 0.6139836\ttest: 0.6084803\tbest: 0.6084803 (838)\ttotal: 11.7s\tremaining: 58.1s\n",
      "839:\tlearn: 0.6139836\ttest: 0.6084803\tbest: 0.6084803 (839)\ttotal: 11.7s\tremaining: 58s\n",
      "840:\tlearn: 0.6139693\ttest: 0.6084663\tbest: 0.6084663 (840)\ttotal: 11.7s\tremaining: 58.1s\n",
      "841:\tlearn: 0.6139691\ttest: 0.6084663\tbest: 0.6084663 (840)\ttotal: 11.8s\tremaining: 58s\n",
      "842:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (842)\ttotal: 11.8s\tremaining: 58.1s\n",
      "843:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (843)\ttotal: 11.8s\tremaining: 58s\n",
      "844:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (844)\ttotal: 11.8s\tremaining: 58s\n",
      "845:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (845)\ttotal: 11.8s\tremaining: 58s\n",
      "846:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (846)\ttotal: 11.8s\tremaining: 57.9s\n",
      "847:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (847)\ttotal: 11.8s\tremaining: 57.9s\n",
      "848:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (848)\ttotal: 11.8s\tremaining: 57.9s\n",
      "849:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (849)\ttotal: 11.9s\tremaining: 57.9s\n",
      "850:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (850)\ttotal: 11.9s\tremaining: 57.9s\n",
      "851:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (851)\ttotal: 11.9s\tremaining: 57.9s\n",
      "852:\tlearn: 0.6139480\ttest: 0.6084474\tbest: 0.6084474 (852)\ttotal: 11.9s\tremaining: 57.8s\n",
      "853:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (853)\ttotal: 11.9s\tremaining: 57.9s\n",
      "854:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (854)\ttotal: 11.9s\tremaining: 57.9s\n",
      "855:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (855)\ttotal: 12s\tremaining: 57.9s\n",
      "856:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (856)\ttotal: 12s\tremaining: 57.8s\n",
      "857:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (857)\ttotal: 12s\tremaining: 57.8s\n",
      "858:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (858)\ttotal: 12s\tremaining: 57.8s\n",
      "859:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (859)\ttotal: 12s\tremaining: 57.8s\n",
      "860:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (860)\ttotal: 12s\tremaining: 57.7s\n",
      "861:\tlearn: 0.6138357\ttest: 0.6083180\tbest: 0.6083180 (861)\ttotal: 12s\tremaining: 57.7s\n",
      "862:\tlearn: 0.6138287\ttest: 0.6083126\tbest: 0.6083126 (862)\ttotal: 12s\tremaining: 57.7s\n",
      "863:\tlearn: 0.6138085\ttest: 0.6082851\tbest: 0.6082851 (863)\ttotal: 12s\tremaining: 57.7s\n",
      "864:\tlearn: 0.6138085\ttest: 0.6082851\tbest: 0.6082851 (864)\ttotal: 12.1s\tremaining: 57.7s\n",
      "865:\tlearn: 0.6138085\ttest: 0.6082851\tbest: 0.6082851 (865)\ttotal: 12.1s\tremaining: 57.6s\n",
      "866:\tlearn: 0.6138085\ttest: 0.6082851\tbest: 0.6082851 (866)\ttotal: 12.1s\tremaining: 57.6s\n",
      "867:\tlearn: 0.6138004\ttest: 0.6082784\tbest: 0.6082784 (867)\ttotal: 12.1s\tremaining: 57.6s\n",
      "868:\tlearn: 0.6137925\ttest: 0.6082757\tbest: 0.6082757 (868)\ttotal: 12.1s\tremaining: 57.6s\n",
      "869:\tlearn: 0.6137925\ttest: 0.6082757\tbest: 0.6082757 (869)\ttotal: 12.1s\tremaining: 57.6s\n",
      "870:\tlearn: 0.6136286\ttest: 0.6081090\tbest: 0.6081090 (870)\ttotal: 12.2s\tremaining: 57.7s\n",
      "871:\tlearn: 0.6136286\ttest: 0.6081090\tbest: 0.6081090 (871)\ttotal: 12.2s\tremaining: 57.7s\n",
      "872:\tlearn: 0.6136116\ttest: 0.6080820\tbest: 0.6080820 (872)\ttotal: 12.2s\tremaining: 57.7s\n",
      "873:\tlearn: 0.6136116\ttest: 0.6080820\tbest: 0.6080820 (873)\ttotal: 12.2s\tremaining: 57.7s\n",
      "874:\tlearn: 0.6136026\ttest: 0.6080734\tbest: 0.6080734 (874)\ttotal: 12.2s\tremaining: 57.7s\n",
      "875:\tlearn: 0.6135658\ttest: 0.6080212\tbest: 0.6080212 (875)\ttotal: 12.3s\tremaining: 57.7s\n",
      "876:\tlearn: 0.6135555\ttest: 0.6080112\tbest: 0.6080112 (876)\ttotal: 12.3s\tremaining: 57.7s\n",
      "877:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (877)\ttotal: 12.3s\tremaining: 57.7s\n",
      "878:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (878)\ttotal: 12.3s\tremaining: 57.7s\n",
      "879:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (879)\ttotal: 12.3s\tremaining: 57.7s\n",
      "880:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (880)\ttotal: 12.3s\tremaining: 57.7s\n",
      "881:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (881)\ttotal: 12.3s\tremaining: 57.6s\n",
      "882:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (882)\ttotal: 12.4s\tremaining: 57.6s\n",
      "883:\tlearn: 0.6135144\ttest: 0.6079769\tbest: 0.6079769 (883)\ttotal: 12.4s\tremaining: 57.6s\n",
      "884:\tlearn: 0.6133959\ttest: 0.6078522\tbest: 0.6078522 (884)\ttotal: 12.4s\tremaining: 57.6s\n",
      "885:\tlearn: 0.6133358\ttest: 0.6077793\tbest: 0.6077793 (885)\ttotal: 12.4s\tremaining: 57.6s\n",
      "886:\tlearn: 0.6133345\ttest: 0.6077791\tbest: 0.6077791 (886)\ttotal: 12.4s\tremaining: 57.6s\n",
      "887:\tlearn: 0.6133345\ttest: 0.6077791\tbest: 0.6077791 (887)\ttotal: 12.4s\tremaining: 57.6s\n",
      "888:\tlearn: 0.6133345\ttest: 0.6077791\tbest: 0.6077791 (888)\ttotal: 12.4s\tremaining: 57.6s\n",
      "889:\tlearn: 0.6133345\ttest: 0.6077791\tbest: 0.6077791 (889)\ttotal: 12.5s\tremaining: 57.5s\n",
      "890:\tlearn: 0.6132517\ttest: 0.6076821\tbest: 0.6076821 (890)\ttotal: 12.5s\tremaining: 57.5s\n",
      "891:\tlearn: 0.6132517\ttest: 0.6076821\tbest: 0.6076821 (891)\ttotal: 12.5s\tremaining: 57.5s\n",
      "892:\tlearn: 0.6132462\ttest: 0.6076764\tbest: 0.6076764 (892)\ttotal: 12.5s\tremaining: 57.5s\n",
      "893:\tlearn: 0.6131604\ttest: 0.6075741\tbest: 0.6075741 (893)\ttotal: 12.5s\tremaining: 57.5s\n",
      "894:\tlearn: 0.6131539\ttest: 0.6075691\tbest: 0.6075691 (894)\ttotal: 12.5s\tremaining: 57.5s\n",
      "895:\tlearn: 0.6131539\ttest: 0.6075691\tbest: 0.6075691 (895)\ttotal: 12.5s\tremaining: 57.5s\n",
      "896:\tlearn: 0.6131539\ttest: 0.6075691\tbest: 0.6075691 (896)\ttotal: 12.6s\tremaining: 57.4s\n",
      "897:\tlearn: 0.6131539\ttest: 0.6075690\tbest: 0.6075690 (897)\ttotal: 12.6s\tremaining: 57.4s\n",
      "898:\tlearn: 0.6131539\ttest: 0.6075690\tbest: 0.6075690 (898)\ttotal: 12.6s\tremaining: 57.4s\n",
      "899:\tlearn: 0.6131539\ttest: 0.6075690\tbest: 0.6075690 (899)\ttotal: 12.6s\tremaining: 57.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900:\tlearn: 0.6131539\ttest: 0.6075690\tbest: 0.6075690 (900)\ttotal: 12.6s\tremaining: 57.4s\n",
      "901:\tlearn: 0.6131539\ttest: 0.6075690\tbest: 0.6075690 (901)\ttotal: 12.6s\tremaining: 57.3s\n",
      "902:\tlearn: 0.6131524\ttest: 0.6075688\tbest: 0.6075688 (902)\ttotal: 12.6s\tremaining: 57.3s\n",
      "903:\tlearn: 0.6131434\ttest: 0.6075644\tbest: 0.6075644 (903)\ttotal: 12.7s\tremaining: 57.3s\n",
      "904:\tlearn: 0.6131434\ttest: 0.6075644\tbest: 0.6075644 (904)\ttotal: 12.7s\tremaining: 57.3s\n",
      "905:\tlearn: 0.6131434\ttest: 0.6075644\tbest: 0.6075644 (905)\ttotal: 12.7s\tremaining: 57.3s\n",
      "906:\tlearn: 0.6130984\ttest: 0.6075297\tbest: 0.6075297 (906)\ttotal: 12.7s\tremaining: 57.3s\n",
      "907:\tlearn: 0.6130748\ttest: 0.6074949\tbest: 0.6074949 (907)\ttotal: 12.7s\tremaining: 57.3s\n",
      "908:\tlearn: 0.6130748\ttest: 0.6074949\tbest: 0.6074949 (908)\ttotal: 12.7s\tremaining: 57.3s\n",
      "909:\tlearn: 0.6130748\ttest: 0.6074949\tbest: 0.6074949 (909)\ttotal: 12.7s\tremaining: 57.3s\n",
      "910:\tlearn: 0.6130439\ttest: 0.6074530\tbest: 0.6074530 (910)\ttotal: 12.8s\tremaining: 57.3s\n",
      "911:\tlearn: 0.6130439\ttest: 0.6074530\tbest: 0.6074530 (911)\ttotal: 12.8s\tremaining: 57.3s\n",
      "912:\tlearn: 0.6130340\ttest: 0.6074453\tbest: 0.6074453 (912)\ttotal: 12.8s\tremaining: 57.3s\n",
      "913:\tlearn: 0.6130340\ttest: 0.6074453\tbest: 0.6074453 (913)\ttotal: 12.8s\tremaining: 57.3s\n",
      "914:\tlearn: 0.6130340\ttest: 0.6074453\tbest: 0.6074453 (914)\ttotal: 12.8s\tremaining: 57.3s\n",
      "915:\tlearn: 0.6130340\ttest: 0.6074453\tbest: 0.6074453 (915)\ttotal: 12.8s\tremaining: 57.2s\n",
      "916:\tlearn: 0.6130340\ttest: 0.6074453\tbest: 0.6074453 (916)\ttotal: 12.9s\tremaining: 57.2s\n",
      "917:\tlearn: 0.6130340\ttest: 0.6074453\tbest: 0.6074453 (917)\ttotal: 12.9s\tremaining: 57.2s\n",
      "918:\tlearn: 0.6129818\ttest: 0.6074003\tbest: 0.6074003 (918)\ttotal: 12.9s\tremaining: 57.3s\n",
      "919:\tlearn: 0.6129739\ttest: 0.6073896\tbest: 0.6073896 (919)\ttotal: 12.9s\tremaining: 57.3s\n",
      "920:\tlearn: 0.6129709\ttest: 0.6073885\tbest: 0.6073885 (920)\ttotal: 12.9s\tremaining: 57.3s\n",
      "921:\tlearn: 0.6129559\ttest: 0.6073694\tbest: 0.6073694 (921)\ttotal: 12.9s\tremaining: 57.3s\n",
      "922:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (922)\ttotal: 13s\tremaining: 57.3s\n",
      "923:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (923)\ttotal: 13s\tremaining: 57.3s\n",
      "924:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (924)\ttotal: 13s\tremaining: 57.3s\n",
      "925:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (925)\ttotal: 13s\tremaining: 57.2s\n",
      "926:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (926)\ttotal: 13s\tremaining: 57.2s\n",
      "927:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (927)\ttotal: 13s\tremaining: 57.2s\n",
      "928:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (928)\ttotal: 13.1s\tremaining: 57.2s\n",
      "929:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (929)\ttotal: 13.1s\tremaining: 57.2s\n",
      "930:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (930)\ttotal: 13.1s\tremaining: 57.1s\n",
      "931:\tlearn: 0.6129439\ttest: 0.6073585\tbest: 0.6073585 (931)\ttotal: 13.1s\tremaining: 57.1s\n",
      "932:\tlearn: 0.6129293\ttest: 0.6073372\tbest: 0.6073372 (932)\ttotal: 13.1s\tremaining: 57.1s\n",
      "933:\tlearn: 0.6129293\ttest: 0.6073372\tbest: 0.6073372 (933)\ttotal: 13.1s\tremaining: 57.1s\n",
      "934:\tlearn: 0.6129293\ttest: 0.6073372\tbest: 0.6073372 (934)\ttotal: 13.1s\tremaining: 57.1s\n",
      "935:\tlearn: 0.6129293\ttest: 0.6073372\tbest: 0.6073372 (935)\ttotal: 13.2s\tremaining: 57.1s\n",
      "936:\tlearn: 0.6129136\ttest: 0.6073153\tbest: 0.6073153 (936)\ttotal: 13.2s\tremaining: 57.1s\n",
      "937:\tlearn: 0.6129136\ttest: 0.6073153\tbest: 0.6073153 (937)\ttotal: 13.2s\tremaining: 57.1s\n",
      "938:\tlearn: 0.6129136\ttest: 0.6073153\tbest: 0.6073153 (938)\ttotal: 13.2s\tremaining: 57.1s\n",
      "939:\tlearn: 0.6129058\ttest: 0.6073077\tbest: 0.6073077 (939)\ttotal: 13.2s\tremaining: 57.1s\n",
      "940:\tlearn: 0.6129058\ttest: 0.6073077\tbest: 0.6073077 (940)\ttotal: 13.2s\tremaining: 57.1s\n",
      "941:\tlearn: 0.6129002\ttest: 0.6073043\tbest: 0.6073043 (941)\ttotal: 13.2s\tremaining: 57.1s\n",
      "942:\tlearn: 0.6129002\ttest: 0.6073043\tbest: 0.6073043 (942)\ttotal: 13.3s\tremaining: 57s\n",
      "943:\tlearn: 0.6128940\ttest: 0.6072996\tbest: 0.6072996 (943)\ttotal: 13.3s\tremaining: 57s\n",
      "944:\tlearn: 0.6128940\ttest: 0.6072996\tbest: 0.6072996 (944)\ttotal: 13.3s\tremaining: 57s\n",
      "945:\tlearn: 0.6128940\ttest: 0.6072996\tbest: 0.6072996 (945)\ttotal: 13.3s\tremaining: 57s\n",
      "946:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.3s\tremaining: 57s\n",
      "947:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.3s\tremaining: 56.9s\n",
      "948:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.3s\tremaining: 56.9s\n",
      "949:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.3s\tremaining: 56.9s\n",
      "950:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.4s\tremaining: 56.9s\n",
      "951:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.4s\tremaining: 56.8s\n",
      "952:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.4s\tremaining: 56.8s\n",
      "953:\tlearn: 0.6128933\ttest: 0.6072998\tbest: 0.6072996 (945)\ttotal: 13.4s\tremaining: 56.8s\n",
      "954:\tlearn: 0.6128817\ttest: 0.6072893\tbest: 0.6072893 (954)\ttotal: 13.4s\tremaining: 56.8s\n",
      "955:\tlearn: 0.6128817\ttest: 0.6072893\tbest: 0.6072893 (955)\ttotal: 13.4s\tremaining: 56.7s\n",
      "956:\tlearn: 0.6128727\ttest: 0.6072771\tbest: 0.6072771 (956)\ttotal: 13.4s\tremaining: 56.7s\n",
      "957:\tlearn: 0.6128683\ttest: 0.6072728\tbest: 0.6072728 (957)\ttotal: 13.4s\tremaining: 56.7s\n",
      "958:\tlearn: 0.6128607\ttest: 0.6072701\tbest: 0.6072701 (958)\ttotal: 13.5s\tremaining: 56.7s\n",
      "959:\tlearn: 0.6128607\ttest: 0.6072701\tbest: 0.6072701 (959)\ttotal: 13.5s\tremaining: 56.7s\n",
      "960:\tlearn: 0.6128607\ttest: 0.6072701\tbest: 0.6072701 (960)\ttotal: 13.5s\tremaining: 56.7s\n",
      "961:\tlearn: 0.6128335\ttest: 0.6072318\tbest: 0.6072318 (961)\ttotal: 13.5s\tremaining: 56.7s\n",
      "962:\tlearn: 0.6128335\ttest: 0.6072318\tbest: 0.6072318 (962)\ttotal: 13.5s\tremaining: 56.7s\n",
      "963:\tlearn: 0.6127977\ttest: 0.6071994\tbest: 0.6071994 (963)\ttotal: 13.6s\tremaining: 56.7s\n",
      "964:\tlearn: 0.6127977\ttest: 0.6071994\tbest: 0.6071994 (964)\ttotal: 13.6s\tremaining: 56.7s\n",
      "965:\tlearn: 0.6127969\ttest: 0.6071987\tbest: 0.6071987 (965)\ttotal: 13.6s\tremaining: 56.7s\n",
      "966:\tlearn: 0.6127969\ttest: 0.6071987\tbest: 0.6071987 (966)\ttotal: 13.6s\tremaining: 56.8s\n",
      "967:\tlearn: 0.6127802\ttest: 0.6071772\tbest: 0.6071772 (967)\ttotal: 13.6s\tremaining: 56.8s\n",
      "968:\tlearn: 0.6127398\ttest: 0.6071274\tbest: 0.6071274 (968)\ttotal: 13.7s\tremaining: 56.8s\n",
      "969:\tlearn: 0.6127334\ttest: 0.6071231\tbest: 0.6071231 (969)\ttotal: 13.7s\tremaining: 56.8s\n",
      "970:\tlearn: 0.6127334\ttest: 0.6071231\tbest: 0.6071231 (969)\ttotal: 13.7s\tremaining: 56.8s\n",
      "971:\tlearn: 0.6127334\ttest: 0.6071231\tbest: 0.6071231 (969)\ttotal: 13.7s\tremaining: 56.8s\n",
      "972:\tlearn: 0.6127334\ttest: 0.6071231\tbest: 0.6071231 (969)\ttotal: 13.7s\tremaining: 56.8s\n",
      "973:\tlearn: 0.6126950\ttest: 0.6070759\tbest: 0.6070759 (973)\ttotal: 13.7s\tremaining: 56.8s\n",
      "974:\tlearn: 0.6126950\ttest: 0.6070759\tbest: 0.6070759 (973)\ttotal: 13.8s\tremaining: 56.8s\n",
      "975:\tlearn: 0.6126950\ttest: 0.6070759\tbest: 0.6070759 (973)\ttotal: 13.8s\tremaining: 56.8s\n",
      "976:\tlearn: 0.6126948\ttest: 0.6070752\tbest: 0.6070752 (976)\ttotal: 13.8s\tremaining: 56.8s\n",
      "977:\tlearn: 0.6126948\ttest: 0.6070752\tbest: 0.6070752 (976)\ttotal: 13.8s\tremaining: 56.8s\n",
      "978:\tlearn: 0.6126948\ttest: 0.6070752\tbest: 0.6070752 (976)\ttotal: 13.8s\tremaining: 56.8s\n",
      "979:\tlearn: 0.6126874\ttest: 0.6070680\tbest: 0.6070680 (979)\ttotal: 13.8s\tremaining: 56.8s\n",
      "980:\tlearn: 0.6126874\ttest: 0.6070680\tbest: 0.6070680 (979)\ttotal: 13.8s\tremaining: 56.7s\n",
      "981:\tlearn: 0.6126874\ttest: 0.6070680\tbest: 0.6070680 (979)\ttotal: 13.9s\tremaining: 56.7s\n",
      "982:\tlearn: 0.6126874\ttest: 0.6070680\tbest: 0.6070680 (979)\ttotal: 13.9s\tremaining: 56.7s\n",
      "983:\tlearn: 0.6126874\ttest: 0.6070680\tbest: 0.6070680 (979)\ttotal: 13.9s\tremaining: 56.7s\n",
      "984:\tlearn: 0.6126874\ttest: 0.6070680\tbest: 0.6070680 (979)\ttotal: 13.9s\tremaining: 56.7s\n",
      "985:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 13.9s\tremaining: 56.7s\n",
      "986:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 13.9s\tremaining: 56.7s\n",
      "987:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 14s\tremaining: 56.7s\n",
      "988:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 14s\tremaining: 56.7s\n",
      "989:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 14s\tremaining: 56.6s\n",
      "990:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 14s\tremaining: 56.6s\n",
      "991:\tlearn: 0.6126817\ttest: 0.6070637\tbest: 0.6070637 (985)\ttotal: 14s\tremaining: 56.6s\n",
      "992:\tlearn: 0.6126745\ttest: 0.6070568\tbest: 0.6070568 (992)\ttotal: 14s\tremaining: 56.6s\n",
      "993:\tlearn: 0.6126636\ttest: 0.6070469\tbest: 0.6070469 (993)\ttotal: 14s\tremaining: 56.6s\n",
      "994:\tlearn: 0.6126636\ttest: 0.6070469\tbest: 0.6070469 (993)\ttotal: 14.1s\tremaining: 56.6s\n",
      "995:\tlearn: 0.6126636\ttest: 0.6070469\tbest: 0.6070469 (993)\ttotal: 14.1s\tremaining: 56.6s\n",
      "996:\tlearn: 0.6126636\ttest: 0.6070469\tbest: 0.6070469 (993)\ttotal: 14.1s\tremaining: 56.6s\n",
      "997:\tlearn: 0.6126586\ttest: 0.6070411\tbest: 0.6070411 (997)\ttotal: 14.1s\tremaining: 56.6s\n",
      "998:\tlearn: 0.6126586\ttest: 0.6070411\tbest: 0.6070411 (997)\ttotal: 14.1s\tremaining: 56.6s\n",
      "999:\tlearn: 0.6126586\ttest: 0.6070411\tbest: 0.6070411 (997)\ttotal: 14.1s\tremaining: 56.6s\n",
      "1000:\tlearn: 0.6126586\ttest: 0.6070411\tbest: 0.6070411 (997)\ttotal: 14.2s\tremaining: 56.6s\n",
      "1001:\tlearn: 0.6126586\ttest: 0.6070411\tbest: 0.6070411 (997)\ttotal: 14.2s\tremaining: 56.5s\n",
      "1002:\tlearn: 0.6126568\ttest: 0.6070372\tbest: 0.6070372 (1002)\ttotal: 14.2s\tremaining: 56.5s\n",
      "1003:\tlearn: 0.6126568\ttest: 0.6070372\tbest: 0.6070372 (1002)\ttotal: 14.2s\tremaining: 56.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004:\tlearn: 0.6126535\ttest: 0.6070349\tbest: 0.6070349 (1004)\ttotal: 14.2s\tremaining: 56.5s\n",
      "1005:\tlearn: 0.6126535\ttest: 0.6070349\tbest: 0.6070349 (1004)\ttotal: 14.2s\tremaining: 56.5s\n",
      "1006:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.2s\tremaining: 56.5s\n",
      "1007:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.5s\n",
      "1008:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.4s\n",
      "1009:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.4s\n",
      "1010:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.4s\n",
      "1011:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.4s\n",
      "1012:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.3s\n",
      "1013:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.3s\n",
      "1014:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.3s\n",
      "1015:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.3s\tremaining: 56.3s\n",
      "1016:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1017:\tlearn: 0.6126494\ttest: 0.6070309\tbest: 0.6070309 (1006)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1018:\tlearn: 0.6126427\ttest: 0.6070284\tbest: 0.6070284 (1018)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1019:\tlearn: 0.6126321\ttest: 0.6070189\tbest: 0.6070189 (1019)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1020:\tlearn: 0.6126088\ttest: 0.6069895\tbest: 0.6069895 (1020)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1021:\tlearn: 0.6126088\ttest: 0.6069895\tbest: 0.6069895 (1020)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1022:\tlearn: 0.6126088\ttest: 0.6069895\tbest: 0.6069895 (1020)\ttotal: 14.4s\tremaining: 56.2s\n",
      "1023:\tlearn: 0.6125976\ttest: 0.6069804\tbest: 0.6069804 (1023)\ttotal: 14.5s\tremaining: 56.2s\n",
      "1024:\tlearn: 0.6125976\ttest: 0.6069804\tbest: 0.6069804 (1023)\ttotal: 14.5s\tremaining: 56.2s\n",
      "1025:\tlearn: 0.6125976\ttest: 0.6069804\tbest: 0.6069804 (1023)\ttotal: 14.5s\tremaining: 56.1s\n",
      "1026:\tlearn: 0.6125404\ttest: 0.6069190\tbest: 0.6069190 (1026)\ttotal: 14.5s\tremaining: 56.2s\n",
      "1027:\tlearn: 0.6125404\ttest: 0.6069190\tbest: 0.6069190 (1026)\ttotal: 14.5s\tremaining: 56.1s\n",
      "1028:\tlearn: 0.6125212\ttest: 0.6069018\tbest: 0.6069018 (1028)\ttotal: 14.5s\tremaining: 56.1s\n",
      "1029:\tlearn: 0.6125212\ttest: 0.6069018\tbest: 0.6069018 (1028)\ttotal: 14.6s\tremaining: 56.1s\n",
      "1030:\tlearn: 0.6125212\ttest: 0.6069018\tbest: 0.6069018 (1028)\ttotal: 14.6s\tremaining: 56.1s\n",
      "1031:\tlearn: 0.6125115\ttest: 0.6068944\tbest: 0.6068944 (1031)\ttotal: 14.6s\tremaining: 56.1s\n",
      "1032:\tlearn: 0.6125115\ttest: 0.6068944\tbest: 0.6068944 (1031)\ttotal: 14.6s\tremaining: 56s\n",
      "1033:\tlearn: 0.6125115\ttest: 0.6068944\tbest: 0.6068944 (1031)\ttotal: 14.6s\tremaining: 56s\n",
      "1034:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.6s\tremaining: 56s\n",
      "1035:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.6s\tremaining: 56s\n",
      "1036:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.6s\tremaining: 56s\n",
      "1037:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.7s\tremaining: 55.9s\n",
      "1038:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.7s\tremaining: 55.9s\n",
      "1039:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.7s\tremaining: 55.9s\n",
      "1040:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.7s\tremaining: 55.8s\n",
      "1041:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.7s\tremaining: 55.8s\n",
      "1042:\tlearn: 0.6124390\ttest: 0.6068073\tbest: 0.6068073 (1034)\ttotal: 14.7s\tremaining: 55.8s\n",
      "1043:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.7s\tremaining: 55.8s\n",
      "1044:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.7s\tremaining: 55.8s\n",
      "1045:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.7s\tremaining: 55.7s\n",
      "1046:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1047:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1048:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1049:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1050:\tlearn: 0.6124336\ttest: 0.6068033\tbest: 0.6068033 (1043)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1051:\tlearn: 0.6123192\ttest: 0.6066607\tbest: 0.6066607 (1051)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1052:\tlearn: 0.6123192\ttest: 0.6066607\tbest: 0.6066607 (1052)\ttotal: 14.8s\tremaining: 55.7s\n",
      "1053:\tlearn: 0.6123192\ttest: 0.6066607\tbest: 0.6066607 (1053)\ttotal: 14.9s\tremaining: 55.6s\n",
      "1054:\tlearn: 0.6123139\ttest: 0.6066570\tbest: 0.6066570 (1054)\ttotal: 14.9s\tremaining: 55.7s\n",
      "1055:\tlearn: 0.6123139\ttest: 0.6066570\tbest: 0.6066570 (1055)\ttotal: 14.9s\tremaining: 55.6s\n",
      "1056:\tlearn: 0.6122896\ttest: 0.6066309\tbest: 0.6066309 (1056)\ttotal: 14.9s\tremaining: 55.6s\n",
      "1057:\tlearn: 0.6122896\ttest: 0.6066309\tbest: 0.6066309 (1057)\ttotal: 14.9s\tremaining: 55.6s\n",
      "1058:\tlearn: 0.6122896\ttest: 0.6066309\tbest: 0.6066309 (1058)\ttotal: 14.9s\tremaining: 55.6s\n",
      "1059:\tlearn: 0.6122896\ttest: 0.6066309\tbest: 0.6066309 (1059)\ttotal: 14.9s\tremaining: 55.6s\n",
      "1060:\tlearn: 0.6122823\ttest: 0.6066244\tbest: 0.6066244 (1060)\ttotal: 15s\tremaining: 55.6s\n",
      "1061:\tlearn: 0.6122732\ttest: 0.6066177\tbest: 0.6066177 (1061)\ttotal: 15s\tremaining: 55.5s\n",
      "1062:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1062)\ttotal: 15s\tremaining: 55.6s\n",
      "1063:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1063)\ttotal: 15s\tremaining: 55.5s\n",
      "1064:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1064)\ttotal: 15s\tremaining: 55.5s\n",
      "1065:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1065)\ttotal: 15s\tremaining: 55.5s\n",
      "1066:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1066)\ttotal: 15s\tremaining: 55.5s\n",
      "1067:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1067)\ttotal: 15.1s\tremaining: 55.4s\n",
      "1068:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1068)\ttotal: 15.1s\tremaining: 55.4s\n",
      "1069:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1069)\ttotal: 15.1s\tremaining: 55.4s\n",
      "1070:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1070)\ttotal: 15.1s\tremaining: 55.4s\n",
      "1071:\tlearn: 0.6122497\ttest: 0.6065930\tbest: 0.6065930 (1071)\ttotal: 15.1s\tremaining: 55.3s\n",
      "1072:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1072)\ttotal: 15.1s\tremaining: 55.3s\n",
      "1073:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1073)\ttotal: 15.1s\tremaining: 55.3s\n",
      "1074:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1074)\ttotal: 15.1s\tremaining: 55.3s\n",
      "1075:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1075)\ttotal: 15.2s\tremaining: 55.3s\n",
      "1076:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1076)\ttotal: 15.2s\tremaining: 55.2s\n",
      "1077:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1077)\ttotal: 15.2s\tremaining: 55.2s\n",
      "1078:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1078)\ttotal: 15.2s\tremaining: 55.2s\n",
      "1079:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1079)\ttotal: 15.2s\tremaining: 55.2s\n",
      "1080:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1080)\ttotal: 15.2s\tremaining: 55.1s\n",
      "1081:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1081)\ttotal: 15.2s\tremaining: 55.1s\n",
      "1082:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1082)\ttotal: 15.2s\tremaining: 55.1s\n",
      "1083:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1083)\ttotal: 15.3s\tremaining: 55.1s\n",
      "1084:\tlearn: 0.6122379\ttest: 0.6065774\tbest: 0.6065774 (1084)\ttotal: 15.3s\tremaining: 55.1s\n",
      "1085:\tlearn: 0.6122029\ttest: 0.6065552\tbest: 0.6065552 (1085)\ttotal: 15.3s\tremaining: 55.1s\n",
      "1086:\tlearn: 0.6122029\ttest: 0.6065552\tbest: 0.6065552 (1086)\ttotal: 15.3s\tremaining: 55.1s\n",
      "1087:\tlearn: 0.6121792\ttest: 0.6065349\tbest: 0.6065349 (1087)\ttotal: 15.3s\tremaining: 55.1s\n",
      "1088:\tlearn: 0.6121792\ttest: 0.6065349\tbest: 0.6065349 (1088)\ttotal: 15.3s\tremaining: 55.1s\n",
      "1089:\tlearn: 0.6121792\ttest: 0.6065349\tbest: 0.6065349 (1089)\ttotal: 15.4s\tremaining: 55.1s\n",
      "1090:\tlearn: 0.6121792\ttest: 0.6065349\tbest: 0.6065349 (1090)\ttotal: 15.4s\tremaining: 55.1s\n",
      "1091:\tlearn: 0.6121792\ttest: 0.6065349\tbest: 0.6065349 (1091)\ttotal: 15.4s\tremaining: 55s\n",
      "1092:\tlearn: 0.6121550\ttest: 0.6065084\tbest: 0.6065084 (1092)\ttotal: 15.4s\tremaining: 55.1s\n",
      "1093:\tlearn: 0.6121550\ttest: 0.6065084\tbest: 0.6065084 (1092)\ttotal: 15.4s\tremaining: 55s\n",
      "1094:\tlearn: 0.6121550\ttest: 0.6065084\tbest: 0.6065084 (1092)\ttotal: 15.4s\tremaining: 55s\n",
      "1095:\tlearn: 0.6121550\ttest: 0.6065084\tbest: 0.6065084 (1092)\ttotal: 15.4s\tremaining: 55s\n",
      "1096:\tlearn: 0.6121550\ttest: 0.6065084\tbest: 0.6065084 (1092)\ttotal: 15.4s\tremaining: 55s\n",
      "1097:\tlearn: 0.6121477\ttest: 0.6065040\tbest: 0.6065040 (1097)\ttotal: 15.5s\tremaining: 55s\n",
      "1098:\tlearn: 0.6121477\ttest: 0.6065040\tbest: 0.6065040 (1097)\ttotal: 15.5s\tremaining: 55s\n",
      "1099:\tlearn: 0.6121477\ttest: 0.6065040\tbest: 0.6065040 (1097)\ttotal: 15.5s\tremaining: 54.9s\n",
      "1100:\tlearn: 0.6121445\ttest: 0.6065023\tbest: 0.6065023 (1100)\ttotal: 15.5s\tremaining: 54.9s\n",
      "1101:\tlearn: 0.6121258\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.5s\tremaining: 54.9s\n",
      "1102:\tlearn: 0.6121258\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.5s\tremaining: 54.9s\n",
      "1103:\tlearn: 0.6121258\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.9s\n",
      "1104:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.9s\n",
      "1105:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.9s\n",
      "1106:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.8s\n",
      "1108:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.8s\n",
      "1109:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.8s\n",
      "1110:\tlearn: 0.6121255\ttest: 0.6064888\tbest: 0.6064888 (1101)\ttotal: 15.6s\tremaining: 54.7s\n",
      "1111:\tlearn: 0.6121184\ttest: 0.6064790\tbest: 0.6064790 (1111)\ttotal: 15.6s\tremaining: 54.7s\n",
      "1112:\tlearn: 0.6121184\ttest: 0.6064790\tbest: 0.6064790 (1111)\ttotal: 15.7s\tremaining: 54.7s\n",
      "1113:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1113)\ttotal: 15.7s\tremaining: 54.7s\n",
      "1114:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1114)\ttotal: 15.7s\tremaining: 54.7s\n",
      "1115:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1115)\ttotal: 15.7s\tremaining: 54.6s\n",
      "1116:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1116)\ttotal: 15.7s\tremaining: 54.6s\n",
      "1117:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1117)\ttotal: 15.7s\tremaining: 54.6s\n",
      "1118:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1118)\ttotal: 15.7s\tremaining: 54.6s\n",
      "1119:\tlearn: 0.6120374\ttest: 0.6063948\tbest: 0.6063948 (1119)\ttotal: 15.7s\tremaining: 54.5s\n",
      "1120:\tlearn: 0.6120262\ttest: 0.6063800\tbest: 0.6063800 (1120)\ttotal: 15.8s\tremaining: 54.5s\n",
      "1121:\tlearn: 0.6120262\ttest: 0.6063800\tbest: 0.6063800 (1121)\ttotal: 15.8s\tremaining: 54.5s\n",
      "1122:\tlearn: 0.6120175\ttest: 0.6063736\tbest: 0.6063736 (1122)\ttotal: 15.8s\tremaining: 54.5s\n",
      "1123:\tlearn: 0.6120094\ttest: 0.6063687\tbest: 0.6063687 (1123)\ttotal: 15.8s\tremaining: 54.5s\n",
      "1124:\tlearn: 0.6120094\ttest: 0.6063687\tbest: 0.6063687 (1123)\ttotal: 15.8s\tremaining: 54.5s\n",
      "1125:\tlearn: 0.6120047\ttest: 0.6063653\tbest: 0.6063653 (1125)\ttotal: 15.8s\tremaining: 54.5s\n",
      "1126:\tlearn: 0.6120047\ttest: 0.6063653\tbest: 0.6063653 (1125)\ttotal: 15.9s\tremaining: 54.5s\n",
      "1127:\tlearn: 0.6119696\ttest: 0.6063247\tbest: 0.6063247 (1127)\ttotal: 15.9s\tremaining: 54.5s\n",
      "1128:\tlearn: 0.6119695\ttest: 0.6063247\tbest: 0.6063247 (1127)\ttotal: 15.9s\tremaining: 54.5s\n",
      "1129:\tlearn: 0.6119695\ttest: 0.6063247\tbest: 0.6063247 (1127)\ttotal: 15.9s\tremaining: 54.5s\n",
      "1130:\tlearn: 0.6119626\ttest: 0.6063185\tbest: 0.6063185 (1130)\ttotal: 15.9s\tremaining: 54.5s\n",
      "1131:\tlearn: 0.6119496\ttest: 0.6063003\tbest: 0.6063003 (1131)\ttotal: 16s\tremaining: 54.5s\n",
      "1132:\tlearn: 0.6119496\ttest: 0.6063003\tbest: 0.6063003 (1131)\ttotal: 16s\tremaining: 54.5s\n",
      "1133:\tlearn: 0.6119496\ttest: 0.6063003\tbest: 0.6063003 (1131)\ttotal: 16s\tremaining: 54.5s\n",
      "1134:\tlearn: 0.6119436\ttest: 0.6062992\tbest: 0.6062992 (1134)\ttotal: 16s\tremaining: 54.6s\n",
      "1135:\tlearn: 0.6119308\ttest: 0.6062813\tbest: 0.6062813 (1135)\ttotal: 16s\tremaining: 54.6s\n",
      "1136:\tlearn: 0.6119238\ttest: 0.6062712\tbest: 0.6062712 (1136)\ttotal: 16.1s\tremaining: 54.6s\n",
      "1137:\tlearn: 0.6119238\ttest: 0.6062712\tbest: 0.6062712 (1136)\ttotal: 16.1s\tremaining: 54.6s\n",
      "1138:\tlearn: 0.6119112\ttest: 0.6062554\tbest: 0.6062554 (1138)\ttotal: 16.1s\tremaining: 54.5s\n",
      "1139:\tlearn: 0.6119112\ttest: 0.6062554\tbest: 0.6062554 (1138)\ttotal: 16.1s\tremaining: 54.5s\n",
      "1140:\tlearn: 0.6119112\ttest: 0.6062554\tbest: 0.6062554 (1138)\ttotal: 16.1s\tremaining: 54.5s\n",
      "1141:\tlearn: 0.6119112\ttest: 0.6062554\tbest: 0.6062554 (1138)\ttotal: 16.1s\tremaining: 54.5s\n",
      "1142:\tlearn: 0.6119096\ttest: 0.6062540\tbest: 0.6062540 (1142)\ttotal: 16.1s\tremaining: 54.5s\n",
      "1143:\tlearn: 0.6119096\ttest: 0.6062540\tbest: 0.6062540 (1142)\ttotal: 16.2s\tremaining: 54.5s\n",
      "1144:\tlearn: 0.6119096\ttest: 0.6062540\tbest: 0.6062540 (1142)\ttotal: 16.2s\tremaining: 54.5s\n",
      "1145:\tlearn: 0.6119096\ttest: 0.6062540\tbest: 0.6062540 (1142)\ttotal: 16.2s\tremaining: 54.5s\n",
      "1146:\tlearn: 0.6119096\ttest: 0.6062540\tbest: 0.6062540 (1142)\ttotal: 16.2s\tremaining: 54.5s\n",
      "1147:\tlearn: 0.6119096\ttest: 0.6062540\tbest: 0.6062540 (1142)\ttotal: 16.2s\tremaining: 54.5s\n",
      "1148:\tlearn: 0.6118247\ttest: 0.6061587\tbest: 0.6061587 (1148)\ttotal: 16.3s\tremaining: 54.5s\n",
      "1149:\tlearn: 0.6118247\ttest: 0.6061587\tbest: 0.6061587 (1149)\ttotal: 16.3s\tremaining: 54.5s\n",
      "1150:\tlearn: 0.6118247\ttest: 0.6061587\tbest: 0.6061587 (1150)\ttotal: 16.3s\tremaining: 54.4s\n",
      "1151:\tlearn: 0.6117438\ttest: 0.6060654\tbest: 0.6060654 (1151)\ttotal: 16.3s\tremaining: 54.4s\n",
      "1152:\tlearn: 0.6117372\ttest: 0.6060595\tbest: 0.6060595 (1152)\ttotal: 16.3s\tremaining: 54.4s\n",
      "1153:\tlearn: 0.6117257\ttest: 0.6060496\tbest: 0.6060496 (1153)\ttotal: 16.3s\tremaining: 54.4s\n",
      "1154:\tlearn: 0.6117075\ttest: 0.6060323\tbest: 0.6060323 (1154)\ttotal: 16.4s\tremaining: 54.4s\n",
      "1155:\tlearn: 0.6117075\ttest: 0.6060323\tbest: 0.6060323 (1155)\ttotal: 16.4s\tremaining: 54.4s\n",
      "1156:\tlearn: 0.6117075\ttest: 0.6060323\tbest: 0.6060323 (1156)\ttotal: 16.4s\tremaining: 54.4s\n",
      "1157:\tlearn: 0.6117075\ttest: 0.6060323\tbest: 0.6060323 (1157)\ttotal: 16.4s\tremaining: 54.4s\n",
      "1158:\tlearn: 0.6116772\ttest: 0.6059927\tbest: 0.6059927 (1158)\ttotal: 16.4s\tremaining: 54.4s\n",
      "1159:\tlearn: 0.6116772\ttest: 0.6059927\tbest: 0.6059927 (1159)\ttotal: 16.4s\tremaining: 54.4s\n",
      "1160:\tlearn: 0.6116772\ttest: 0.6059927\tbest: 0.6059927 (1160)\ttotal: 16.5s\tremaining: 54.4s\n",
      "1161:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1161)\ttotal: 16.5s\tremaining: 54.4s\n",
      "1162:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1162)\ttotal: 16.5s\tremaining: 54.4s\n",
      "1163:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1163)\ttotal: 16.5s\tremaining: 54.4s\n",
      "1164:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1164)\ttotal: 16.5s\tremaining: 54.4s\n",
      "1165:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1165)\ttotal: 16.5s\tremaining: 54.3s\n",
      "1166:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1166)\ttotal: 16.5s\tremaining: 54.3s\n",
      "1167:\tlearn: 0.6116725\ttest: 0.6059877\tbest: 0.6059877 (1167)\ttotal: 16.5s\tremaining: 54.3s\n",
      "1168:\tlearn: 0.6116674\ttest: 0.6059836\tbest: 0.6059836 (1168)\ttotal: 16.6s\tremaining: 54.3s\n",
      "1169:\tlearn: 0.6116603\ttest: 0.6059777\tbest: 0.6059777 (1169)\ttotal: 16.6s\tremaining: 54.3s\n",
      "1170:\tlearn: 0.6116603\ttest: 0.6059777\tbest: 0.6059777 (1170)\ttotal: 16.6s\tremaining: 54.2s\n",
      "1171:\tlearn: 0.6116603\ttest: 0.6059777\tbest: 0.6059777 (1171)\ttotal: 16.6s\tremaining: 54.2s\n",
      "1172:\tlearn: 0.6116603\ttest: 0.6059777\tbest: 0.6059777 (1172)\ttotal: 16.6s\tremaining: 54.2s\n",
      "1173:\tlearn: 0.6116603\ttest: 0.6059777\tbest: 0.6059777 (1173)\ttotal: 16.6s\tremaining: 54.2s\n",
      "1174:\tlearn: 0.6116486\ttest: 0.6059611\tbest: 0.6059611 (1174)\ttotal: 16.6s\tremaining: 54.2s\n",
      "1175:\tlearn: 0.6116486\ttest: 0.6059611\tbest: 0.6059611 (1175)\ttotal: 16.6s\tremaining: 54.1s\n",
      "1176:\tlearn: 0.6116486\ttest: 0.6059611\tbest: 0.6059611 (1176)\ttotal: 16.7s\tremaining: 54.1s\n",
      "1177:\tlearn: 0.6115657\ttest: 0.6058605\tbest: 0.6058605 (1177)\ttotal: 16.7s\tremaining: 54.1s\n",
      "1178:\tlearn: 0.6115657\ttest: 0.6058605\tbest: 0.6058605 (1178)\ttotal: 16.7s\tremaining: 54.1s\n",
      "1179:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1179)\ttotal: 16.7s\tremaining: 54.1s\n",
      "1180:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1180)\ttotal: 16.7s\tremaining: 54.1s\n",
      "1181:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1181)\ttotal: 16.7s\tremaining: 54.1s\n",
      "1182:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1182)\ttotal: 16.7s\tremaining: 54s\n",
      "1183:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1183)\ttotal: 16.8s\tremaining: 54s\n",
      "1184:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1184)\ttotal: 16.8s\tremaining: 54s\n",
      "1185:\tlearn: 0.6115509\ttest: 0.6058466\tbest: 0.6058466 (1185)\ttotal: 16.8s\tremaining: 54s\n",
      "1186:\tlearn: 0.6115502\ttest: 0.6058464\tbest: 0.6058464 (1186)\ttotal: 16.8s\tremaining: 54s\n",
      "1187:\tlearn: 0.6115502\ttest: 0.6058464\tbest: 0.6058464 (1187)\ttotal: 16.8s\tremaining: 53.9s\n",
      "1188:\tlearn: 0.6115502\ttest: 0.6058464\tbest: 0.6058464 (1188)\ttotal: 16.8s\tremaining: 53.9s\n",
      "1189:\tlearn: 0.6115502\ttest: 0.6058464\tbest: 0.6058464 (1189)\ttotal: 16.8s\tremaining: 53.9s\n",
      "1190:\tlearn: 0.6115502\ttest: 0.6058464\tbest: 0.6058464 (1190)\ttotal: 16.9s\tremaining: 53.9s\n",
      "1191:\tlearn: 0.6115216\ttest: 0.6058202\tbest: 0.6058202 (1191)\ttotal: 16.9s\tremaining: 53.9s\n",
      "1192:\tlearn: 0.6115138\ttest: 0.6058146\tbest: 0.6058146 (1192)\ttotal: 16.9s\tremaining: 53.9s\n",
      "1193:\tlearn: 0.6115138\ttest: 0.6058146\tbest: 0.6058146 (1193)\ttotal: 16.9s\tremaining: 53.9s\n",
      "1194:\tlearn: 0.6115138\ttest: 0.6058146\tbest: 0.6058146 (1194)\ttotal: 16.9s\tremaining: 53.9s\n",
      "1195:\tlearn: 0.6115082\ttest: 0.6058138\tbest: 0.6058138 (1195)\ttotal: 16.9s\tremaining: 53.9s\n",
      "1196:\tlearn: 0.6115082\ttest: 0.6058138\tbest: 0.6058138 (1196)\ttotal: 16.9s\tremaining: 53.8s\n",
      "1197:\tlearn: 0.6114443\ttest: 0.6057592\tbest: 0.6057592 (1197)\ttotal: 17s\tremaining: 53.9s\n",
      "1198:\tlearn: 0.6113828\ttest: 0.6056780\tbest: 0.6056780 (1198)\ttotal: 17s\tremaining: 53.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199:\tlearn: 0.6113745\ttest: 0.6056702\tbest: 0.6056702 (1199)\ttotal: 17s\tremaining: 53.9s\n",
      "1200:\tlearn: 0.6113745\ttest: 0.6056702\tbest: 0.6056702 (1200)\ttotal: 17s\tremaining: 53.9s\n",
      "1201:\tlearn: 0.6113745\ttest: 0.6056702\tbest: 0.6056702 (1201)\ttotal: 17s\tremaining: 53.9s\n",
      "1202:\tlearn: 0.6113745\ttest: 0.6056702\tbest: 0.6056702 (1202)\ttotal: 17.1s\tremaining: 53.8s\n",
      "1203:\tlearn: 0.6113745\ttest: 0.6056702\tbest: 0.6056702 (1203)\ttotal: 17.1s\tremaining: 53.9s\n",
      "1204:\tlearn: 0.6113602\ttest: 0.6056568\tbest: 0.6056568 (1204)\ttotal: 17.1s\tremaining: 53.9s\n",
      "1205:\tlearn: 0.6113602\ttest: 0.6056568\tbest: 0.6056568 (1205)\ttotal: 17.1s\tremaining: 53.8s\n",
      "1206:\tlearn: 0.6113602\ttest: 0.6056568\tbest: 0.6056568 (1206)\ttotal: 17.1s\tremaining: 53.8s\n",
      "1207:\tlearn: 0.6113602\ttest: 0.6056568\tbest: 0.6056568 (1207)\ttotal: 17.1s\tremaining: 53.8s\n",
      "1208:\tlearn: 0.6113602\ttest: 0.6056568\tbest: 0.6056568 (1208)\ttotal: 17.2s\tremaining: 53.8s\n",
      "1209:\tlearn: 0.6113602\ttest: 0.6056568\tbest: 0.6056568 (1209)\ttotal: 17.2s\tremaining: 53.8s\n",
      "1210:\tlearn: 0.6113394\ttest: 0.6056366\tbest: 0.6056366 (1210)\ttotal: 17.2s\tremaining: 53.8s\n",
      "1211:\tlearn: 0.6113394\ttest: 0.6056366\tbest: 0.6056366 (1210)\ttotal: 17.2s\tremaining: 53.8s\n",
      "1212:\tlearn: 0.6113394\ttest: 0.6056366\tbest: 0.6056366 (1210)\ttotal: 17.2s\tremaining: 53.8s\n",
      "1213:\tlearn: 0.6113394\ttest: 0.6056366\tbest: 0.6056366 (1210)\ttotal: 17.2s\tremaining: 53.8s\n",
      "1214:\tlearn: 0.6112685\ttest: 0.6055528\tbest: 0.6055528 (1214)\ttotal: 17.3s\tremaining: 53.8s\n",
      "1215:\tlearn: 0.6112685\ttest: 0.6055528\tbest: 0.6055528 (1215)\ttotal: 17.3s\tremaining: 53.8s\n",
      "1216:\tlearn: 0.6112655\ttest: 0.6055501\tbest: 0.6055501 (1216)\ttotal: 17.3s\tremaining: 53.8s\n",
      "1217:\tlearn: 0.6112585\ttest: 0.6055457\tbest: 0.6055457 (1217)\ttotal: 17.3s\tremaining: 53.8s\n",
      "1218:\tlearn: 0.6112585\ttest: 0.6055457\tbest: 0.6055457 (1218)\ttotal: 17.3s\tremaining: 53.8s\n",
      "1219:\tlearn: 0.6112197\ttest: 0.6055021\tbest: 0.6055021 (1219)\ttotal: 17.4s\tremaining: 53.8s\n",
      "1220:\tlearn: 0.6112197\ttest: 0.6055021\tbest: 0.6055021 (1220)\ttotal: 17.4s\tremaining: 53.8s\n",
      "1221:\tlearn: 0.6112197\ttest: 0.6055021\tbest: 0.6055021 (1221)\ttotal: 17.4s\tremaining: 53.8s\n",
      "1222:\tlearn: 0.6112086\ttest: 0.6054881\tbest: 0.6054881 (1222)\ttotal: 17.4s\tremaining: 53.7s\n",
      "1223:\tlearn: 0.6112086\ttest: 0.6054881\tbest: 0.6054881 (1223)\ttotal: 17.4s\tremaining: 53.7s\n",
      "1224:\tlearn: 0.6112086\ttest: 0.6054881\tbest: 0.6054881 (1224)\ttotal: 17.4s\tremaining: 53.7s\n",
      "1225:\tlearn: 0.6112086\ttest: 0.6054881\tbest: 0.6054881 (1225)\ttotal: 17.4s\tremaining: 53.7s\n",
      "1226:\tlearn: 0.6112086\ttest: 0.6054881\tbest: 0.6054881 (1226)\ttotal: 17.5s\tremaining: 53.7s\n",
      "1227:\tlearn: 0.6111992\ttest: 0.6054813\tbest: 0.6054813 (1227)\ttotal: 17.5s\tremaining: 53.7s\n",
      "1228:\tlearn: 0.6111992\ttest: 0.6054813\tbest: 0.6054813 (1228)\ttotal: 17.5s\tremaining: 53.6s\n",
      "1229:\tlearn: 0.6111992\ttest: 0.6054813\tbest: 0.6054813 (1229)\ttotal: 17.5s\tremaining: 53.6s\n",
      "1230:\tlearn: 0.6111992\ttest: 0.6054813\tbest: 0.6054813 (1230)\ttotal: 17.5s\tremaining: 53.6s\n",
      "1231:\tlearn: 0.6111942\ttest: 0.6054765\tbest: 0.6054765 (1231)\ttotal: 17.5s\tremaining: 53.6s\n",
      "1232:\tlearn: 0.6111942\ttest: 0.6054765\tbest: 0.6054765 (1232)\ttotal: 17.5s\tremaining: 53.6s\n",
      "1233:\tlearn: 0.6111759\ttest: 0.6054511\tbest: 0.6054511 (1233)\ttotal: 17.6s\tremaining: 53.6s\n",
      "1234:\tlearn: 0.6111580\ttest: 0.6054308\tbest: 0.6054308 (1234)\ttotal: 17.6s\tremaining: 53.6s\n",
      "1235:\tlearn: 0.6111501\ttest: 0.6054179\tbest: 0.6054179 (1235)\ttotal: 17.6s\tremaining: 53.6s\n",
      "1236:\tlearn: 0.6111501\ttest: 0.6054179\tbest: 0.6054179 (1236)\ttotal: 17.6s\tremaining: 53.5s\n",
      "1237:\tlearn: 0.6111438\ttest: 0.6054090\tbest: 0.6054090 (1237)\ttotal: 17.6s\tremaining: 53.5s\n",
      "1238:\tlearn: 0.6111298\ttest: 0.6053929\tbest: 0.6053929 (1238)\ttotal: 17.7s\tremaining: 53.6s\n",
      "1239:\tlearn: 0.6111298\ttest: 0.6053929\tbest: 0.6053929 (1238)\ttotal: 17.7s\tremaining: 53.6s\n",
      "1240:\tlearn: 0.6111298\ttest: 0.6053929\tbest: 0.6053929 (1238)\ttotal: 17.7s\tremaining: 53.5s\n",
      "1241:\tlearn: 0.6111298\ttest: 0.6053929\tbest: 0.6053929 (1238)\ttotal: 17.7s\tremaining: 53.5s\n",
      "1242:\tlearn: 0.6110946\ttest: 0.6053595\tbest: 0.6053595 (1242)\ttotal: 17.7s\tremaining: 53.5s\n",
      "1243:\tlearn: 0.6110946\ttest: 0.6053595\tbest: 0.6053595 (1243)\ttotal: 17.7s\tremaining: 53.5s\n",
      "1244:\tlearn: 0.6110945\ttest: 0.6053594\tbest: 0.6053594 (1244)\ttotal: 17.7s\tremaining: 53.5s\n",
      "1245:\tlearn: 0.6110945\ttest: 0.6053594\tbest: 0.6053594 (1245)\ttotal: 17.8s\tremaining: 53.5s\n",
      "1246:\tlearn: 0.6110945\ttest: 0.6053594\tbest: 0.6053594 (1246)\ttotal: 17.8s\tremaining: 53.5s\n",
      "1247:\tlearn: 0.6110945\ttest: 0.6053594\tbest: 0.6053594 (1247)\ttotal: 17.8s\tremaining: 53.5s\n",
      "1248:\tlearn: 0.6110905\ttest: 0.6053568\tbest: 0.6053568 (1248)\ttotal: 17.8s\tremaining: 53.5s\n",
      "1249:\tlearn: 0.6110827\ttest: 0.6053501\tbest: 0.6053501 (1249)\ttotal: 17.8s\tremaining: 53.5s\n",
      "1250:\tlearn: 0.6110827\ttest: 0.6053501\tbest: 0.6053501 (1250)\ttotal: 17.8s\tremaining: 53.4s\n",
      "1251:\tlearn: 0.6110786\ttest: 0.6053458\tbest: 0.6053458 (1251)\ttotal: 17.9s\tremaining: 53.4s\n",
      "1252:\tlearn: 0.6109944\ttest: 0.6052461\tbest: 0.6052461 (1252)\ttotal: 17.9s\tremaining: 53.5s\n",
      "1253:\tlearn: 0.6109857\ttest: 0.6052399\tbest: 0.6052399 (1253)\ttotal: 17.9s\tremaining: 53.4s\n",
      "1254:\tlearn: 0.6109752\ttest: 0.6052332\tbest: 0.6052332 (1254)\ttotal: 17.9s\tremaining: 53.5s\n",
      "1255:\tlearn: 0.6109727\ttest: 0.6052277\tbest: 0.6052277 (1255)\ttotal: 17.9s\tremaining: 53.4s\n",
      "1256:\tlearn: 0.6109557\ttest: 0.6052060\tbest: 0.6052060 (1256)\ttotal: 17.9s\tremaining: 53.4s\n",
      "1257:\tlearn: 0.6109432\ttest: 0.6051930\tbest: 0.6051930 (1257)\ttotal: 18s\tremaining: 53.4s\n",
      "1258:\tlearn: 0.6108762\ttest: 0.6051139\tbest: 0.6051139 (1258)\ttotal: 18s\tremaining: 53.5s\n",
      "1259:\tlearn: 0.6108756\ttest: 0.6051138\tbest: 0.6051138 (1259)\ttotal: 18s\tremaining: 53.4s\n",
      "1260:\tlearn: 0.6108756\ttest: 0.6051138\tbest: 0.6051138 (1260)\ttotal: 18s\tremaining: 53.4s\n",
      "1261:\tlearn: 0.6108756\ttest: 0.6051138\tbest: 0.6051138 (1261)\ttotal: 18s\tremaining: 53.4s\n",
      "1262:\tlearn: 0.6108756\ttest: 0.6051138\tbest: 0.6051138 (1262)\ttotal: 18s\tremaining: 53.4s\n",
      "1263:\tlearn: 0.6108356\ttest: 0.6050550\tbest: 0.6050550 (1263)\ttotal: 18.1s\tremaining: 53.4s\n",
      "1264:\tlearn: 0.6108356\ttest: 0.6050550\tbest: 0.6050550 (1263)\ttotal: 18.1s\tremaining: 53.4s\n",
      "1265:\tlearn: 0.6108356\ttest: 0.6050550\tbest: 0.6050550 (1263)\ttotal: 18.1s\tremaining: 53.4s\n",
      "1266:\tlearn: 0.6108356\ttest: 0.6050550\tbest: 0.6050550 (1263)\ttotal: 18.1s\tremaining: 53.3s\n",
      "1267:\tlearn: 0.6108356\ttest: 0.6050550\tbest: 0.6050550 (1263)\ttotal: 18.1s\tremaining: 53.3s\n",
      "1268:\tlearn: 0.6108356\ttest: 0.6050550\tbest: 0.6050550 (1263)\ttotal: 18.1s\tremaining: 53.3s\n",
      "1269:\tlearn: 0.6107955\ttest: 0.6050148\tbest: 0.6050148 (1269)\ttotal: 18.2s\tremaining: 53.3s\n",
      "1270:\tlearn: 0.6107955\ttest: 0.6050148\tbest: 0.6050148 (1269)\ttotal: 18.2s\tremaining: 53.3s\n",
      "1271:\tlearn: 0.6107955\ttest: 0.6050148\tbest: 0.6050148 (1269)\ttotal: 18.2s\tremaining: 53.3s\n",
      "1272:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.2s\tremaining: 53.3s\n",
      "1273:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.2s\tremaining: 53.3s\n",
      "1274:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.2s\tremaining: 53.3s\n",
      "1275:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.3s\tremaining: 53.3s\n",
      "1276:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.3s\tremaining: 53.3s\n",
      "1277:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.3s\tremaining: 53.3s\n",
      "1278:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.3s\tremaining: 53.3s\n",
      "1279:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.3s\tremaining: 53.2s\n",
      "1280:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.3s\tremaining: 53.2s\n",
      "1281:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.2s\n",
      "1282:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.2s\n",
      "1283:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.2s\n",
      "1284:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.2s\n",
      "1285:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.1s\n",
      "1286:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.1s\n",
      "1287:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.1s\n",
      "1288:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.4s\tremaining: 53.1s\n",
      "1289:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.5s\tremaining: 53.1s\n",
      "1290:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.5s\tremaining: 53.1s\n",
      "1291:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.5s\tremaining: 53s\n",
      "1292:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.5s\tremaining: 53s\n",
      "1293:\tlearn: 0.6107890\ttest: 0.6050082\tbest: 0.6050082 (1272)\ttotal: 18.5s\tremaining: 53s\n",
      "1294:\tlearn: 0.6107829\ttest: 0.6049997\tbest: 0.6049997 (1294)\ttotal: 18.5s\tremaining: 53s\n",
      "1295:\tlearn: 0.6107829\ttest: 0.6049997\tbest: 0.6049997 (1294)\ttotal: 18.5s\tremaining: 53s\n",
      "1296:\tlearn: 0.6107488\ttest: 0.6049552\tbest: 0.6049552 (1296)\ttotal: 18.6s\tremaining: 53s\n",
      "1297:\tlearn: 0.6107488\ttest: 0.6049552\tbest: 0.6049552 (1296)\ttotal: 18.6s\tremaining: 53s\n",
      "1298:\tlearn: 0.6107456\ttest: 0.6049530\tbest: 0.6049530 (1298)\ttotal: 18.6s\tremaining: 53s\n",
      "1299:\tlearn: 0.6107456\ttest: 0.6049530\tbest: 0.6049530 (1298)\ttotal: 18.6s\tremaining: 52.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300:\tlearn: 0.6107456\ttest: 0.6049530\tbest: 0.6049530 (1298)\ttotal: 18.6s\tremaining: 52.9s\n",
      "1301:\tlearn: 0.6107355\ttest: 0.6049402\tbest: 0.6049402 (1301)\ttotal: 18.6s\tremaining: 52.9s\n",
      "1302:\tlearn: 0.6107355\ttest: 0.6049402\tbest: 0.6049402 (1301)\ttotal: 18.6s\tremaining: 52.9s\n",
      "1303:\tlearn: 0.6107355\ttest: 0.6049402\tbest: 0.6049402 (1301)\ttotal: 18.7s\tremaining: 52.9s\n",
      "1304:\tlearn: 0.6107355\ttest: 0.6049402\tbest: 0.6049402 (1301)\ttotal: 18.7s\tremaining: 52.8s\n",
      "1305:\tlearn: 0.6107355\ttest: 0.6049402\tbest: 0.6049402 (1301)\ttotal: 18.7s\tremaining: 52.8s\n",
      "1306:\tlearn: 0.6107252\ttest: 0.6049281\tbest: 0.6049281 (1306)\ttotal: 18.7s\tremaining: 52.8s\n",
      "1307:\tlearn: 0.6107252\ttest: 0.6049281\tbest: 0.6049281 (1306)\ttotal: 18.7s\tremaining: 52.8s\n",
      "1308:\tlearn: 0.6107240\ttest: 0.6049264\tbest: 0.6049264 (1308)\ttotal: 18.7s\tremaining: 52.8s\n",
      "1309:\tlearn: 0.6107163\ttest: 0.6049144\tbest: 0.6049144 (1309)\ttotal: 18.7s\tremaining: 52.8s\n",
      "1310:\tlearn: 0.6107163\ttest: 0.6049145\tbest: 0.6049144 (1309)\ttotal: 18.8s\tremaining: 52.8s\n",
      "1311:\tlearn: 0.6107163\ttest: 0.6049145\tbest: 0.6049144 (1309)\ttotal: 18.8s\tremaining: 52.7s\n",
      "1312:\tlearn: 0.6107104\ttest: 0.6049046\tbest: 0.6049046 (1312)\ttotal: 18.8s\tremaining: 52.7s\n",
      "1313:\tlearn: 0.6107068\ttest: 0.6049024\tbest: 0.6049024 (1313)\ttotal: 18.8s\tremaining: 52.7s\n",
      "1314:\tlearn: 0.6107024\ttest: 0.6048981\tbest: 0.6048981 (1314)\ttotal: 18.8s\tremaining: 52.7s\n",
      "1315:\tlearn: 0.6107024\ttest: 0.6048981\tbest: 0.6048981 (1314)\ttotal: 18.8s\tremaining: 52.7s\n",
      "1316:\tlearn: 0.6106975\ttest: 0.6048944\tbest: 0.6048944 (1316)\ttotal: 18.8s\tremaining: 52.7s\n",
      "1317:\tlearn: 0.6106972\ttest: 0.6048943\tbest: 0.6048943 (1317)\ttotal: 18.9s\tremaining: 52.7s\n",
      "1318:\tlearn: 0.6106972\ttest: 0.6048944\tbest: 0.6048943 (1317)\ttotal: 18.9s\tremaining: 52.7s\n",
      "1319:\tlearn: 0.6106972\ttest: 0.6048944\tbest: 0.6048943 (1317)\ttotal: 18.9s\tremaining: 52.7s\n",
      "1320:\tlearn: 0.6106972\ttest: 0.6048944\tbest: 0.6048943 (1317)\ttotal: 18.9s\tremaining: 52.6s\n",
      "1321:\tlearn: 0.6106972\ttest: 0.6048944\tbest: 0.6048943 (1317)\ttotal: 18.9s\tremaining: 52.6s\n",
      "1322:\tlearn: 0.6106972\ttest: 0.6048944\tbest: 0.6048943 (1317)\ttotal: 18.9s\tremaining: 52.6s\n",
      "1323:\tlearn: 0.6106919\ttest: 0.6048934\tbest: 0.6048934 (1323)\ttotal: 19s\tremaining: 52.6s\n",
      "1324:\tlearn: 0.6106919\ttest: 0.6048934\tbest: 0.6048934 (1323)\ttotal: 19s\tremaining: 52.6s\n",
      "1325:\tlearn: 0.6106919\ttest: 0.6048934\tbest: 0.6048934 (1323)\ttotal: 19s\tremaining: 52.6s\n",
      "1326:\tlearn: 0.6106873\ttest: 0.6048865\tbest: 0.6048865 (1326)\ttotal: 19s\tremaining: 52.6s\n",
      "1327:\tlearn: 0.6106873\ttest: 0.6048865\tbest: 0.6048865 (1326)\ttotal: 19s\tremaining: 52.6s\n",
      "1328:\tlearn: 0.6106873\ttest: 0.6048865\tbest: 0.6048865 (1326)\ttotal: 19s\tremaining: 52.5s\n",
      "1329:\tlearn: 0.6106871\ttest: 0.6048860\tbest: 0.6048860 (1329)\ttotal: 19s\tremaining: 52.5s\n",
      "1330:\tlearn: 0.6106871\ttest: 0.6048860\tbest: 0.6048860 (1329)\ttotal: 19.1s\tremaining: 52.5s\n",
      "1331:\tlearn: 0.6106871\ttest: 0.6048860\tbest: 0.6048860 (1329)\ttotal: 19.1s\tremaining: 52.5s\n",
      "1332:\tlearn: 0.6106871\ttest: 0.6048860\tbest: 0.6048860 (1329)\ttotal: 19.1s\tremaining: 52.5s\n",
      "1333:\tlearn: 0.6106867\ttest: 0.6048859\tbest: 0.6048859 (1333)\ttotal: 19.1s\tremaining: 52.5s\n",
      "1334:\tlearn: 0.6106867\ttest: 0.6048859\tbest: 0.6048859 (1333)\ttotal: 19.1s\tremaining: 52.4s\n",
      "1335:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.1s\tremaining: 52.4s\n",
      "1336:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.1s\tremaining: 52.4s\n",
      "1337:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.1s\tremaining: 52.4s\n",
      "1338:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.2s\tremaining: 52.4s\n",
      "1339:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.2s\tremaining: 52.4s\n",
      "1340:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.2s\tremaining: 52.3s\n",
      "1341:\tlearn: 0.6106831\ttest: 0.6048828\tbest: 0.6048828 (1335)\ttotal: 19.2s\tremaining: 52.3s\n",
      "1342:\tlearn: 0.6106698\ttest: 0.6048697\tbest: 0.6048697 (1342)\ttotal: 19.2s\tremaining: 52.3s\n",
      "1343:\tlearn: 0.6106698\ttest: 0.6048697\tbest: 0.6048697 (1342)\ttotal: 19.2s\tremaining: 52.3s\n",
      "1344:\tlearn: 0.6106698\ttest: 0.6048697\tbest: 0.6048697 (1342)\ttotal: 19.2s\tremaining: 52.3s\n",
      "1345:\tlearn: 0.6106698\ttest: 0.6048697\tbest: 0.6048697 (1342)\ttotal: 19.3s\tremaining: 52.3s\n",
      "1346:\tlearn: 0.6106698\ttest: 0.6048697\tbest: 0.6048697 (1342)\ttotal: 19.3s\tremaining: 52.2s\n",
      "1347:\tlearn: 0.6106588\ttest: 0.6048613\tbest: 0.6048613 (1347)\ttotal: 19.3s\tremaining: 52.2s\n",
      "1348:\tlearn: 0.6106588\ttest: 0.6048613\tbest: 0.6048613 (1347)\ttotal: 19.3s\tremaining: 52.2s\n",
      "1349:\tlearn: 0.6106492\ttest: 0.6048536\tbest: 0.6048536 (1349)\ttotal: 19.3s\tremaining: 52.2s\n",
      "1350:\tlearn: 0.6106492\ttest: 0.6048536\tbest: 0.6048536 (1349)\ttotal: 19.3s\tremaining: 52.2s\n",
      "1351:\tlearn: 0.6106492\ttest: 0.6048536\tbest: 0.6048536 (1349)\ttotal: 19.3s\tremaining: 52.2s\n",
      "1352:\tlearn: 0.6106492\ttest: 0.6048536\tbest: 0.6048536 (1349)\ttotal: 19.3s\tremaining: 52.1s\n",
      "1353:\tlearn: 0.6106492\ttest: 0.6048536\tbest: 0.6048536 (1349)\ttotal: 19.4s\tremaining: 52.1s\n",
      "1354:\tlearn: 0.6106407\ttest: 0.6048409\tbest: 0.6048409 (1354)\ttotal: 19.4s\tremaining: 52.1s\n",
      "1355:\tlearn: 0.6106407\ttest: 0.6048409\tbest: 0.6048409 (1354)\ttotal: 19.4s\tremaining: 52.1s\n",
      "1356:\tlearn: 0.6106407\ttest: 0.6048409\tbest: 0.6048409 (1354)\ttotal: 19.4s\tremaining: 52.1s\n",
      "1357:\tlearn: 0.6106407\ttest: 0.6048409\tbest: 0.6048409 (1354)\ttotal: 19.4s\tremaining: 52.1s\n",
      "1358:\tlearn: 0.6106407\ttest: 0.6048409\tbest: 0.6048409 (1354)\ttotal: 19.4s\tremaining: 52.1s\n",
      "1359:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52.1s\n",
      "1360:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52.1s\n",
      "1361:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52.1s\n",
      "1362:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52s\n",
      "1363:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52s\n",
      "1364:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52s\n",
      "1365:\tlearn: 0.6105900\ttest: 0.6047792\tbest: 0.6047792 (1359)\ttotal: 19.5s\tremaining: 52s\n",
      "1366:\tlearn: 0.6105900\ttest: 0.6047793\tbest: 0.6047792 (1359)\ttotal: 19.6s\tremaining: 52s\n",
      "1367:\tlearn: 0.6105900\ttest: 0.6047793\tbest: 0.6047792 (1359)\ttotal: 19.6s\tremaining: 52s\n",
      "1368:\tlearn: 0.6105788\ttest: 0.6047717\tbest: 0.6047717 (1368)\ttotal: 19.6s\tremaining: 52s\n",
      "1369:\tlearn: 0.6105788\ttest: 0.6047717\tbest: 0.6047717 (1368)\ttotal: 19.6s\tremaining: 52s\n",
      "1370:\tlearn: 0.6105694\ttest: 0.6047598\tbest: 0.6047598 (1370)\ttotal: 19.6s\tremaining: 52s\n",
      "1371:\tlearn: 0.6105694\ttest: 0.6047598\tbest: 0.6047598 (1370)\ttotal: 19.6s\tremaining: 51.9s\n",
      "1372:\tlearn: 0.6104493\ttest: 0.6046349\tbest: 0.6046349 (1372)\ttotal: 19.7s\tremaining: 51.9s\n",
      "1373:\tlearn: 0.6104493\ttest: 0.6046349\tbest: 0.6046349 (1372)\ttotal: 19.7s\tremaining: 51.9s\n",
      "1374:\tlearn: 0.6104212\ttest: 0.6046052\tbest: 0.6046052 (1374)\ttotal: 19.7s\tremaining: 51.9s\n",
      "1375:\tlearn: 0.6104212\ttest: 0.6046052\tbest: 0.6046052 (1374)\ttotal: 19.7s\tremaining: 51.9s\n",
      "1376:\tlearn: 0.6104135\ttest: 0.6045980\tbest: 0.6045980 (1376)\ttotal: 19.7s\tremaining: 51.9s\n",
      "1377:\tlearn: 0.6104055\ttest: 0.6045859\tbest: 0.6045859 (1377)\ttotal: 19.7s\tremaining: 51.9s\n",
      "1378:\tlearn: 0.6103478\ttest: 0.6045270\tbest: 0.6045270 (1378)\ttotal: 19.8s\tremaining: 51.9s\n",
      "1379:\tlearn: 0.6103363\ttest: 0.6045163\tbest: 0.6045163 (1379)\ttotal: 19.8s\tremaining: 51.9s\n",
      "1380:\tlearn: 0.6103363\ttest: 0.6045163\tbest: 0.6045163 (1380)\ttotal: 19.8s\tremaining: 51.9s\n",
      "1381:\tlearn: 0.6103363\ttest: 0.6045163\tbest: 0.6045163 (1381)\ttotal: 19.8s\tremaining: 51.9s\n",
      "1382:\tlearn: 0.6103363\ttest: 0.6045163\tbest: 0.6045163 (1382)\ttotal: 19.8s\tremaining: 51.8s\n",
      "1383:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1383)\ttotal: 19.8s\tremaining: 51.8s\n",
      "1384:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1384)\ttotal: 19.9s\tremaining: 51.8s\n",
      "1385:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1385)\ttotal: 19.9s\tremaining: 51.8s\n",
      "1386:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1386)\ttotal: 19.9s\tremaining: 51.8s\n",
      "1387:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1387)\ttotal: 19.9s\tremaining: 51.8s\n",
      "1388:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1388)\ttotal: 19.9s\tremaining: 51.8s\n",
      "1389:\tlearn: 0.6103300\ttest: 0.6045075\tbest: 0.6045075 (1389)\ttotal: 19.9s\tremaining: 51.7s\n",
      "1390:\tlearn: 0.6103299\ttest: 0.6045073\tbest: 0.6045073 (1390)\ttotal: 19.9s\tremaining: 51.7s\n",
      "1391:\tlearn: 0.6103299\ttest: 0.6045073\tbest: 0.6045073 (1391)\ttotal: 19.9s\tremaining: 51.7s\n",
      "1392:\tlearn: 0.6103131\ttest: 0.6044845\tbest: 0.6044845 (1392)\ttotal: 20s\tremaining: 51.7s\n",
      "1393:\tlearn: 0.6102529\ttest: 0.6044256\tbest: 0.6044256 (1393)\ttotal: 20s\tremaining: 51.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394:\tlearn: 0.6102529\ttest: 0.6044256\tbest: 0.6044256 (1393)\ttotal: 20s\tremaining: 51.7s\n",
      "1395:\tlearn: 0.6102529\ttest: 0.6044256\tbest: 0.6044256 (1393)\ttotal: 20s\tremaining: 51.7s\n",
      "1396:\tlearn: 0.6102529\ttest: 0.6044256\tbest: 0.6044256 (1393)\ttotal: 20s\tremaining: 51.7s\n",
      "1397:\tlearn: 0.6102529\ttest: 0.6044256\tbest: 0.6044256 (1393)\ttotal: 20s\tremaining: 51.7s\n",
      "1398:\tlearn: 0.6102396\ttest: 0.6044142\tbest: 0.6044142 (1398)\ttotal: 20.1s\tremaining: 51.7s\n",
      "1399:\tlearn: 0.6102396\ttest: 0.6044142\tbest: 0.6044142 (1398)\ttotal: 20.1s\tremaining: 51.6s\n",
      "1400:\tlearn: 0.6102396\ttest: 0.6044142\tbest: 0.6044142 (1398)\ttotal: 20.1s\tremaining: 51.6s\n",
      "1401:\tlearn: 0.6102396\ttest: 0.6044142\tbest: 0.6044142 (1398)\ttotal: 20.1s\tremaining: 51.6s\n",
      "1402:\tlearn: 0.6102184\ttest: 0.6044034\tbest: 0.6044034 (1402)\ttotal: 20.1s\tremaining: 51.6s\n",
      "1403:\tlearn: 0.6102184\ttest: 0.6044034\tbest: 0.6044034 (1402)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1404:\tlearn: 0.6102074\ttest: 0.6043889\tbest: 0.6043889 (1404)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1405:\tlearn: 0.6102074\ttest: 0.6043889\tbest: 0.6043889 (1404)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1406:\tlearn: 0.6101992\ttest: 0.6043792\tbest: 0.6043792 (1406)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1407:\tlearn: 0.6101702\ttest: 0.6043579\tbest: 0.6043579 (1407)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1408:\tlearn: 0.6101702\ttest: 0.6043579\tbest: 0.6043579 (1407)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1409:\tlearn: 0.6101702\ttest: 0.6043579\tbest: 0.6043579 (1407)\ttotal: 20.2s\tremaining: 51.6s\n",
      "1410:\tlearn: 0.6101605\ttest: 0.6043428\tbest: 0.6043428 (1410)\ttotal: 20.3s\tremaining: 51.6s\n",
      "1411:\tlearn: 0.6101595\ttest: 0.6043428\tbest: 0.6043428 (1410)\ttotal: 20.3s\tremaining: 51.5s\n",
      "1412:\tlearn: 0.6101595\ttest: 0.6043428\tbest: 0.6043428 (1410)\ttotal: 20.3s\tremaining: 51.5s\n",
      "1413:\tlearn: 0.6101255\ttest: 0.6043027\tbest: 0.6043027 (1413)\ttotal: 20.3s\tremaining: 51.5s\n",
      "1414:\tlearn: 0.6101255\ttest: 0.6043027\tbest: 0.6043027 (1413)\ttotal: 20.3s\tremaining: 51.5s\n",
      "1415:\tlearn: 0.6101255\ttest: 0.6043027\tbest: 0.6043027 (1413)\ttotal: 20.3s\tremaining: 51.5s\n",
      "1416:\tlearn: 0.6101199\ttest: 0.6042944\tbest: 0.6042944 (1416)\ttotal: 20.4s\tremaining: 51.5s\n",
      "1417:\tlearn: 0.6101199\ttest: 0.6042944\tbest: 0.6042944 (1416)\ttotal: 20.4s\tremaining: 51.5s\n",
      "1418:\tlearn: 0.6101199\ttest: 0.6042944\tbest: 0.6042944 (1416)\ttotal: 20.4s\tremaining: 51.4s\n",
      "1419:\tlearn: 0.6101199\ttest: 0.6042944\tbest: 0.6042944 (1416)\ttotal: 20.4s\tremaining: 51.4s\n",
      "1420:\tlearn: 0.6101199\ttest: 0.6042944\tbest: 0.6042944 (1416)\ttotal: 20.4s\tremaining: 51.4s\n",
      "1421:\tlearn: 0.6101145\ttest: 0.6042828\tbest: 0.6042828 (1421)\ttotal: 20.4s\tremaining: 51.4s\n",
      "1422:\tlearn: 0.6101145\ttest: 0.6042828\tbest: 0.6042828 (1421)\ttotal: 20.4s\tremaining: 51.4s\n",
      "1423:\tlearn: 0.6101145\ttest: 0.6042828\tbest: 0.6042828 (1421)\ttotal: 20.4s\tremaining: 51.4s\n",
      "1424:\tlearn: 0.6101145\ttest: 0.6042828\tbest: 0.6042828 (1421)\ttotal: 20.5s\tremaining: 51.3s\n",
      "1425:\tlearn: 0.6101133\ttest: 0.6042819\tbest: 0.6042819 (1425)\ttotal: 20.5s\tremaining: 51.3s\n",
      "1426:\tlearn: 0.6099998\ttest: 0.6041557\tbest: 0.6041557 (1426)\ttotal: 20.5s\tremaining: 51.3s\n",
      "1427:\tlearn: 0.6099998\ttest: 0.6041557\tbest: 0.6041557 (1426)\ttotal: 20.5s\tremaining: 51.3s\n",
      "1428:\tlearn: 0.6099933\ttest: 0.6041492\tbest: 0.6041492 (1428)\ttotal: 20.5s\tremaining: 51.3s\n",
      "1429:\tlearn: 0.6099897\ttest: 0.6041436\tbest: 0.6041436 (1429)\ttotal: 20.6s\tremaining: 51.3s\n",
      "1430:\tlearn: 0.6099676\ttest: 0.6041146\tbest: 0.6041146 (1430)\ttotal: 20.6s\tremaining: 51.4s\n",
      "1431:\tlearn: 0.6099676\ttest: 0.6041146\tbest: 0.6041146 (1430)\ttotal: 20.6s\tremaining: 51.4s\n",
      "1432:\tlearn: 0.6099676\ttest: 0.6041146\tbest: 0.6041146 (1430)\ttotal: 20.6s\tremaining: 51.4s\n",
      "1433:\tlearn: 0.6099676\ttest: 0.6041146\tbest: 0.6041146 (1430)\ttotal: 20.6s\tremaining: 51.3s\n",
      "1434:\tlearn: 0.6099676\ttest: 0.6041146\tbest: 0.6041146 (1430)\ttotal: 20.7s\tremaining: 51.3s\n",
      "1435:\tlearn: 0.6099676\ttest: 0.6041146\tbest: 0.6041146 (1430)\ttotal: 20.7s\tremaining: 51.3s\n",
      "1436:\tlearn: 0.6099652\ttest: 0.6041092\tbest: 0.6041092 (1436)\ttotal: 20.7s\tremaining: 51.3s\n",
      "1437:\tlearn: 0.6099652\ttest: 0.6041092\tbest: 0.6041092 (1436)\ttotal: 20.7s\tremaining: 51.3s\n",
      "1438:\tlearn: 0.6099354\ttest: 0.6040637\tbest: 0.6040637 (1438)\ttotal: 20.7s\tremaining: 51.3s\n",
      "1439:\tlearn: 0.6099354\ttest: 0.6040637\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.3s\n",
      "1440:\tlearn: 0.6099354\ttest: 0.6040637\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.3s\n",
      "1441:\tlearn: 0.6099354\ttest: 0.6040637\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.3s\n",
      "1442:\tlearn: 0.6099354\ttest: 0.6040637\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.3s\n",
      "1443:\tlearn: 0.6099354\ttest: 0.6040637\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.3s\n",
      "1444:\tlearn: 0.6099354\ttest: 0.6040638\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.2s\n",
      "1445:\tlearn: 0.6099354\ttest: 0.6040638\tbest: 0.6040637 (1438)\ttotal: 20.8s\tremaining: 51.2s\n",
      "1446:\tlearn: 0.6099093\ttest: 0.6040343\tbest: 0.6040343 (1446)\ttotal: 20.9s\tremaining: 51.2s\n",
      "1447:\tlearn: 0.6099093\ttest: 0.6040343\tbest: 0.6040343 (1446)\ttotal: 20.9s\tremaining: 51.2s\n",
      "1448:\tlearn: 0.6099093\ttest: 0.6040343\tbest: 0.6040343 (1446)\ttotal: 20.9s\tremaining: 51.2s\n",
      "1449:\tlearn: 0.6099039\ttest: 0.6040295\tbest: 0.6040295 (1449)\ttotal: 20.9s\tremaining: 51.2s\n",
      "1450:\tlearn: 0.6099039\ttest: 0.6040295\tbest: 0.6040295 (1449)\ttotal: 20.9s\tremaining: 51.2s\n",
      "1451:\tlearn: 0.6098303\ttest: 0.6039475\tbest: 0.6039475 (1451)\ttotal: 20.9s\tremaining: 51.2s\n",
      "1452:\tlearn: 0.6098217\ttest: 0.6039364\tbest: 0.6039364 (1452)\ttotal: 21s\tremaining: 51.2s\n",
      "1453:\tlearn: 0.6098181\ttest: 0.6039329\tbest: 0.6039329 (1453)\ttotal: 21s\tremaining: 51.2s\n",
      "1454:\tlearn: 0.6098181\ttest: 0.6039329\tbest: 0.6039329 (1454)\ttotal: 21s\tremaining: 51.2s\n",
      "1455:\tlearn: 0.6098181\ttest: 0.6039329\tbest: 0.6039329 (1455)\ttotal: 21s\tremaining: 51.1s\n",
      "1456:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1456)\ttotal: 21s\tremaining: 51.1s\n",
      "1457:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1457)\ttotal: 21s\tremaining: 51.1s\n",
      "1458:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1458)\ttotal: 21.1s\tremaining: 51.1s\n",
      "1459:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1459)\ttotal: 21.1s\tremaining: 51.1s\n",
      "1460:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1460)\ttotal: 21.1s\tremaining: 51.1s\n",
      "1461:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1461)\ttotal: 21.1s\tremaining: 51.1s\n",
      "1462:\tlearn: 0.6098134\ttest: 0.6039266\tbest: 0.6039266 (1462)\ttotal: 21.1s\tremaining: 51.1s\n",
      "1463:\tlearn: 0.6098034\ttest: 0.6039172\tbest: 0.6039172 (1463)\ttotal: 21.1s\tremaining: 51.1s\n",
      "1464:\tlearn: 0.6098034\ttest: 0.6039172\tbest: 0.6039172 (1464)\ttotal: 21.2s\tremaining: 51s\n",
      "1465:\tlearn: 0.6097969\ttest: 0.6039123\tbest: 0.6039123 (1465)\ttotal: 21.2s\tremaining: 51s\n",
      "1466:\tlearn: 0.6097923\ttest: 0.6039092\tbest: 0.6039092 (1466)\ttotal: 21.2s\tremaining: 51s\n",
      "1467:\tlearn: 0.6097923\ttest: 0.6039092\tbest: 0.6039092 (1467)\ttotal: 21.2s\tremaining: 51s\n",
      "1468:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1468)\ttotal: 21.2s\tremaining: 51s\n",
      "1469:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1469)\ttotal: 21.2s\tremaining: 51s\n",
      "1470:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1470)\ttotal: 21.2s\tremaining: 51s\n",
      "1471:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1471)\ttotal: 21.3s\tremaining: 50.9s\n",
      "1472:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1472)\ttotal: 21.3s\tremaining: 50.9s\n",
      "1473:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1473)\ttotal: 21.3s\tremaining: 50.9s\n",
      "1474:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1474)\ttotal: 21.3s\tremaining: 50.9s\n",
      "1475:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1475)\ttotal: 21.3s\tremaining: 50.9s\n",
      "1476:\tlearn: 0.6097867\ttest: 0.6039061\tbest: 0.6039061 (1476)\ttotal: 21.3s\tremaining: 50.8s\n",
      "1477:\tlearn: 0.6097862\ttest: 0.6039060\tbest: 0.6039060 (1477)\ttotal: 21.3s\tremaining: 50.8s\n",
      "1478:\tlearn: 0.6097862\ttest: 0.6039060\tbest: 0.6039060 (1478)\ttotal: 21.3s\tremaining: 50.8s\n",
      "1479:\tlearn: 0.6097781\ttest: 0.6038981\tbest: 0.6038981 (1479)\ttotal: 21.4s\tremaining: 50.8s\n",
      "1480:\tlearn: 0.6097712\ttest: 0.6038933\tbest: 0.6038933 (1480)\ttotal: 21.4s\tremaining: 50.8s\n",
      "1481:\tlearn: 0.6097655\ttest: 0.6038911\tbest: 0.6038911 (1481)\ttotal: 21.4s\tremaining: 50.8s\n",
      "1482:\tlearn: 0.6097655\ttest: 0.6038911\tbest: 0.6038911 (1481)\ttotal: 21.4s\tremaining: 50.8s\n",
      "1483:\tlearn: 0.6097655\ttest: 0.6038911\tbest: 0.6038911 (1481)\ttotal: 21.4s\tremaining: 50.8s\n",
      "1484:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1484)\ttotal: 21.5s\tremaining: 50.8s\n",
      "1485:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1485)\ttotal: 21.5s\tremaining: 50.8s\n",
      "1486:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1486)\ttotal: 21.5s\tremaining: 50.8s\n",
      "1487:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1487)\ttotal: 21.5s\tremaining: 50.7s\n",
      "1488:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1488)\ttotal: 21.5s\tremaining: 50.7s\n",
      "1489:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1489)\ttotal: 21.5s\tremaining: 50.7s\n",
      "1490:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1490)\ttotal: 21.5s\tremaining: 50.7s\n",
      "1491:\tlearn: 0.6097128\ttest: 0.6038273\tbest: 0.6038273 (1491)\ttotal: 21.6s\tremaining: 50.7s\n",
      "1492:\tlearn: 0.6097108\ttest: 0.6038243\tbest: 0.6038243 (1492)\ttotal: 21.6s\tremaining: 50.7s\n",
      "1493:\tlearn: 0.6097108\ttest: 0.6038243\tbest: 0.6038243 (1492)\ttotal: 21.6s\tremaining: 50.7s\n",
      "1494:\tlearn: 0.6097046\ttest: 0.6038144\tbest: 0.6038144 (1494)\ttotal: 21.6s\tremaining: 50.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495:\tlearn: 0.6097046\ttest: 0.6038144\tbest: 0.6038144 (1494)\ttotal: 21.6s\tremaining: 50.7s\n",
      "1496:\tlearn: 0.6097046\ttest: 0.6038144\tbest: 0.6038144 (1494)\ttotal: 21.6s\tremaining: 50.6s\n",
      "1497:\tlearn: 0.6097046\ttest: 0.6038144\tbest: 0.6038144 (1494)\ttotal: 21.7s\tremaining: 50.6s\n",
      "1498:\tlearn: 0.6097046\ttest: 0.6038144\tbest: 0.6038144 (1494)\ttotal: 21.7s\tremaining: 50.6s\n",
      "1499:\tlearn: 0.6097033\ttest: 0.6038110\tbest: 0.6038110 (1499)\ttotal: 21.7s\tremaining: 50.6s\n",
      "1500:\tlearn: 0.6097033\ttest: 0.6038110\tbest: 0.6038110 (1499)\ttotal: 21.7s\tremaining: 50.6s\n",
      "1501:\tlearn: 0.6097032\ttest: 0.6038109\tbest: 0.6038109 (1501)\ttotal: 21.7s\tremaining: 50.6s\n",
      "1502:\tlearn: 0.6097032\ttest: 0.6038109\tbest: 0.6038109 (1501)\ttotal: 21.8s\tremaining: 50.6s\n",
      "1503:\tlearn: 0.6097025\ttest: 0.6038110\tbest: 0.6038109 (1501)\ttotal: 21.8s\tremaining: 50.7s\n",
      "1504:\tlearn: 0.6097025\ttest: 0.6038110\tbest: 0.6038109 (1501)\ttotal: 21.8s\tremaining: 50.6s\n",
      "1505:\tlearn: 0.6097025\ttest: 0.6038110\tbest: 0.6038109 (1501)\ttotal: 21.8s\tremaining: 50.6s\n",
      "1506:\tlearn: 0.6097025\ttest: 0.6038110\tbest: 0.6038109 (1501)\ttotal: 21.8s\tremaining: 50.6s\n",
      "1507:\tlearn: 0.6097025\ttest: 0.6038110\tbest: 0.6038109 (1501)\ttotal: 21.9s\tremaining: 50.6s\n",
      "1508:\tlearn: 0.6096775\ttest: 0.6037845\tbest: 0.6037845 (1508)\ttotal: 21.9s\tremaining: 50.6s\n",
      "1509:\tlearn: 0.6096772\ttest: 0.6037845\tbest: 0.6037845 (1508)\ttotal: 21.9s\tremaining: 50.6s\n",
      "1510:\tlearn: 0.6096772\ttest: 0.6037845\tbest: 0.6037845 (1508)\ttotal: 21.9s\tremaining: 50.6s\n",
      "1511:\tlearn: 0.6096772\ttest: 0.6037845\tbest: 0.6037845 (1508)\ttotal: 21.9s\tremaining: 50.6s\n",
      "1512:\tlearn: 0.6096635\ttest: 0.6037700\tbest: 0.6037700 (1512)\ttotal: 21.9s\tremaining: 50.6s\n",
      "1513:\tlearn: 0.6096488\ttest: 0.6037644\tbest: 0.6037644 (1513)\ttotal: 22s\tremaining: 50.6s\n",
      "1514:\tlearn: 0.6096464\ttest: 0.6037591\tbest: 0.6037591 (1514)\ttotal: 22s\tremaining: 50.6s\n",
      "1515:\tlearn: 0.6096327\ttest: 0.6037458\tbest: 0.6037458 (1515)\ttotal: 22s\tremaining: 50.6s\n",
      "1516:\tlearn: 0.6096327\ttest: 0.6037458\tbest: 0.6037458 (1515)\ttotal: 22s\tremaining: 50.6s\n",
      "1517:\tlearn: 0.6096327\ttest: 0.6037458\tbest: 0.6037458 (1515)\ttotal: 22.1s\tremaining: 50.6s\n",
      "1518:\tlearn: 0.6095878\ttest: 0.6036921\tbest: 0.6036921 (1518)\ttotal: 22.1s\tremaining: 50.6s\n",
      "1519:\tlearn: 0.6095680\ttest: 0.6036716\tbest: 0.6036716 (1519)\ttotal: 22.1s\tremaining: 50.6s\n",
      "1520:\tlearn: 0.6095680\ttest: 0.6036716\tbest: 0.6036716 (1519)\ttotal: 22.1s\tremaining: 50.6s\n",
      "1521:\tlearn: 0.6095680\ttest: 0.6036716\tbest: 0.6036716 (1519)\ttotal: 22.1s\tremaining: 50.6s\n",
      "1522:\tlearn: 0.6095680\ttest: 0.6036716\tbest: 0.6036716 (1519)\ttotal: 22.2s\tremaining: 50.6s\n",
      "1523:\tlearn: 0.6095589\ttest: 0.6036632\tbest: 0.6036632 (1523)\ttotal: 22.2s\tremaining: 50.6s\n",
      "1524:\tlearn: 0.6095492\ttest: 0.6036538\tbest: 0.6036538 (1524)\ttotal: 22.2s\tremaining: 50.6s\n",
      "1525:\tlearn: 0.6095462\ttest: 0.6036488\tbest: 0.6036488 (1525)\ttotal: 22.2s\tremaining: 50.6s\n",
      "1526:\tlearn: 0.6095366\ttest: 0.6036426\tbest: 0.6036426 (1526)\ttotal: 22.3s\tremaining: 50.6s\n",
      "1527:\tlearn: 0.6095366\ttest: 0.6036426\tbest: 0.6036426 (1526)\ttotal: 22.3s\tremaining: 50.6s\n",
      "1528:\tlearn: 0.6095364\ttest: 0.6036425\tbest: 0.6036425 (1528)\ttotal: 22.3s\tremaining: 50.6s\n",
      "1529:\tlearn: 0.6095364\ttest: 0.6036425\tbest: 0.6036425 (1528)\ttotal: 22.3s\tremaining: 50.6s\n",
      "1530:\tlearn: 0.6095364\ttest: 0.6036425\tbest: 0.6036425 (1528)\ttotal: 22.3s\tremaining: 50.6s\n",
      "1531:\tlearn: 0.6094426\ttest: 0.6035489\tbest: 0.6035489 (1531)\ttotal: 22.3s\tremaining: 50.6s\n",
      "1532:\tlearn: 0.6094426\ttest: 0.6035489\tbest: 0.6035489 (1531)\ttotal: 22.4s\tremaining: 50.6s\n",
      "1533:\tlearn: 0.6094368\ttest: 0.6035410\tbest: 0.6035410 (1533)\ttotal: 22.4s\tremaining: 50.6s\n",
      "1534:\tlearn: 0.6094368\ttest: 0.6035410\tbest: 0.6035410 (1533)\ttotal: 22.4s\tremaining: 50.5s\n",
      "1535:\tlearn: 0.6094366\ttest: 0.6035409\tbest: 0.6035409 (1535)\ttotal: 22.4s\tremaining: 50.5s\n",
      "1536:\tlearn: 0.6094366\ttest: 0.6035409\tbest: 0.6035409 (1535)\ttotal: 22.4s\tremaining: 50.5s\n",
      "1537:\tlearn: 0.6094366\ttest: 0.6035409\tbest: 0.6035409 (1535)\ttotal: 22.4s\tremaining: 50.5s\n",
      "1538:\tlearn: 0.6094366\ttest: 0.6035409\tbest: 0.6035409 (1535)\ttotal: 22.4s\tremaining: 50.5s\n",
      "1539:\tlearn: 0.6094347\ttest: 0.6035361\tbest: 0.6035361 (1539)\ttotal: 22.5s\tremaining: 50.5s\n",
      "1540:\tlearn: 0.6094070\ttest: 0.6034990\tbest: 0.6034990 (1540)\ttotal: 22.5s\tremaining: 50.5s\n",
      "1541:\tlearn: 0.6094070\ttest: 0.6034990\tbest: 0.6034990 (1540)\ttotal: 22.5s\tremaining: 50.5s\n",
      "1542:\tlearn: 0.6094036\ttest: 0.6034972\tbest: 0.6034972 (1542)\ttotal: 22.5s\tremaining: 50.5s\n",
      "1543:\tlearn: 0.6094019\ttest: 0.6034953\tbest: 0.6034953 (1543)\ttotal: 22.6s\tremaining: 50.5s\n",
      "1544:\tlearn: 0.6093818\ttest: 0.6034714\tbest: 0.6034714 (1544)\ttotal: 22.6s\tremaining: 50.5s\n",
      "1545:\tlearn: 0.6093818\ttest: 0.6034714\tbest: 0.6034714 (1544)\ttotal: 22.6s\tremaining: 50.5s\n",
      "1546:\tlearn: 0.6093782\ttest: 0.6034654\tbest: 0.6034654 (1546)\ttotal: 22.6s\tremaining: 50.5s\n",
      "1547:\tlearn: 0.6093782\ttest: 0.6034654\tbest: 0.6034654 (1546)\ttotal: 22.6s\tremaining: 50.5s\n",
      "1548:\tlearn: 0.6093780\ttest: 0.6034653\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.5s\n",
      "1549:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.5s\n",
      "1550:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.5s\n",
      "1551:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.4s\n",
      "1552:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.4s\n",
      "1553:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.4s\n",
      "1554:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.7s\tremaining: 50.4s\n",
      "1555:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.8s\tremaining: 50.4s\n",
      "1556:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.8s\tremaining: 50.4s\n",
      "1557:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.8s\tremaining: 50.4s\n",
      "1558:\tlearn: 0.6093780\ttest: 0.6034654\tbest: 0.6034653 (1548)\ttotal: 22.8s\tremaining: 50.4s\n",
      "1559:\tlearn: 0.6093775\ttest: 0.6034645\tbest: 0.6034645 (1559)\ttotal: 22.9s\tremaining: 50.4s\n",
      "1560:\tlearn: 0.6093775\ttest: 0.6034645\tbest: 0.6034645 (1559)\ttotal: 22.9s\tremaining: 50.4s\n",
      "1561:\tlearn: 0.6093775\ttest: 0.6034645\tbest: 0.6034645 (1559)\ttotal: 22.9s\tremaining: 50.4s\n",
      "1562:\tlearn: 0.6093509\ttest: 0.6034478\tbest: 0.6034478 (1562)\ttotal: 22.9s\tremaining: 50.4s\n",
      "1563:\tlearn: 0.6093452\ttest: 0.6034389\tbest: 0.6034389 (1563)\ttotal: 22.9s\tremaining: 50.4s\n",
      "1564:\tlearn: 0.6093452\ttest: 0.6034389\tbest: 0.6034389 (1563)\ttotal: 22.9s\tremaining: 50.4s\n",
      "1565:\tlearn: 0.6093452\ttest: 0.6034389\tbest: 0.6034389 (1563)\ttotal: 23s\tremaining: 50.3s\n",
      "1566:\tlearn: 0.6093452\ttest: 0.6034389\tbest: 0.6034389 (1563)\ttotal: 23s\tremaining: 50.3s\n",
      "1567:\tlearn: 0.6093452\ttest: 0.6034389\tbest: 0.6034389 (1563)\ttotal: 23s\tremaining: 50.3s\n",
      "1568:\tlearn: 0.6093428\ttest: 0.6034376\tbest: 0.6034376 (1568)\ttotal: 23s\tremaining: 50.3s\n",
      "1569:\tlearn: 0.6093428\ttest: 0.6034376\tbest: 0.6034376 (1568)\ttotal: 23s\tremaining: 50.3s\n",
      "1570:\tlearn: 0.6093428\ttest: 0.6034376\tbest: 0.6034376 (1570)\ttotal: 23s\tremaining: 50.3s\n",
      "1571:\tlearn: 0.6093428\ttest: 0.6034376\tbest: 0.6034376 (1570)\ttotal: 23.1s\tremaining: 50.3s\n",
      "1572:\tlearn: 0.6093428\ttest: 0.6034376\tbest: 0.6034376 (1570)\ttotal: 23.1s\tremaining: 50.3s\n",
      "1573:\tlearn: 0.6093428\ttest: 0.6034376\tbest: 0.6034376 (1570)\ttotal: 23.1s\tremaining: 50.2s\n",
      "1574:\tlearn: 0.6093385\ttest: 0.6034281\tbest: 0.6034281 (1574)\ttotal: 23.1s\tremaining: 50.2s\n",
      "1575:\tlearn: 0.6093385\ttest: 0.6034281\tbest: 0.6034281 (1574)\ttotal: 23.1s\tremaining: 50.2s\n",
      "1576:\tlearn: 0.6093144\ttest: 0.6033965\tbest: 0.6033965 (1576)\ttotal: 23.1s\tremaining: 50.2s\n",
      "1577:\tlearn: 0.6093144\ttest: 0.6033965\tbest: 0.6033965 (1576)\ttotal: 23.2s\tremaining: 50.2s\n",
      "1578:\tlearn: 0.6093109\ttest: 0.6033936\tbest: 0.6033936 (1578)\ttotal: 23.2s\tremaining: 50.2s\n",
      "1579:\tlearn: 0.6093109\ttest: 0.6033936\tbest: 0.6033936 (1578)\ttotal: 23.2s\tremaining: 50.2s\n",
      "1580:\tlearn: 0.6093109\ttest: 0.6033936\tbest: 0.6033936 (1578)\ttotal: 23.2s\tremaining: 50.2s\n",
      "1581:\tlearn: 0.6093109\ttest: 0.6033936\tbest: 0.6033936 (1578)\ttotal: 23.2s\tremaining: 50.2s\n",
      "1582:\tlearn: 0.6093037\ttest: 0.6033887\tbest: 0.6033887 (1582)\ttotal: 23.2s\tremaining: 50.2s\n",
      "1583:\tlearn: 0.6093037\ttest: 0.6033887\tbest: 0.6033887 (1582)\ttotal: 23.3s\tremaining: 50.2s\n",
      "1584:\tlearn: 0.6092869\ttest: 0.6033680\tbest: 0.6033680 (1584)\ttotal: 23.3s\tremaining: 50.2s\n",
      "1585:\tlearn: 0.6092829\ttest: 0.6033610\tbest: 0.6033610 (1585)\ttotal: 23.3s\tremaining: 50.2s\n",
      "1586:\tlearn: 0.6092829\ttest: 0.6033610\tbest: 0.6033610 (1585)\ttotal: 23.3s\tremaining: 50.2s\n",
      "1587:\tlearn: 0.6092829\ttest: 0.6033610\tbest: 0.6033610 (1585)\ttotal: 23.3s\tremaining: 50.1s\n",
      "1588:\tlearn: 0.6092822\ttest: 0.6033610\tbest: 0.6033610 (1585)\ttotal: 23.4s\tremaining: 50.1s\n",
      "1589:\tlearn: 0.6092822\ttest: 0.6033610\tbest: 0.6033610 (1585)\ttotal: 23.4s\tremaining: 50.1s\n",
      "1590:\tlearn: 0.6092822\ttest: 0.6033611\tbest: 0.6033610 (1585)\ttotal: 23.4s\tremaining: 50.1s\n",
      "1591:\tlearn: 0.6092685\ttest: 0.6033443\tbest: 0.6033443 (1591)\ttotal: 23.4s\tremaining: 50.1s\n",
      "1592:\tlearn: 0.6092631\ttest: 0.6033428\tbest: 0.6033428 (1592)\ttotal: 23.4s\tremaining: 50.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593:\tlearn: 0.6092401\ttest: 0.6033191\tbest: 0.6033191 (1593)\ttotal: 23.5s\tremaining: 50.1s\n",
      "1594:\tlearn: 0.6092125\ttest: 0.6032834\tbest: 0.6032834 (1594)\ttotal: 23.5s\tremaining: 50.1s\n",
      "1595:\tlearn: 0.6092125\ttest: 0.6032834\tbest: 0.6032834 (1594)\ttotal: 23.5s\tremaining: 50.1s\n",
      "1596:\tlearn: 0.6092044\ttest: 0.6032783\tbest: 0.6032783 (1596)\ttotal: 23.5s\tremaining: 50.1s\n",
      "1597:\tlearn: 0.6091485\ttest: 0.6032295\tbest: 0.6032295 (1597)\ttotal: 23.5s\tremaining: 50.1s\n",
      "1598:\tlearn: 0.6091485\ttest: 0.6032295\tbest: 0.6032295 (1597)\ttotal: 23.6s\tremaining: 50.1s\n",
      "1599:\tlearn: 0.6090634\ttest: 0.6031132\tbest: 0.6031132 (1599)\ttotal: 23.6s\tremaining: 50.1s\n",
      "1600:\tlearn: 0.6090634\ttest: 0.6031132\tbest: 0.6031132 (1599)\ttotal: 23.6s\tremaining: 50.1s\n",
      "1601:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.6s\tremaining: 50.1s\n",
      "1602:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.6s\tremaining: 50.1s\n",
      "1603:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.7s\tremaining: 50.1s\n",
      "1604:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.7s\tremaining: 50.1s\n",
      "1605:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.7s\tremaining: 50s\n",
      "1606:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.7s\tremaining: 50s\n",
      "1607:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.7s\tremaining: 50s\n",
      "1608:\tlearn: 0.6090588\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.7s\tremaining: 50s\n",
      "1609:\tlearn: 0.6090584\ttest: 0.6031054\tbest: 0.6031054 (1601)\ttotal: 23.8s\tremaining: 50s\n",
      "1610:\tlearn: 0.6090556\ttest: 0.6030994\tbest: 0.6030994 (1610)\ttotal: 23.8s\tremaining: 50s\n",
      "1611:\tlearn: 0.6090528\ttest: 0.6030978\tbest: 0.6030978 (1611)\ttotal: 23.8s\tremaining: 50s\n",
      "1612:\tlearn: 0.6090528\ttest: 0.6030978\tbest: 0.6030978 (1611)\ttotal: 23.8s\tremaining: 50s\n",
      "1613:\tlearn: 0.6090528\ttest: 0.6030978\tbest: 0.6030978 (1611)\ttotal: 23.8s\tremaining: 50s\n",
      "1614:\tlearn: 0.6090528\ttest: 0.6030978\tbest: 0.6030978 (1611)\ttotal: 23.9s\tremaining: 50s\n",
      "1615:\tlearn: 0.6090528\ttest: 0.6030978\tbest: 0.6030978 (1611)\ttotal: 23.9s\tremaining: 50s\n",
      "1616:\tlearn: 0.6090187\ttest: 0.6030627\tbest: 0.6030627 (1616)\ttotal: 23.9s\tremaining: 50s\n",
      "1617:\tlearn: 0.6090158\ttest: 0.6030598\tbest: 0.6030598 (1617)\ttotal: 23.9s\tremaining: 50s\n",
      "1618:\tlearn: 0.6090129\ttest: 0.6030538\tbest: 0.6030538 (1618)\ttotal: 23.9s\tremaining: 50s\n",
      "1619:\tlearn: 0.6090129\ttest: 0.6030538\tbest: 0.6030538 (1618)\ttotal: 23.9s\tremaining: 50s\n",
      "1620:\tlearn: 0.6090129\ttest: 0.6030538\tbest: 0.6030538 (1618)\ttotal: 24s\tremaining: 50s\n",
      "1621:\tlearn: 0.6090078\ttest: 0.6030525\tbest: 0.6030525 (1621)\ttotal: 24s\tremaining: 50s\n",
      "1622:\tlearn: 0.6090078\ttest: 0.6030525\tbest: 0.6030525 (1621)\ttotal: 24s\tremaining: 49.9s\n",
      "1623:\tlearn: 0.6090053\ttest: 0.6030471\tbest: 0.6030471 (1623)\ttotal: 24s\tremaining: 50s\n",
      "1624:\tlearn: 0.6089992\ttest: 0.6030390\tbest: 0.6030390 (1624)\ttotal: 24.1s\tremaining: 50s\n",
      "1625:\tlearn: 0.6089942\ttest: 0.6030336\tbest: 0.6030336 (1625)\ttotal: 24.1s\tremaining: 50s\n",
      "1626:\tlearn: 0.6089942\ttest: 0.6030336\tbest: 0.6030336 (1625)\ttotal: 24.1s\tremaining: 49.9s\n",
      "1627:\tlearn: 0.6089891\ttest: 0.6030297\tbest: 0.6030297 (1627)\ttotal: 24.1s\tremaining: 49.9s\n",
      "1628:\tlearn: 0.6089888\ttest: 0.6030297\tbest: 0.6030297 (1628)\ttotal: 24.1s\tremaining: 49.9s\n",
      "1629:\tlearn: 0.6089825\ttest: 0.6030218\tbest: 0.6030218 (1629)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1630:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1631:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1632:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1633:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1634:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1635:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.2s\tremaining: 49.9s\n",
      "1636:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.3s\tremaining: 49.9s\n",
      "1637:\tlearn: 0.6089762\ttest: 0.6030100\tbest: 0.6030100 (1630)\ttotal: 24.3s\tremaining: 49.9s\n",
      "1638:\tlearn: 0.6089424\ttest: 0.6029710\tbest: 0.6029710 (1638)\ttotal: 24.3s\tremaining: 49.9s\n",
      "1639:\tlearn: 0.6089424\ttest: 0.6029710\tbest: 0.6029710 (1638)\ttotal: 24.3s\tremaining: 49.9s\n",
      "1640:\tlearn: 0.6089423\ttest: 0.6029710\tbest: 0.6029710 (1638)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1641:\tlearn: 0.6089317\ttest: 0.6029618\tbest: 0.6029618 (1641)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1642:\tlearn: 0.6089317\ttest: 0.6029619\tbest: 0.6029618 (1641)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1643:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1644:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1645:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1646:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.4s\tremaining: 49.8s\n",
      "1647:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.8s\n",
      "1648:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.7s\n",
      "1649:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.7s\n",
      "1650:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.7s\n",
      "1651:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.7s\n",
      "1652:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.7s\n",
      "1653:\tlearn: 0.6089297\ttest: 0.6029599\tbest: 0.6029599 (1643)\ttotal: 24.5s\tremaining: 49.7s\n",
      "1654:\tlearn: 0.6089247\ttest: 0.6029596\tbest: 0.6029596 (1654)\ttotal: 24.6s\tremaining: 49.7s\n",
      "1655:\tlearn: 0.6088717\ttest: 0.6028934\tbest: 0.6028934 (1655)\ttotal: 24.6s\tremaining: 49.7s\n",
      "1656:\tlearn: 0.6088717\ttest: 0.6028934\tbest: 0.6028934 (1655)\ttotal: 24.6s\tremaining: 49.6s\n",
      "1657:\tlearn: 0.6088717\ttest: 0.6028934\tbest: 0.6028934 (1655)\ttotal: 24.6s\tremaining: 49.6s\n",
      "1658:\tlearn: 0.6088571\ttest: 0.6028877\tbest: 0.6028877 (1658)\ttotal: 24.7s\tremaining: 49.6s\n",
      "1659:\tlearn: 0.6088571\ttest: 0.6028877\tbest: 0.6028877 (1658)\ttotal: 24.7s\tremaining: 49.6s\n",
      "1660:\tlearn: 0.6088509\ttest: 0.6028819\tbest: 0.6028819 (1660)\ttotal: 24.7s\tremaining: 49.6s\n",
      "1661:\tlearn: 0.6088506\ttest: 0.6028818\tbest: 0.6028818 (1661)\ttotal: 24.7s\tremaining: 49.6s\n",
      "1662:\tlearn: 0.6088412\ttest: 0.6028733\tbest: 0.6028733 (1662)\ttotal: 24.8s\tremaining: 49.7s\n",
      "1663:\tlearn: 0.6088412\ttest: 0.6028733\tbest: 0.6028733 (1662)\ttotal: 24.8s\tremaining: 49.7s\n",
      "1664:\tlearn: 0.6088409\ttest: 0.6028732\tbest: 0.6028732 (1664)\ttotal: 24.8s\tremaining: 49.6s\n",
      "1665:\tlearn: 0.6088409\ttest: 0.6028732\tbest: 0.6028732 (1664)\ttotal: 24.8s\tremaining: 49.6s\n",
      "1666:\tlearn: 0.6088409\ttest: 0.6028732\tbest: 0.6028732 (1664)\ttotal: 24.8s\tremaining: 49.6s\n",
      "1667:\tlearn: 0.6088376\ttest: 0.6028715\tbest: 0.6028715 (1667)\ttotal: 24.8s\tremaining: 49.6s\n",
      "1668:\tlearn: 0.6088376\ttest: 0.6028715\tbest: 0.6028715 (1667)\ttotal: 24.8s\tremaining: 49.6s\n",
      "1669:\tlearn: 0.6088376\ttest: 0.6028715\tbest: 0.6028715 (1667)\ttotal: 24.9s\tremaining: 49.6s\n",
      "1670:\tlearn: 0.6088376\ttest: 0.6028715\tbest: 0.6028715 (1667)\ttotal: 24.9s\tremaining: 49.5s\n",
      "1671:\tlearn: 0.6088348\ttest: 0.6028688\tbest: 0.6028688 (1671)\ttotal: 24.9s\tremaining: 49.5s\n",
      "1672:\tlearn: 0.6088348\ttest: 0.6028688\tbest: 0.6028688 (1671)\ttotal: 24.9s\tremaining: 49.5s\n",
      "1673:\tlearn: 0.6088348\ttest: 0.6028688\tbest: 0.6028688 (1671)\ttotal: 24.9s\tremaining: 49.5s\n",
      "1674:\tlearn: 0.6088348\ttest: 0.6028688\tbest: 0.6028688 (1671)\ttotal: 24.9s\tremaining: 49.5s\n",
      "1675:\tlearn: 0.6088348\ttest: 0.6028688\tbest: 0.6028688 (1671)\ttotal: 25s\tremaining: 49.5s\n",
      "1676:\tlearn: 0.6088348\ttest: 0.6028688\tbest: 0.6028688 (1671)\ttotal: 25s\tremaining: 49.5s\n",
      "1677:\tlearn: 0.6088279\ttest: 0.6028642\tbest: 0.6028642 (1677)\ttotal: 25s\tremaining: 49.5s\n",
      "1678:\tlearn: 0.6088279\ttest: 0.6028642\tbest: 0.6028642 (1677)\ttotal: 25s\tremaining: 49.4s\n",
      "1679:\tlearn: 0.6088279\ttest: 0.6028642\tbest: 0.6028642 (1677)\ttotal: 25s\tremaining: 49.4s\n",
      "1680:\tlearn: 0.6088279\ttest: 0.6028642\tbest: 0.6028642 (1677)\ttotal: 25s\tremaining: 49.4s\n",
      "1681:\tlearn: 0.6088118\ttest: 0.6028460\tbest: 0.6028460 (1681)\ttotal: 25.1s\tremaining: 49.4s\n",
      "1682:\tlearn: 0.6088118\ttest: 0.6028460\tbest: 0.6028460 (1681)\ttotal: 25.1s\tremaining: 49.4s\n",
      "1683:\tlearn: 0.6088118\ttest: 0.6028460\tbest: 0.6028460 (1681)\ttotal: 25.1s\tremaining: 49.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684:\tlearn: 0.6088118\ttest: 0.6028460\tbest: 0.6028460 (1681)\ttotal: 25.1s\tremaining: 49.4s\n",
      "1685:\tlearn: 0.6088118\ttest: 0.6028460\tbest: 0.6028460 (1681)\ttotal: 25.1s\tremaining: 49.4s\n",
      "1686:\tlearn: 0.6088076\ttest: 0.6028399\tbest: 0.6028399 (1686)\ttotal: 25.1s\tremaining: 49.4s\n",
      "1687:\tlearn: 0.6088076\ttest: 0.6028399\tbest: 0.6028399 (1686)\ttotal: 25.2s\tremaining: 49.4s\n",
      "1688:\tlearn: 0.6088049\ttest: 0.6028359\tbest: 0.6028359 (1688)\ttotal: 25.2s\tremaining: 49.4s\n",
      "1689:\tlearn: 0.6087945\ttest: 0.6028303\tbest: 0.6028303 (1689)\ttotal: 25.2s\tremaining: 49.4s\n",
      "1690:\tlearn: 0.6087945\ttest: 0.6028303\tbest: 0.6028303 (1689)\ttotal: 25.2s\tremaining: 49.4s\n",
      "1691:\tlearn: 0.6087867\ttest: 0.6028274\tbest: 0.6028274 (1691)\ttotal: 25.3s\tremaining: 49.4s\n",
      "1692:\tlearn: 0.6087867\ttest: 0.6028274\tbest: 0.6028274 (1691)\ttotal: 25.3s\tremaining: 49.4s\n",
      "1693:\tlearn: 0.6087867\ttest: 0.6028274\tbest: 0.6028274 (1691)\ttotal: 25.3s\tremaining: 49.3s\n",
      "1694:\tlearn: 0.6087867\ttest: 0.6028274\tbest: 0.6028274 (1691)\ttotal: 25.3s\tremaining: 49.3s\n",
      "1695:\tlearn: 0.6087867\ttest: 0.6028274\tbest: 0.6028274 (1691)\ttotal: 25.3s\tremaining: 49.3s\n",
      "1696:\tlearn: 0.6087867\ttest: 0.6028274\tbest: 0.6028274 (1691)\ttotal: 25.3s\tremaining: 49.3s\n",
      "1697:\tlearn: 0.6087821\ttest: 0.6028267\tbest: 0.6028267 (1697)\ttotal: 25.4s\tremaining: 49.3s\n",
      "1698:\tlearn: 0.6087818\ttest: 0.6028266\tbest: 0.6028266 (1698)\ttotal: 25.4s\tremaining: 49.3s\n",
      "1699:\tlearn: 0.6087818\ttest: 0.6028266\tbest: 0.6028266 (1698)\ttotal: 25.4s\tremaining: 49.3s\n",
      "1700:\tlearn: 0.6087774\ttest: 0.6028206\tbest: 0.6028206 (1700)\ttotal: 25.4s\tremaining: 49.3s\n",
      "1701:\tlearn: 0.6087717\ttest: 0.6028137\tbest: 0.6028137 (1701)\ttotal: 25.4s\tremaining: 49.3s\n",
      "1702:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.3s\n",
      "1703:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.3s\n",
      "1704:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.2s\n",
      "1705:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.2s\n",
      "1706:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.2s\n",
      "1707:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.2s\n",
      "1708:\tlearn: 0.6087502\ttest: 0.6027993\tbest: 0.6027993 (1702)\ttotal: 25.5s\tremaining: 49.2s\n",
      "1709:\tlearn: 0.6087330\ttest: 0.6027898\tbest: 0.6027898 (1709)\ttotal: 25.6s\tremaining: 49.2s\n",
      "1710:\tlearn: 0.6087330\ttest: 0.6027898\tbest: 0.6027898 (1709)\ttotal: 25.6s\tremaining: 49.2s\n",
      "1711:\tlearn: 0.6087330\ttest: 0.6027898\tbest: 0.6027898 (1709)\ttotal: 25.6s\tremaining: 49.2s\n",
      "1712:\tlearn: 0.6087330\ttest: 0.6027898\tbest: 0.6027898 (1709)\ttotal: 25.6s\tremaining: 49.1s\n",
      "1713:\tlearn: 0.6087303\ttest: 0.6027873\tbest: 0.6027873 (1713)\ttotal: 25.6s\tremaining: 49.1s\n",
      "1714:\tlearn: 0.6087303\ttest: 0.6027873\tbest: 0.6027873 (1713)\ttotal: 25.7s\tremaining: 49.1s\n",
      "1715:\tlearn: 0.6087303\ttest: 0.6027873\tbest: 0.6027873 (1713)\ttotal: 25.7s\tremaining: 49.1s\n",
      "1716:\tlearn: 0.6086812\ttest: 0.6027381\tbest: 0.6027381 (1716)\ttotal: 25.7s\tremaining: 49.1s\n",
      "1717:\tlearn: 0.6086812\ttest: 0.6027381\tbest: 0.6027381 (1716)\ttotal: 25.7s\tremaining: 49.1s\n",
      "1718:\tlearn: 0.6086812\ttest: 0.6027381\tbest: 0.6027381 (1716)\ttotal: 25.7s\tremaining: 49.1s\n",
      "1719:\tlearn: 0.6086809\ttest: 0.6027380\tbest: 0.6027380 (1719)\ttotal: 25.8s\tremaining: 49.1s\n",
      "1720:\tlearn: 0.6086787\ttest: 0.6027372\tbest: 0.6027372 (1720)\ttotal: 25.8s\tremaining: 49.1s\n",
      "1721:\tlearn: 0.6086787\ttest: 0.6027372\tbest: 0.6027372 (1720)\ttotal: 25.8s\tremaining: 49.1s\n",
      "1722:\tlearn: 0.6086787\ttest: 0.6027372\tbest: 0.6027372 (1720)\ttotal: 25.8s\tremaining: 49.1s\n",
      "1723:\tlearn: 0.6086787\ttest: 0.6027372\tbest: 0.6027372 (1720)\ttotal: 25.8s\tremaining: 49.1s\n",
      "1724:\tlearn: 0.6086787\ttest: 0.6027372\tbest: 0.6027372 (1720)\ttotal: 25.8s\tremaining: 49s\n",
      "1725:\tlearn: 0.6086762\ttest: 0.6027348\tbest: 0.6027348 (1725)\ttotal: 25.9s\tremaining: 49s\n",
      "1726:\tlearn: 0.6086762\ttest: 0.6027348\tbest: 0.6027348 (1725)\ttotal: 25.9s\tremaining: 49s\n",
      "1727:\tlearn: 0.6086749\ttest: 0.6027329\tbest: 0.6027329 (1727)\ttotal: 25.9s\tremaining: 49s\n",
      "1728:\tlearn: 0.6086706\ttest: 0.6027266\tbest: 0.6027266 (1728)\ttotal: 25.9s\tremaining: 49s\n",
      "1729:\tlearn: 0.6086706\ttest: 0.6027266\tbest: 0.6027266 (1728)\ttotal: 25.9s\tremaining: 49s\n",
      "1730:\tlearn: 0.6086706\ttest: 0.6027266\tbest: 0.6027266 (1728)\ttotal: 25.9s\tremaining: 49s\n",
      "1731:\tlearn: 0.6086706\ttest: 0.6027266\tbest: 0.6027266 (1728)\ttotal: 25.9s\tremaining: 49s\n",
      "1732:\tlearn: 0.6086659\ttest: 0.6027196\tbest: 0.6027196 (1732)\ttotal: 26s\tremaining: 48.9s\n",
      "1733:\tlearn: 0.6086595\ttest: 0.6027111\tbest: 0.6027111 (1733)\ttotal: 26s\tremaining: 48.9s\n",
      "1734:\tlearn: 0.6086595\ttest: 0.6027111\tbest: 0.6027111 (1733)\ttotal: 26s\tremaining: 48.9s\n",
      "1735:\tlearn: 0.6086039\ttest: 0.6026584\tbest: 0.6026584 (1735)\ttotal: 26s\tremaining: 48.9s\n",
      "1736:\tlearn: 0.6086039\ttest: 0.6026584\tbest: 0.6026584 (1735)\ttotal: 26s\tremaining: 48.9s\n",
      "1737:\tlearn: 0.6086039\ttest: 0.6026584\tbest: 0.6026584 (1735)\ttotal: 26.1s\tremaining: 48.9s\n",
      "1738:\tlearn: 0.6086039\ttest: 0.6026584\tbest: 0.6026584 (1735)\ttotal: 26.1s\tremaining: 48.9s\n",
      "1739:\tlearn: 0.6086039\ttest: 0.6026584\tbest: 0.6026584 (1735)\ttotal: 26.1s\tremaining: 48.9s\n",
      "1740:\tlearn: 0.6086039\ttest: 0.6026585\tbest: 0.6026584 (1735)\ttotal: 26.1s\tremaining: 48.9s\n",
      "1741:\tlearn: 0.6086033\ttest: 0.6026578\tbest: 0.6026578 (1741)\ttotal: 26.1s\tremaining: 48.9s\n",
      "1742:\tlearn: 0.6086030\ttest: 0.6026577\tbest: 0.6026577 (1742)\ttotal: 26.1s\tremaining: 48.9s\n",
      "1743:\tlearn: 0.6085962\ttest: 0.6026496\tbest: 0.6026496 (1743)\ttotal: 26.2s\tremaining: 48.9s\n",
      "1744:\tlearn: 0.6085962\ttest: 0.6026496\tbest: 0.6026496 (1743)\ttotal: 26.2s\tremaining: 48.8s\n",
      "1745:\tlearn: 0.6085962\ttest: 0.6026496\tbest: 0.6026496 (1743)\ttotal: 26.2s\tremaining: 48.8s\n",
      "1746:\tlearn: 0.6085910\ttest: 0.6026461\tbest: 0.6026461 (1746)\ttotal: 26.2s\tremaining: 48.8s\n",
      "1747:\tlearn: 0.6085910\ttest: 0.6026461\tbest: 0.6026461 (1746)\ttotal: 26.2s\tremaining: 48.8s\n",
      "1748:\tlearn: 0.6085910\ttest: 0.6026461\tbest: 0.6026461 (1746)\ttotal: 26.3s\tremaining: 48.8s\n",
      "1749:\tlearn: 0.6085838\ttest: 0.6026393\tbest: 0.6026393 (1749)\ttotal: 26.3s\tremaining: 48.8s\n",
      "1750:\tlearn: 0.6085838\ttest: 0.6026393\tbest: 0.6026393 (1749)\ttotal: 26.3s\tremaining: 48.8s\n",
      "1751:\tlearn: 0.6085838\ttest: 0.6026393\tbest: 0.6026393 (1749)\ttotal: 26.3s\tremaining: 48.8s\n",
      "1752:\tlearn: 0.6085838\ttest: 0.6026394\tbest: 0.6026393 (1749)\ttotal: 26.3s\tremaining: 48.8s\n",
      "1753:\tlearn: 0.6085837\ttest: 0.6026394\tbest: 0.6026393 (1749)\ttotal: 26.3s\tremaining: 48.7s\n",
      "1754:\tlearn: 0.6085837\ttest: 0.6026394\tbest: 0.6026393 (1749)\ttotal: 26.4s\tremaining: 48.7s\n",
      "1755:\tlearn: 0.6085837\ttest: 0.6026394\tbest: 0.6026393 (1749)\ttotal: 26.4s\tremaining: 48.7s\n",
      "1756:\tlearn: 0.6085837\ttest: 0.6026394\tbest: 0.6026393 (1749)\ttotal: 26.4s\tremaining: 48.7s\n",
      "1757:\tlearn: 0.6085814\ttest: 0.6026346\tbest: 0.6026346 (1757)\ttotal: 26.4s\tremaining: 48.7s\n",
      "1758:\tlearn: 0.6085814\ttest: 0.6026346\tbest: 0.6026346 (1757)\ttotal: 26.4s\tremaining: 48.7s\n",
      "1759:\tlearn: 0.6085111\ttest: 0.6025673\tbest: 0.6025673 (1759)\ttotal: 26.4s\tremaining: 48.7s\n",
      "1760:\tlearn: 0.6085111\ttest: 0.6025673\tbest: 0.6025673 (1759)\ttotal: 26.4s\tremaining: 48.6s\n",
      "1761:\tlearn: 0.6085111\ttest: 0.6025673\tbest: 0.6025673 (1759)\ttotal: 26.5s\tremaining: 48.6s\n",
      "1762:\tlearn: 0.6085014\ttest: 0.6025593\tbest: 0.6025593 (1762)\ttotal: 26.5s\tremaining: 48.6s\n",
      "1763:\tlearn: 0.6084979\ttest: 0.6025569\tbest: 0.6025569 (1763)\ttotal: 26.5s\tremaining: 48.6s\n",
      "1764:\tlearn: 0.6084979\ttest: 0.6025569\tbest: 0.6025569 (1763)\ttotal: 26.5s\tremaining: 48.6s\n",
      "1765:\tlearn: 0.6084906\ttest: 0.6025538\tbest: 0.6025538 (1765)\ttotal: 26.5s\tremaining: 48.6s\n",
      "1766:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.5s\tremaining: 48.5s\n",
      "1767:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.5s\tremaining: 48.5s\n",
      "1768:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.6s\tremaining: 48.5s\n",
      "1769:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.6s\tremaining: 48.5s\n",
      "1770:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.6s\tremaining: 48.5s\n",
      "1771:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.6s\tremaining: 48.4s\n",
      "1772:\tlearn: 0.6084906\ttest: 0.6025539\tbest: 0.6025538 (1765)\ttotal: 26.6s\tremaining: 48.4s\n",
      "1773:\tlearn: 0.6084851\ttest: 0.6025499\tbest: 0.6025499 (1773)\ttotal: 26.6s\tremaining: 48.4s\n",
      "1774:\tlearn: 0.6084781\ttest: 0.6025433\tbest: 0.6025433 (1774)\ttotal: 26.6s\tremaining: 48.4s\n",
      "1775:\tlearn: 0.6084781\ttest: 0.6025433\tbest: 0.6025433 (1774)\ttotal: 26.7s\tremaining: 48.4s\n",
      "1776:\tlearn: 0.6084781\ttest: 0.6025433\tbest: 0.6025433 (1774)\ttotal: 26.7s\tremaining: 48.4s\n",
      "1777:\tlearn: 0.6084709\ttest: 0.6025369\tbest: 0.6025369 (1777)\ttotal: 26.7s\tremaining: 48.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1778:\tlearn: 0.6084683\ttest: 0.6025347\tbest: 0.6025347 (1778)\ttotal: 26.7s\tremaining: 48.4s\n",
      "1779:\tlearn: 0.6084672\ttest: 0.6025327\tbest: 0.6025327 (1779)\ttotal: 26.7s\tremaining: 48.3s\n",
      "1780:\tlearn: 0.6084672\ttest: 0.6025327\tbest: 0.6025327 (1779)\ttotal: 26.7s\tremaining: 48.3s\n",
      "1781:\tlearn: 0.6084609\ttest: 0.6025284\tbest: 0.6025284 (1781)\ttotal: 26.8s\tremaining: 48.3s\n",
      "1782:\tlearn: 0.6084609\ttest: 0.6025284\tbest: 0.6025284 (1781)\ttotal: 26.8s\tremaining: 48.3s\n",
      "1783:\tlearn: 0.6084609\ttest: 0.6025284\tbest: 0.6025284 (1781)\ttotal: 26.8s\tremaining: 48.3s\n",
      "1784:\tlearn: 0.6084609\ttest: 0.6025284\tbest: 0.6025284 (1781)\ttotal: 26.8s\tremaining: 48.3s\n",
      "1785:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.8s\tremaining: 48.3s\n",
      "1786:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.8s\tremaining: 48.2s\n",
      "1787:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.8s\tremaining: 48.2s\n",
      "1788:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.9s\tremaining: 48.2s\n",
      "1789:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.9s\tremaining: 48.2s\n",
      "1790:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.9s\tremaining: 48.2s\n",
      "1791:\tlearn: 0.6084213\ttest: 0.6024811\tbest: 0.6024811 (1785)\ttotal: 26.9s\tremaining: 48.2s\n",
      "1792:\tlearn: 0.6084212\ttest: 0.6024811\tbest: 0.6024811 (1792)\ttotal: 26.9s\tremaining: 48.2s\n",
      "1793:\tlearn: 0.6084210\ttest: 0.6024811\tbest: 0.6024811 (1792)\ttotal: 26.9s\tremaining: 48.1s\n",
      "1794:\tlearn: 0.6084210\ttest: 0.6024811\tbest: 0.6024811 (1792)\ttotal: 27s\tremaining: 48.1s\n",
      "1795:\tlearn: 0.6084210\ttest: 0.6024811\tbest: 0.6024811 (1792)\ttotal: 27s\tremaining: 48.1s\n",
      "1796:\tlearn: 0.6084137\ttest: 0.6024750\tbest: 0.6024750 (1796)\ttotal: 27s\tremaining: 48.1s\n",
      "1797:\tlearn: 0.6084137\ttest: 0.6024750\tbest: 0.6024750 (1796)\ttotal: 27s\tremaining: 48.1s\n",
      "1798:\tlearn: 0.6084096\ttest: 0.6024734\tbest: 0.6024734 (1798)\ttotal: 27s\tremaining: 48.1s\n",
      "1799:\tlearn: 0.6083923\ttest: 0.6024504\tbest: 0.6024504 (1799)\ttotal: 27s\tremaining: 48.1s\n",
      "1800:\tlearn: 0.6083923\ttest: 0.6024504\tbest: 0.6024504 (1799)\ttotal: 27.1s\tremaining: 48s\n",
      "1801:\tlearn: 0.6083923\ttest: 0.6024504\tbest: 0.6024504 (1799)\ttotal: 27.1s\tremaining: 48s\n",
      "1802:\tlearn: 0.6083923\ttest: 0.6024504\tbest: 0.6024504 (1799)\ttotal: 27.1s\tremaining: 48s\n",
      "1803:\tlearn: 0.6083748\ttest: 0.6024322\tbest: 0.6024322 (1803)\ttotal: 27.1s\tremaining: 48s\n",
      "1804:\tlearn: 0.6083727\ttest: 0.6024277\tbest: 0.6024277 (1804)\ttotal: 27.1s\tremaining: 48s\n",
      "1805:\tlearn: 0.6083727\ttest: 0.6024277\tbest: 0.6024277 (1804)\ttotal: 27.1s\tremaining: 48s\n",
      "1806:\tlearn: 0.6083727\ttest: 0.6024277\tbest: 0.6024277 (1804)\ttotal: 27.1s\tremaining: 47.9s\n",
      "1807:\tlearn: 0.6083727\ttest: 0.6024277\tbest: 0.6024277 (1804)\ttotal: 27.1s\tremaining: 47.9s\n",
      "1808:\tlearn: 0.6083727\ttest: 0.6024277\tbest: 0.6024277 (1804)\ttotal: 27.2s\tremaining: 47.9s\n",
      "1809:\tlearn: 0.6083549\ttest: 0.6024115\tbest: 0.6024115 (1809)\ttotal: 27.2s\tremaining: 47.9s\n",
      "1810:\tlearn: 0.6083549\ttest: 0.6024115\tbest: 0.6024115 (1809)\ttotal: 27.2s\tremaining: 47.9s\n",
      "1811:\tlearn: 0.6083549\ttest: 0.6024115\tbest: 0.6024115 (1809)\ttotal: 27.2s\tremaining: 47.9s\n",
      "1812:\tlearn: 0.6083517\ttest: 0.6024082\tbest: 0.6024082 (1812)\ttotal: 27.2s\tremaining: 47.9s\n",
      "1813:\tlearn: 0.6083510\ttest: 0.6024083\tbest: 0.6024082 (1812)\ttotal: 27.2s\tremaining: 47.9s\n",
      "1814:\tlearn: 0.6083510\ttest: 0.6024083\tbest: 0.6024082 (1812)\ttotal: 27.3s\tremaining: 47.8s\n",
      "1815:\tlearn: 0.6083470\ttest: 0.6024026\tbest: 0.6024026 (1815)\ttotal: 27.3s\tremaining: 47.8s\n",
      "1816:\tlearn: 0.6083470\ttest: 0.6024026\tbest: 0.6024026 (1815)\ttotal: 27.3s\tremaining: 47.8s\n",
      "1817:\tlearn: 0.6083470\ttest: 0.6024026\tbest: 0.6024026 (1815)\ttotal: 27.3s\tremaining: 47.8s\n",
      "1818:\tlearn: 0.6083470\ttest: 0.6024026\tbest: 0.6024026 (1815)\ttotal: 27.3s\tremaining: 47.8s\n",
      "1819:\tlearn: 0.6083470\ttest: 0.6024026\tbest: 0.6024026 (1815)\ttotal: 27.3s\tremaining: 47.7s\n",
      "1820:\tlearn: 0.6083417\ttest: 0.6023990\tbest: 0.6023990 (1820)\ttotal: 27.3s\tremaining: 47.7s\n",
      "1821:\tlearn: 0.6083417\ttest: 0.6023990\tbest: 0.6023990 (1820)\ttotal: 27.4s\tremaining: 47.7s\n",
      "1822:\tlearn: 0.6083417\ttest: 0.6023990\tbest: 0.6023990 (1820)\ttotal: 27.4s\tremaining: 47.7s\n",
      "1823:\tlearn: 0.6083417\ttest: 0.6023990\tbest: 0.6023990 (1820)\ttotal: 27.4s\tremaining: 47.7s\n",
      "1824:\tlearn: 0.6083334\ttest: 0.6023899\tbest: 0.6023899 (1824)\ttotal: 27.4s\tremaining: 47.7s\n",
      "1825:\tlearn: 0.6083246\ttest: 0.6023792\tbest: 0.6023792 (1825)\ttotal: 27.4s\tremaining: 47.7s\n",
      "1826:\tlearn: 0.6083246\ttest: 0.6023792\tbest: 0.6023792 (1825)\ttotal: 27.4s\tremaining: 47.6s\n",
      "1827:\tlearn: 0.6083246\ttest: 0.6023792\tbest: 0.6023792 (1825)\ttotal: 27.4s\tremaining: 47.6s\n",
      "1828:\tlearn: 0.6083230\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.5s\tremaining: 47.6s\n",
      "1829:\tlearn: 0.6083230\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.5s\tremaining: 47.6s\n",
      "1830:\tlearn: 0.6083230\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.5s\tremaining: 47.6s\n",
      "1831:\tlearn: 0.6083229\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.5s\tremaining: 47.6s\n",
      "1832:\tlearn: 0.6083229\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.5s\tremaining: 47.6s\n",
      "1833:\tlearn: 0.6083229\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.6s\tremaining: 47.6s\n",
      "1834:\tlearn: 0.6083229\ttest: 0.6023776\tbest: 0.6023776 (1828)\ttotal: 27.6s\tremaining: 47.5s\n",
      "1835:\tlearn: 0.6083201\ttest: 0.6023725\tbest: 0.6023725 (1835)\ttotal: 27.6s\tremaining: 47.5s\n",
      "1836:\tlearn: 0.6083042\ttest: 0.6023658\tbest: 0.6023658 (1836)\ttotal: 27.6s\tremaining: 47.6s\n",
      "1837:\tlearn: 0.6083042\ttest: 0.6023658\tbest: 0.6023658 (1836)\ttotal: 27.6s\tremaining: 47.5s\n",
      "1838:\tlearn: 0.6082539\ttest: 0.6022998\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.5s\n",
      "1839:\tlearn: 0.6082539\ttest: 0.6022998\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.5s\n",
      "1840:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.5s\n",
      "1841:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.5s\n",
      "1842:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.5s\n",
      "1843:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.5s\n",
      "1844:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.7s\tremaining: 47.4s\n",
      "1845:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.8s\tremaining: 47.4s\n",
      "1846:\tlearn: 0.6082539\ttest: 0.6022999\tbest: 0.6022998 (1838)\ttotal: 27.8s\tremaining: 47.4s\n",
      "1847:\tlearn: 0.6082185\ttest: 0.6022603\tbest: 0.6022603 (1847)\ttotal: 27.8s\tremaining: 47.4s\n",
      "1848:\tlearn: 0.6082185\ttest: 0.6022604\tbest: 0.6022603 (1847)\ttotal: 27.8s\tremaining: 47.4s\n",
      "1849:\tlearn: 0.6082155\ttest: 0.6022588\tbest: 0.6022588 (1849)\ttotal: 27.8s\tremaining: 47.4s\n",
      "1850:\tlearn: 0.6082155\ttest: 0.6022588\tbest: 0.6022588 (1849)\ttotal: 27.8s\tremaining: 47.4s\n",
      "1851:\tlearn: 0.6082155\ttest: 0.6022588\tbest: 0.6022588 (1849)\ttotal: 27.9s\tremaining: 47.3s\n",
      "1852:\tlearn: 0.6082155\ttest: 0.6022588\tbest: 0.6022588 (1849)\ttotal: 27.9s\tremaining: 47.3s\n",
      "1853:\tlearn: 0.6082155\ttest: 0.6022588\tbest: 0.6022588 (1849)\ttotal: 27.9s\tremaining: 47.3s\n",
      "1854:\tlearn: 0.6082155\ttest: 0.6022588\tbest: 0.6022588 (1849)\ttotal: 27.9s\tremaining: 47.3s\n",
      "1855:\tlearn: 0.6082141\ttest: 0.6022581\tbest: 0.6022581 (1855)\ttotal: 27.9s\tremaining: 47.3s\n",
      "1856:\tlearn: 0.6082132\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 27.9s\tremaining: 47.3s\n",
      "1857:\tlearn: 0.6082132\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 27.9s\tremaining: 47.2s\n",
      "1858:\tlearn: 0.6082132\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 27.9s\tremaining: 47.2s\n",
      "1859:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.2s\n",
      "1860:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.2s\n",
      "1861:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.2s\n",
      "1862:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.2s\n",
      "1863:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.1s\n",
      "1864:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.1s\n",
      "1865:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28s\tremaining: 47.1s\n",
      "1866:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28.1s\tremaining: 47.1s\n",
      "1867:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28.1s\tremaining: 47.1s\n",
      "1868:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28.1s\tremaining: 47s\n",
      "1869:\tlearn: 0.6082131\ttest: 0.6022577\tbest: 0.6022577 (1856)\ttotal: 28.1s\tremaining: 47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870:\tlearn: 0.6082050\ttest: 0.6022510\tbest: 0.6022510 (1870)\ttotal: 28.1s\tremaining: 47s\n",
      "1871:\tlearn: 0.6082050\ttest: 0.6022510\tbest: 0.6022510 (1870)\ttotal: 28.1s\tremaining: 47s\n",
      "1872:\tlearn: 0.6081936\ttest: 0.6022397\tbest: 0.6022397 (1872)\ttotal: 28.1s\tremaining: 47s\n",
      "1873:\tlearn: 0.6081921\ttest: 0.6022370\tbest: 0.6022370 (1873)\ttotal: 28.2s\tremaining: 47s\n",
      "1874:\tlearn: 0.6081921\ttest: 0.6022370\tbest: 0.6022370 (1873)\ttotal: 28.2s\tremaining: 47s\n",
      "1875:\tlearn: 0.6081921\ttest: 0.6022370\tbest: 0.6022370 (1873)\ttotal: 28.2s\tremaining: 46.9s\n",
      "1876:\tlearn: 0.6081921\ttest: 0.6022370\tbest: 0.6022370 (1873)\ttotal: 28.2s\tremaining: 46.9s\n",
      "1877:\tlearn: 0.6081921\ttest: 0.6022370\tbest: 0.6022370 (1873)\ttotal: 28.2s\tremaining: 46.9s\n",
      "1878:\tlearn: 0.6081606\ttest: 0.6022143\tbest: 0.6022143 (1878)\ttotal: 28.2s\tremaining: 46.9s\n",
      "1879:\tlearn: 0.6081539\ttest: 0.6022102\tbest: 0.6022102 (1879)\ttotal: 28.2s\tremaining: 46.9s\n",
      "1880:\tlearn: 0.6081337\ttest: 0.6021966\tbest: 0.6021966 (1880)\ttotal: 28.3s\tremaining: 46.9s\n",
      "1881:\tlearn: 0.6081270\ttest: 0.6021909\tbest: 0.6021909 (1881)\ttotal: 28.3s\tremaining: 46.9s\n",
      "1882:\tlearn: 0.6081270\ttest: 0.6021909\tbest: 0.6021909 (1881)\ttotal: 28.3s\tremaining: 46.8s\n",
      "1883:\tlearn: 0.6081270\ttest: 0.6021909\tbest: 0.6021909 (1881)\ttotal: 28.3s\tremaining: 46.8s\n",
      "1884:\tlearn: 0.6081270\ttest: 0.6021909\tbest: 0.6021909 (1881)\ttotal: 28.3s\tremaining: 46.8s\n",
      "1885:\tlearn: 0.6081000\ttest: 0.6021610\tbest: 0.6021610 (1885)\ttotal: 28.3s\tremaining: 46.8s\n",
      "1886:\tlearn: 0.6081000\ttest: 0.6021610\tbest: 0.6021610 (1885)\ttotal: 28.4s\tremaining: 46.8s\n",
      "1887:\tlearn: 0.6081000\ttest: 0.6021610\tbest: 0.6021610 (1885)\ttotal: 28.4s\tremaining: 46.8s\n",
      "1888:\tlearn: 0.6081000\ttest: 0.6021610\tbest: 0.6021610 (1885)\ttotal: 28.4s\tremaining: 46.7s\n",
      "1889:\tlearn: 0.6081000\ttest: 0.6021611\tbest: 0.6021610 (1885)\ttotal: 28.4s\tremaining: 46.7s\n",
      "1890:\tlearn: 0.6080999\ttest: 0.6021610\tbest: 0.6021610 (1890)\ttotal: 28.4s\tremaining: 46.7s\n",
      "1891:\tlearn: 0.6080591\ttest: 0.6021058\tbest: 0.6021058 (1891)\ttotal: 28.4s\tremaining: 46.7s\n",
      "1892:\tlearn: 0.6080591\ttest: 0.6021058\tbest: 0.6021058 (1891)\ttotal: 28.4s\tremaining: 46.7s\n",
      "1893:\tlearn: 0.6080591\ttest: 0.6021058\tbest: 0.6021058 (1891)\ttotal: 28.5s\tremaining: 46.7s\n",
      "1894:\tlearn: 0.6080590\ttest: 0.6021058\tbest: 0.6021058 (1891)\ttotal: 28.5s\tremaining: 46.7s\n",
      "1895:\tlearn: 0.6080523\ttest: 0.6020983\tbest: 0.6020983 (1895)\ttotal: 28.5s\tremaining: 46.6s\n",
      "1896:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.5s\tremaining: 46.6s\n",
      "1897:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.5s\tremaining: 46.6s\n",
      "1898:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.5s\tremaining: 46.6s\n",
      "1899:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.6s\tremaining: 46.6s\n",
      "1900:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.6s\tremaining: 46.6s\n",
      "1901:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.6s\tremaining: 46.6s\n",
      "1902:\tlearn: 0.6080487\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.6s\tremaining: 46.6s\n",
      "1903:\tlearn: 0.6080487\ttest: 0.6020967\tbest: 0.6020966 (1896)\ttotal: 28.6s\tremaining: 46.5s\n",
      "1904:\tlearn: 0.6080487\ttest: 0.6020967\tbest: 0.6020966 (1896)\ttotal: 28.6s\tremaining: 46.5s\n",
      "1905:\tlearn: 0.6080487\ttest: 0.6020967\tbest: 0.6020966 (1896)\ttotal: 28.7s\tremaining: 46.5s\n",
      "1906:\tlearn: 0.6080487\ttest: 0.6020967\tbest: 0.6020966 (1896)\ttotal: 28.7s\tremaining: 46.5s\n",
      "1907:\tlearn: 0.6080487\ttest: 0.6020967\tbest: 0.6020966 (1896)\ttotal: 28.7s\tremaining: 46.5s\n",
      "1908:\tlearn: 0.6080480\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.7s\tremaining: 46.5s\n",
      "1909:\tlearn: 0.6080480\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.7s\tremaining: 46.5s\n",
      "1910:\tlearn: 0.6080480\ttest: 0.6020966\tbest: 0.6020966 (1896)\ttotal: 28.7s\tremaining: 46.4s\n",
      "1911:\tlearn: 0.6080435\ttest: 0.6020932\tbest: 0.6020932 (1911)\ttotal: 28.7s\tremaining: 46.4s\n",
      "1912:\tlearn: 0.6080435\ttest: 0.6020932\tbest: 0.6020932 (1911)\ttotal: 28.8s\tremaining: 46.4s\n",
      "1913:\tlearn: 0.6080435\ttest: 0.6020933\tbest: 0.6020932 (1911)\ttotal: 28.8s\tremaining: 46.4s\n",
      "1914:\tlearn: 0.6080435\ttest: 0.6020933\tbest: 0.6020932 (1911)\ttotal: 28.8s\tremaining: 46.4s\n",
      "1915:\tlearn: 0.6080435\ttest: 0.6020933\tbest: 0.6020932 (1911)\ttotal: 28.8s\tremaining: 46.4s\n",
      "1916:\tlearn: 0.6080372\ttest: 0.6020892\tbest: 0.6020892 (1916)\ttotal: 28.8s\tremaining: 46.3s\n",
      "1917:\tlearn: 0.6080371\ttest: 0.6020892\tbest: 0.6020892 (1916)\ttotal: 28.8s\tremaining: 46.3s\n",
      "1918:\tlearn: 0.6080280\ttest: 0.6020800\tbest: 0.6020800 (1918)\ttotal: 28.8s\tremaining: 46.3s\n",
      "1919:\tlearn: 0.6080280\ttest: 0.6020800\tbest: 0.6020800 (1918)\ttotal: 28.9s\tremaining: 46.3s\n",
      "1920:\tlearn: 0.6080280\ttest: 0.6020800\tbest: 0.6020800 (1918)\ttotal: 28.9s\tremaining: 46.3s\n",
      "1921:\tlearn: 0.6080117\ttest: 0.6020646\tbest: 0.6020646 (1921)\ttotal: 28.9s\tremaining: 46.3s\n",
      "1922:\tlearn: 0.6080117\ttest: 0.6020646\tbest: 0.6020646 (1921)\ttotal: 28.9s\tremaining: 46.3s\n",
      "1923:\tlearn: 0.6080117\ttest: 0.6020647\tbest: 0.6020646 (1921)\ttotal: 28.9s\tremaining: 46.2s\n",
      "1924:\tlearn: 0.6080117\ttest: 0.6020647\tbest: 0.6020646 (1921)\ttotal: 28.9s\tremaining: 46.2s\n",
      "1925:\tlearn: 0.6080117\ttest: 0.6020647\tbest: 0.6020646 (1921)\ttotal: 29s\tremaining: 46.2s\n",
      "1926:\tlearn: 0.6080117\ttest: 0.6020647\tbest: 0.6020646 (1921)\ttotal: 29s\tremaining: 46.2s\n",
      "1927:\tlearn: 0.6080117\ttest: 0.6020647\tbest: 0.6020646 (1921)\ttotal: 29s\tremaining: 46.2s\n",
      "1928:\tlearn: 0.6080113\ttest: 0.6020640\tbest: 0.6020640 (1928)\ttotal: 29s\tremaining: 46.2s\n",
      "1929:\tlearn: 0.6080113\ttest: 0.6020640\tbest: 0.6020640 (1928)\ttotal: 29s\tremaining: 46.2s\n",
      "1930:\tlearn: 0.6080113\ttest: 0.6020640\tbest: 0.6020640 (1928)\ttotal: 29s\tremaining: 46.1s\n",
      "1931:\tlearn: 0.6080113\ttest: 0.6020641\tbest: 0.6020640 (1928)\ttotal: 29s\tremaining: 46.1s\n",
      "1932:\tlearn: 0.6080113\ttest: 0.6020641\tbest: 0.6020640 (1928)\ttotal: 29.1s\tremaining: 46.1s\n",
      "1933:\tlearn: 0.6080090\ttest: 0.6020589\tbest: 0.6020589 (1933)\ttotal: 29.1s\tremaining: 46.1s\n",
      "1934:\tlearn: 0.6080090\ttest: 0.6020589\tbest: 0.6020589 (1933)\ttotal: 29.1s\tremaining: 46.1s\n",
      "1935:\tlearn: 0.6080090\ttest: 0.6020589\tbest: 0.6020589 (1933)\ttotal: 29.1s\tremaining: 46.1s\n",
      "1936:\tlearn: 0.6080090\ttest: 0.6020589\tbest: 0.6020589 (1933)\ttotal: 29.1s\tremaining: 46s\n",
      "1937:\tlearn: 0.6080090\ttest: 0.6020589\tbest: 0.6020589 (1933)\ttotal: 29.1s\tremaining: 46s\n",
      "1938:\tlearn: 0.6079936\ttest: 0.6020433\tbest: 0.6020433 (1938)\ttotal: 29.1s\tremaining: 46s\n",
      "1939:\tlearn: 0.6079936\ttest: 0.6020433\tbest: 0.6020433 (1938)\ttotal: 29.2s\tremaining: 46s\n",
      "1940:\tlearn: 0.6079887\ttest: 0.6020388\tbest: 0.6020388 (1940)\ttotal: 29.2s\tremaining: 46s\n",
      "1941:\tlearn: 0.6079887\ttest: 0.6020388\tbest: 0.6020388 (1940)\ttotal: 29.2s\tremaining: 46s\n",
      "1942:\tlearn: 0.6079887\ttest: 0.6020388\tbest: 0.6020388 (1940)\ttotal: 29.2s\tremaining: 45.9s\n",
      "1943:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.2s\tremaining: 45.9s\n",
      "1944:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.2s\tremaining: 45.9s\n",
      "1945:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.9s\n",
      "1946:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.9s\n",
      "1947:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.9s\n",
      "1948:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.9s\n",
      "1949:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.8s\n",
      "1950:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.8s\n",
      "1951:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.8s\n",
      "1952:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.3s\tremaining: 45.8s\n",
      "1953:\tlearn: 0.6079814\ttest: 0.6020318\tbest: 0.6020318 (1943)\ttotal: 29.4s\tremaining: 45.8s\n",
      "1954:\tlearn: 0.6079791\ttest: 0.6020297\tbest: 0.6020297 (1954)\ttotal: 29.4s\tremaining: 45.8s\n",
      "1955:\tlearn: 0.6079791\ttest: 0.6020297\tbest: 0.6020297 (1954)\ttotal: 29.4s\tremaining: 45.7s\n",
      "1956:\tlearn: 0.6079791\ttest: 0.6020297\tbest: 0.6020297 (1954)\ttotal: 29.4s\tremaining: 45.7s\n",
      "1957:\tlearn: 0.6079779\ttest: 0.6020276\tbest: 0.6020276 (1957)\ttotal: 29.4s\tremaining: 45.7s\n",
      "1958:\tlearn: 0.6079728\ttest: 0.6020207\tbest: 0.6020207 (1958)\ttotal: 29.4s\tremaining: 45.7s\n",
      "1959:\tlearn: 0.6079728\ttest: 0.6020207\tbest: 0.6020207 (1958)\ttotal: 29.5s\tremaining: 45.7s\n",
      "1960:\tlearn: 0.6079714\ttest: 0.6020190\tbest: 0.6020190 (1960)\ttotal: 29.5s\tremaining: 45.7s\n",
      "1961:\tlearn: 0.6079665\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.5s\tremaining: 45.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962:\tlearn: 0.6079664\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.5s\tremaining: 45.7s\n",
      "1963:\tlearn: 0.6079664\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.5s\tremaining: 45.6s\n",
      "1964:\tlearn: 0.6079664\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.5s\tremaining: 45.6s\n",
      "1965:\tlearn: 0.6079664\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.6s\tremaining: 45.6s\n",
      "1966:\tlearn: 0.6079664\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.6s\tremaining: 45.6s\n",
      "1967:\tlearn: 0.6079664\ttest: 0.6020153\tbest: 0.6020153 (1961)\ttotal: 29.6s\tremaining: 45.6s\n",
      "1968:\tlearn: 0.6079627\ttest: 0.6020097\tbest: 0.6020097 (1968)\ttotal: 29.6s\tremaining: 45.6s\n",
      "1969:\tlearn: 0.6079627\ttest: 0.6020097\tbest: 0.6020097 (1968)\ttotal: 29.6s\tremaining: 45.6s\n",
      "1970:\tlearn: 0.6079620\ttest: 0.6020094\tbest: 0.6020094 (1970)\ttotal: 29.6s\tremaining: 45.5s\n",
      "1971:\tlearn: 0.6079620\ttest: 0.6020094\tbest: 0.6020094 (1970)\ttotal: 29.6s\tremaining: 45.5s\n",
      "1972:\tlearn: 0.6079589\ttest: 0.6020069\tbest: 0.6020069 (1972)\ttotal: 29.7s\tremaining: 45.5s\n",
      "1973:\tlearn: 0.6079589\ttest: 0.6020069\tbest: 0.6020069 (1972)\ttotal: 29.7s\tremaining: 45.5s\n",
      "1974:\tlearn: 0.6079589\ttest: 0.6020069\tbest: 0.6020069 (1972)\ttotal: 29.7s\tremaining: 45.5s\n",
      "1975:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.7s\tremaining: 45.5s\n",
      "1976:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.7s\tremaining: 45.4s\n",
      "1977:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.7s\tremaining: 45.4s\n",
      "1978:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.8s\tremaining: 45.4s\n",
      "1979:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.8s\tremaining: 45.4s\n",
      "1980:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.8s\tremaining: 45.4s\n",
      "1981:\tlearn: 0.6079586\ttest: 0.6020069\tbest: 0.6020069 (1975)\ttotal: 29.8s\tremaining: 45.4s\n",
      "1982:\tlearn: 0.6079576\ttest: 0.6020056\tbest: 0.6020056 (1982)\ttotal: 29.8s\tremaining: 45.4s\n",
      "1983:\tlearn: 0.6079565\ttest: 0.6020036\tbest: 0.6020036 (1983)\ttotal: 29.8s\tremaining: 45.4s\n",
      "1984:\tlearn: 0.6079565\ttest: 0.6020036\tbest: 0.6020036 (1983)\ttotal: 29.8s\tremaining: 45.3s\n",
      "1985:\tlearn: 0.6079565\ttest: 0.6020036\tbest: 0.6020036 (1983)\ttotal: 29.9s\tremaining: 45.3s\n",
      "1986:\tlearn: 0.6079565\ttest: 0.6020036\tbest: 0.6020036 (1983)\ttotal: 29.9s\tremaining: 45.3s\n",
      "1987:\tlearn: 0.6079565\ttest: 0.6020036\tbest: 0.6020036 (1983)\ttotal: 29.9s\tremaining: 45.3s\n",
      "1988:\tlearn: 0.6079513\ttest: 0.6019990\tbest: 0.6019990 (1988)\ttotal: 29.9s\tremaining: 45.3s\n",
      "1989:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 29.9s\tremaining: 45.3s\n",
      "1990:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 29.9s\tremaining: 45.2s\n",
      "1991:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 30s\tremaining: 45.2s\n",
      "1992:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 30s\tremaining: 45.2s\n",
      "1993:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 30s\tremaining: 45.2s\n",
      "1994:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 30s\tremaining: 45.2s\n",
      "1995:\tlearn: 0.6079486\ttest: 0.6019969\tbest: 0.6019969 (1989)\ttotal: 30s\tremaining: 45.2s\n",
      "1996:\tlearn: 0.6079486\ttest: 0.6019970\tbest: 0.6019969 (1989)\ttotal: 30s\tremaining: 45.2s\n",
      "1997:\tlearn: 0.6079454\ttest: 0.6019928\tbest: 0.6019928 (1997)\ttotal: 30.1s\tremaining: 45.2s\n",
      "1998:\tlearn: 0.6079454\ttest: 0.6019928\tbest: 0.6019928 (1997)\ttotal: 30.1s\tremaining: 45.1s\n",
      "1999:\tlearn: 0.6079454\ttest: 0.6019928\tbest: 0.6019928 (1997)\ttotal: 30.1s\tremaining: 45.1s\n",
      "2000:\tlearn: 0.6079451\ttest: 0.6019928\tbest: 0.6019928 (2000)\ttotal: 30.1s\tremaining: 45.1s\n",
      "2001:\tlearn: 0.6079451\ttest: 0.6019928\tbest: 0.6019928 (2000)\ttotal: 30.1s\tremaining: 45.1s\n",
      "2002:\tlearn: 0.6079417\ttest: 0.6019876\tbest: 0.6019876 (2002)\ttotal: 30.1s\tremaining: 45.1s\n",
      "2003:\tlearn: 0.6079417\ttest: 0.6019876\tbest: 0.6019876 (2002)\ttotal: 30.1s\tremaining: 45.1s\n",
      "2004:\tlearn: 0.6079417\ttest: 0.6019876\tbest: 0.6019876 (2002)\ttotal: 30.2s\tremaining: 45s\n",
      "2005:\tlearn: 0.6079417\ttest: 0.6019876\tbest: 0.6019876 (2002)\ttotal: 30.2s\tremaining: 45s\n",
      "2006:\tlearn: 0.6079417\ttest: 0.6019876\tbest: 0.6019876 (2002)\ttotal: 30.2s\tremaining: 45s\n",
      "2007:\tlearn: 0.6079388\ttest: 0.6019837\tbest: 0.6019837 (2007)\ttotal: 30.2s\tremaining: 45s\n",
      "2008:\tlearn: 0.6079341\ttest: 0.6019798\tbest: 0.6019798 (2008)\ttotal: 30.2s\tremaining: 45s\n",
      "2009:\tlearn: 0.6079341\ttest: 0.6019798\tbest: 0.6019798 (2008)\ttotal: 30.2s\tremaining: 45s\n",
      "2010:\tlearn: 0.6079341\ttest: 0.6019798\tbest: 0.6019798 (2008)\ttotal: 30.2s\tremaining: 45s\n",
      "2011:\tlearn: 0.6079341\ttest: 0.6019798\tbest: 0.6019798 (2008)\ttotal: 30.3s\tremaining: 44.9s\n",
      "2012:\tlearn: 0.6079341\ttest: 0.6019798\tbest: 0.6019798 (2008)\ttotal: 30.3s\tremaining: 44.9s\n",
      "2013:\tlearn: 0.6079341\ttest: 0.6019798\tbest: 0.6019798 (2008)\ttotal: 30.3s\tremaining: 44.9s\n",
      "2014:\tlearn: 0.6079283\ttest: 0.6019760\tbest: 0.6019760 (2014)\ttotal: 30.3s\tremaining: 44.9s\n",
      "2015:\tlearn: 0.6079283\ttest: 0.6019760\tbest: 0.6019760 (2014)\ttotal: 30.3s\tremaining: 44.9s\n",
      "2016:\tlearn: 0.6079283\ttest: 0.6019760\tbest: 0.6019760 (2014)\ttotal: 30.3s\tremaining: 44.8s\n",
      "2017:\tlearn: 0.6079283\ttest: 0.6019760\tbest: 0.6019760 (2014)\ttotal: 30.3s\tremaining: 44.8s\n",
      "2018:\tlearn: 0.6079283\ttest: 0.6019760\tbest: 0.6019760 (2014)\ttotal: 30.3s\tremaining: 44.8s\n",
      "2019:\tlearn: 0.6079253\ttest: 0.6019730\tbest: 0.6019730 (2019)\ttotal: 30.4s\tremaining: 44.8s\n",
      "2020:\tlearn: 0.6079253\ttest: 0.6019730\tbest: 0.6019730 (2019)\ttotal: 30.4s\tremaining: 44.8s\n",
      "2021:\tlearn: 0.6079237\ttest: 0.6019732\tbest: 0.6019730 (2019)\ttotal: 30.4s\tremaining: 44.8s\n",
      "2022:\tlearn: 0.6079208\ttest: 0.6019731\tbest: 0.6019730 (2019)\ttotal: 30.4s\tremaining: 44.8s\n",
      "2023:\tlearn: 0.6079208\ttest: 0.6019731\tbest: 0.6019730 (2019)\ttotal: 30.4s\tremaining: 44.8s\n",
      "2024:\tlearn: 0.6079187\ttest: 0.6019711\tbest: 0.6019711 (2024)\ttotal: 30.5s\tremaining: 44.7s\n",
      "2025:\tlearn: 0.6079187\ttest: 0.6019711\tbest: 0.6019711 (2024)\ttotal: 30.5s\tremaining: 44.7s\n",
      "2026:\tlearn: 0.6079187\ttest: 0.6019711\tbest: 0.6019711 (2024)\ttotal: 30.5s\tremaining: 44.7s\n",
      "2027:\tlearn: 0.6078827\ttest: 0.6019369\tbest: 0.6019369 (2027)\ttotal: 30.5s\tremaining: 44.7s\n",
      "2028:\tlearn: 0.6078827\ttest: 0.6019369\tbest: 0.6019369 (2027)\ttotal: 30.5s\tremaining: 44.7s\n",
      "2029:\tlearn: 0.6078827\ttest: 0.6019369\tbest: 0.6019369 (2027)\ttotal: 30.5s\tremaining: 44.7s\n",
      "2030:\tlearn: 0.6078827\ttest: 0.6019369\tbest: 0.6019369 (2027)\ttotal: 30.6s\tremaining: 44.7s\n",
      "2031:\tlearn: 0.6078827\ttest: 0.6019369\tbest: 0.6019369 (2027)\ttotal: 30.6s\tremaining: 44.6s\n",
      "2032:\tlearn: 0.6078827\ttest: 0.6019369\tbest: 0.6019369 (2027)\ttotal: 30.6s\tremaining: 44.6s\n",
      "2033:\tlearn: 0.6078764\ttest: 0.6019259\tbest: 0.6019259 (2033)\ttotal: 30.6s\tremaining: 44.6s\n",
      "2034:\tlearn: 0.6078764\ttest: 0.6019259\tbest: 0.6019259 (2033)\ttotal: 30.6s\tremaining: 44.6s\n",
      "2035:\tlearn: 0.6078764\ttest: 0.6019259\tbest: 0.6019259 (2033)\ttotal: 30.6s\tremaining: 44.6s\n",
      "2036:\tlearn: 0.6078764\ttest: 0.6019259\tbest: 0.6019259 (2033)\ttotal: 30.6s\tremaining: 44.6s\n",
      "2037:\tlearn: 0.6078764\ttest: 0.6019259\tbest: 0.6019259 (2033)\ttotal: 30.6s\tremaining: 44.5s\n",
      "2038:\tlearn: 0.6078710\ttest: 0.6019181\tbest: 0.6019181 (2038)\ttotal: 30.7s\tremaining: 44.5s\n",
      "2039:\tlearn: 0.6078710\ttest: 0.6019182\tbest: 0.6019181 (2038)\ttotal: 30.7s\tremaining: 44.5s\n",
      "2040:\tlearn: 0.6078177\ttest: 0.6018669\tbest: 0.6018669 (2040)\ttotal: 30.7s\tremaining: 44.5s\n",
      "2041:\tlearn: 0.6078165\ttest: 0.6018648\tbest: 0.6018648 (2041)\ttotal: 30.7s\tremaining: 44.5s\n",
      "2042:\tlearn: 0.6078113\ttest: 0.6018595\tbest: 0.6018595 (2042)\ttotal: 30.7s\tremaining: 44.5s\n",
      "2043:\tlearn: 0.6078113\ttest: 0.6018595\tbest: 0.6018595 (2042)\ttotal: 30.8s\tremaining: 44.5s\n",
      "2044:\tlearn: 0.6078113\ttest: 0.6018595\tbest: 0.6018595 (2042)\ttotal: 30.8s\tremaining: 44.5s\n",
      "2045:\tlearn: 0.6077999\ttest: 0.6018455\tbest: 0.6018455 (2045)\ttotal: 30.8s\tremaining: 44.5s\n",
      "2046:\tlearn: 0.6077999\ttest: 0.6018455\tbest: 0.6018455 (2045)\ttotal: 30.8s\tremaining: 44.4s\n",
      "2047:\tlearn: 0.6077999\ttest: 0.6018455\tbest: 0.6018455 (2045)\ttotal: 30.8s\tremaining: 44.4s\n",
      "2048:\tlearn: 0.6077985\ttest: 0.6018444\tbest: 0.6018444 (2048)\ttotal: 30.8s\tremaining: 44.4s\n",
      "2049:\tlearn: 0.6077985\ttest: 0.6018444\tbest: 0.6018444 (2048)\ttotal: 30.9s\tremaining: 44.4s\n",
      "2050:\tlearn: 0.6077985\ttest: 0.6018444\tbest: 0.6018444 (2048)\ttotal: 30.9s\tremaining: 44.4s\n",
      "2051:\tlearn: 0.6077452\ttest: 0.6017690\tbest: 0.6017690 (2051)\ttotal: 30.9s\tremaining: 44.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2052:\tlearn: 0.6077452\ttest: 0.6017690\tbest: 0.6017690 (2051)\ttotal: 30.9s\tremaining: 44.4s\n",
      "2053:\tlearn: 0.6077414\ttest: 0.6017627\tbest: 0.6017627 (2053)\ttotal: 30.9s\tremaining: 44.4s\n",
      "2054:\tlearn: 0.6077414\ttest: 0.6017627\tbest: 0.6017627 (2053)\ttotal: 31s\tremaining: 44.4s\n",
      "2055:\tlearn: 0.6077414\ttest: 0.6017627\tbest: 0.6017627 (2053)\ttotal: 31s\tremaining: 44.3s\n",
      "2056:\tlearn: 0.6077414\ttest: 0.6017627\tbest: 0.6017627 (2053)\ttotal: 31s\tremaining: 44.3s\n",
      "2057:\tlearn: 0.6077382\ttest: 0.6017612\tbest: 0.6017612 (2057)\ttotal: 31s\tremaining: 44.3s\n",
      "2058:\tlearn: 0.6077382\ttest: 0.6017612\tbest: 0.6017612 (2057)\ttotal: 31s\tremaining: 44.3s\n",
      "2059:\tlearn: 0.6077382\ttest: 0.6017612\tbest: 0.6017612 (2057)\ttotal: 31s\tremaining: 44.3s\n",
      "2060:\tlearn: 0.6077382\ttest: 0.6017612\tbest: 0.6017612 (2057)\ttotal: 31s\tremaining: 44.2s\n",
      "2061:\tlearn: 0.6076482\ttest: 0.6016748\tbest: 0.6016748 (2061)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2062:\tlearn: 0.6076450\ttest: 0.6016732\tbest: 0.6016732 (2062)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2063:\tlearn: 0.6076450\ttest: 0.6016732\tbest: 0.6016732 (2062)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2064:\tlearn: 0.6076450\ttest: 0.6016732\tbest: 0.6016732 (2062)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2065:\tlearn: 0.6076450\ttest: 0.6016733\tbest: 0.6016732 (2062)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2066:\tlearn: 0.6076429\ttest: 0.6016722\tbest: 0.6016722 (2066)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2067:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.1s\tremaining: 44.2s\n",
      "2068:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44.1s\n",
      "2069:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44.1s\n",
      "2070:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44.1s\n",
      "2071:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44.1s\n",
      "2072:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44.1s\n",
      "2073:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44s\n",
      "2074:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44s\n",
      "2075:\tlearn: 0.6076375\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.2s\tremaining: 44s\n",
      "2076:\tlearn: 0.6076372\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.3s\tremaining: 44s\n",
      "2077:\tlearn: 0.6076372\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.3s\tremaining: 44s\n",
      "2078:\tlearn: 0.6076372\ttest: 0.6016673\tbest: 0.6016673 (2067)\ttotal: 31.3s\tremaining: 44s\n",
      "2079:\tlearn: 0.6076319\ttest: 0.6016608\tbest: 0.6016608 (2079)\ttotal: 31.3s\tremaining: 44s\n",
      "2080:\tlearn: 0.6076319\ttest: 0.6016608\tbest: 0.6016608 (2079)\ttotal: 31.3s\tremaining: 43.9s\n",
      "2081:\tlearn: 0.6076319\ttest: 0.6016608\tbest: 0.6016608 (2079)\ttotal: 31.3s\tremaining: 43.9s\n",
      "2082:\tlearn: 0.6076319\ttest: 0.6016608\tbest: 0.6016608 (2079)\ttotal: 31.3s\tremaining: 43.9s\n",
      "2083:\tlearn: 0.6076319\ttest: 0.6016608\tbest: 0.6016608 (2079)\ttotal: 31.4s\tremaining: 43.9s\n",
      "2084:\tlearn: 0.6076243\ttest: 0.6016533\tbest: 0.6016533 (2084)\ttotal: 31.4s\tremaining: 43.9s\n",
      "2085:\tlearn: 0.6076242\ttest: 0.6016534\tbest: 0.6016533 (2084)\ttotal: 31.4s\tremaining: 43.9s\n",
      "2086:\tlearn: 0.6076242\ttest: 0.6016534\tbest: 0.6016533 (2084)\ttotal: 31.4s\tremaining: 43.8s\n",
      "2087:\tlearn: 0.6076242\ttest: 0.6016534\tbest: 0.6016533 (2084)\ttotal: 31.4s\tremaining: 43.8s\n",
      "2088:\tlearn: 0.6076237\ttest: 0.6016532\tbest: 0.6016532 (2088)\ttotal: 31.4s\tremaining: 43.8s\n",
      "2089:\tlearn: 0.6076237\ttest: 0.6016532\tbest: 0.6016532 (2088)\ttotal: 31.5s\tremaining: 43.8s\n",
      "2090:\tlearn: 0.6076235\ttest: 0.6016531\tbest: 0.6016531 (2090)\ttotal: 31.5s\tremaining: 43.8s\n",
      "2091:\tlearn: 0.6076235\ttest: 0.6016531\tbest: 0.6016531 (2090)\ttotal: 31.5s\tremaining: 43.8s\n",
      "2092:\tlearn: 0.6076122\ttest: 0.6016366\tbest: 0.6016366 (2092)\ttotal: 31.5s\tremaining: 43.8s\n",
      "2093:\tlearn: 0.6076122\ttest: 0.6016366\tbest: 0.6016366 (2092)\ttotal: 31.5s\tremaining: 43.8s\n",
      "2094:\tlearn: 0.6076122\ttest: 0.6016366\tbest: 0.6016366 (2092)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2095:\tlearn: 0.6076122\ttest: 0.6016366\tbest: 0.6016366 (2092)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2096:\tlearn: 0.6076122\ttest: 0.6016366\tbest: 0.6016366 (2092)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2097:\tlearn: 0.6076122\ttest: 0.6016366\tbest: 0.6016366 (2092)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2098:\tlearn: 0.6076112\ttest: 0.6016366\tbest: 0.6016366 (2098)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2099:\tlearn: 0.6076112\ttest: 0.6016366\tbest: 0.6016366 (2098)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2100:\tlearn: 0.6076083\ttest: 0.6016337\tbest: 0.6016337 (2100)\ttotal: 31.6s\tremaining: 43.7s\n",
      "2101:\tlearn: 0.6076083\ttest: 0.6016337\tbest: 0.6016337 (2100)\ttotal: 31.7s\tremaining: 43.6s\n",
      "2102:\tlearn: 0.6076083\ttest: 0.6016337\tbest: 0.6016337 (2100)\ttotal: 31.7s\tremaining: 43.6s\n",
      "2103:\tlearn: 0.6075961\ttest: 0.6016234\tbest: 0.6016234 (2103)\ttotal: 31.7s\tremaining: 43.6s\n",
      "2104:\tlearn: 0.6075961\ttest: 0.6016234\tbest: 0.6016234 (2103)\ttotal: 31.7s\tremaining: 43.6s\n",
      "2105:\tlearn: 0.6075961\ttest: 0.6016234\tbest: 0.6016234 (2103)\ttotal: 31.7s\tremaining: 43.6s\n",
      "2106:\tlearn: 0.6075917\ttest: 0.6016195\tbest: 0.6016195 (2106)\ttotal: 31.7s\tremaining: 43.6s\n",
      "2107:\tlearn: 0.6075917\ttest: 0.6016195\tbest: 0.6016195 (2106)\ttotal: 31.7s\tremaining: 43.5s\n",
      "2108:\tlearn: 0.6075820\ttest: 0.6016078\tbest: 0.6016078 (2108)\ttotal: 31.8s\tremaining: 43.5s\n",
      "2109:\tlearn: 0.6075790\ttest: 0.6016017\tbest: 0.6016017 (2109)\ttotal: 31.8s\tremaining: 43.5s\n",
      "2110:\tlearn: 0.6075790\ttest: 0.6016017\tbest: 0.6016017 (2109)\ttotal: 31.8s\tremaining: 43.5s\n",
      "2111:\tlearn: 0.6075790\ttest: 0.6016017\tbest: 0.6016017 (2109)\ttotal: 31.8s\tremaining: 43.5s\n",
      "2112:\tlearn: 0.6075761\ttest: 0.6015989\tbest: 0.6015989 (2112)\ttotal: 31.8s\tremaining: 43.5s\n",
      "2113:\tlearn: 0.6075703\ttest: 0.6015948\tbest: 0.6015948 (2113)\ttotal: 31.9s\tremaining: 43.5s\n",
      "2114:\tlearn: 0.6075703\ttest: 0.6015948\tbest: 0.6015948 (2113)\ttotal: 31.9s\tremaining: 43.5s\n",
      "2115:\tlearn: 0.6075639\ttest: 0.6015822\tbest: 0.6015822 (2115)\ttotal: 31.9s\tremaining: 43.5s\n",
      "2116:\tlearn: 0.6075639\ttest: 0.6015822\tbest: 0.6015822 (2115)\ttotal: 31.9s\tremaining: 43.5s\n",
      "2117:\tlearn: 0.6075639\ttest: 0.6015822\tbest: 0.6015822 (2115)\ttotal: 31.9s\tremaining: 43.4s\n",
      "2118:\tlearn: 0.6075639\ttest: 0.6015822\tbest: 0.6015822 (2115)\ttotal: 31.9s\tremaining: 43.4s\n",
      "2119:\tlearn: 0.6075639\ttest: 0.6015822\tbest: 0.6015822 (2115)\ttotal: 32s\tremaining: 43.4s\n",
      "2120:\tlearn: 0.6075325\ttest: 0.6015395\tbest: 0.6015395 (2120)\ttotal: 32s\tremaining: 43.4s\n",
      "2121:\tlearn: 0.6075325\ttest: 0.6015395\tbest: 0.6015395 (2120)\ttotal: 32s\tremaining: 43.4s\n",
      "2122:\tlearn: 0.6075036\ttest: 0.6015197\tbest: 0.6015197 (2122)\ttotal: 32.1s\tremaining: 43.4s\n",
      "2123:\tlearn: 0.6075026\ttest: 0.6015179\tbest: 0.6015179 (2123)\ttotal: 32.1s\tremaining: 43.4s\n",
      "2124:\tlearn: 0.6075026\ttest: 0.6015179\tbest: 0.6015179 (2123)\ttotal: 32.1s\tremaining: 43.4s\n",
      "2125:\tlearn: 0.6075026\ttest: 0.6015179\tbest: 0.6015179 (2123)\ttotal: 32.1s\tremaining: 43.4s\n",
      "2126:\tlearn: 0.6075026\ttest: 0.6015179\tbest: 0.6015179 (2123)\ttotal: 32.1s\tremaining: 43.4s\n",
      "2127:\tlearn: 0.6075026\ttest: 0.6015179\tbest: 0.6015179 (2123)\ttotal: 32.1s\tremaining: 43.4s\n",
      "2128:\tlearn: 0.6074992\ttest: 0.6015165\tbest: 0.6015165 (2128)\ttotal: 32.1s\tremaining: 43.3s\n",
      "2129:\tlearn: 0.6074992\ttest: 0.6015165\tbest: 0.6015165 (2128)\ttotal: 32.2s\tremaining: 43.3s\n",
      "2130:\tlearn: 0.6074992\ttest: 0.6015165\tbest: 0.6015165 (2128)\ttotal: 32.2s\tremaining: 43.3s\n",
      "2131:\tlearn: 0.6074938\ttest: 0.6015131\tbest: 0.6015131 (2131)\ttotal: 32.2s\tremaining: 43.3s\n",
      "2132:\tlearn: 0.6074938\ttest: 0.6015131\tbest: 0.6015131 (2131)\ttotal: 32.2s\tremaining: 43.3s\n",
      "2133:\tlearn: 0.6074938\ttest: 0.6015131\tbest: 0.6015131 (2131)\ttotal: 32.2s\tremaining: 43.3s\n",
      "2134:\tlearn: 0.6074900\ttest: 0.6015055\tbest: 0.6015055 (2134)\ttotal: 32.2s\tremaining: 43.3s\n",
      "2135:\tlearn: 0.6074900\ttest: 0.6015055\tbest: 0.6015055 (2134)\ttotal: 32.2s\tremaining: 43.2s\n",
      "2136:\tlearn: 0.6074900\ttest: 0.6015055\tbest: 0.6015055 (2134)\ttotal: 32.3s\tremaining: 43.2s\n",
      "2137:\tlearn: 0.6074681\ttest: 0.6014726\tbest: 0.6014726 (2137)\ttotal: 32.3s\tremaining: 43.2s\n",
      "2138:\tlearn: 0.6074681\ttest: 0.6014726\tbest: 0.6014726 (2137)\ttotal: 32.3s\tremaining: 43.2s\n",
      "2139:\tlearn: 0.6074668\ttest: 0.6014680\tbest: 0.6014680 (2139)\ttotal: 32.3s\tremaining: 43.2s\n",
      "2140:\tlearn: 0.6074668\ttest: 0.6014680\tbest: 0.6014680 (2139)\ttotal: 32.3s\tremaining: 43.2s\n",
      "2141:\tlearn: 0.6074644\ttest: 0.6014661\tbest: 0.6014661 (2141)\ttotal: 32.3s\tremaining: 43.1s\n",
      "2142:\tlearn: 0.6074644\ttest: 0.6014661\tbest: 0.6014661 (2141)\ttotal: 32.4s\tremaining: 43.1s\n",
      "2143:\tlearn: 0.6074546\ttest: 0.6014566\tbest: 0.6014566 (2143)\ttotal: 32.4s\tremaining: 43.1s\n",
      "2144:\tlearn: 0.6074546\ttest: 0.6014566\tbest: 0.6014566 (2143)\ttotal: 32.4s\tremaining: 43.1s\n",
      "2145:\tlearn: 0.6074546\ttest: 0.6014566\tbest: 0.6014566 (2143)\ttotal: 32.4s\tremaining: 43.1s\n",
      "2146:\tlearn: 0.6074546\ttest: 0.6014566\tbest: 0.6014566 (2143)\ttotal: 32.4s\tremaining: 43.1s\n",
      "2147:\tlearn: 0.6074546\ttest: 0.6014566\tbest: 0.6014566 (2143)\ttotal: 32.4s\tremaining: 43.1s\n",
      "2148:\tlearn: 0.6074535\ttest: 0.6014537\tbest: 0.6014537 (2148)\ttotal: 32.5s\tremaining: 43.1s\n",
      "2149:\tlearn: 0.6074531\ttest: 0.6014532\tbest: 0.6014532 (2149)\ttotal: 32.5s\tremaining: 43.1s\n",
      "2150:\tlearn: 0.6074531\ttest: 0.6014532\tbest: 0.6014532 (2149)\ttotal: 32.5s\tremaining: 43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2151:\tlearn: 0.6074498\ttest: 0.6014517\tbest: 0.6014517 (2151)\ttotal: 32.5s\tremaining: 43s\n",
      "2152:\tlearn: 0.6074498\ttest: 0.6014517\tbest: 0.6014517 (2151)\ttotal: 32.5s\tremaining: 43s\n",
      "2153:\tlearn: 0.6074485\ttest: 0.6014515\tbest: 0.6014515 (2153)\ttotal: 32.6s\tremaining: 43s\n",
      "2154:\tlearn: 0.6074485\ttest: 0.6014515\tbest: 0.6014515 (2153)\ttotal: 32.6s\tremaining: 43s\n",
      "2155:\tlearn: 0.6074485\ttest: 0.6014515\tbest: 0.6014515 (2153)\ttotal: 32.6s\tremaining: 43s\n",
      "2156:\tlearn: 0.6073993\ttest: 0.6013966\tbest: 0.6013966 (2156)\ttotal: 32.6s\tremaining: 43s\n",
      "2157:\tlearn: 0.6073993\ttest: 0.6013966\tbest: 0.6013966 (2156)\ttotal: 32.6s\tremaining: 43s\n",
      "2158:\tlearn: 0.6073993\ttest: 0.6013966\tbest: 0.6013966 (2156)\ttotal: 32.6s\tremaining: 43s\n",
      "2159:\tlearn: 0.6073992\ttest: 0.6013966\tbest: 0.6013966 (2156)\ttotal: 32.7s\tremaining: 42.9s\n",
      "2160:\tlearn: 0.6073963\ttest: 0.6013922\tbest: 0.6013922 (2160)\ttotal: 32.7s\tremaining: 42.9s\n",
      "2161:\tlearn: 0.6073963\ttest: 0.6013922\tbest: 0.6013922 (2161)\ttotal: 32.7s\tremaining: 42.9s\n",
      "2162:\tlearn: 0.6073963\ttest: 0.6013922\tbest: 0.6013922 (2161)\ttotal: 32.7s\tremaining: 42.9s\n",
      "2163:\tlearn: 0.6073961\ttest: 0.6013921\tbest: 0.6013921 (2163)\ttotal: 32.7s\tremaining: 42.9s\n",
      "2164:\tlearn: 0.6073925\ttest: 0.6013891\tbest: 0.6013891 (2164)\ttotal: 32.8s\tremaining: 42.9s\n",
      "2165:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.8s\tremaining: 42.9s\n",
      "2166:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.8s\tremaining: 42.9s\n",
      "2167:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.8s\tremaining: 42.9s\n",
      "2168:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.8s\tremaining: 42.8s\n",
      "2169:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.8s\tremaining: 42.8s\n",
      "2170:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.8s\tremaining: 42.8s\n",
      "2171:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.9s\tremaining: 42.8s\n",
      "2172:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.9s\tremaining: 42.8s\n",
      "2173:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.9s\tremaining: 42.8s\n",
      "2174:\tlearn: 0.6073768\ttest: 0.6013795\tbest: 0.6013795 (2165)\ttotal: 32.9s\tremaining: 42.7s\n",
      "2175:\tlearn: 0.6073755\ttest: 0.6013779\tbest: 0.6013779 (2175)\ttotal: 32.9s\tremaining: 42.7s\n",
      "2176:\tlearn: 0.6073755\ttest: 0.6013779\tbest: 0.6013779 (2175)\ttotal: 32.9s\tremaining: 42.7s\n",
      "2177:\tlearn: 0.6073755\ttest: 0.6013779\tbest: 0.6013779 (2175)\ttotal: 32.9s\tremaining: 42.7s\n",
      "2178:\tlearn: 0.6073713\ttest: 0.6013735\tbest: 0.6013735 (2178)\ttotal: 33s\tremaining: 42.7s\n",
      "2179:\tlearn: 0.6073672\ttest: 0.6013694\tbest: 0.6013694 (2179)\ttotal: 33s\tremaining: 42.7s\n",
      "2180:\tlearn: 0.6073672\ttest: 0.6013694\tbest: 0.6013694 (2179)\ttotal: 33s\tremaining: 42.6s\n",
      "2181:\tlearn: 0.6073672\ttest: 0.6013694\tbest: 0.6013694 (2179)\ttotal: 33s\tremaining: 42.6s\n",
      "2182:\tlearn: 0.6073651\ttest: 0.6013692\tbest: 0.6013692 (2182)\ttotal: 33s\tremaining: 42.6s\n",
      "2183:\tlearn: 0.6073651\ttest: 0.6013692\tbest: 0.6013692 (2182)\ttotal: 33s\tremaining: 42.6s\n",
      "2184:\tlearn: 0.6073651\ttest: 0.6013692\tbest: 0.6013692 (2182)\ttotal: 33s\tremaining: 42.6s\n",
      "2185:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.1s\tremaining: 42.6s\n",
      "2186:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.1s\tremaining: 42.5s\n",
      "2187:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.1s\tremaining: 42.5s\n",
      "2188:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.1s\tremaining: 42.5s\n",
      "2189:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.1s\tremaining: 42.5s\n",
      "2190:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.1s\tremaining: 42.5s\n",
      "2191:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.2s\tremaining: 42.5s\n",
      "2192:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.2s\tremaining: 42.5s\n",
      "2193:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.2s\tremaining: 42.4s\n",
      "2194:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.2s\tremaining: 42.4s\n",
      "2195:\tlearn: 0.6073626\ttest: 0.6013677\tbest: 0.6013677 (2185)\ttotal: 33.2s\tremaining: 42.4s\n",
      "2196:\tlearn: 0.6073599\ttest: 0.6013652\tbest: 0.6013652 (2196)\ttotal: 33.2s\tremaining: 42.4s\n",
      "2197:\tlearn: 0.6073599\ttest: 0.6013652\tbest: 0.6013652 (2196)\ttotal: 33.2s\tremaining: 42.4s\n",
      "2198:\tlearn: 0.6073566\ttest: 0.6013604\tbest: 0.6013604 (2198)\ttotal: 33.3s\tremaining: 42.4s\n",
      "2199:\tlearn: 0.6073539\ttest: 0.6013561\tbest: 0.6013561 (2199)\ttotal: 33.3s\tremaining: 42.4s\n",
      "2200:\tlearn: 0.6073537\ttest: 0.6013560\tbest: 0.6013560 (2200)\ttotal: 33.3s\tremaining: 42.3s\n",
      "2201:\tlearn: 0.6073537\ttest: 0.6013560\tbest: 0.6013560 (2200)\ttotal: 33.3s\tremaining: 42.3s\n",
      "2202:\tlearn: 0.6073525\ttest: 0.6013571\tbest: 0.6013560 (2200)\ttotal: 33.3s\tremaining: 42.3s\n",
      "2203:\tlearn: 0.6073525\ttest: 0.6013571\tbest: 0.6013560 (2200)\ttotal: 33.3s\tremaining: 42.3s\n",
      "2204:\tlearn: 0.6073521\ttest: 0.6013565\tbest: 0.6013560 (2200)\ttotal: 33.4s\tremaining: 42.3s\n",
      "2205:\tlearn: 0.6073518\ttest: 0.6013565\tbest: 0.6013560 (2200)\ttotal: 33.4s\tremaining: 42.3s\n",
      "2206:\tlearn: 0.6073518\ttest: 0.6013565\tbest: 0.6013560 (2200)\ttotal: 33.4s\tremaining: 42.2s\n",
      "2207:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.4s\tremaining: 42.2s\n",
      "2208:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.4s\tremaining: 42.2s\n",
      "2209:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.4s\tremaining: 42.2s\n",
      "2210:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.4s\tremaining: 42.2s\n",
      "2211:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.5s\tremaining: 42.2s\n",
      "2212:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.5s\tremaining: 42.1s\n",
      "2213:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.5s\tremaining: 42.1s\n",
      "2214:\tlearn: 0.6073515\ttest: 0.6013559\tbest: 0.6013559 (2207)\ttotal: 33.5s\tremaining: 42.1s\n",
      "2215:\tlearn: 0.6073512\ttest: 0.6013550\tbest: 0.6013550 (2215)\ttotal: 33.5s\tremaining: 42.1s\n",
      "2216:\tlearn: 0.6073512\ttest: 0.6013550\tbest: 0.6013550 (2215)\ttotal: 33.5s\tremaining: 42.1s\n",
      "2217:\tlearn: 0.6073512\ttest: 0.6013550\tbest: 0.6013550 (2215)\ttotal: 33.5s\tremaining: 42.1s\n",
      "2218:\tlearn: 0.6073380\ttest: 0.6013396\tbest: 0.6013396 (2218)\ttotal: 33.6s\tremaining: 42.1s\n",
      "2219:\tlearn: 0.6073380\ttest: 0.6013396\tbest: 0.6013396 (2218)\ttotal: 33.6s\tremaining: 42s\n",
      "2220:\tlearn: 0.6073380\ttest: 0.6013396\tbest: 0.6013396 (2218)\ttotal: 33.6s\tremaining: 42s\n",
      "2221:\tlearn: 0.6073380\ttest: 0.6013396\tbest: 0.6013396 (2218)\ttotal: 33.6s\tremaining: 42s\n",
      "2222:\tlearn: 0.6073369\ttest: 0.6013391\tbest: 0.6013391 (2222)\ttotal: 33.6s\tremaining: 42s\n",
      "2223:\tlearn: 0.6073356\ttest: 0.6013359\tbest: 0.6013359 (2223)\ttotal: 33.6s\tremaining: 42s\n",
      "2224:\tlearn: 0.6073356\ttest: 0.6013359\tbest: 0.6013359 (2223)\ttotal: 33.7s\tremaining: 42s\n",
      "2225:\tlearn: 0.6073356\ttest: 0.6013359\tbest: 0.6013359 (2223)\ttotal: 33.7s\tremaining: 42s\n",
      "2226:\tlearn: 0.6073356\ttest: 0.6013359\tbest: 0.6013359 (2223)\ttotal: 33.7s\tremaining: 41.9s\n",
      "2227:\tlearn: 0.6073356\ttest: 0.6013359\tbest: 0.6013359 (2223)\ttotal: 33.7s\tremaining: 41.9s\n",
      "2228:\tlearn: 0.6073356\ttest: 0.6013359\tbest: 0.6013359 (2223)\ttotal: 33.7s\tremaining: 41.9s\n",
      "2229:\tlearn: 0.6073316\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.7s\tremaining: 41.9s\n",
      "2230:\tlearn: 0.6073316\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.9s\n",
      "2231:\tlearn: 0.6073316\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.9s\n",
      "2232:\tlearn: 0.6073316\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.9s\n",
      "2233:\tlearn: 0.6073316\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.8s\n",
      "2234:\tlearn: 0.6073315\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.8s\n",
      "2235:\tlearn: 0.6073315\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.8s\n",
      "2236:\tlearn: 0.6073315\ttest: 0.6013320\tbest: 0.6013320 (2229)\ttotal: 33.8s\tremaining: 41.8s\n",
      "2237:\tlearn: 0.6073270\ttest: 0.6013279\tbest: 0.6013279 (2237)\ttotal: 33.9s\tremaining: 41.8s\n",
      "2238:\tlearn: 0.6073191\ttest: 0.6013161\tbest: 0.6013161 (2238)\ttotal: 33.9s\tremaining: 41.8s\n",
      "2239:\tlearn: 0.6073191\ttest: 0.6013161\tbest: 0.6013161 (2238)\ttotal: 33.9s\tremaining: 41.8s\n",
      "2240:\tlearn: 0.6073071\ttest: 0.6013008\tbest: 0.6013008 (2240)\ttotal: 33.9s\tremaining: 41.8s\n",
      "2241:\tlearn: 0.6073071\ttest: 0.6013008\tbest: 0.6013008 (2240)\ttotal: 33.9s\tremaining: 41.8s\n",
      "2242:\tlearn: 0.6073017\ttest: 0.6012973\tbest: 0.6012973 (2242)\ttotal: 34s\tremaining: 41.7s\n",
      "2243:\tlearn: 0.6073017\ttest: 0.6012973\tbest: 0.6012973 (2242)\ttotal: 34s\tremaining: 41.7s\n",
      "2244:\tlearn: 0.6073017\ttest: 0.6012973\tbest: 0.6012973 (2242)\ttotal: 34s\tremaining: 41.7s\n",
      "2245:\tlearn: 0.6073017\ttest: 0.6012973\tbest: 0.6012973 (2242)\ttotal: 34s\tremaining: 41.7s\n",
      "2246:\tlearn: 0.6073017\ttest: 0.6012973\tbest: 0.6012973 (2242)\ttotal: 34s\tremaining: 41.7s\n",
      "2247:\tlearn: 0.6073017\ttest: 0.6012973\tbest: 0.6012973 (2242)\ttotal: 34s\tremaining: 41.7s\n",
      "2248:\tlearn: 0.6072971\ttest: 0.6012933\tbest: 0.6012933 (2248)\ttotal: 34.1s\tremaining: 41.7s\n",
      "2249:\tlearn: 0.6072971\ttest: 0.6012933\tbest: 0.6012933 (2248)\ttotal: 34.1s\tremaining: 41.6s\n",
      "2250:\tlearn: 0.6072801\ttest: 0.6012715\tbest: 0.6012715 (2250)\ttotal: 34.1s\tremaining: 41.6s\n",
      "2251:\tlearn: 0.6072801\ttest: 0.6012715\tbest: 0.6012715 (2250)\ttotal: 34.1s\tremaining: 41.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252:\tlearn: 0.6072801\ttest: 0.6012715\tbest: 0.6012715 (2250)\ttotal: 34.1s\tremaining: 41.6s\n",
      "2253:\tlearn: 0.6072694\ttest: 0.6012617\tbest: 0.6012617 (2253)\ttotal: 34.2s\tremaining: 41.6s\n",
      "2254:\tlearn: 0.6072694\ttest: 0.6012617\tbest: 0.6012617 (2253)\ttotal: 34.2s\tremaining: 41.6s\n",
      "2255:\tlearn: 0.6072694\ttest: 0.6012617\tbest: 0.6012617 (2253)\ttotal: 34.2s\tremaining: 41.6s\n",
      "2256:\tlearn: 0.6072694\ttest: 0.6012617\tbest: 0.6012617 (2253)\ttotal: 34.2s\tremaining: 41.6s\n",
      "2257:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.2s\tremaining: 41.6s\n",
      "2258:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.2s\tremaining: 41.5s\n",
      "2259:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.2s\tremaining: 41.5s\n",
      "2260:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.3s\tremaining: 41.5s\n",
      "2261:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.3s\tremaining: 41.5s\n",
      "2262:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.3s\tremaining: 41.5s\n",
      "2263:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.3s\tremaining: 41.5s\n",
      "2264:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.3s\tremaining: 41.4s\n",
      "2265:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.3s\tremaining: 41.4s\n",
      "2266:\tlearn: 0.6072686\ttest: 0.6012597\tbest: 0.6012597 (2257)\ttotal: 34.4s\tremaining: 41.4s\n",
      "2267:\tlearn: 0.6072646\ttest: 0.6012572\tbest: 0.6012572 (2267)\ttotal: 34.4s\tremaining: 41.4s\n",
      "2268:\tlearn: 0.6072646\ttest: 0.6012572\tbest: 0.6012572 (2267)\ttotal: 34.4s\tremaining: 41.4s\n",
      "2269:\tlearn: 0.6072646\ttest: 0.6012572\tbest: 0.6012572 (2267)\ttotal: 34.4s\tremaining: 41.4s\n",
      "2270:\tlearn: 0.6072602\ttest: 0.6012534\tbest: 0.6012534 (2270)\ttotal: 34.4s\tremaining: 41.4s\n",
      "2271:\tlearn: 0.6072512\ttest: 0.6012463\tbest: 0.6012463 (2271)\ttotal: 34.4s\tremaining: 41.4s\n",
      "2272:\tlearn: 0.6072512\ttest: 0.6012463\tbest: 0.6012463 (2271)\ttotal: 34.5s\tremaining: 41.3s\n",
      "2273:\tlearn: 0.6072462\ttest: 0.6012432\tbest: 0.6012432 (2273)\ttotal: 34.5s\tremaining: 41.3s\n",
      "2274:\tlearn: 0.6072451\ttest: 0.6012413\tbest: 0.6012413 (2274)\ttotal: 34.5s\tremaining: 41.3s\n",
      "2275:\tlearn: 0.6072451\ttest: 0.6012413\tbest: 0.6012413 (2274)\ttotal: 34.5s\tremaining: 41.3s\n",
      "2276:\tlearn: 0.6072451\ttest: 0.6012413\tbest: 0.6012413 (2274)\ttotal: 34.5s\tremaining: 41.3s\n",
      "2277:\tlearn: 0.6072451\ttest: 0.6012413\tbest: 0.6012413 (2274)\ttotal: 34.5s\tremaining: 41.3s\n",
      "2278:\tlearn: 0.6072442\ttest: 0.6012386\tbest: 0.6012386 (2278)\ttotal: 34.5s\tremaining: 41.2s\n",
      "2279:\tlearn: 0.6072442\ttest: 0.6012386\tbest: 0.6012386 (2278)\ttotal: 34.6s\tremaining: 41.2s\n",
      "2280:\tlearn: 0.6072415\ttest: 0.6012372\tbest: 0.6012372 (2280)\ttotal: 34.6s\tremaining: 41.2s\n",
      "2281:\tlearn: 0.6072415\ttest: 0.6012373\tbest: 0.6012372 (2280)\ttotal: 34.6s\tremaining: 41.2s\n",
      "2282:\tlearn: 0.6072365\ttest: 0.6012343\tbest: 0.6012343 (2282)\ttotal: 34.6s\tremaining: 41.2s\n",
      "2283:\tlearn: 0.6072355\ttest: 0.6012339\tbest: 0.6012339 (2283)\ttotal: 34.6s\tremaining: 41.2s\n",
      "2284:\tlearn: 0.6072355\ttest: 0.6012339\tbest: 0.6012339 (2283)\ttotal: 34.6s\tremaining: 41.2s\n",
      "2285:\tlearn: 0.6072277\ttest: 0.6012250\tbest: 0.6012250 (2285)\ttotal: 34.7s\tremaining: 41.2s\n",
      "2286:\tlearn: 0.6072235\ttest: 0.6012211\tbest: 0.6012211 (2286)\ttotal: 34.7s\tremaining: 41.2s\n",
      "2287:\tlearn: 0.6072224\ttest: 0.6012190\tbest: 0.6012190 (2287)\ttotal: 34.7s\tremaining: 41.1s\n",
      "2288:\tlearn: 0.6072224\ttest: 0.6012190\tbest: 0.6012190 (2287)\ttotal: 34.7s\tremaining: 41.1s\n",
      "2289:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.7s\tremaining: 41.1s\n",
      "2290:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.8s\tremaining: 41.1s\n",
      "2291:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.8s\tremaining: 41.1s\n",
      "2292:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.8s\tremaining: 41.1s\n",
      "2293:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.8s\tremaining: 41s\n",
      "2294:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.8s\tremaining: 41s\n",
      "2295:\tlearn: 0.6071682\ttest: 0.6011429\tbest: 0.6011429 (2289)\ttotal: 34.8s\tremaining: 41s\n",
      "2296:\tlearn: 0.6071679\ttest: 0.6011425\tbest: 0.6011425 (2296)\ttotal: 34.8s\tremaining: 41s\n",
      "2297:\tlearn: 0.6071679\ttest: 0.6011425\tbest: 0.6011425 (2296)\ttotal: 34.9s\tremaining: 41s\n",
      "2298:\tlearn: 0.6071679\ttest: 0.6011425\tbest: 0.6011425 (2296)\ttotal: 34.9s\tremaining: 41s\n",
      "2299:\tlearn: 0.6071679\ttest: 0.6011425\tbest: 0.6011425 (2296)\ttotal: 34.9s\tremaining: 40.9s\n",
      "2300:\tlearn: 0.6071637\ttest: 0.6011387\tbest: 0.6011387 (2300)\ttotal: 34.9s\tremaining: 40.9s\n",
      "2301:\tlearn: 0.6071637\ttest: 0.6011387\tbest: 0.6011387 (2300)\ttotal: 34.9s\tremaining: 40.9s\n",
      "2302:\tlearn: 0.6071637\ttest: 0.6011387\tbest: 0.6011387 (2300)\ttotal: 34.9s\tremaining: 40.9s\n",
      "2303:\tlearn: 0.6071112\ttest: 0.6010787\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.9s\n",
      "2304:\tlearn: 0.6071112\ttest: 0.6010787\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.9s\n",
      "2305:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.9s\n",
      "2306:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.8s\n",
      "2307:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.8s\n",
      "2308:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.8s\n",
      "2309:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.8s\n",
      "2310:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35s\tremaining: 40.8s\n",
      "2311:\tlearn: 0.6071112\ttest: 0.6010788\tbest: 0.6010787 (2303)\ttotal: 35.1s\tremaining: 40.8s\n",
      "2312:\tlearn: 0.6070984\ttest: 0.6010672\tbest: 0.6010672 (2312)\ttotal: 35.1s\tremaining: 40.8s\n",
      "2313:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.1s\tremaining: 40.8s\n",
      "2314:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.1s\tremaining: 40.7s\n",
      "2315:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.1s\tremaining: 40.7s\n",
      "2316:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.2s\tremaining: 40.7s\n",
      "2317:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.2s\tremaining: 40.7s\n",
      "2318:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.2s\tremaining: 40.7s\n",
      "2319:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.2s\tremaining: 40.7s\n",
      "2320:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.2s\tremaining: 40.6s\n",
      "2321:\tlearn: 0.6070836\ttest: 0.6010518\tbest: 0.6010518 (2313)\ttotal: 35.2s\tremaining: 40.6s\n",
      "2322:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.2s\tremaining: 40.6s\n",
      "2323:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.3s\tremaining: 40.6s\n",
      "2324:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.3s\tremaining: 40.6s\n",
      "2325:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.3s\tremaining: 40.6s\n",
      "2326:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.3s\tremaining: 40.5s\n",
      "2327:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.3s\tremaining: 40.5s\n",
      "2328:\tlearn: 0.6070826\ttest: 0.6010497\tbest: 0.6010497 (2322)\ttotal: 35.3s\tremaining: 40.5s\n",
      "2329:\tlearn: 0.6070793\ttest: 0.6010445\tbest: 0.6010445 (2329)\ttotal: 35.3s\tremaining: 40.5s\n",
      "2330:\tlearn: 0.6070749\ttest: 0.6010404\tbest: 0.6010404 (2330)\ttotal: 35.4s\tremaining: 40.5s\n",
      "2331:\tlearn: 0.6070749\ttest: 0.6010404\tbest: 0.6010404 (2330)\ttotal: 35.4s\tremaining: 40.5s\n",
      "2332:\tlearn: 0.6070733\ttest: 0.6010389\tbest: 0.6010389 (2332)\ttotal: 35.4s\tremaining: 40.5s\n",
      "2333:\tlearn: 0.6070733\ttest: 0.6010389\tbest: 0.6010389 (2332)\ttotal: 35.4s\tremaining: 40.5s\n",
      "2334:\tlearn: 0.6070733\ttest: 0.6010389\tbest: 0.6010389 (2332)\ttotal: 35.4s\tremaining: 40.4s\n",
      "2335:\tlearn: 0.6070733\ttest: 0.6010390\tbest: 0.6010389 (2332)\ttotal: 35.5s\tremaining: 40.4s\n",
      "2336:\tlearn: 0.6070733\ttest: 0.6010390\tbest: 0.6010389 (2332)\ttotal: 35.5s\tremaining: 40.4s\n",
      "2337:\tlearn: 0.6070687\ttest: 0.6010343\tbest: 0.6010343 (2337)\ttotal: 35.5s\tremaining: 40.4s\n",
      "2338:\tlearn: 0.6070687\ttest: 0.6010343\tbest: 0.6010343 (2337)\ttotal: 35.5s\tremaining: 40.4s\n",
      "2339:\tlearn: 0.6070687\ttest: 0.6010343\tbest: 0.6010343 (2337)\ttotal: 35.5s\tremaining: 40.4s\n",
      "2340:\tlearn: 0.6070684\ttest: 0.6010337\tbest: 0.6010337 (2340)\ttotal: 35.5s\tremaining: 40.4s\n",
      "2341:\tlearn: 0.6070684\ttest: 0.6010337\tbest: 0.6010337 (2340)\ttotal: 35.5s\tremaining: 40.3s\n",
      "2342:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.6s\tremaining: 40.3s\n",
      "2343:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.6s\tremaining: 40.3s\n",
      "2344:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.6s\tremaining: 40.3s\n",
      "2345:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.6s\tremaining: 40.3s\n",
      "2346:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.6s\tremaining: 40.3s\n",
      "2347:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.6s\tremaining: 40.3s\n",
      "2348:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.7s\tremaining: 40.2s\n",
      "2349:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.7s\tremaining: 40.2s\n",
      "2350:\tlearn: 0.6070635\ttest: 0.6010307\tbest: 0.6010307 (2342)\ttotal: 35.7s\tremaining: 40.2s\n",
      "2351:\tlearn: 0.6070614\ttest: 0.6010278\tbest: 0.6010278 (2351)\ttotal: 35.7s\tremaining: 40.2s\n",
      "2352:\tlearn: 0.6070614\ttest: 0.6010278\tbest: 0.6010278 (2351)\ttotal: 35.7s\tremaining: 40.2s\n",
      "2353:\tlearn: 0.6070614\ttest: 0.6010278\tbest: 0.6010278 (2351)\ttotal: 35.7s\tremaining: 40.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2354:\tlearn: 0.6070614\ttest: 0.6010278\tbest: 0.6010278 (2351)\ttotal: 35.8s\tremaining: 40.2s\n",
      "2355:\tlearn: 0.6070614\ttest: 0.6010278\tbest: 0.6010278 (2351)\ttotal: 35.8s\tremaining: 40.1s\n",
      "2356:\tlearn: 0.6070586\ttest: 0.6010280\tbest: 0.6010278 (2351)\ttotal: 35.8s\tremaining: 40.1s\n",
      "2357:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.8s\tremaining: 40.1s\n",
      "2358:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.8s\tremaining: 40.1s\n",
      "2359:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.8s\tremaining: 40.1s\n",
      "2360:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.8s\tremaining: 40.1s\n",
      "2361:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.9s\tremaining: 40s\n",
      "2362:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.9s\tremaining: 40s\n",
      "2363:\tlearn: 0.6070550\ttest: 0.6010258\tbest: 0.6010258 (2357)\ttotal: 35.9s\tremaining: 40s\n",
      "2364:\tlearn: 0.6070532\ttest: 0.6010244\tbest: 0.6010244 (2364)\ttotal: 35.9s\tremaining: 40s\n",
      "2365:\tlearn: 0.6070532\ttest: 0.6010244\tbest: 0.6010244 (2364)\ttotal: 35.9s\tremaining: 40s\n",
      "2366:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2366)\ttotal: 35.9s\tremaining: 40s\n",
      "2367:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2366)\ttotal: 35.9s\tremaining: 39.9s\n",
      "2368:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2366)\ttotal: 36s\tremaining: 39.9s\n",
      "2369:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2369)\ttotal: 36s\tremaining: 39.9s\n",
      "2370:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2369)\ttotal: 36s\tremaining: 39.9s\n",
      "2371:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2369)\ttotal: 36s\tremaining: 39.9s\n",
      "2372:\tlearn: 0.6070500\ttest: 0.6010193\tbest: 0.6010193 (2369)\ttotal: 36s\tremaining: 39.9s\n",
      "2373:\tlearn: 0.6070496\ttest: 0.6010188\tbest: 0.6010188 (2373)\ttotal: 36s\tremaining: 39.9s\n",
      "2374:\tlearn: 0.6070496\ttest: 0.6010188\tbest: 0.6010188 (2373)\ttotal: 36s\tremaining: 39.8s\n",
      "2375:\tlearn: 0.6070496\ttest: 0.6010188\tbest: 0.6010188 (2373)\ttotal: 36.1s\tremaining: 39.8s\n",
      "2376:\tlearn: 0.6070496\ttest: 0.6010188\tbest: 0.6010188 (2373)\ttotal: 36.1s\tremaining: 39.8s\n",
      "2377:\tlearn: 0.6070496\ttest: 0.6010188\tbest: 0.6010188 (2373)\ttotal: 36.1s\tremaining: 39.8s\n",
      "2378:\tlearn: 0.6070496\ttest: 0.6010189\tbest: 0.6010188 (2373)\ttotal: 36.1s\tremaining: 39.8s\n",
      "2379:\tlearn: 0.6070496\ttest: 0.6010189\tbest: 0.6010188 (2373)\ttotal: 36.1s\tremaining: 39.7s\n",
      "2380:\tlearn: 0.6070475\ttest: 0.6010170\tbest: 0.6010170 (2380)\ttotal: 36.1s\tremaining: 39.7s\n",
      "2381:\tlearn: 0.6070475\ttest: 0.6010170\tbest: 0.6010170 (2380)\ttotal: 36.1s\tremaining: 39.7s\n",
      "2382:\tlearn: 0.6070425\ttest: 0.6010073\tbest: 0.6010073 (2382)\ttotal: 36.2s\tremaining: 39.7s\n",
      "2383:\tlearn: 0.6070425\ttest: 0.6010073\tbest: 0.6010073 (2382)\ttotal: 36.2s\tremaining: 39.7s\n",
      "2384:\tlearn: 0.6070425\ttest: 0.6010073\tbest: 0.6010073 (2382)\ttotal: 36.2s\tremaining: 39.7s\n",
      "2385:\tlearn: 0.6070425\ttest: 0.6010073\tbest: 0.6010073 (2382)\ttotal: 36.2s\tremaining: 39.7s\n",
      "2386:\tlearn: 0.6070425\ttest: 0.6010073\tbest: 0.6010073 (2382)\ttotal: 36.2s\tremaining: 39.6s\n",
      "2387:\tlearn: 0.6070412\ttest: 0.6010055\tbest: 0.6010055 (2387)\ttotal: 36.2s\tremaining: 39.6s\n",
      "2388:\tlearn: 0.6070412\ttest: 0.6010055\tbest: 0.6010055 (2387)\ttotal: 36.2s\tremaining: 39.6s\n",
      "2389:\tlearn: 0.6070403\ttest: 0.6010020\tbest: 0.6010020 (2389)\ttotal: 36.3s\tremaining: 39.6s\n",
      "2390:\tlearn: 0.6070403\ttest: 0.6010020\tbest: 0.6010020 (2389)\ttotal: 36.3s\tremaining: 39.6s\n",
      "2391:\tlearn: 0.6070360\ttest: 0.6009982\tbest: 0.6009982 (2391)\ttotal: 36.3s\tremaining: 39.6s\n",
      "2392:\tlearn: 0.6070316\ttest: 0.6009941\tbest: 0.6009941 (2392)\ttotal: 36.3s\tremaining: 39.6s\n",
      "2393:\tlearn: 0.6070316\ttest: 0.6009940\tbest: 0.6009940 (2393)\ttotal: 36.3s\tremaining: 39.5s\n",
      "2394:\tlearn: 0.6070173\ttest: 0.6009770\tbest: 0.6009770 (2394)\ttotal: 36.4s\tremaining: 39.5s\n",
      "2395:\tlearn: 0.6070166\ttest: 0.6009747\tbest: 0.6009747 (2395)\ttotal: 36.4s\tremaining: 39.5s\n",
      "2396:\tlearn: 0.6070166\ttest: 0.6009748\tbest: 0.6009747 (2395)\ttotal: 36.4s\tremaining: 39.5s\n",
      "2397:\tlearn: 0.6070166\ttest: 0.6009748\tbest: 0.6009747 (2395)\ttotal: 36.4s\tremaining: 39.5s\n",
      "2398:\tlearn: 0.6070165\ttest: 0.6009749\tbest: 0.6009747 (2395)\ttotal: 36.4s\tremaining: 39.5s\n",
      "2399:\tlearn: 0.6070107\ttest: 0.6009654\tbest: 0.6009654 (2399)\ttotal: 36.4s\tremaining: 39.5s\n",
      "2400:\tlearn: 0.6070105\ttest: 0.6009650\tbest: 0.6009650 (2400)\ttotal: 36.5s\tremaining: 39.5s\n",
      "2401:\tlearn: 0.6070105\ttest: 0.6009650\tbest: 0.6009650 (2400)\ttotal: 36.5s\tremaining: 39.4s\n",
      "2402:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.5s\tremaining: 39.4s\n",
      "2403:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.5s\tremaining: 39.4s\n",
      "2404:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.5s\tremaining: 39.4s\n",
      "2405:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.5s\tremaining: 39.4s\n",
      "2406:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.5s\tremaining: 39.4s\n",
      "2407:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.6s\tremaining: 39.4s\n",
      "2408:\tlearn: 0.6070062\ttest: 0.6009613\tbest: 0.6009613 (2402)\ttotal: 36.6s\tremaining: 39.3s\n",
      "2409:\tlearn: 0.6069997\ttest: 0.6009583\tbest: 0.6009583 (2409)\ttotal: 36.6s\tremaining: 39.3s\n",
      "2410:\tlearn: 0.6069997\ttest: 0.6009583\tbest: 0.6009583 (2409)\ttotal: 36.6s\tremaining: 39.3s\n",
      "2411:\tlearn: 0.6069997\ttest: 0.6009583\tbest: 0.6009583 (2409)\ttotal: 36.6s\tremaining: 39.3s\n",
      "2412:\tlearn: 0.6069985\ttest: 0.6009549\tbest: 0.6009549 (2412)\ttotal: 36.7s\tremaining: 39.3s\n",
      "2413:\tlearn: 0.6069976\ttest: 0.6009546\tbest: 0.6009546 (2413)\ttotal: 36.7s\tremaining: 39.3s\n",
      "2414:\tlearn: 0.6069976\ttest: 0.6009546\tbest: 0.6009546 (2413)\ttotal: 36.7s\tremaining: 39.3s\n",
      "2415:\tlearn: 0.6069976\ttest: 0.6009546\tbest: 0.6009546 (2413)\ttotal: 36.7s\tremaining: 39.3s\n",
      "2416:\tlearn: 0.6069976\ttest: 0.6009546\tbest: 0.6009546 (2413)\ttotal: 36.7s\tremaining: 39.2s\n",
      "2417:\tlearn: 0.6069976\ttest: 0.6009546\tbest: 0.6009546 (2413)\ttotal: 36.7s\tremaining: 39.2s\n",
      "2418:\tlearn: 0.6069859\ttest: 0.6009431\tbest: 0.6009431 (2418)\ttotal: 36.8s\tremaining: 39.2s\n",
      "2419:\tlearn: 0.6069421\ttest: 0.6009040\tbest: 0.6009040 (2419)\ttotal: 36.8s\tremaining: 39.2s\n",
      "2420:\tlearn: 0.6069421\ttest: 0.6009040\tbest: 0.6009040 (2419)\ttotal: 36.8s\tremaining: 39.2s\n",
      "2421:\tlearn: 0.6069421\ttest: 0.6009040\tbest: 0.6009040 (2419)\ttotal: 36.8s\tremaining: 39.2s\n",
      "2422:\tlearn: 0.6069421\ttest: 0.6009040\tbest: 0.6009040 (2419)\ttotal: 36.8s\tremaining: 39.2s\n",
      "2423:\tlearn: 0.6069406\ttest: 0.6009041\tbest: 0.6009040 (2419)\ttotal: 36.8s\tremaining: 39.1s\n",
      "2424:\tlearn: 0.6069369\ttest: 0.6009007\tbest: 0.6009007 (2424)\ttotal: 36.9s\tremaining: 39.1s\n",
      "2425:\tlearn: 0.6069369\ttest: 0.6009007\tbest: 0.6009007 (2424)\ttotal: 36.9s\tremaining: 39.1s\n",
      "2426:\tlearn: 0.6069369\ttest: 0.6009007\tbest: 0.6009007 (2424)\ttotal: 36.9s\tremaining: 39.1s\n",
      "2427:\tlearn: 0.6069369\ttest: 0.6009007\tbest: 0.6009007 (2424)\ttotal: 36.9s\tremaining: 39.1s\n",
      "2428:\tlearn: 0.6069369\ttest: 0.6009007\tbest: 0.6009007 (2424)\ttotal: 36.9s\tremaining: 39.1s\n",
      "2429:\tlearn: 0.6069367\ttest: 0.6009007\tbest: 0.6009007 (2424)\ttotal: 36.9s\tremaining: 39.1s\n",
      "2430:\tlearn: 0.6069311\ttest: 0.6008956\tbest: 0.6008956 (2430)\ttotal: 36.9s\tremaining: 39s\n",
      "2431:\tlearn: 0.6069311\ttest: 0.6008956\tbest: 0.6008956 (2430)\ttotal: 37s\tremaining: 39s\n",
      "2432:\tlearn: 0.6069311\ttest: 0.6008956\tbest: 0.6008956 (2430)\ttotal: 37s\tremaining: 39s\n",
      "2433:\tlearn: 0.6069266\ttest: 0.6008900\tbest: 0.6008900 (2433)\ttotal: 37s\tremaining: 39s\n",
      "2434:\tlearn: 0.6069266\ttest: 0.6008900\tbest: 0.6008900 (2433)\ttotal: 37s\tremaining: 39s\n",
      "2435:\tlearn: 0.6069266\ttest: 0.6008900\tbest: 0.6008900 (2433)\ttotal: 37s\tremaining: 39s\n",
      "2436:\tlearn: 0.6069266\ttest: 0.6008900\tbest: 0.6008900 (2433)\ttotal: 37s\tremaining: 38.9s\n",
      "2437:\tlearn: 0.6069266\ttest: 0.6008900\tbest: 0.6008900 (2433)\ttotal: 37s\tremaining: 38.9s\n",
      "2438:\tlearn: 0.6069242\ttest: 0.6008865\tbest: 0.6008865 (2438)\ttotal: 37.1s\tremaining: 38.9s\n",
      "2439:\tlearn: 0.6069242\ttest: 0.6008865\tbest: 0.6008865 (2438)\ttotal: 37.1s\tremaining: 38.9s\n",
      "2440:\tlearn: 0.6069242\ttest: 0.6008865\tbest: 0.6008865 (2438)\ttotal: 37.1s\tremaining: 38.9s\n",
      "2441:\tlearn: 0.6069242\ttest: 0.6008865\tbest: 0.6008865 (2438)\ttotal: 37.1s\tremaining: 38.9s\n",
      "2442:\tlearn: 0.6068719\ttest: 0.6008348\tbest: 0.6008348 (2442)\ttotal: 37.1s\tremaining: 38.9s\n",
      "2443:\tlearn: 0.6068719\ttest: 0.6008348\tbest: 0.6008348 (2442)\ttotal: 37.2s\tremaining: 38.9s\n",
      "2444:\tlearn: 0.6068719\ttest: 0.6008348\tbest: 0.6008348 (2442)\ttotal: 37.2s\tremaining: 38.8s\n",
      "2445:\tlearn: 0.6068711\ttest: 0.6008346\tbest: 0.6008346 (2445)\ttotal: 37.2s\tremaining: 38.8s\n",
      "2446:\tlearn: 0.6068711\ttest: 0.6008346\tbest: 0.6008346 (2445)\ttotal: 37.2s\tremaining: 38.8s\n",
      "2447:\tlearn: 0.6068711\ttest: 0.6008346\tbest: 0.6008346 (2445)\ttotal: 37.2s\tremaining: 38.8s\n",
      "2448:\tlearn: 0.6068689\ttest: 0.6008308\tbest: 0.6008308 (2448)\ttotal: 37.2s\tremaining: 38.8s\n",
      "2449:\tlearn: 0.6068652\ttest: 0.6008234\tbest: 0.6008234 (2449)\ttotal: 37.3s\tremaining: 38.8s\n",
      "2450:\tlearn: 0.6068652\ttest: 0.6008234\tbest: 0.6008234 (2449)\ttotal: 37.3s\tremaining: 38.8s\n",
      "2451:\tlearn: 0.6068643\ttest: 0.6008211\tbest: 0.6008211 (2451)\ttotal: 37.3s\tremaining: 38.7s\n",
      "2452:\tlearn: 0.6068643\ttest: 0.6008211\tbest: 0.6008211 (2451)\ttotal: 37.3s\tremaining: 38.7s\n",
      "2453:\tlearn: 0.6068643\ttest: 0.6008211\tbest: 0.6008211 (2451)\ttotal: 37.3s\tremaining: 38.7s\n",
      "2454:\tlearn: 0.6068643\ttest: 0.6008211\tbest: 0.6008211 (2451)\ttotal: 37.3s\tremaining: 38.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2455:\tlearn: 0.6068642\ttest: 0.6008210\tbest: 0.6008210 (2455)\ttotal: 37.3s\tremaining: 38.7s\n",
      "2456:\tlearn: 0.6068642\ttest: 0.6008210\tbest: 0.6008210 (2455)\ttotal: 37.4s\tremaining: 38.7s\n",
      "2457:\tlearn: 0.6068640\ttest: 0.6008205\tbest: 0.6008205 (2457)\ttotal: 37.4s\tremaining: 38.7s\n",
      "2458:\tlearn: 0.6068640\ttest: 0.6008204\tbest: 0.6008204 (2458)\ttotal: 37.4s\tremaining: 38.6s\n",
      "2459:\tlearn: 0.6068640\ttest: 0.6008204\tbest: 0.6008204 (2458)\ttotal: 37.4s\tremaining: 38.6s\n",
      "2460:\tlearn: 0.6068524\ttest: 0.6008113\tbest: 0.6008113 (2460)\ttotal: 37.4s\tremaining: 38.6s\n",
      "2461:\tlearn: 0.6068502\ttest: 0.6008078\tbest: 0.6008078 (2461)\ttotal: 37.5s\tremaining: 38.6s\n",
      "2462:\tlearn: 0.6068502\ttest: 0.6008078\tbest: 0.6008078 (2461)\ttotal: 37.5s\tremaining: 38.6s\n",
      "2463:\tlearn: 0.6068502\ttest: 0.6008078\tbest: 0.6008078 (2461)\ttotal: 37.5s\tremaining: 38.6s\n",
      "2464:\tlearn: 0.6068502\ttest: 0.6008078\tbest: 0.6008078 (2461)\ttotal: 37.5s\tremaining: 38.6s\n",
      "2465:\tlearn: 0.6068502\ttest: 0.6008078\tbest: 0.6008078 (2461)\ttotal: 37.5s\tremaining: 38.6s\n",
      "2466:\tlearn: 0.6068502\ttest: 0.6008078\tbest: 0.6008078 (2461)\ttotal: 37.5s\tremaining: 38.6s\n",
      "2467:\tlearn: 0.6068501\ttest: 0.6008075\tbest: 0.6008075 (2467)\ttotal: 37.6s\tremaining: 38.5s\n",
      "2468:\tlearn: 0.6068453\ttest: 0.6008045\tbest: 0.6008045 (2468)\ttotal: 37.6s\tremaining: 38.5s\n",
      "2469:\tlearn: 0.6068450\ttest: 0.6008045\tbest: 0.6008045 (2469)\ttotal: 37.6s\tremaining: 38.5s\n",
      "2470:\tlearn: 0.6068397\ttest: 0.6008036\tbest: 0.6008036 (2470)\ttotal: 37.6s\tremaining: 38.5s\n",
      "2471:\tlearn: 0.6068395\ttest: 0.6008036\tbest: 0.6008036 (2471)\ttotal: 37.7s\tremaining: 38.5s\n",
      "2472:\tlearn: 0.6068395\ttest: 0.6008036\tbest: 0.6008036 (2471)\ttotal: 37.7s\tremaining: 38.5s\n",
      "2473:\tlearn: 0.6068368\ttest: 0.6008038\tbest: 0.6008036 (2471)\ttotal: 37.7s\tremaining: 38.5s\n",
      "2474:\tlearn: 0.6068368\ttest: 0.6008038\tbest: 0.6008036 (2471)\ttotal: 37.7s\tremaining: 38.5s\n",
      "2475:\tlearn: 0.6068368\ttest: 0.6008038\tbest: 0.6008036 (2471)\ttotal: 37.7s\tremaining: 38.5s\n",
      "2476:\tlearn: 0.6068367\ttest: 0.6008035\tbest: 0.6008035 (2476)\ttotal: 37.7s\tremaining: 38.4s\n",
      "2477:\tlearn: 0.6068367\ttest: 0.6008035\tbest: 0.6008035 (2476)\ttotal: 37.8s\tremaining: 38.4s\n",
      "2478:\tlearn: 0.6068367\ttest: 0.6008035\tbest: 0.6008035 (2476)\ttotal: 37.8s\tremaining: 38.4s\n",
      "2479:\tlearn: 0.6068363\ttest: 0.6008018\tbest: 0.6008018 (2479)\ttotal: 37.8s\tremaining: 38.4s\n",
      "2480:\tlearn: 0.6068363\ttest: 0.6008019\tbest: 0.6008018 (2479)\ttotal: 37.8s\tremaining: 38.4s\n",
      "2481:\tlearn: 0.6068363\ttest: 0.6008019\tbest: 0.6008018 (2479)\ttotal: 37.8s\tremaining: 38.4s\n",
      "2482:\tlearn: 0.6068363\ttest: 0.6008019\tbest: 0.6008018 (2479)\ttotal: 37.8s\tremaining: 38.4s\n",
      "2483:\tlearn: 0.6068332\ttest: 0.6008013\tbest: 0.6008013 (2483)\ttotal: 37.9s\tremaining: 38.3s\n",
      "2484:\tlearn: 0.6068332\ttest: 0.6008013\tbest: 0.6008013 (2483)\ttotal: 37.9s\tremaining: 38.3s\n",
      "2485:\tlearn: 0.6068326\ttest: 0.6008011\tbest: 0.6008011 (2485)\ttotal: 37.9s\tremaining: 38.3s\n",
      "2486:\tlearn: 0.6068326\ttest: 0.6008011\tbest: 0.6008011 (2485)\ttotal: 37.9s\tremaining: 38.3s\n",
      "2487:\tlearn: 0.6068326\ttest: 0.6008011\tbest: 0.6008011 (2485)\ttotal: 37.9s\tremaining: 38.3s\n",
      "2488:\tlearn: 0.6067895\ttest: 0.6007611\tbest: 0.6007611 (2488)\ttotal: 37.9s\tremaining: 38.3s\n",
      "2489:\tlearn: 0.6067894\ttest: 0.6007611\tbest: 0.6007611 (2489)\ttotal: 38s\tremaining: 38.3s\n",
      "2490:\tlearn: 0.6067894\ttest: 0.6007611\tbest: 0.6007611 (2489)\ttotal: 38s\tremaining: 38.2s\n",
      "2491:\tlearn: 0.6067894\ttest: 0.6007611\tbest: 0.6007611 (2489)\ttotal: 38s\tremaining: 38.2s\n",
      "2492:\tlearn: 0.6067894\ttest: 0.6007611\tbest: 0.6007611 (2489)\ttotal: 38s\tremaining: 38.2s\n",
      "2493:\tlearn: 0.6067894\ttest: 0.6007611\tbest: 0.6007611 (2489)\ttotal: 38s\tremaining: 38.2s\n",
      "2494:\tlearn: 0.6067875\ttest: 0.6007605\tbest: 0.6007605 (2494)\ttotal: 38s\tremaining: 38.2s\n",
      "2495:\tlearn: 0.6067719\ttest: 0.6007519\tbest: 0.6007519 (2495)\ttotal: 38.1s\tremaining: 38.2s\n",
      "2496:\tlearn: 0.6067719\ttest: 0.6007519\tbest: 0.6007519 (2495)\ttotal: 38.1s\tremaining: 38.2s\n",
      "2497:\tlearn: 0.6067009\ttest: 0.6006802\tbest: 0.6006802 (2497)\ttotal: 38.1s\tremaining: 38.2s\n",
      "2498:\tlearn: 0.6066806\ttest: 0.6006499\tbest: 0.6006499 (2498)\ttotal: 38.1s\tremaining: 38.2s\n",
      "2499:\tlearn: 0.6066656\ttest: 0.6006303\tbest: 0.6006303 (2499)\ttotal: 38.1s\tremaining: 38.1s\n",
      "2500:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.2s\tremaining: 38.1s\n",
      "2501:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.2s\tremaining: 38.1s\n",
      "2502:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.2s\tremaining: 38.1s\n",
      "2503:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.2s\tremaining: 38.1s\n",
      "2504:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.2s\tremaining: 38.1s\n",
      "2505:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.2s\tremaining: 38.1s\n",
      "2506:\tlearn: 0.6066554\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.3s\tremaining: 38s\n",
      "2507:\tlearn: 0.6066553\ttest: 0.6006205\tbest: 0.6006205 (2500)\ttotal: 38.3s\tremaining: 38s\n",
      "2508:\tlearn: 0.6066540\ttest: 0.6006175\tbest: 0.6006175 (2508)\ttotal: 38.3s\tremaining: 38s\n",
      "2509:\tlearn: 0.6066522\ttest: 0.6006161\tbest: 0.6006161 (2509)\ttotal: 38.3s\tremaining: 38s\n",
      "2510:\tlearn: 0.6066522\ttest: 0.6006161\tbest: 0.6006161 (2509)\ttotal: 38.3s\tremaining: 38s\n",
      "2511:\tlearn: 0.6066475\ttest: 0.6006120\tbest: 0.6006120 (2511)\ttotal: 38.4s\tremaining: 38s\n",
      "2512:\tlearn: 0.6066475\ttest: 0.6006120\tbest: 0.6006120 (2511)\ttotal: 38.4s\tremaining: 38s\n",
      "2513:\tlearn: 0.6066475\ttest: 0.6006120\tbest: 0.6006120 (2511)\ttotal: 38.4s\tremaining: 38s\n",
      "2514:\tlearn: 0.6066475\ttest: 0.6006120\tbest: 0.6006120 (2511)\ttotal: 38.4s\tremaining: 37.9s\n",
      "2515:\tlearn: 0.6066455\ttest: 0.6006087\tbest: 0.6006087 (2515)\ttotal: 38.4s\tremaining: 37.9s\n",
      "2516:\tlearn: 0.6066455\ttest: 0.6006087\tbest: 0.6006087 (2515)\ttotal: 38.4s\tremaining: 37.9s\n",
      "2517:\tlearn: 0.6066455\ttest: 0.6006087\tbest: 0.6006087 (2515)\ttotal: 38.5s\tremaining: 37.9s\n",
      "2518:\tlearn: 0.6066422\ttest: 0.6006074\tbest: 0.6006074 (2518)\ttotal: 38.5s\tremaining: 37.9s\n",
      "2519:\tlearn: 0.6066422\ttest: 0.6006074\tbest: 0.6006074 (2518)\ttotal: 38.5s\tremaining: 37.9s\n",
      "2520:\tlearn: 0.6066422\ttest: 0.6006074\tbest: 0.6006074 (2518)\ttotal: 38.5s\tremaining: 37.9s\n",
      "2521:\tlearn: 0.6066422\ttest: 0.6006074\tbest: 0.6006074 (2518)\ttotal: 38.5s\tremaining: 37.8s\n",
      "2522:\tlearn: 0.6066422\ttest: 0.6006074\tbest: 0.6006074 (2518)\ttotal: 38.5s\tremaining: 37.8s\n",
      "2523:\tlearn: 0.6066419\ttest: 0.6006059\tbest: 0.6006059 (2523)\ttotal: 38.5s\tremaining: 37.8s\n",
      "2524:\tlearn: 0.6066409\ttest: 0.6006039\tbest: 0.6006039 (2524)\ttotal: 38.6s\tremaining: 37.8s\n",
      "2525:\tlearn: 0.6066409\ttest: 0.6006039\tbest: 0.6006039 (2524)\ttotal: 38.6s\tremaining: 37.8s\n",
      "2526:\tlearn: 0.6066362\ttest: 0.6005994\tbest: 0.6005994 (2526)\ttotal: 38.6s\tremaining: 37.8s\n",
      "2527:\tlearn: 0.6066362\ttest: 0.6005994\tbest: 0.6005994 (2526)\ttotal: 38.6s\tremaining: 37.8s\n",
      "2528:\tlearn: 0.6066328\ttest: 0.6005964\tbest: 0.6005964 (2528)\ttotal: 38.6s\tremaining: 37.7s\n",
      "2529:\tlearn: 0.6066328\ttest: 0.6005964\tbest: 0.6005964 (2528)\ttotal: 38.6s\tremaining: 37.7s\n",
      "2530:\tlearn: 0.6066326\ttest: 0.6005964\tbest: 0.6005964 (2530)\ttotal: 38.7s\tremaining: 37.7s\n",
      "2531:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.7s\tremaining: 37.7s\n",
      "2532:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.7s\tremaining: 37.7s\n",
      "2533:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.7s\tremaining: 37.7s\n",
      "2534:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.7s\tremaining: 37.7s\n",
      "2535:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.8s\tremaining: 37.7s\n",
      "2536:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.8s\tremaining: 37.6s\n",
      "2537:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.8s\tremaining: 37.6s\n",
      "2538:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.8s\tremaining: 37.6s\n",
      "2539:\tlearn: 0.6066289\ttest: 0.6005935\tbest: 0.6005935 (2531)\ttotal: 38.8s\tremaining: 37.6s\n",
      "2540:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.8s\tremaining: 37.6s\n",
      "2541:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.6s\n",
      "2542:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.5s\n",
      "2543:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.5s\n",
      "2544:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.5s\n",
      "2545:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.5s\n",
      "2546:\tlearn: 0.6066113\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.5s\n",
      "2547:\tlearn: 0.6066113\ttest: 0.6005771\tbest: 0.6005770 (2540)\ttotal: 38.9s\tremaining: 37.5s\n",
      "2548:\tlearn: 0.6066113\ttest: 0.6005771\tbest: 0.6005770 (2540)\ttotal: 39s\tremaining: 37.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2549:\tlearn: 0.6066113\ttest: 0.6005771\tbest: 0.6005770 (2540)\ttotal: 39s\tremaining: 37.4s\n",
      "2550:\tlearn: 0.6066112\ttest: 0.6005770\tbest: 0.6005770 (2540)\ttotal: 39s\tremaining: 37.4s\n",
      "2551:\tlearn: 0.6066090\ttest: 0.6005758\tbest: 0.6005758 (2551)\ttotal: 39s\tremaining: 37.4s\n",
      "2552:\tlearn: 0.6066090\ttest: 0.6005758\tbest: 0.6005758 (2551)\ttotal: 39s\tremaining: 37.4s\n",
      "2553:\tlearn: 0.6066090\ttest: 0.6005758\tbest: 0.6005758 (2551)\ttotal: 39s\tremaining: 37.4s\n",
      "2554:\tlearn: 0.6066090\ttest: 0.6005758\tbest: 0.6005758 (2551)\ttotal: 39s\tremaining: 37.4s\n",
      "2555:\tlearn: 0.6066090\ttest: 0.6005758\tbest: 0.6005758 (2551)\ttotal: 39.1s\tremaining: 37.4s\n",
      "2556:\tlearn: 0.6066072\ttest: 0.6005749\tbest: 0.6005749 (2556)\ttotal: 39.1s\tremaining: 37.3s\n",
      "2557:\tlearn: 0.6066072\ttest: 0.6005749\tbest: 0.6005749 (2556)\ttotal: 39.1s\tremaining: 37.3s\n",
      "2558:\tlearn: 0.6066065\ttest: 0.6005747\tbest: 0.6005747 (2558)\ttotal: 39.1s\tremaining: 37.3s\n",
      "2559:\tlearn: 0.6066065\ttest: 0.6005747\tbest: 0.6005747 (2558)\ttotal: 39.1s\tremaining: 37.3s\n",
      "2560:\tlearn: 0.6066065\ttest: 0.6005747\tbest: 0.6005747 (2558)\ttotal: 39.1s\tremaining: 37.3s\n",
      "2561:\tlearn: 0.6066065\ttest: 0.6005747\tbest: 0.6005747 (2558)\ttotal: 39.2s\tremaining: 37.3s\n",
      "2562:\tlearn: 0.6066065\ttest: 0.6005747\tbest: 0.6005747 (2558)\ttotal: 39.2s\tremaining: 37.2s\n",
      "2563:\tlearn: 0.6066065\ttest: 0.6005747\tbest: 0.6005747 (2558)\ttotal: 39.2s\tremaining: 37.2s\n",
      "2564:\tlearn: 0.6066060\ttest: 0.6005746\tbest: 0.6005746 (2564)\ttotal: 39.2s\tremaining: 37.2s\n",
      "2565:\tlearn: 0.6066060\ttest: 0.6005746\tbest: 0.6005746 (2564)\ttotal: 39.2s\tremaining: 37.2s\n",
      "2566:\tlearn: 0.6066060\ttest: 0.6005746\tbest: 0.6005746 (2564)\ttotal: 39.2s\tremaining: 37.2s\n",
      "2567:\tlearn: 0.6066060\ttest: 0.6005746\tbest: 0.6005746 (2564)\ttotal: 39.2s\tremaining: 37.2s\n",
      "2568:\tlearn: 0.6066060\ttest: 0.6005746\tbest: 0.6005746 (2564)\ttotal: 39.3s\tremaining: 37.1s\n",
      "2569:\tlearn: 0.6066060\ttest: 0.6005746\tbest: 0.6005746 (2564)\ttotal: 39.3s\tremaining: 37.1s\n",
      "2570:\tlearn: 0.6066059\ttest: 0.6005746\tbest: 0.6005746 (2570)\ttotal: 39.3s\tremaining: 37.1s\n",
      "2571:\tlearn: 0.6065928\ttest: 0.6005619\tbest: 0.6005619 (2571)\ttotal: 39.3s\tremaining: 37.1s\n",
      "2572:\tlearn: 0.6065922\ttest: 0.6005618\tbest: 0.6005618 (2572)\ttotal: 39.3s\tremaining: 37.1s\n",
      "2573:\tlearn: 0.6065922\ttest: 0.6005618\tbest: 0.6005618 (2572)\ttotal: 39.3s\tremaining: 37.1s\n",
      "2574:\tlearn: 0.6065922\ttest: 0.6005618\tbest: 0.6005618 (2572)\ttotal: 39.4s\tremaining: 37.1s\n",
      "2575:\tlearn: 0.6065922\ttest: 0.6005618\tbest: 0.6005618 (2572)\ttotal: 39.4s\tremaining: 37s\n",
      "2576:\tlearn: 0.6065917\ttest: 0.6005617\tbest: 0.6005617 (2576)\ttotal: 39.4s\tremaining: 37s\n",
      "2577:\tlearn: 0.6065883\ttest: 0.6005596\tbest: 0.6005596 (2577)\ttotal: 39.4s\tremaining: 37s\n",
      "2578:\tlearn: 0.6065883\ttest: 0.6005596\tbest: 0.6005596 (2577)\ttotal: 39.4s\tremaining: 37s\n",
      "2579:\tlearn: 0.6065883\ttest: 0.6005596\tbest: 0.6005596 (2577)\ttotal: 39.4s\tremaining: 37s\n",
      "2580:\tlearn: 0.6065883\ttest: 0.6005596\tbest: 0.6005596 (2577)\ttotal: 39.5s\tremaining: 37s\n",
      "2581:\tlearn: 0.6065883\ttest: 0.6005596\tbest: 0.6005596 (2577)\ttotal: 39.5s\tremaining: 37s\n",
      "2582:\tlearn: 0.6065883\ttest: 0.6005596\tbest: 0.6005596 (2577)\ttotal: 39.5s\tremaining: 37s\n",
      "2583:\tlearn: 0.6065861\ttest: 0.6005602\tbest: 0.6005596 (2577)\ttotal: 39.5s\tremaining: 36.9s\n",
      "2584:\tlearn: 0.6065585\ttest: 0.6005411\tbest: 0.6005411 (2584)\ttotal: 39.5s\tremaining: 36.9s\n",
      "2585:\tlearn: 0.6065578\ttest: 0.6005410\tbest: 0.6005410 (2585)\ttotal: 39.6s\tremaining: 36.9s\n",
      "2586:\tlearn: 0.6065578\ttest: 0.6005410\tbest: 0.6005410 (2585)\ttotal: 39.6s\tremaining: 36.9s\n",
      "2587:\tlearn: 0.6065578\ttest: 0.6005410\tbest: 0.6005410 (2585)\ttotal: 39.6s\tremaining: 36.9s\n",
      "2588:\tlearn: 0.6065456\ttest: 0.6005287\tbest: 0.6005287 (2588)\ttotal: 39.6s\tremaining: 36.9s\n",
      "2589:\tlearn: 0.6065456\ttest: 0.6005287\tbest: 0.6005287 (2588)\ttotal: 39.6s\tremaining: 36.9s\n",
      "2590:\tlearn: 0.6065456\ttest: 0.6005287\tbest: 0.6005287 (2588)\ttotal: 39.6s\tremaining: 36.9s\n",
      "2591:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.8s\n",
      "2592:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.8s\n",
      "2593:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.8s\n",
      "2594:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.8s\n",
      "2595:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.8s\n",
      "2596:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.8s\n",
      "2597:\tlearn: 0.6065406\ttest: 0.6005234\tbest: 0.6005234 (2591)\ttotal: 39.7s\tremaining: 36.7s\n",
      "2598:\tlearn: 0.6065378\ttest: 0.6005188\tbest: 0.6005188 (2598)\ttotal: 39.8s\tremaining: 36.7s\n",
      "2599:\tlearn: 0.6065378\ttest: 0.6005188\tbest: 0.6005188 (2598)\ttotal: 39.8s\tremaining: 36.7s\n",
      "2600:\tlearn: 0.6065375\ttest: 0.6005184\tbest: 0.6005184 (2600)\ttotal: 39.8s\tremaining: 36.7s\n",
      "2601:\tlearn: 0.6065375\ttest: 0.6005184\tbest: 0.6005184 (2600)\ttotal: 39.8s\tremaining: 36.7s\n",
      "2602:\tlearn: 0.6065375\ttest: 0.6005184\tbest: 0.6005184 (2600)\ttotal: 39.8s\tremaining: 36.7s\n",
      "2603:\tlearn: 0.6065375\ttest: 0.6005184\tbest: 0.6005184 (2600)\ttotal: 39.8s\tremaining: 36.6s\n",
      "2604:\tlearn: 0.6065370\ttest: 0.6005169\tbest: 0.6005169 (2604)\ttotal: 39.8s\tremaining: 36.6s\n",
      "2605:\tlearn: 0.6064579\ttest: 0.6004505\tbest: 0.6004505 (2605)\ttotal: 39.9s\tremaining: 36.6s\n",
      "2606:\tlearn: 0.6064579\ttest: 0.6004505\tbest: 0.6004505 (2605)\ttotal: 39.9s\tremaining: 36.6s\n",
      "2607:\tlearn: 0.6064579\ttest: 0.6004505\tbest: 0.6004505 (2605)\ttotal: 39.9s\tremaining: 36.6s\n",
      "2608:\tlearn: 0.6064579\ttest: 0.6004505\tbest: 0.6004505 (2605)\ttotal: 39.9s\tremaining: 36.6s\n",
      "2609:\tlearn: 0.6064579\ttest: 0.6004506\tbest: 0.6004505 (2605)\ttotal: 39.9s\tremaining: 36.6s\n",
      "2610:\tlearn: 0.6064394\ttest: 0.6004315\tbest: 0.6004315 (2610)\ttotal: 39.9s\tremaining: 36.5s\n",
      "2611:\tlearn: 0.6064394\ttest: 0.6004315\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.5s\n",
      "2612:\tlearn: 0.6064394\ttest: 0.6004315\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.5s\n",
      "2613:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.5s\n",
      "2614:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.5s\n",
      "2615:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.5s\n",
      "2616:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.5s\n",
      "2617:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40s\tremaining: 36.4s\n",
      "2618:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40.1s\tremaining: 36.4s\n",
      "2619:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40.1s\tremaining: 36.4s\n",
      "2620:\tlearn: 0.6064391\ttest: 0.6004316\tbest: 0.6004315 (2610)\ttotal: 40.1s\tremaining: 36.4s\n",
      "2621:\tlearn: 0.6064372\ttest: 0.6004285\tbest: 0.6004285 (2621)\ttotal: 40.1s\tremaining: 36.4s\n",
      "2622:\tlearn: 0.6064372\ttest: 0.6004285\tbest: 0.6004285 (2621)\ttotal: 40.1s\tremaining: 36.4s\n",
      "2623:\tlearn: 0.6064372\ttest: 0.6004285\tbest: 0.6004285 (2621)\ttotal: 40.1s\tremaining: 36.3s\n",
      "2624:\tlearn: 0.6064371\ttest: 0.6004285\tbest: 0.6004285 (2624)\ttotal: 40.2s\tremaining: 36.3s\n",
      "2625:\tlearn: 0.6064370\ttest: 0.6004284\tbest: 0.6004284 (2625)\ttotal: 40.2s\tremaining: 36.3s\n",
      "2626:\tlearn: 0.6064370\ttest: 0.6004284\tbest: 0.6004284 (2625)\ttotal: 40.2s\tremaining: 36.3s\n",
      "2627:\tlearn: 0.6064370\ttest: 0.6004284\tbest: 0.6004284 (2625)\ttotal: 40.2s\tremaining: 36.3s\n",
      "2628:\tlearn: 0.6064370\ttest: 0.6004284\tbest: 0.6004284 (2625)\ttotal: 40.2s\tremaining: 36.3s\n",
      "2629:\tlearn: 0.6064370\ttest: 0.6004284\tbest: 0.6004284 (2625)\ttotal: 40.2s\tremaining: 36.2s\n",
      "2630:\tlearn: 0.6064344\ttest: 0.6004271\tbest: 0.6004271 (2630)\ttotal: 40.2s\tremaining: 36.2s\n",
      "2631:\tlearn: 0.6064344\ttest: 0.6004271\tbest: 0.6004271 (2630)\ttotal: 40.3s\tremaining: 36.2s\n",
      "2632:\tlearn: 0.6064258\ttest: 0.6004169\tbest: 0.6004169 (2632)\ttotal: 40.3s\tremaining: 36.2s\n",
      "2633:\tlearn: 0.6064258\ttest: 0.6004169\tbest: 0.6004169 (2632)\ttotal: 40.3s\tremaining: 36.2s\n",
      "2634:\tlearn: 0.6064258\ttest: 0.6004169\tbest: 0.6004169 (2632)\ttotal: 40.3s\tremaining: 36.2s\n",
      "2635:\tlearn: 0.6064253\ttest: 0.6004168\tbest: 0.6004168 (2635)\ttotal: 40.3s\tremaining: 36.2s\n",
      "2636:\tlearn: 0.6064216\ttest: 0.6004138\tbest: 0.6004138 (2636)\ttotal: 40.3s\tremaining: 36.2s\n",
      "2637:\tlearn: 0.6064174\ttest: 0.6004101\tbest: 0.6004101 (2637)\ttotal: 40.4s\tremaining: 36.1s\n",
      "2638:\tlearn: 0.6064162\ttest: 0.6004078\tbest: 0.6004078 (2638)\ttotal: 40.4s\tremaining: 36.1s\n",
      "2639:\tlearn: 0.6064139\ttest: 0.6004068\tbest: 0.6004068 (2639)\ttotal: 40.4s\tremaining: 36.1s\n",
      "2640:\tlearn: 0.6064094\ttest: 0.6004042\tbest: 0.6004042 (2640)\ttotal: 40.4s\tremaining: 36.1s\n",
      "2641:\tlearn: 0.6064094\ttest: 0.6004042\tbest: 0.6004042 (2640)\ttotal: 40.4s\tremaining: 36.1s\n",
      "2642:\tlearn: 0.6064005\ttest: 0.6004007\tbest: 0.6004007 (2642)\ttotal: 40.5s\tremaining: 36.1s\n",
      "2643:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.5s\tremaining: 36.1s\n",
      "2644:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.5s\tremaining: 36s\n",
      "2645:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.5s\tremaining: 36s\n",
      "2646:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.5s\tremaining: 36s\n",
      "2647:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.5s\tremaining: 36s\n",
      "2648:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.5s\tremaining: 36s\n",
      "2649:\tlearn: 0.6063999\ttest: 0.6004001\tbest: 0.6004001 (2643)\ttotal: 40.6s\tremaining: 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650:\tlearn: 0.6063994\ttest: 0.6004000\tbest: 0.6004000 (2650)\ttotal: 40.6s\tremaining: 36s\n",
      "2651:\tlearn: 0.6063899\ttest: 0.6003910\tbest: 0.6003910 (2651)\ttotal: 40.6s\tremaining: 35.9s\n",
      "2652:\tlearn: 0.6063796\ttest: 0.6003786\tbest: 0.6003786 (2652)\ttotal: 40.6s\tremaining: 35.9s\n",
      "2653:\tlearn: 0.6063796\ttest: 0.6003786\tbest: 0.6003786 (2652)\ttotal: 40.6s\tremaining: 35.9s\n",
      "2654:\tlearn: 0.6063796\ttest: 0.6003787\tbest: 0.6003786 (2652)\ttotal: 40.7s\tremaining: 35.9s\n",
      "2655:\tlearn: 0.6063796\ttest: 0.6003787\tbest: 0.6003786 (2652)\ttotal: 40.7s\tremaining: 35.9s\n",
      "2656:\tlearn: 0.6063796\ttest: 0.6003787\tbest: 0.6003786 (2652)\ttotal: 40.7s\tremaining: 35.9s\n",
      "2657:\tlearn: 0.6063796\ttest: 0.6003787\tbest: 0.6003786 (2652)\ttotal: 40.7s\tremaining: 35.9s\n",
      "2658:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.7s\tremaining: 35.8s\n",
      "2659:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.7s\tremaining: 35.8s\n",
      "2660:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.8s\tremaining: 35.8s\n",
      "2661:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.8s\tremaining: 35.8s\n",
      "2662:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.8s\tremaining: 35.8s\n",
      "2663:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.8s\tremaining: 35.8s\n",
      "2664:\tlearn: 0.6063790\ttest: 0.6003774\tbest: 0.6003774 (2658)\ttotal: 40.8s\tremaining: 35.8s\n",
      "2665:\tlearn: 0.6063348\ttest: 0.6003152\tbest: 0.6003152 (2665)\ttotal: 40.8s\tremaining: 35.7s\n",
      "2666:\tlearn: 0.6063348\ttest: 0.6003152\tbest: 0.6003152 (2665)\ttotal: 40.8s\tremaining: 35.7s\n",
      "2667:\tlearn: 0.6063348\ttest: 0.6003152\tbest: 0.6003152 (2665)\ttotal: 40.9s\tremaining: 35.7s\n",
      "2668:\tlearn: 0.6063298\ttest: 0.6003109\tbest: 0.6003109 (2668)\ttotal: 40.9s\tremaining: 35.7s\n",
      "2669:\tlearn: 0.6063273\ttest: 0.6003111\tbest: 0.6003109 (2668)\ttotal: 40.9s\tremaining: 35.7s\n",
      "2670:\tlearn: 0.6063273\ttest: 0.6003111\tbest: 0.6003109 (2668)\ttotal: 40.9s\tremaining: 35.7s\n",
      "2671:\tlearn: 0.6063267\ttest: 0.6003110\tbest: 0.6003109 (2668)\ttotal: 40.9s\tremaining: 35.7s\n",
      "2672:\tlearn: 0.6063267\ttest: 0.6003110\tbest: 0.6003109 (2668)\ttotal: 40.9s\tremaining: 35.6s\n",
      "2673:\tlearn: 0.6063267\ttest: 0.6003110\tbest: 0.6003109 (2668)\ttotal: 41s\tremaining: 35.6s\n",
      "2674:\tlearn: 0.6063267\ttest: 0.6003110\tbest: 0.6003109 (2668)\ttotal: 41s\tremaining: 35.6s\n",
      "2675:\tlearn: 0.6063267\ttest: 0.6003110\tbest: 0.6003109 (2668)\ttotal: 41s\tremaining: 35.6s\n",
      "2676:\tlearn: 0.6063262\ttest: 0.6003105\tbest: 0.6003105 (2676)\ttotal: 41s\tremaining: 35.6s\n",
      "2677:\tlearn: 0.6063256\ttest: 0.6003107\tbest: 0.6003105 (2676)\ttotal: 41s\tremaining: 35.6s\n",
      "2678:\tlearn: 0.6063256\ttest: 0.6003107\tbest: 0.6003105 (2676)\ttotal: 41s\tremaining: 35.6s\n",
      "2679:\tlearn: 0.6062899\ttest: 0.6002641\tbest: 0.6002641 (2679)\ttotal: 41.1s\tremaining: 35.6s\n",
      "2680:\tlearn: 0.6062896\ttest: 0.6002628\tbest: 0.6002628 (2680)\ttotal: 41.1s\tremaining: 35.5s\n",
      "2681:\tlearn: 0.6062868\ttest: 0.6002600\tbest: 0.6002600 (2681)\ttotal: 41.1s\tremaining: 35.5s\n",
      "2682:\tlearn: 0.6062600\ttest: 0.6002356\tbest: 0.6002356 (2682)\ttotal: 41.1s\tremaining: 35.5s\n",
      "2683:\tlearn: 0.6062600\ttest: 0.6002356\tbest: 0.6002356 (2682)\ttotal: 41.2s\tremaining: 35.5s\n",
      "2684:\tlearn: 0.6062600\ttest: 0.6002356\tbest: 0.6002356 (2682)\ttotal: 41.2s\tremaining: 35.5s\n",
      "2685:\tlearn: 0.6062539\ttest: 0.6002304\tbest: 0.6002304 (2685)\ttotal: 41.2s\tremaining: 35.5s\n",
      "2686:\tlearn: 0.6062539\ttest: 0.6002304\tbest: 0.6002304 (2685)\ttotal: 41.2s\tremaining: 35.5s\n",
      "2687:\tlearn: 0.6062539\ttest: 0.6002304\tbest: 0.6002304 (2685)\ttotal: 41.2s\tremaining: 35.5s\n",
      "2688:\tlearn: 0.6062514\ttest: 0.6002269\tbest: 0.6002269 (2688)\ttotal: 41.3s\tremaining: 35.5s\n",
      "2689:\tlearn: 0.6062514\ttest: 0.6002269\tbest: 0.6002269 (2688)\ttotal: 41.3s\tremaining: 35.4s\n",
      "2690:\tlearn: 0.6062514\ttest: 0.6002269\tbest: 0.6002269 (2688)\ttotal: 41.3s\tremaining: 35.4s\n",
      "2691:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.3s\tremaining: 35.4s\n",
      "2692:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.3s\tremaining: 35.4s\n",
      "2693:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.3s\tremaining: 35.4s\n",
      "2694:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.4s\n",
      "2695:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.4s\n",
      "2696:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.3s\n",
      "2697:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.3s\n",
      "2698:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.3s\n",
      "2699:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.3s\n",
      "2700:\tlearn: 0.6062499\ttest: 0.6002255\tbest: 0.6002255 (2691)\ttotal: 41.4s\tremaining: 35.3s\n",
      "2701:\tlearn: 0.6062452\ttest: 0.6002208\tbest: 0.6002208 (2701)\ttotal: 41.5s\tremaining: 35.3s\n",
      "2702:\tlearn: 0.6062452\ttest: 0.6002208\tbest: 0.6002208 (2701)\ttotal: 41.5s\tremaining: 35.2s\n",
      "2703:\tlearn: 0.6062452\ttest: 0.6002208\tbest: 0.6002208 (2701)\ttotal: 41.5s\tremaining: 35.2s\n",
      "2704:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.5s\tremaining: 35.2s\n",
      "2705:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.5s\tremaining: 35.2s\n",
      "2706:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.5s\tremaining: 35.2s\n",
      "2707:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.5s\tremaining: 35.2s\n",
      "2708:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.6s\tremaining: 35.1s\n",
      "2709:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.6s\tremaining: 35.1s\n",
      "2710:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.6s\tremaining: 35.1s\n",
      "2711:\tlearn: 0.6062414\ttest: 0.6002171\tbest: 0.6002171 (2704)\ttotal: 41.6s\tremaining: 35.1s\n",
      "2712:\tlearn: 0.6062377\ttest: 0.6002098\tbest: 0.6002098 (2712)\ttotal: 41.6s\tremaining: 35.1s\n",
      "2713:\tlearn: 0.6062377\ttest: 0.6002098\tbest: 0.6002098 (2712)\ttotal: 41.6s\tremaining: 35.1s\n",
      "2714:\tlearn: 0.6062377\ttest: 0.6002098\tbest: 0.6002098 (2712)\ttotal: 41.6s\tremaining: 35s\n",
      "2715:\tlearn: 0.6062372\ttest: 0.6002089\tbest: 0.6002089 (2715)\ttotal: 41.7s\tremaining: 35s\n",
      "2716:\tlearn: 0.6062372\ttest: 0.6002089\tbest: 0.6002089 (2715)\ttotal: 41.7s\tremaining: 35s\n",
      "2717:\tlearn: 0.6062369\ttest: 0.6002077\tbest: 0.6002077 (2717)\ttotal: 41.7s\tremaining: 35s\n",
      "2718:\tlearn: 0.6062369\ttest: 0.6002078\tbest: 0.6002077 (2717)\ttotal: 41.7s\tremaining: 35s\n",
      "2719:\tlearn: 0.6062369\ttest: 0.6002078\tbest: 0.6002077 (2717)\ttotal: 41.7s\tremaining: 35s\n",
      "2720:\tlearn: 0.6062369\ttest: 0.6002078\tbest: 0.6002077 (2717)\ttotal: 41.7s\tremaining: 35s\n",
      "2721:\tlearn: 0.6062369\ttest: 0.6002078\tbest: 0.6002077 (2717)\ttotal: 41.7s\tremaining: 34.9s\n",
      "2722:\tlearn: 0.6062314\ttest: 0.6002024\tbest: 0.6002024 (2722)\ttotal: 41.8s\tremaining: 34.9s\n",
      "2723:\tlearn: 0.6062301\ttest: 0.6001991\tbest: 0.6001991 (2723)\ttotal: 41.8s\tremaining: 34.9s\n",
      "2724:\tlearn: 0.6062301\ttest: 0.6001991\tbest: 0.6001991 (2723)\ttotal: 41.8s\tremaining: 34.9s\n",
      "2725:\tlearn: 0.6062301\ttest: 0.6001991\tbest: 0.6001991 (2723)\ttotal: 41.8s\tremaining: 34.9s\n",
      "2726:\tlearn: 0.6062289\ttest: 0.6001982\tbest: 0.6001982 (2726)\ttotal: 41.8s\tremaining: 34.9s\n",
      "2727:\tlearn: 0.6062241\ttest: 0.6001949\tbest: 0.6001949 (2727)\ttotal: 41.8s\tremaining: 34.9s\n",
      "2728:\tlearn: 0.6062241\ttest: 0.6001949\tbest: 0.6001949 (2727)\ttotal: 41.9s\tremaining: 34.8s\n",
      "2729:\tlearn: 0.6062241\ttest: 0.6001949\tbest: 0.6001949 (2727)\ttotal: 41.9s\tremaining: 34.8s\n",
      "2730:\tlearn: 0.6062214\ttest: 0.6001925\tbest: 0.6001925 (2730)\ttotal: 41.9s\tremaining: 34.8s\n",
      "2731:\tlearn: 0.6062176\ttest: 0.6001890\tbest: 0.6001890 (2731)\ttotal: 41.9s\tremaining: 34.8s\n",
      "2732:\tlearn: 0.6062176\ttest: 0.6001890\tbest: 0.6001890 (2731)\ttotal: 41.9s\tremaining: 34.8s\n",
      "2733:\tlearn: 0.6062176\ttest: 0.6001890\tbest: 0.6001890 (2731)\ttotal: 41.9s\tremaining: 34.7s\n",
      "2734:\tlearn: 0.6062176\ttest: 0.6001890\tbest: 0.6001890 (2731)\ttotal: 41.9s\tremaining: 34.7s\n",
      "2735:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.7s\n",
      "2736:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.7s\n",
      "2737:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.7s\n",
      "2738:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.7s\n",
      "2739:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.7s\n",
      "2740:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.6s\n",
      "2741:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42s\tremaining: 34.6s\n",
      "2742:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42.1s\tremaining: 34.6s\n",
      "2743:\tlearn: 0.6061937\ttest: 0.6001624\tbest: 0.6001624 (2735)\ttotal: 42.1s\tremaining: 34.6s\n",
      "2744:\tlearn: 0.6061472\ttest: 0.6001049\tbest: 0.6001049 (2744)\ttotal: 42.1s\tremaining: 34.6s\n",
      "2745:\tlearn: 0.6061472\ttest: 0.6001049\tbest: 0.6001049 (2744)\ttotal: 42.1s\tremaining: 34.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2746:\tlearn: 0.6061472\ttest: 0.6001049\tbest: 0.6001049 (2744)\ttotal: 42.1s\tremaining: 34.6s\n",
      "2747:\tlearn: 0.6061472\ttest: 0.6001049\tbest: 0.6001049 (2744)\ttotal: 42.1s\tremaining: 34.5s\n",
      "2748:\tlearn: 0.6061472\ttest: 0.6001049\tbest: 0.6001049 (2744)\ttotal: 42.2s\tremaining: 34.5s\n",
      "2749:\tlearn: 0.6061470\ttest: 0.6001042\tbest: 0.6001042 (2749)\ttotal: 42.2s\tremaining: 34.5s\n",
      "2750:\tlearn: 0.6061470\ttest: 0.6001042\tbest: 0.6001042 (2749)\ttotal: 42.2s\tremaining: 34.5s\n",
      "2751:\tlearn: 0.6061470\ttest: 0.6001042\tbest: 0.6001042 (2749)\ttotal: 42.2s\tremaining: 34.5s\n",
      "2752:\tlearn: 0.6061451\ttest: 0.6001023\tbest: 0.6001023 (2752)\ttotal: 42.2s\tremaining: 34.5s\n",
      "2753:\tlearn: 0.6061415\ttest: 0.6000993\tbest: 0.6000993 (2753)\ttotal: 42.3s\tremaining: 34.5s\n",
      "2754:\tlearn: 0.6061415\ttest: 0.6000993\tbest: 0.6000993 (2753)\ttotal: 42.3s\tremaining: 34.4s\n",
      "2755:\tlearn: 0.6061415\ttest: 0.6000993\tbest: 0.6000993 (2753)\ttotal: 42.3s\tremaining: 34.4s\n",
      "2756:\tlearn: 0.6061353\ttest: 0.6000935\tbest: 0.6000935 (2756)\ttotal: 42.3s\tremaining: 34.4s\n",
      "2757:\tlearn: 0.6061353\ttest: 0.6000935\tbest: 0.6000935 (2756)\ttotal: 42.3s\tremaining: 34.4s\n",
      "2758:\tlearn: 0.6061353\ttest: 0.6000935\tbest: 0.6000935 (2756)\ttotal: 42.3s\tremaining: 34.4s\n",
      "2759:\tlearn: 0.6061339\ttest: 0.6000926\tbest: 0.6000926 (2759)\ttotal: 42.4s\tremaining: 34.4s\n",
      "2760:\tlearn: 0.6061339\ttest: 0.6000926\tbest: 0.6000926 (2759)\ttotal: 42.4s\tremaining: 34.4s\n",
      "2761:\tlearn: 0.6061320\ttest: 0.6000893\tbest: 0.6000893 (2761)\ttotal: 42.4s\tremaining: 34.4s\n",
      "2762:\tlearn: 0.6061320\ttest: 0.6000893\tbest: 0.6000893 (2761)\ttotal: 42.4s\tremaining: 34.3s\n",
      "2763:\tlearn: 0.6061320\ttest: 0.6000893\tbest: 0.6000893 (2761)\ttotal: 42.4s\tremaining: 34.3s\n",
      "2764:\tlearn: 0.6061320\ttest: 0.6000893\tbest: 0.6000893 (2761)\ttotal: 42.5s\tremaining: 34.3s\n",
      "2765:\tlearn: 0.6061320\ttest: 0.6000893\tbest: 0.6000893 (2761)\ttotal: 42.5s\tremaining: 34.3s\n",
      "2766:\tlearn: 0.6061289\ttest: 0.6000845\tbest: 0.6000845 (2766)\ttotal: 42.5s\tremaining: 34.3s\n",
      "2767:\tlearn: 0.6061289\ttest: 0.6000845\tbest: 0.6000845 (2766)\ttotal: 42.5s\tremaining: 34.3s\n",
      "2768:\tlearn: 0.6061217\ttest: 0.6000827\tbest: 0.6000827 (2768)\ttotal: 42.5s\tremaining: 34.3s\n",
      "2769:\tlearn: 0.6061146\ttest: 0.6000824\tbest: 0.6000824 (2769)\ttotal: 42.5s\tremaining: 34.2s\n",
      "2770:\tlearn: 0.6061146\ttest: 0.6000824\tbest: 0.6000824 (2769)\ttotal: 42.6s\tremaining: 34.2s\n",
      "2771:\tlearn: 0.6061085\ttest: 0.6000772\tbest: 0.6000772 (2771)\ttotal: 42.6s\tremaining: 34.2s\n",
      "2772:\tlearn: 0.6061085\ttest: 0.6000772\tbest: 0.6000772 (2771)\ttotal: 42.6s\tremaining: 34.2s\n",
      "2773:\tlearn: 0.6061085\ttest: 0.6000772\tbest: 0.6000772 (2771)\ttotal: 42.6s\tremaining: 34.2s\n",
      "2774:\tlearn: 0.6061085\ttest: 0.6000772\tbest: 0.6000772 (2771)\ttotal: 42.6s\tremaining: 34.2s\n",
      "2775:\tlearn: 0.6061083\ttest: 0.6000769\tbest: 0.6000769 (2775)\ttotal: 42.6s\tremaining: 34.2s\n",
      "2776:\tlearn: 0.6061083\ttest: 0.6000769\tbest: 0.6000769 (2775)\ttotal: 42.6s\tremaining: 34.1s\n",
      "2777:\tlearn: 0.6061083\ttest: 0.6000769\tbest: 0.6000769 (2775)\ttotal: 42.7s\tremaining: 34.1s\n",
      "2778:\tlearn: 0.6061062\ttest: 0.6000736\tbest: 0.6000736 (2778)\ttotal: 42.7s\tremaining: 34.1s\n",
      "2779:\tlearn: 0.6061062\ttest: 0.6000736\tbest: 0.6000736 (2778)\ttotal: 42.7s\tremaining: 34.1s\n",
      "2780:\tlearn: 0.6061003\ttest: 0.6000685\tbest: 0.6000685 (2780)\ttotal: 42.7s\tremaining: 34.1s\n",
      "2781:\tlearn: 0.6060972\ttest: 0.6000667\tbest: 0.6000667 (2781)\ttotal: 42.7s\tremaining: 34.1s\n",
      "2782:\tlearn: 0.6060972\ttest: 0.6000667\tbest: 0.6000667 (2781)\ttotal: 42.7s\tremaining: 34s\n",
      "2783:\tlearn: 0.6060972\ttest: 0.6000667\tbest: 0.6000667 (2781)\ttotal: 42.8s\tremaining: 34s\n",
      "2784:\tlearn: 0.6060972\ttest: 0.6000667\tbest: 0.6000667 (2781)\ttotal: 42.8s\tremaining: 34s\n",
      "2785:\tlearn: 0.6060969\ttest: 0.6000657\tbest: 0.6000657 (2785)\ttotal: 42.8s\tremaining: 34s\n",
      "2786:\tlearn: 0.6060969\ttest: 0.6000657\tbest: 0.6000657 (2785)\ttotal: 42.8s\tremaining: 34s\n",
      "2787:\tlearn: 0.6060956\ttest: 0.6000624\tbest: 0.6000624 (2787)\ttotal: 42.8s\tremaining: 34s\n",
      "2788:\tlearn: 0.6060956\ttest: 0.6000624\tbest: 0.6000624 (2787)\ttotal: 42.8s\tremaining: 34s\n",
      "2789:\tlearn: 0.6060941\ttest: 0.6000598\tbest: 0.6000598 (2789)\ttotal: 42.8s\tremaining: 33.9s\n",
      "2790:\tlearn: 0.6060941\ttest: 0.6000598\tbest: 0.6000598 (2789)\ttotal: 42.9s\tremaining: 33.9s\n",
      "2791:\tlearn: 0.6060941\ttest: 0.6000598\tbest: 0.6000598 (2789)\ttotal: 42.9s\tremaining: 33.9s\n",
      "2792:\tlearn: 0.6060887\ttest: 0.6000510\tbest: 0.6000510 (2792)\ttotal: 42.9s\tremaining: 33.9s\n",
      "2793:\tlearn: 0.6060855\ttest: 0.6000508\tbest: 0.6000508 (2793)\ttotal: 42.9s\tremaining: 33.9s\n",
      "2794:\tlearn: 0.6060666\ttest: 0.6000303\tbest: 0.6000303 (2794)\ttotal: 42.9s\tremaining: 33.9s\n",
      "2795:\tlearn: 0.6060666\ttest: 0.6000303\tbest: 0.6000303 (2794)\ttotal: 43s\tremaining: 33.9s\n",
      "2796:\tlearn: 0.6060666\ttest: 0.6000303\tbest: 0.6000303 (2794)\ttotal: 43s\tremaining: 33.8s\n",
      "2797:\tlearn: 0.6060666\ttest: 0.6000303\tbest: 0.6000303 (2794)\ttotal: 43s\tremaining: 33.8s\n",
      "2798:\tlearn: 0.6060661\ttest: 0.6000292\tbest: 0.6000292 (2798)\ttotal: 43s\tremaining: 33.8s\n",
      "2799:\tlearn: 0.6060660\ttest: 0.6000292\tbest: 0.6000292 (2798)\ttotal: 43s\tremaining: 33.8s\n",
      "2800:\tlearn: 0.6060639\ttest: 0.6000274\tbest: 0.6000274 (2800)\ttotal: 43s\tremaining: 33.8s\n",
      "2801:\tlearn: 0.6060626\ttest: 0.6000261\tbest: 0.6000261 (2801)\ttotal: 43.1s\tremaining: 33.8s\n",
      "2802:\tlearn: 0.6060626\ttest: 0.6000261\tbest: 0.6000261 (2801)\ttotal: 43.1s\tremaining: 33.8s\n",
      "2803:\tlearn: 0.6060626\ttest: 0.6000261\tbest: 0.6000261 (2801)\ttotal: 43.1s\tremaining: 33.7s\n",
      "2804:\tlearn: 0.6060626\ttest: 0.6000261\tbest: 0.6000261 (2801)\ttotal: 43.1s\tremaining: 33.7s\n",
      "2805:\tlearn: 0.6059823\ttest: 0.5999276\tbest: 0.5999276 (2805)\ttotal: 43.1s\tremaining: 33.7s\n",
      "2806:\tlearn: 0.6059823\ttest: 0.5999276\tbest: 0.5999276 (2805)\ttotal: 43.1s\tremaining: 33.7s\n",
      "2807:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.7s\n",
      "2808:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.7s\n",
      "2809:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.7s\n",
      "2810:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.6s\n",
      "2811:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.6s\n",
      "2812:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.6s\n",
      "2813:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.6s\n",
      "2814:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.2s\tremaining: 33.6s\n",
      "2815:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2816:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2817:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2818:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2819:\tlearn: 0.6059823\ttest: 0.5999277\tbest: 0.5999276 (2805)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2820:\tlearn: 0.6059810\ttest: 0.5999253\tbest: 0.5999253 (2820)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2821:\tlearn: 0.6059810\ttest: 0.5999253\tbest: 0.5999253 (2820)\ttotal: 43.3s\tremaining: 33.5s\n",
      "2822:\tlearn: 0.6059810\ttest: 0.5999253\tbest: 0.5999253 (2820)\ttotal: 43.4s\tremaining: 33.4s\n",
      "2823:\tlearn: 0.6059810\ttest: 0.5999253\tbest: 0.5999253 (2820)\ttotal: 43.4s\tremaining: 33.4s\n",
      "2824:\tlearn: 0.6059810\ttest: 0.5999253\tbest: 0.5999253 (2820)\ttotal: 43.4s\tremaining: 33.4s\n",
      "2825:\tlearn: 0.6059719\ttest: 0.5999146\tbest: 0.5999146 (2825)\ttotal: 43.4s\tremaining: 33.4s\n",
      "2826:\tlearn: 0.6059719\ttest: 0.5999146\tbest: 0.5999146 (2825)\ttotal: 43.4s\tremaining: 33.4s\n",
      "2827:\tlearn: 0.6059719\ttest: 0.5999146\tbest: 0.5999146 (2825)\ttotal: 43.5s\tremaining: 33.4s\n",
      "2828:\tlearn: 0.6059719\ttest: 0.5999146\tbest: 0.5999146 (2825)\ttotal: 43.5s\tremaining: 33.4s\n",
      "2829:\tlearn: 0.6059712\ttest: 0.5999129\tbest: 0.5999129 (2829)\ttotal: 43.5s\tremaining: 33.4s\n",
      "2830:\tlearn: 0.6059679\ttest: 0.5999112\tbest: 0.5999112 (2830)\ttotal: 43.5s\tremaining: 33.3s\n",
      "2831:\tlearn: 0.6059679\ttest: 0.5999112\tbest: 0.5999112 (2830)\ttotal: 43.5s\tremaining: 33.3s\n",
      "2832:\tlearn: 0.6059679\ttest: 0.5999112\tbest: 0.5999112 (2830)\ttotal: 43.5s\tremaining: 33.3s\n",
      "2833:\tlearn: 0.6059679\ttest: 0.5999112\tbest: 0.5999112 (2830)\ttotal: 43.6s\tremaining: 33.3s\n",
      "2834:\tlearn: 0.6059679\ttest: 0.5999112\tbest: 0.5999112 (2830)\ttotal: 43.6s\tremaining: 33.3s\n",
      "2835:\tlearn: 0.6059679\ttest: 0.5999112\tbest: 0.5999112 (2830)\ttotal: 43.6s\tremaining: 33.3s\n",
      "2836:\tlearn: 0.6059432\ttest: 0.5998959\tbest: 0.5998959 (2836)\ttotal: 43.6s\tremaining: 33.3s\n",
      "2837:\tlearn: 0.6059432\ttest: 0.5998959\tbest: 0.5998959 (2836)\ttotal: 43.6s\tremaining: 33.2s\n",
      "2838:\tlearn: 0.6059340\ttest: 0.5998886\tbest: 0.5998886 (2838)\ttotal: 43.7s\tremaining: 33.2s\n",
      "2839:\tlearn: 0.6059340\ttest: 0.5998886\tbest: 0.5998886 (2838)\ttotal: 43.7s\tremaining: 33.2s\n",
      "2840:\tlearn: 0.6059318\ttest: 0.5998872\tbest: 0.5998872 (2840)\ttotal: 43.7s\tremaining: 33.2s\n",
      "2841:\tlearn: 0.6059318\ttest: 0.5998872\tbest: 0.5998872 (2840)\ttotal: 43.7s\tremaining: 33.2s\n",
      "2842:\tlearn: 0.6059318\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.7s\tremaining: 33.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2843:\tlearn: 0.6059318\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.7s\tremaining: 33.2s\n",
      "2844:\tlearn: 0.6059318\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.8s\tremaining: 33.1s\n",
      "2845:\tlearn: 0.6059316\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.8s\tremaining: 33.1s\n",
      "2846:\tlearn: 0.6059316\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.8s\tremaining: 33.1s\n",
      "2847:\tlearn: 0.6059316\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.8s\tremaining: 33.1s\n",
      "2848:\tlearn: 0.6059316\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.8s\tremaining: 33.1s\n",
      "2849:\tlearn: 0.6059316\ttest: 0.5998873\tbest: 0.5998872 (2840)\ttotal: 43.8s\tremaining: 33.1s\n",
      "2850:\tlearn: 0.6059278\ttest: 0.5998830\tbest: 0.5998830 (2850)\ttotal: 43.8s\tremaining: 33s\n",
      "2851:\tlearn: 0.6059278\ttest: 0.5998830\tbest: 0.5998830 (2850)\ttotal: 43.9s\tremaining: 33s\n",
      "2852:\tlearn: 0.6059278\ttest: 0.5998830\tbest: 0.5998830 (2850)\ttotal: 43.9s\tremaining: 33s\n",
      "2853:\tlearn: 0.6059276\ttest: 0.5998816\tbest: 0.5998816 (2853)\ttotal: 43.9s\tremaining: 33s\n",
      "2854:\tlearn: 0.6059276\ttest: 0.5998816\tbest: 0.5998816 (2853)\ttotal: 43.9s\tremaining: 33s\n",
      "2855:\tlearn: 0.6059276\ttest: 0.5998816\tbest: 0.5998816 (2853)\ttotal: 43.9s\tremaining: 33s\n",
      "2856:\tlearn: 0.6059274\ttest: 0.5998810\tbest: 0.5998810 (2856)\ttotal: 43.9s\tremaining: 33s\n",
      "2857:\tlearn: 0.6059274\ttest: 0.5998810\tbest: 0.5998810 (2856)\ttotal: 43.9s\tremaining: 32.9s\n",
      "2858:\tlearn: 0.6059274\ttest: 0.5998811\tbest: 0.5998810 (2856)\ttotal: 44s\tremaining: 32.9s\n",
      "2859:\tlearn: 0.6059230\ttest: 0.5998784\tbest: 0.5998784 (2859)\ttotal: 44s\tremaining: 32.9s\n",
      "2860:\tlearn: 0.6059230\ttest: 0.5998784\tbest: 0.5998784 (2859)\ttotal: 44s\tremaining: 32.9s\n",
      "2861:\tlearn: 0.6059230\ttest: 0.5998784\tbest: 0.5998784 (2859)\ttotal: 44s\tremaining: 32.9s\n",
      "2862:\tlearn: 0.6059230\ttest: 0.5998784\tbest: 0.5998784 (2859)\ttotal: 44s\tremaining: 32.9s\n",
      "2863:\tlearn: 0.6059230\ttest: 0.5998784\tbest: 0.5998784 (2859)\ttotal: 44s\tremaining: 32.8s\n",
      "2864:\tlearn: 0.6059096\ttest: 0.5998603\tbest: 0.5998603 (2864)\ttotal: 44.1s\tremaining: 32.8s\n",
      "2865:\tlearn: 0.6059093\ttest: 0.5998603\tbest: 0.5998603 (2864)\ttotal: 44.1s\tremaining: 32.8s\n",
      "2866:\tlearn: 0.6058291\ttest: 0.5997644\tbest: 0.5997644 (2866)\ttotal: 44.1s\tremaining: 32.8s\n",
      "2867:\tlearn: 0.6058291\ttest: 0.5997644\tbest: 0.5997644 (2866)\ttotal: 44.1s\tremaining: 32.8s\n",
      "2868:\tlearn: 0.6058244\ttest: 0.5997616\tbest: 0.5997616 (2868)\ttotal: 44.1s\tremaining: 32.8s\n",
      "2869:\tlearn: 0.6058244\ttest: 0.5997616\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.8s\n",
      "2870:\tlearn: 0.6058244\ttest: 0.5997616\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.8s\n",
      "2871:\tlearn: 0.6058244\ttest: 0.5997616\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.7s\n",
      "2872:\tlearn: 0.6058244\ttest: 0.5997617\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.7s\n",
      "2873:\tlearn: 0.6058244\ttest: 0.5997617\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.7s\n",
      "2874:\tlearn: 0.6058244\ttest: 0.5997617\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.7s\n",
      "2875:\tlearn: 0.6058244\ttest: 0.5997617\tbest: 0.5997616 (2868)\ttotal: 44.2s\tremaining: 32.7s\n",
      "2876:\tlearn: 0.6058198\ttest: 0.5997585\tbest: 0.5997585 (2876)\ttotal: 44.3s\tremaining: 32.7s\n",
      "2877:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.3s\tremaining: 32.6s\n",
      "2878:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.3s\tremaining: 32.6s\n",
      "2879:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.3s\tremaining: 32.6s\n",
      "2880:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.3s\tremaining: 32.6s\n",
      "2881:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.3s\tremaining: 32.6s\n",
      "2882:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.3s\tremaining: 32.6s\n",
      "2883:\tlearn: 0.6057796\ttest: 0.5997136\tbest: 0.5997136 (2877)\ttotal: 44.4s\tremaining: 32.5s\n",
      "2884:\tlearn: 0.6057796\ttest: 0.5997137\tbest: 0.5997136 (2877)\ttotal: 44.4s\tremaining: 32.5s\n",
      "2885:\tlearn: 0.6057796\ttest: 0.5997137\tbest: 0.5997136 (2877)\ttotal: 44.4s\tremaining: 32.5s\n",
      "2886:\tlearn: 0.6057678\ttest: 0.5997000\tbest: 0.5997000 (2886)\ttotal: 44.4s\tremaining: 32.5s\n",
      "2887:\tlearn: 0.6057675\ttest: 0.5997000\tbest: 0.5997000 (2886)\ttotal: 44.4s\tremaining: 32.5s\n",
      "2888:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.4s\tremaining: 32.5s\n",
      "2889:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.5s\tremaining: 32.5s\n",
      "2890:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.5s\tremaining: 32.4s\n",
      "2891:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.5s\tremaining: 32.4s\n",
      "2892:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.5s\tremaining: 32.4s\n",
      "2893:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.5s\tremaining: 32.4s\n",
      "2894:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.5s\tremaining: 32.4s\n",
      "2895:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.6s\tremaining: 32.4s\n",
      "2896:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.6s\tremaining: 32.4s\n",
      "2897:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.6s\tremaining: 32.3s\n",
      "2898:\tlearn: 0.6057666\ttest: 0.5996991\tbest: 0.5996991 (2888)\ttotal: 44.6s\tremaining: 32.3s\n",
      "2899:\tlearn: 0.6057666\ttest: 0.5996992\tbest: 0.5996991 (2888)\ttotal: 44.6s\tremaining: 32.3s\n",
      "2900:\tlearn: 0.6057642\ttest: 0.5996971\tbest: 0.5996971 (2900)\ttotal: 44.6s\tremaining: 32.3s\n",
      "2901:\tlearn: 0.6057642\ttest: 0.5996971\tbest: 0.5996971 (2900)\ttotal: 44.7s\tremaining: 32.3s\n",
      "2902:\tlearn: 0.6057518\ttest: 0.5996868\tbest: 0.5996868 (2902)\ttotal: 44.7s\tremaining: 32.3s\n",
      "2903:\tlearn: 0.6057518\ttest: 0.5996868\tbest: 0.5996868 (2902)\ttotal: 44.7s\tremaining: 32.3s\n",
      "2904:\tlearn: 0.6057511\ttest: 0.5996856\tbest: 0.5996856 (2904)\ttotal: 44.7s\tremaining: 32.3s\n",
      "2905:\tlearn: 0.6057511\ttest: 0.5996856\tbest: 0.5996856 (2904)\ttotal: 44.7s\tremaining: 32.2s\n",
      "2906:\tlearn: 0.6057511\ttest: 0.5996856\tbest: 0.5996856 (2904)\ttotal: 44.7s\tremaining: 32.2s\n",
      "2907:\tlearn: 0.6057232\ttest: 0.5996407\tbest: 0.5996407 (2907)\ttotal: 44.8s\tremaining: 32.2s\n",
      "2908:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.8s\tremaining: 32.2s\n",
      "2909:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.8s\tremaining: 32.2s\n",
      "2910:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.8s\tremaining: 32.2s\n",
      "2911:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.8s\tremaining: 32.2s\n",
      "2912:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.9s\tremaining: 32.1s\n",
      "2913:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.9s\tremaining: 32.1s\n",
      "2914:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.9s\tremaining: 32.1s\n",
      "2915:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.9s\tremaining: 32.1s\n",
      "2916:\tlearn: 0.6057215\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.9s\tremaining: 32.1s\n",
      "2917:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 44.9s\tremaining: 32.1s\n",
      "2918:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 32s\n",
      "2919:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 32s\n",
      "2920:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 32s\n",
      "2921:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 32s\n",
      "2922:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 32s\n",
      "2923:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 32s\n",
      "2924:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 31.9s\n",
      "2925:\tlearn: 0.6057212\ttest: 0.5996392\tbest: 0.5996392 (2908)\ttotal: 45s\tremaining: 31.9s\n",
      "2926:\tlearn: 0.6057181\ttest: 0.5996372\tbest: 0.5996372 (2926)\ttotal: 45.1s\tremaining: 31.9s\n",
      "2927:\tlearn: 0.6057161\ttest: 0.5996372\tbest: 0.5996372 (2926)\ttotal: 45.1s\tremaining: 31.9s\n",
      "2928:\tlearn: 0.6057161\ttest: 0.5996372\tbest: 0.5996372 (2926)\ttotal: 45.1s\tremaining: 31.9s\n",
      "2929:\tlearn: 0.6057161\ttest: 0.5996372\tbest: 0.5996372 (2926)\ttotal: 45.1s\tremaining: 31.9s\n",
      "2930:\tlearn: 0.6057161\ttest: 0.5996372\tbest: 0.5996372 (2926)\ttotal: 45.1s\tremaining: 31.9s\n",
      "2931:\tlearn: 0.6057082\ttest: 0.5996283\tbest: 0.5996283 (2931)\ttotal: 45.1s\tremaining: 31.8s\n",
      "2932:\tlearn: 0.6057082\ttest: 0.5996283\tbest: 0.5996283 (2931)\ttotal: 45.2s\tremaining: 31.8s\n",
      "2933:\tlearn: 0.6057082\ttest: 0.5996283\tbest: 0.5996283 (2931)\ttotal: 45.2s\tremaining: 31.8s\n",
      "2934:\tlearn: 0.6057082\ttest: 0.5996283\tbest: 0.5996283 (2931)\ttotal: 45.2s\tremaining: 31.8s\n",
      "2935:\tlearn: 0.6057082\ttest: 0.5996283\tbest: 0.5996283 (2931)\ttotal: 45.2s\tremaining: 31.8s\n",
      "2936:\tlearn: 0.6057073\ttest: 0.5996277\tbest: 0.5996277 (2936)\ttotal: 45.2s\tremaining: 31.8s\n",
      "2937:\tlearn: 0.6057072\ttest: 0.5996270\tbest: 0.5996270 (2937)\ttotal: 45.3s\tremaining: 31.8s\n",
      "2938:\tlearn: 0.6057058\ttest: 0.5996250\tbest: 0.5996250 (2938)\ttotal: 45.3s\tremaining: 31.8s\n",
      "2939:\tlearn: 0.6057058\ttest: 0.5996250\tbest: 0.5996250 (2938)\ttotal: 45.3s\tremaining: 31.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940:\tlearn: 0.6057054\ttest: 0.5996232\tbest: 0.5996232 (2940)\ttotal: 45.3s\tremaining: 31.7s\n",
      "2941:\tlearn: 0.6056973\ttest: 0.5996141\tbest: 0.5996141 (2941)\ttotal: 45.3s\tremaining: 31.7s\n",
      "2942:\tlearn: 0.6056973\ttest: 0.5996141\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.7s\n",
      "2943:\tlearn: 0.6056973\ttest: 0.5996141\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.7s\n",
      "2944:\tlearn: 0.6056973\ttest: 0.5996141\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.7s\n",
      "2945:\tlearn: 0.6056973\ttest: 0.5996141\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.6s\n",
      "2946:\tlearn: 0.6056973\ttest: 0.5996141\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.6s\n",
      "2947:\tlearn: 0.6056973\ttest: 0.5996142\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.6s\n",
      "2948:\tlearn: 0.6056973\ttest: 0.5996142\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.6s\n",
      "2949:\tlearn: 0.6056973\ttest: 0.5996142\tbest: 0.5996141 (2941)\ttotal: 45.4s\tremaining: 31.6s\n",
      "2950:\tlearn: 0.6056973\ttest: 0.5996142\tbest: 0.5996141 (2941)\ttotal: 45.5s\tremaining: 31.6s\n",
      "2951:\tlearn: 0.6056973\ttest: 0.5996142\tbest: 0.5996141 (2941)\ttotal: 45.5s\tremaining: 31.6s\n",
      "2952:\tlearn: 0.6056736\ttest: 0.5995910\tbest: 0.5995910 (2952)\ttotal: 45.5s\tremaining: 31.5s\n",
      "2953:\tlearn: 0.6056736\ttest: 0.5995910\tbest: 0.5995910 (2952)\ttotal: 45.5s\tremaining: 31.5s\n",
      "2954:\tlearn: 0.6056736\ttest: 0.5995910\tbest: 0.5995910 (2952)\ttotal: 45.5s\tremaining: 31.5s\n",
      "2955:\tlearn: 0.6056736\ttest: 0.5995910\tbest: 0.5995910 (2952)\ttotal: 45.5s\tremaining: 31.5s\n",
      "2956:\tlearn: 0.6056283\ttest: 0.5995438\tbest: 0.5995438 (2956)\ttotal: 45.6s\tremaining: 31.5s\n",
      "2957:\tlearn: 0.6056283\ttest: 0.5995438\tbest: 0.5995438 (2956)\ttotal: 45.6s\tremaining: 31.5s\n",
      "2958:\tlearn: 0.6056283\ttest: 0.5995438\tbest: 0.5995438 (2956)\ttotal: 45.6s\tremaining: 31.5s\n",
      "2959:\tlearn: 0.6056283\ttest: 0.5995438\tbest: 0.5995438 (2956)\ttotal: 45.6s\tremaining: 31.4s\n",
      "2960:\tlearn: 0.6056244\ttest: 0.5995403\tbest: 0.5995403 (2960)\ttotal: 45.6s\tremaining: 31.4s\n",
      "2961:\tlearn: 0.6056244\ttest: 0.5995404\tbest: 0.5995403 (2960)\ttotal: 45.7s\tremaining: 31.4s\n",
      "2962:\tlearn: 0.6056244\ttest: 0.5995404\tbest: 0.5995403 (2960)\ttotal: 45.7s\tremaining: 31.4s\n",
      "2963:\tlearn: 0.6056244\ttest: 0.5995404\tbest: 0.5995403 (2960)\ttotal: 45.7s\tremaining: 31.4s\n",
      "2964:\tlearn: 0.6056244\ttest: 0.5995404\tbest: 0.5995403 (2960)\ttotal: 45.7s\tremaining: 31.4s\n",
      "2965:\tlearn: 0.6056244\ttest: 0.5995404\tbest: 0.5995403 (2960)\ttotal: 45.7s\tremaining: 31.4s\n",
      "2966:\tlearn: 0.6056226\ttest: 0.5995377\tbest: 0.5995377 (2966)\ttotal: 45.8s\tremaining: 31.4s\n",
      "2967:\tlearn: 0.6056226\ttest: 0.5995377\tbest: 0.5995377 (2966)\ttotal: 45.8s\tremaining: 31.3s\n",
      "2968:\tlearn: 0.6055667\ttest: 0.5994715\tbest: 0.5994715 (2968)\ttotal: 45.8s\tremaining: 31.3s\n",
      "2969:\tlearn: 0.6055663\ttest: 0.5994705\tbest: 0.5994705 (2969)\ttotal: 45.8s\tremaining: 31.3s\n",
      "2970:\tlearn: 0.6055663\ttest: 0.5994705\tbest: 0.5994705 (2969)\ttotal: 45.8s\tremaining: 31.3s\n",
      "2971:\tlearn: 0.6055663\ttest: 0.5994705\tbest: 0.5994705 (2969)\ttotal: 45.9s\tremaining: 31.3s\n",
      "2972:\tlearn: 0.6055663\ttest: 0.5994705\tbest: 0.5994705 (2969)\ttotal: 45.9s\tremaining: 31.3s\n",
      "2973:\tlearn: 0.6055663\ttest: 0.5994705\tbest: 0.5994705 (2969)\ttotal: 45.9s\tremaining: 31.3s\n",
      "2974:\tlearn: 0.6055657\ttest: 0.5994704\tbest: 0.5994704 (2974)\ttotal: 45.9s\tremaining: 31.2s\n",
      "2975:\tlearn: 0.6055657\ttest: 0.5994704\tbest: 0.5994704 (2974)\ttotal: 45.9s\tremaining: 31.2s\n",
      "2976:\tlearn: 0.6055657\ttest: 0.5994704\tbest: 0.5994704 (2974)\ttotal: 45.9s\tremaining: 31.2s\n",
      "2977:\tlearn: 0.6055657\ttest: 0.5994704\tbest: 0.5994704 (2974)\ttotal: 45.9s\tremaining: 31.2s\n",
      "2978:\tlearn: 0.6055657\ttest: 0.5994704\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.2s\n",
      "2979:\tlearn: 0.6055657\ttest: 0.5994704\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.2s\n",
      "2980:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.1s\n",
      "2981:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.1s\n",
      "2982:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.1s\n",
      "2983:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.1s\n",
      "2984:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.1s\n",
      "2985:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46s\tremaining: 31.1s\n",
      "2986:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46.1s\tremaining: 31s\n",
      "2987:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46.1s\tremaining: 31s\n",
      "2988:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46.1s\tremaining: 31s\n",
      "2989:\tlearn: 0.6055657\ttest: 0.5994705\tbest: 0.5994704 (2974)\ttotal: 46.1s\tremaining: 31s\n",
      "2990:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.1s\tremaining: 31s\n",
      "2991:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.1s\tremaining: 31s\n",
      "2992:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.1s\tremaining: 30.9s\n",
      "2993:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.9s\n",
      "2994:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.9s\n",
      "2995:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.9s\n",
      "2996:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.9s\n",
      "2997:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.9s\n",
      "2998:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.8s\n",
      "2999:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.2s\tremaining: 30.8s\n",
      "3000:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.3s\tremaining: 30.8s\n",
      "3001:\tlearn: 0.6055618\ttest: 0.5994684\tbest: 0.5994684 (2990)\ttotal: 46.3s\tremaining: 30.8s\n",
      "3002:\tlearn: 0.6055598\ttest: 0.5994665\tbest: 0.5994665 (3002)\ttotal: 46.3s\tremaining: 30.8s\n",
      "3003:\tlearn: 0.6055598\ttest: 0.5994666\tbest: 0.5994665 (3002)\ttotal: 46.3s\tremaining: 30.8s\n",
      "3004:\tlearn: 0.6055598\ttest: 0.5994666\tbest: 0.5994665 (3002)\ttotal: 46.3s\tremaining: 30.7s\n",
      "3005:\tlearn: 0.6055598\ttest: 0.5994666\tbest: 0.5994665 (3002)\ttotal: 46.3s\tremaining: 30.7s\n",
      "3006:\tlearn: 0.6055598\ttest: 0.5994666\tbest: 0.5994665 (3002)\ttotal: 46.3s\tremaining: 30.7s\n",
      "3007:\tlearn: 0.6055598\ttest: 0.5994666\tbest: 0.5994665 (3002)\ttotal: 46.4s\tremaining: 30.7s\n",
      "3008:\tlearn: 0.6055560\ttest: 0.5994646\tbest: 0.5994646 (3008)\ttotal: 46.4s\tremaining: 30.7s\n",
      "3009:\tlearn: 0.6055514\ttest: 0.5994604\tbest: 0.5994604 (3009)\ttotal: 46.4s\tremaining: 30.7s\n",
      "3010:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.4s\tremaining: 30.7s\n",
      "3011:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.4s\tremaining: 30.6s\n",
      "3012:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.4s\tremaining: 30.6s\n",
      "3013:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.6s\n",
      "3014:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.6s\n",
      "3015:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.6s\n",
      "3016:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.6s\n",
      "3017:\tlearn: 0.6055458\ttest: 0.5994535\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.5s\n",
      "3018:\tlearn: 0.6055445\ttest: 0.5994543\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.5s\n",
      "3019:\tlearn: 0.6055445\ttest: 0.5994543\tbest: 0.5994535 (3010)\ttotal: 46.5s\tremaining: 30.5s\n",
      "3020:\tlearn: 0.6055445\ttest: 0.5994543\tbest: 0.5994535 (3010)\ttotal: 46.6s\tremaining: 30.5s\n",
      "3021:\tlearn: 0.6055445\ttest: 0.5994543\tbest: 0.5994535 (3010)\ttotal: 46.6s\tremaining: 30.5s\n",
      "3022:\tlearn: 0.6055419\ttest: 0.5994527\tbest: 0.5994527 (3022)\ttotal: 46.6s\tremaining: 30.5s\n",
      "3023:\tlearn: 0.6055418\ttest: 0.5994527\tbest: 0.5994527 (3023)\ttotal: 46.6s\tremaining: 30.4s\n",
      "3024:\tlearn: 0.6055180\ttest: 0.5994358\tbest: 0.5994358 (3024)\ttotal: 46.6s\tremaining: 30.4s\n",
      "3025:\tlearn: 0.6055167\ttest: 0.5994335\tbest: 0.5994335 (3025)\ttotal: 46.6s\tremaining: 30.4s\n",
      "3026:\tlearn: 0.6055006\ttest: 0.5994222\tbest: 0.5994222 (3026)\ttotal: 46.7s\tremaining: 30.4s\n",
      "3027:\tlearn: 0.6054947\ttest: 0.5994173\tbest: 0.5994173 (3027)\ttotal: 46.7s\tremaining: 30.4s\n",
      "3028:\tlearn: 0.6054947\ttest: 0.5994173\tbest: 0.5994173 (3027)\ttotal: 46.7s\tremaining: 30.4s\n",
      "3029:\tlearn: 0.6054947\ttest: 0.5994173\tbest: 0.5994173 (3027)\ttotal: 46.7s\tremaining: 30.4s\n",
      "3030:\tlearn: 0.6054947\ttest: 0.5994173\tbest: 0.5994173 (3027)\ttotal: 46.7s\tremaining: 30.3s\n",
      "3031:\tlearn: 0.6054947\ttest: 0.5994173\tbest: 0.5994173 (3027)\ttotal: 46.7s\tremaining: 30.3s\n",
      "3032:\tlearn: 0.6054905\ttest: 0.5994135\tbest: 0.5994135 (3032)\ttotal: 46.7s\tremaining: 30.3s\n",
      "3033:\tlearn: 0.6054882\ttest: 0.5994115\tbest: 0.5994115 (3033)\ttotal: 46.8s\tremaining: 30.3s\n",
      "3034:\tlearn: 0.6054879\ttest: 0.5994115\tbest: 0.5994115 (3034)\ttotal: 46.8s\tremaining: 30.3s\n",
      "3035:\tlearn: 0.6054879\ttest: 0.5994115\tbest: 0.5994115 (3034)\ttotal: 46.8s\tremaining: 30.3s\n",
      "3036:\tlearn: 0.6054879\ttest: 0.5994115\tbest: 0.5994115 (3034)\ttotal: 46.8s\tremaining: 30.3s\n",
      "3037:\tlearn: 0.6054854\ttest: 0.5994126\tbest: 0.5994115 (3034)\ttotal: 46.8s\tremaining: 30.2s\n",
      "3038:\tlearn: 0.6054829\ttest: 0.5994105\tbest: 0.5994105 (3038)\ttotal: 46.9s\tremaining: 30.2s\n",
      "3039:\tlearn: 0.6054829\ttest: 0.5994105\tbest: 0.5994105 (3038)\ttotal: 46.9s\tremaining: 30.2s\n",
      "3040:\tlearn: 0.6054797\ttest: 0.5994088\tbest: 0.5994088 (3040)\ttotal: 46.9s\tremaining: 30.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3041:\tlearn: 0.6054797\ttest: 0.5994088\tbest: 0.5994088 (3040)\ttotal: 46.9s\tremaining: 30.2s\n",
      "3042:\tlearn: 0.6054797\ttest: 0.5994088\tbest: 0.5994088 (3040)\ttotal: 46.9s\tremaining: 30.2s\n",
      "3043:\tlearn: 0.6054797\ttest: 0.5994088\tbest: 0.5994088 (3040)\ttotal: 46.9s\tremaining: 30.2s\n",
      "3044:\tlearn: 0.6054797\ttest: 0.5994088\tbest: 0.5994088 (3040)\ttotal: 47s\tremaining: 30.1s\n",
      "3045:\tlearn: 0.6054797\ttest: 0.5994088\tbest: 0.5994088 (3040)\ttotal: 47s\tremaining: 30.1s\n",
      "3046:\tlearn: 0.6054710\ttest: 0.5993981\tbest: 0.5993981 (3046)\ttotal: 47s\tremaining: 30.1s\n",
      "3047:\tlearn: 0.6054710\ttest: 0.5993981\tbest: 0.5993981 (3046)\ttotal: 47s\tremaining: 30.1s\n",
      "3048:\tlearn: 0.6054710\ttest: 0.5993981\tbest: 0.5993981 (3046)\ttotal: 47s\tremaining: 30.1s\n",
      "3049:\tlearn: 0.6054708\ttest: 0.5993974\tbest: 0.5993974 (3049)\ttotal: 47s\tremaining: 30.1s\n",
      "3050:\tlearn: 0.6054708\ttest: 0.5993974\tbest: 0.5993974 (3049)\ttotal: 47.1s\tremaining: 30.1s\n",
      "3051:\tlearn: 0.6054708\ttest: 0.5993974\tbest: 0.5993974 (3049)\ttotal: 47.1s\tremaining: 30s\n",
      "3052:\tlearn: 0.6054665\ttest: 0.5993949\tbest: 0.5993949 (3052)\ttotal: 47.1s\tremaining: 30s\n",
      "3053:\tlearn: 0.6054665\ttest: 0.5993949\tbest: 0.5993949 (3052)\ttotal: 47.1s\tremaining: 30s\n",
      "3054:\tlearn: 0.6054665\ttest: 0.5993949\tbest: 0.5993949 (3052)\ttotal: 47.1s\tremaining: 30s\n",
      "3055:\tlearn: 0.6054618\ttest: 0.5993858\tbest: 0.5993858 (3055)\ttotal: 47.1s\tremaining: 30s\n",
      "3056:\tlearn: 0.6054618\ttest: 0.5993858\tbest: 0.5993858 (3055)\ttotal: 47.2s\tremaining: 30s\n",
      "3057:\tlearn: 0.6054495\ttest: 0.5993763\tbest: 0.5993763 (3057)\ttotal: 47.2s\tremaining: 30s\n",
      "3058:\tlearn: 0.6054483\ttest: 0.5993748\tbest: 0.5993748 (3058)\ttotal: 47.2s\tremaining: 30s\n",
      "3059:\tlearn: 0.6054483\ttest: 0.5993748\tbest: 0.5993748 (3059)\ttotal: 47.2s\tremaining: 29.9s\n",
      "3060:\tlearn: 0.6054483\ttest: 0.5993748\tbest: 0.5993748 (3059)\ttotal: 47.2s\tremaining: 29.9s\n",
      "3061:\tlearn: 0.6054428\ttest: 0.5993701\tbest: 0.5993701 (3061)\ttotal: 47.3s\tremaining: 29.9s\n",
      "3062:\tlearn: 0.6054399\ttest: 0.5993668\tbest: 0.5993668 (3062)\ttotal: 47.3s\tremaining: 29.9s\n",
      "3063:\tlearn: 0.6054399\ttest: 0.5993668\tbest: 0.5993668 (3062)\ttotal: 47.3s\tremaining: 29.9s\n",
      "3064:\tlearn: 0.6054399\ttest: 0.5993668\tbest: 0.5993668 (3062)\ttotal: 47.3s\tremaining: 29.9s\n",
      "3065:\tlearn: 0.6054369\ttest: 0.5993655\tbest: 0.5993655 (3065)\ttotal: 47.3s\tremaining: 29.9s\n",
      "3066:\tlearn: 0.6054361\ttest: 0.5993647\tbest: 0.5993647 (3066)\ttotal: 47.4s\tremaining: 29.8s\n",
      "3067:\tlearn: 0.6054361\ttest: 0.5993647\tbest: 0.5993647 (3066)\ttotal: 47.4s\tremaining: 29.8s\n",
      "3068:\tlearn: 0.6054361\ttest: 0.5993647\tbest: 0.5993647 (3066)\ttotal: 47.4s\tremaining: 29.8s\n",
      "3069:\tlearn: 0.6054361\ttest: 0.5993647\tbest: 0.5993647 (3066)\ttotal: 47.4s\tremaining: 29.8s\n",
      "3070:\tlearn: 0.6054308\ttest: 0.5993597\tbest: 0.5993597 (3070)\ttotal: 47.4s\tremaining: 29.8s\n",
      "3071:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.4s\tremaining: 29.8s\n",
      "3072:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.8s\n",
      "3073:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.7s\n",
      "3074:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.7s\n",
      "3075:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.7s\n",
      "3076:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.7s\n",
      "3077:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.7s\n",
      "3078:\tlearn: 0.6054304\ttest: 0.5993597\tbest: 0.5993597 (3071)\ttotal: 47.5s\tremaining: 29.7s\n",
      "3079:\tlearn: 0.6054288\ttest: 0.5993573\tbest: 0.5993573 (3079)\ttotal: 47.5s\tremaining: 29.6s\n",
      "3080:\tlearn: 0.6054288\ttest: 0.5993573\tbest: 0.5993573 (3079)\ttotal: 47.6s\tremaining: 29.6s\n",
      "3081:\tlearn: 0.6054288\ttest: 0.5993573\tbest: 0.5993573 (3079)\ttotal: 47.6s\tremaining: 29.6s\n",
      "3082:\tlearn: 0.6054288\ttest: 0.5993573\tbest: 0.5993573 (3079)\ttotal: 47.6s\tremaining: 29.6s\n",
      "3083:\tlearn: 0.6054288\ttest: 0.5993573\tbest: 0.5993573 (3079)\ttotal: 47.6s\tremaining: 29.6s\n",
      "3084:\tlearn: 0.6054288\ttest: 0.5993573\tbest: 0.5993573 (3079)\ttotal: 47.6s\tremaining: 29.6s\n",
      "3085:\tlearn: 0.6053582\ttest: 0.5992842\tbest: 0.5992842 (3085)\ttotal: 47.6s\tremaining: 29.5s\n",
      "3086:\tlearn: 0.6053582\ttest: 0.5992842\tbest: 0.5992842 (3085)\ttotal: 47.7s\tremaining: 29.5s\n",
      "3087:\tlearn: 0.6053582\ttest: 0.5992842\tbest: 0.5992842 (3085)\ttotal: 47.7s\tremaining: 29.5s\n",
      "3088:\tlearn: 0.6053582\ttest: 0.5992842\tbest: 0.5992842 (3085)\ttotal: 47.7s\tremaining: 29.5s\n",
      "3089:\tlearn: 0.6053563\ttest: 0.5992826\tbest: 0.5992826 (3089)\ttotal: 47.7s\tremaining: 29.5s\n",
      "3090:\tlearn: 0.6053563\ttest: 0.5992826\tbest: 0.5992826 (3089)\ttotal: 47.7s\tremaining: 29.5s\n",
      "3091:\tlearn: 0.6053563\ttest: 0.5992826\tbest: 0.5992826 (3089)\ttotal: 47.7s\tremaining: 29.5s\n",
      "3092:\tlearn: 0.6053563\ttest: 0.5992826\tbest: 0.5992826 (3089)\ttotal: 47.7s\tremaining: 29.4s\n",
      "3093:\tlearn: 0.6053364\ttest: 0.5992616\tbest: 0.5992616 (3093)\ttotal: 47.8s\tremaining: 29.4s\n",
      "3094:\tlearn: 0.6053326\ttest: 0.5992577\tbest: 0.5992577 (3094)\ttotal: 47.8s\tremaining: 29.4s\n",
      "3095:\tlearn: 0.6052463\ttest: 0.5991746\tbest: 0.5991746 (3095)\ttotal: 47.8s\tremaining: 29.4s\n",
      "3096:\tlearn: 0.6052463\ttest: 0.5991746\tbest: 0.5991746 (3095)\ttotal: 47.8s\tremaining: 29.4s\n",
      "3097:\tlearn: 0.6052463\ttest: 0.5991746\tbest: 0.5991746 (3095)\ttotal: 47.9s\tremaining: 29.4s\n",
      "3098:\tlearn: 0.6052463\ttest: 0.5991746\tbest: 0.5991746 (3095)\ttotal: 47.9s\tremaining: 29.4s\n",
      "3099:\tlearn: 0.6052393\ttest: 0.5991716\tbest: 0.5991716 (3099)\ttotal: 47.9s\tremaining: 29.4s\n",
      "3100:\tlearn: 0.6052393\ttest: 0.5991717\tbest: 0.5991716 (3099)\ttotal: 47.9s\tremaining: 29.3s\n",
      "3101:\tlearn: 0.6052393\ttest: 0.5991717\tbest: 0.5991716 (3099)\ttotal: 47.9s\tremaining: 29.3s\n",
      "3102:\tlearn: 0.6052393\ttest: 0.5991717\tbest: 0.5991716 (3099)\ttotal: 47.9s\tremaining: 29.3s\n",
      "3103:\tlearn: 0.6052393\ttest: 0.5991717\tbest: 0.5991716 (3099)\ttotal: 47.9s\tremaining: 29.3s\n",
      "3104:\tlearn: 0.6052393\ttest: 0.5991717\tbest: 0.5991716 (3099)\ttotal: 48s\tremaining: 29.3s\n",
      "3105:\tlearn: 0.6052243\ttest: 0.5991540\tbest: 0.5991540 (3105)\ttotal: 48s\tremaining: 29.3s\n",
      "3106:\tlearn: 0.6052243\ttest: 0.5991540\tbest: 0.5991540 (3105)\ttotal: 48s\tremaining: 29.3s\n",
      "3107:\tlearn: 0.6052243\ttest: 0.5991540\tbest: 0.5991540 (3105)\ttotal: 48s\tremaining: 29.2s\n",
      "3108:\tlearn: 0.6052243\ttest: 0.5991540\tbest: 0.5991540 (3105)\ttotal: 48.1s\tremaining: 29.2s\n",
      "3109:\tlearn: 0.6052185\ttest: 0.5991465\tbest: 0.5991465 (3109)\ttotal: 48.1s\tremaining: 29.2s\n",
      "3110:\tlearn: 0.6052170\ttest: 0.5991424\tbest: 0.5991424 (3110)\ttotal: 48.1s\tremaining: 29.2s\n",
      "3111:\tlearn: 0.6052170\ttest: 0.5991424\tbest: 0.5991424 (3110)\ttotal: 48.1s\tremaining: 29.2s\n",
      "3112:\tlearn: 0.6052170\ttest: 0.5991424\tbest: 0.5991424 (3110)\ttotal: 48.1s\tremaining: 29.2s\n",
      "3113:\tlearn: 0.6052170\ttest: 0.5991424\tbest: 0.5991424 (3110)\ttotal: 48.2s\tremaining: 29.2s\n",
      "3114:\tlearn: 0.6052170\ttest: 0.5991424\tbest: 0.5991424 (3110)\ttotal: 48.2s\tremaining: 29.1s\n",
      "3115:\tlearn: 0.6052170\ttest: 0.5991424\tbest: 0.5991424 (3110)\ttotal: 48.2s\tremaining: 29.1s\n",
      "3116:\tlearn: 0.6051618\ttest: 0.5990892\tbest: 0.5990892 (3116)\ttotal: 48.2s\tremaining: 29.1s\n",
      "3117:\tlearn: 0.6051618\ttest: 0.5990892\tbest: 0.5990892 (3116)\ttotal: 48.2s\tremaining: 29.1s\n",
      "3118:\tlearn: 0.6051600\ttest: 0.5990878\tbest: 0.5990878 (3118)\ttotal: 48.2s\tremaining: 29.1s\n",
      "3119:\tlearn: 0.6051600\ttest: 0.5990878\tbest: 0.5990878 (3118)\ttotal: 48.2s\tremaining: 29.1s\n",
      "3120:\tlearn: 0.6051569\ttest: 0.5990863\tbest: 0.5990863 (3120)\ttotal: 48.3s\tremaining: 29.1s\n",
      "3121:\tlearn: 0.6051565\ttest: 0.5990863\tbest: 0.5990863 (3121)\ttotal: 48.3s\tremaining: 29s\n",
      "3122:\tlearn: 0.6051565\ttest: 0.5990863\tbest: 0.5990863 (3121)\ttotal: 48.3s\tremaining: 29s\n",
      "3123:\tlearn: 0.6051565\ttest: 0.5990863\tbest: 0.5990863 (3121)\ttotal: 48.3s\tremaining: 29s\n",
      "3124:\tlearn: 0.6051558\ttest: 0.5990856\tbest: 0.5990856 (3124)\ttotal: 48.3s\tremaining: 29s\n",
      "3125:\tlearn: 0.6051517\ttest: 0.5990799\tbest: 0.5990799 (3125)\ttotal: 48.3s\tremaining: 29s\n",
      "3126:\tlearn: 0.6051517\ttest: 0.5990799\tbest: 0.5990799 (3125)\ttotal: 48.4s\tremaining: 29s\n",
      "3127:\tlearn: 0.6051517\ttest: 0.5990799\tbest: 0.5990799 (3125)\ttotal: 48.4s\tremaining: 28.9s\n",
      "3128:\tlearn: 0.6051517\ttest: 0.5990799\tbest: 0.5990799 (3125)\ttotal: 48.4s\tremaining: 28.9s\n",
      "3129:\tlearn: 0.6051498\ttest: 0.5990752\tbest: 0.5990752 (3129)\ttotal: 48.4s\tremaining: 28.9s\n",
      "3130:\tlearn: 0.6051498\ttest: 0.5990752\tbest: 0.5990752 (3129)\ttotal: 48.4s\tremaining: 28.9s\n",
      "3131:\tlearn: 0.6051498\ttest: 0.5990752\tbest: 0.5990752 (3129)\ttotal: 48.4s\tremaining: 28.9s\n",
      "3132:\tlearn: 0.6051477\ttest: 0.5990712\tbest: 0.5990712 (3132)\ttotal: 48.4s\tremaining: 28.9s\n",
      "3133:\tlearn: 0.6051477\ttest: 0.5990712\tbest: 0.5990712 (3132)\ttotal: 48.4s\tremaining: 28.8s\n",
      "3134:\tlearn: 0.6051449\ttest: 0.5990676\tbest: 0.5990676 (3134)\ttotal: 48.5s\tremaining: 28.8s\n",
      "3135:\tlearn: 0.6051449\ttest: 0.5990676\tbest: 0.5990676 (3134)\ttotal: 48.5s\tremaining: 28.8s\n",
      "3136:\tlearn: 0.6051449\ttest: 0.5990676\tbest: 0.5990676 (3134)\ttotal: 48.5s\tremaining: 28.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3137:\tlearn: 0.6051449\ttest: 0.5990676\tbest: 0.5990676 (3134)\ttotal: 48.5s\tremaining: 28.8s\n",
      "3138:\tlearn: 0.6051448\ttest: 0.5990675\tbest: 0.5990675 (3138)\ttotal: 48.5s\tremaining: 28.8s\n",
      "3139:\tlearn: 0.6051415\ttest: 0.5990658\tbest: 0.5990658 (3139)\ttotal: 48.6s\tremaining: 28.8s\n",
      "3140:\tlearn: 0.6051411\ttest: 0.5990646\tbest: 0.5990646 (3140)\ttotal: 48.6s\tremaining: 28.8s\n",
      "3141:\tlearn: 0.6051282\ttest: 0.5990539\tbest: 0.5990539 (3141)\ttotal: 48.6s\tremaining: 28.7s\n",
      "3142:\tlearn: 0.6051282\ttest: 0.5990539\tbest: 0.5990539 (3141)\ttotal: 48.6s\tremaining: 28.7s\n",
      "3143:\tlearn: 0.6051282\ttest: 0.5990539\tbest: 0.5990539 (3141)\ttotal: 48.6s\tremaining: 28.7s\n",
      "3144:\tlearn: 0.6051282\ttest: 0.5990539\tbest: 0.5990539 (3141)\ttotal: 48.6s\tremaining: 28.7s\n",
      "3145:\tlearn: 0.6051282\ttest: 0.5990539\tbest: 0.5990539 (3141)\ttotal: 48.7s\tremaining: 28.7s\n",
      "3146:\tlearn: 0.6051282\ttest: 0.5990537\tbest: 0.5990537 (3146)\ttotal: 48.7s\tremaining: 28.7s\n",
      "3147:\tlearn: 0.6051282\ttest: 0.5990537\tbest: 0.5990537 (3146)\ttotal: 48.7s\tremaining: 28.6s\n",
      "3148:\tlearn: 0.6051282\ttest: 0.5990537\tbest: 0.5990537 (3146)\ttotal: 48.7s\tremaining: 28.6s\n",
      "3149:\tlearn: 0.6050906\ttest: 0.5990015\tbest: 0.5990015 (3149)\ttotal: 48.7s\tremaining: 28.6s\n",
      "3150:\tlearn: 0.6050906\ttest: 0.5990015\tbest: 0.5990015 (3149)\ttotal: 48.7s\tremaining: 28.6s\n",
      "3151:\tlearn: 0.6050906\ttest: 0.5990015\tbest: 0.5990015 (3149)\ttotal: 48.8s\tremaining: 28.6s\n",
      "3152:\tlearn: 0.6050906\ttest: 0.5990015\tbest: 0.5990015 (3149)\ttotal: 48.8s\tremaining: 28.6s\n",
      "3153:\tlearn: 0.6050397\ttest: 0.5989425\tbest: 0.5989425 (3153)\ttotal: 48.8s\tremaining: 28.6s\n",
      "3154:\tlearn: 0.6050384\ttest: 0.5989404\tbest: 0.5989404 (3154)\ttotal: 48.8s\tremaining: 28.5s\n",
      "3155:\tlearn: 0.6050379\ttest: 0.5989393\tbest: 0.5989393 (3155)\ttotal: 48.8s\tremaining: 28.5s\n",
      "3156:\tlearn: 0.6050379\ttest: 0.5989393\tbest: 0.5989393 (3155)\ttotal: 48.8s\tremaining: 28.5s\n",
      "3157:\tlearn: 0.6050193\ttest: 0.5989163\tbest: 0.5989163 (3157)\ttotal: 48.9s\tremaining: 28.5s\n",
      "3158:\tlearn: 0.6050193\ttest: 0.5989163\tbest: 0.5989163 (3157)\ttotal: 48.9s\tremaining: 28.5s\n",
      "3159:\tlearn: 0.6050186\ttest: 0.5989157\tbest: 0.5989157 (3159)\ttotal: 48.9s\tremaining: 28.5s\n",
      "3160:\tlearn: 0.6050186\ttest: 0.5989157\tbest: 0.5989157 (3159)\ttotal: 48.9s\tremaining: 28.5s\n",
      "3161:\tlearn: 0.6050186\ttest: 0.5989157\tbest: 0.5989157 (3159)\ttotal: 48.9s\tremaining: 28.4s\n",
      "3162:\tlearn: 0.6050186\ttest: 0.5989157\tbest: 0.5989157 (3159)\ttotal: 48.9s\tremaining: 28.4s\n",
      "3163:\tlearn: 0.6050186\ttest: 0.5989157\tbest: 0.5989157 (3159)\ttotal: 49s\tremaining: 28.4s\n",
      "3164:\tlearn: 0.6050009\ttest: 0.5989016\tbest: 0.5989016 (3164)\ttotal: 49s\tremaining: 28.4s\n",
      "3165:\tlearn: 0.6050005\ttest: 0.5989005\tbest: 0.5989005 (3165)\ttotal: 49s\tremaining: 28.4s\n",
      "3166:\tlearn: 0.6050005\ttest: 0.5989005\tbest: 0.5989005 (3165)\ttotal: 49s\tremaining: 28.4s\n",
      "3167:\tlearn: 0.6050004\ttest: 0.5988999\tbest: 0.5988999 (3167)\ttotal: 49s\tremaining: 28.4s\n",
      "3168:\tlearn: 0.6050004\ttest: 0.5988999\tbest: 0.5988999 (3167)\ttotal: 49.1s\tremaining: 28.3s\n",
      "3169:\tlearn: 0.6050004\ttest: 0.5988999\tbest: 0.5988999 (3167)\ttotal: 49.1s\tremaining: 28.3s\n",
      "3170:\tlearn: 0.6050004\ttest: 0.5988999\tbest: 0.5988999 (3167)\ttotal: 49.1s\tremaining: 28.3s\n",
      "3171:\tlearn: 0.6050004\ttest: 0.5988999\tbest: 0.5988999 (3167)\ttotal: 49.1s\tremaining: 28.3s\n",
      "3172:\tlearn: 0.6050004\ttest: 0.5988999\tbest: 0.5988999 (3167)\ttotal: 49.1s\tremaining: 28.3s\n",
      "3173:\tlearn: 0.6049997\ttest: 0.5988993\tbest: 0.5988993 (3173)\ttotal: 49.1s\tremaining: 28.3s\n",
      "3174:\tlearn: 0.6049937\ttest: 0.5988916\tbest: 0.5988916 (3174)\ttotal: 49.2s\tremaining: 28.3s\n",
      "3175:\tlearn: 0.6049937\ttest: 0.5988916\tbest: 0.5988916 (3174)\ttotal: 49.2s\tremaining: 28.3s\n",
      "3176:\tlearn: 0.6049937\ttest: 0.5988916\tbest: 0.5988916 (3174)\ttotal: 49.2s\tremaining: 28.2s\n",
      "3177:\tlearn: 0.6049937\ttest: 0.5988916\tbest: 0.5988916 (3174)\ttotal: 49.2s\tremaining: 28.2s\n",
      "3178:\tlearn: 0.6049888\ttest: 0.5988875\tbest: 0.5988875 (3178)\ttotal: 49.2s\tremaining: 28.2s\n",
      "3179:\tlearn: 0.6049888\ttest: 0.5988875\tbest: 0.5988875 (3178)\ttotal: 49.3s\tremaining: 28.2s\n",
      "3180:\tlearn: 0.6049888\ttest: 0.5988875\tbest: 0.5988875 (3178)\ttotal: 49.3s\tremaining: 28.2s\n",
      "3181:\tlearn: 0.6049875\ttest: 0.5988854\tbest: 0.5988854 (3181)\ttotal: 49.3s\tremaining: 28.2s\n",
      "3182:\tlearn: 0.6049875\ttest: 0.5988854\tbest: 0.5988854 (3181)\ttotal: 49.3s\tremaining: 28.1s\n",
      "3183:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.3s\tremaining: 28.1s\n",
      "3184:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.3s\tremaining: 28.1s\n",
      "3185:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28.1s\n",
      "3186:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28.1s\n",
      "3187:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28.1s\n",
      "3188:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28.1s\n",
      "3189:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28s\n",
      "3190:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28s\n",
      "3191:\tlearn: 0.6049874\ttest: 0.5988846\tbest: 0.5988846 (3183)\ttotal: 49.4s\tremaining: 28s\n",
      "3192:\tlearn: 0.6049831\ttest: 0.5988828\tbest: 0.5988828 (3192)\ttotal: 49.5s\tremaining: 28s\n",
      "3193:\tlearn: 0.6049828\ttest: 0.5988829\tbest: 0.5988828 (3192)\ttotal: 49.5s\tremaining: 28s\n",
      "3194:\tlearn: 0.6049828\ttest: 0.5988829\tbest: 0.5988828 (3192)\ttotal: 49.5s\tremaining: 28s\n",
      "3195:\tlearn: 0.6049795\ttest: 0.5988778\tbest: 0.5988778 (3195)\ttotal: 49.5s\tremaining: 28s\n",
      "3196:\tlearn: 0.6049795\ttest: 0.5988778\tbest: 0.5988778 (3195)\ttotal: 49.5s\tremaining: 27.9s\n",
      "3197:\tlearn: 0.6049795\ttest: 0.5988778\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.9s\n",
      "3198:\tlearn: 0.6049795\ttest: 0.5988778\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.9s\n",
      "3199:\tlearn: 0.6049795\ttest: 0.5988778\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.9s\n",
      "3200:\tlearn: 0.6049795\ttest: 0.5988778\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.9s\n",
      "3201:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.9s\n",
      "3202:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.8s\n",
      "3203:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.6s\tremaining: 27.8s\n",
      "3204:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.7s\tremaining: 27.8s\n",
      "3205:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.7s\tremaining: 27.8s\n",
      "3206:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.7s\tremaining: 27.8s\n",
      "3207:\tlearn: 0.6049794\ttest: 0.5988779\tbest: 0.5988778 (3195)\ttotal: 49.7s\tremaining: 27.8s\n",
      "3208:\tlearn: 0.6049784\ttest: 0.5988773\tbest: 0.5988773 (3208)\ttotal: 49.7s\tremaining: 27.7s\n",
      "3209:\tlearn: 0.6049784\ttest: 0.5988773\tbest: 0.5988773 (3208)\ttotal: 49.7s\tremaining: 27.7s\n",
      "3210:\tlearn: 0.6049698\ttest: 0.5988671\tbest: 0.5988671 (3210)\ttotal: 49.8s\tremaining: 27.7s\n",
      "3211:\tlearn: 0.6049698\ttest: 0.5988671\tbest: 0.5988671 (3210)\ttotal: 49.8s\tremaining: 27.7s\n",
      "3212:\tlearn: 0.6049688\ttest: 0.5988652\tbest: 0.5988652 (3212)\ttotal: 49.8s\tremaining: 27.7s\n",
      "3213:\tlearn: 0.6049688\ttest: 0.5988652\tbest: 0.5988652 (3212)\ttotal: 49.8s\tremaining: 27.7s\n",
      "3214:\tlearn: 0.6049688\ttest: 0.5988652\tbest: 0.5988652 (3212)\ttotal: 49.8s\tremaining: 27.7s\n",
      "3215:\tlearn: 0.6049688\ttest: 0.5988652\tbest: 0.5988652 (3212)\ttotal: 49.8s\tremaining: 27.6s\n",
      "3216:\tlearn: 0.6049645\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 49.8s\tremaining: 27.6s\n",
      "3217:\tlearn: 0.6049645\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 49.8s\tremaining: 27.6s\n",
      "3218:\tlearn: 0.6049644\ttest: 0.5988628\tbest: 0.5988627 (3216)\ttotal: 49.9s\tremaining: 27.6s\n",
      "3219:\tlearn: 0.6049644\ttest: 0.5988628\tbest: 0.5988627 (3216)\ttotal: 49.9s\tremaining: 27.6s\n",
      "3220:\tlearn: 0.6049644\ttest: 0.5988628\tbest: 0.5988627 (3216)\ttotal: 49.9s\tremaining: 27.6s\n",
      "3221:\tlearn: 0.6049634\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 49.9s\tremaining: 27.5s\n",
      "3222:\tlearn: 0.6049634\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 49.9s\tremaining: 27.5s\n",
      "3223:\tlearn: 0.6049634\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 49.9s\tremaining: 27.5s\n",
      "3224:\tlearn: 0.6049634\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 50s\tremaining: 27.5s\n",
      "3225:\tlearn: 0.6049634\ttest: 0.5988627\tbest: 0.5988627 (3216)\ttotal: 50s\tremaining: 27.5s\n",
      "3226:\tlearn: 0.6049618\ttest: 0.5988613\tbest: 0.5988613 (3226)\ttotal: 50s\tremaining: 27.5s\n",
      "3227:\tlearn: 0.6049618\ttest: 0.5988613\tbest: 0.5988613 (3226)\ttotal: 50s\tremaining: 27.5s\n",
      "3228:\tlearn: 0.6049584\ttest: 0.5988544\tbest: 0.5988544 (3228)\ttotal: 50s\tremaining: 27.4s\n",
      "3229:\tlearn: 0.6049574\ttest: 0.5988525\tbest: 0.5988525 (3229)\ttotal: 50s\tremaining: 27.4s\n",
      "3230:\tlearn: 0.6049574\ttest: 0.5988525\tbest: 0.5988525 (3229)\ttotal: 50.1s\tremaining: 27.4s\n",
      "3231:\tlearn: 0.6049574\ttest: 0.5988525\tbest: 0.5988525 (3229)\ttotal: 50.1s\tremaining: 27.4s\n",
      "3232:\tlearn: 0.6049500\ttest: 0.5988477\tbest: 0.5988477 (3232)\ttotal: 50.1s\tremaining: 27.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233:\tlearn: 0.6049071\ttest: 0.5987968\tbest: 0.5987968 (3233)\ttotal: 50.1s\tremaining: 27.4s\n",
      "3234:\tlearn: 0.6049069\ttest: 0.5987964\tbest: 0.5987964 (3234)\ttotal: 50.1s\tremaining: 27.4s\n",
      "3235:\tlearn: 0.6049069\ttest: 0.5987964\tbest: 0.5987964 (3234)\ttotal: 50.2s\tremaining: 27.3s\n",
      "3236:\tlearn: 0.6049069\ttest: 0.5987965\tbest: 0.5987964 (3234)\ttotal: 50.2s\tremaining: 27.3s\n",
      "3237:\tlearn: 0.6049069\ttest: 0.5987965\tbest: 0.5987964 (3234)\ttotal: 50.2s\tremaining: 27.3s\n",
      "3238:\tlearn: 0.6049069\ttest: 0.5987965\tbest: 0.5987964 (3234)\ttotal: 50.2s\tremaining: 27.3s\n",
      "3239:\tlearn: 0.6049069\ttest: 0.5987965\tbest: 0.5987964 (3234)\ttotal: 50.2s\tremaining: 27.3s\n",
      "3240:\tlearn: 0.6049069\ttest: 0.5987965\tbest: 0.5987964 (3234)\ttotal: 50.2s\tremaining: 27.3s\n",
      "3241:\tlearn: 0.6049069\ttest: 0.5987965\tbest: 0.5987964 (3234)\ttotal: 50.3s\tremaining: 27.3s\n",
      "3242:\tlearn: 0.6049069\ttest: 0.5987963\tbest: 0.5987963 (3242)\ttotal: 50.3s\tremaining: 27.2s\n",
      "3243:\tlearn: 0.6049069\ttest: 0.5987963\tbest: 0.5987963 (3242)\ttotal: 50.3s\tremaining: 27.2s\n",
      "3244:\tlearn: 0.6049065\ttest: 0.5987964\tbest: 0.5987963 (3242)\ttotal: 50.3s\tremaining: 27.2s\n",
      "3245:\tlearn: 0.6049065\ttest: 0.5987964\tbest: 0.5987963 (3242)\ttotal: 50.3s\tremaining: 27.2s\n",
      "3246:\tlearn: 0.6049065\ttest: 0.5987964\tbest: 0.5987963 (3242)\ttotal: 50.3s\tremaining: 27.2s\n",
      "3247:\tlearn: 0.6049065\ttest: 0.5987964\tbest: 0.5987963 (3242)\ttotal: 50.4s\tremaining: 27.2s\n",
      "3248:\tlearn: 0.6048612\ttest: 0.5987445\tbest: 0.5987445 (3248)\ttotal: 50.4s\tremaining: 27.2s\n",
      "3249:\tlearn: 0.6048612\ttest: 0.5987445\tbest: 0.5987445 (3248)\ttotal: 50.4s\tremaining: 27.1s\n",
      "3250:\tlearn: 0.6048599\ttest: 0.5987439\tbest: 0.5987439 (3250)\ttotal: 50.4s\tremaining: 27.1s\n",
      "3251:\tlearn: 0.6048599\ttest: 0.5987439\tbest: 0.5987439 (3250)\ttotal: 50.4s\tremaining: 27.1s\n",
      "3252:\tlearn: 0.6048599\ttest: 0.5987439\tbest: 0.5987439 (3250)\ttotal: 50.5s\tremaining: 27.1s\n",
      "3253:\tlearn: 0.6048599\ttest: 0.5987439\tbest: 0.5987439 (3250)\ttotal: 50.5s\tremaining: 27.1s\n",
      "3254:\tlearn: 0.6048599\ttest: 0.5987439\tbest: 0.5987439 (3250)\ttotal: 50.5s\tremaining: 27.1s\n",
      "3255:\tlearn: 0.6048599\ttest: 0.5987439\tbest: 0.5987439 (3250)\ttotal: 50.5s\tremaining: 27.1s\n",
      "3256:\tlearn: 0.6048384\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.5s\tremaining: 27s\n",
      "3257:\tlearn: 0.6048384\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.5s\tremaining: 27s\n",
      "3258:\tlearn: 0.6048384\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 27s\n",
      "3259:\tlearn: 0.6048384\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 27s\n",
      "3260:\tlearn: 0.6048384\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 27s\n",
      "3261:\tlearn: 0.6048384\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 27s\n",
      "3262:\tlearn: 0.6048383\ttest: 0.5987197\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 26.9s\n",
      "3263:\tlearn: 0.6048383\ttest: 0.5987197\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 26.9s\n",
      "3264:\tlearn: 0.6048383\ttest: 0.5987197\tbest: 0.5987196 (3256)\ttotal: 50.6s\tremaining: 26.9s\n",
      "3265:\tlearn: 0.6048383\ttest: 0.5987197\tbest: 0.5987196 (3256)\ttotal: 50.7s\tremaining: 26.9s\n",
      "3266:\tlearn: 0.6048383\ttest: 0.5987197\tbest: 0.5987196 (3256)\ttotal: 50.7s\tremaining: 26.9s\n",
      "3267:\tlearn: 0.6048383\ttest: 0.5987197\tbest: 0.5987196 (3256)\ttotal: 50.7s\tremaining: 26.9s\n",
      "3268:\tlearn: 0.6048383\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.7s\tremaining: 26.8s\n",
      "3269:\tlearn: 0.6048383\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.7s\tremaining: 26.8s\n",
      "3270:\tlearn: 0.6048383\ttest: 0.5987196\tbest: 0.5987196 (3256)\ttotal: 50.7s\tremaining: 26.8s\n",
      "3271:\tlearn: 0.6048299\ttest: 0.5987118\tbest: 0.5987118 (3271)\ttotal: 50.8s\tremaining: 26.8s\n",
      "3272:\tlearn: 0.6048299\ttest: 0.5987118\tbest: 0.5987118 (3271)\ttotal: 50.8s\tremaining: 26.8s\n",
      "3273:\tlearn: 0.6048299\ttest: 0.5987118\tbest: 0.5987118 (3271)\ttotal: 50.8s\tremaining: 26.8s\n",
      "3274:\tlearn: 0.6047807\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.8s\tremaining: 26.8s\n",
      "3275:\tlearn: 0.6047807\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.8s\tremaining: 26.7s\n",
      "3276:\tlearn: 0.6047807\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.8s\tremaining: 26.7s\n",
      "3277:\tlearn: 0.6047807\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.8s\tremaining: 26.7s\n",
      "3278:\tlearn: 0.6047807\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.8s\tremaining: 26.7s\n",
      "3279:\tlearn: 0.6047807\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.9s\tremaining: 26.7s\n",
      "3280:\tlearn: 0.6047803\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.9s\tremaining: 26.7s\n",
      "3281:\tlearn: 0.6047803\ttest: 0.5986535\tbest: 0.5986535 (3274)\ttotal: 50.9s\tremaining: 26.6s\n",
      "3282:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 50.9s\tremaining: 26.6s\n",
      "3283:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 50.9s\tremaining: 26.6s\n",
      "3284:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 50.9s\tremaining: 26.6s\n",
      "3285:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 51s\tremaining: 26.6s\n",
      "3286:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 51s\tremaining: 26.6s\n",
      "3287:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 51s\tremaining: 26.5s\n",
      "3288:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 51s\tremaining: 26.5s\n",
      "3289:\tlearn: 0.6047803\ttest: 0.5986536\tbest: 0.5986535 (3274)\ttotal: 51s\tremaining: 26.5s\n",
      "3290:\tlearn: 0.6047790\ttest: 0.5986520\tbest: 0.5986520 (3290)\ttotal: 51s\tremaining: 26.5s\n",
      "3291:\tlearn: 0.6047790\ttest: 0.5986520\tbest: 0.5986520 (3290)\ttotal: 51s\tremaining: 26.5s\n",
      "3292:\tlearn: 0.6047772\ttest: 0.5986505\tbest: 0.5986505 (3292)\ttotal: 51.1s\tremaining: 26.5s\n",
      "3293:\tlearn: 0.6047701\ttest: 0.5986383\tbest: 0.5986383 (3293)\ttotal: 51.1s\tremaining: 26.5s\n",
      "3294:\tlearn: 0.6047701\ttest: 0.5986383\tbest: 0.5986383 (3293)\ttotal: 51.1s\tremaining: 26.4s\n",
      "3295:\tlearn: 0.6047701\ttest: 0.5986383\tbest: 0.5986383 (3293)\ttotal: 51.1s\tremaining: 26.4s\n",
      "3296:\tlearn: 0.6047701\ttest: 0.5986383\tbest: 0.5986383 (3293)\ttotal: 51.1s\tremaining: 26.4s\n",
      "3297:\tlearn: 0.6047701\ttest: 0.5986383\tbest: 0.5986383 (3293)\ttotal: 51.1s\tremaining: 26.4s\n",
      "3298:\tlearn: 0.6047701\ttest: 0.5986383\tbest: 0.5986383 (3293)\ttotal: 51.2s\tremaining: 26.4s\n",
      "3299:\tlearn: 0.6047643\ttest: 0.5986357\tbest: 0.5986357 (3299)\ttotal: 51.2s\tremaining: 26.4s\n",
      "3300:\tlearn: 0.6047643\ttest: 0.5986357\tbest: 0.5986357 (3299)\ttotal: 51.2s\tremaining: 26.4s\n",
      "3301:\tlearn: 0.6047643\ttest: 0.5986357\tbest: 0.5986357 (3299)\ttotal: 51.2s\tremaining: 26.3s\n",
      "3302:\tlearn: 0.6047606\ttest: 0.5986280\tbest: 0.5986280 (3302)\ttotal: 51.2s\tremaining: 26.3s\n",
      "3303:\tlearn: 0.6047606\ttest: 0.5986280\tbest: 0.5986280 (3302)\ttotal: 51.2s\tremaining: 26.3s\n",
      "3304:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.3s\n",
      "3305:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.3s\n",
      "3306:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.3s\n",
      "3307:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.2s\n",
      "3308:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.2s\n",
      "3309:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.2s\n",
      "3310:\tlearn: 0.6047552\ttest: 0.5986187\tbest: 0.5986187 (3304)\ttotal: 51.3s\tremaining: 26.2s\n",
      "3311:\tlearn: 0.6047476\ttest: 0.5986151\tbest: 0.5986151 (3311)\ttotal: 51.4s\tremaining: 26.2s\n",
      "3312:\tlearn: 0.6047334\ttest: 0.5986049\tbest: 0.5986049 (3312)\ttotal: 51.4s\tremaining: 26.2s\n",
      "3313:\tlearn: 0.6047334\ttest: 0.5986049\tbest: 0.5986049 (3312)\ttotal: 51.4s\tremaining: 26.2s\n",
      "3314:\tlearn: 0.6047202\ttest: 0.5985908\tbest: 0.5985908 (3314)\ttotal: 51.4s\tremaining: 26.2s\n",
      "3315:\tlearn: 0.6047202\ttest: 0.5985908\tbest: 0.5985908 (3314)\ttotal: 51.5s\tremaining: 26.1s\n",
      "3316:\tlearn: 0.6047202\ttest: 0.5985908\tbest: 0.5985908 (3314)\ttotal: 51.5s\tremaining: 26.1s\n",
      "3317:\tlearn: 0.6047187\ttest: 0.5985889\tbest: 0.5985889 (3317)\ttotal: 51.5s\tremaining: 26.1s\n",
      "3318:\tlearn: 0.6047187\ttest: 0.5985889\tbest: 0.5985889 (3317)\ttotal: 51.5s\tremaining: 26.1s\n",
      "3319:\tlearn: 0.6047187\ttest: 0.5985889\tbest: 0.5985889 (3317)\ttotal: 51.5s\tremaining: 26.1s\n",
      "3320:\tlearn: 0.6047163\ttest: 0.5985839\tbest: 0.5985839 (3320)\ttotal: 51.6s\tremaining: 26.1s\n",
      "3321:\tlearn: 0.6047163\ttest: 0.5985839\tbest: 0.5985839 (3320)\ttotal: 51.6s\tremaining: 26.1s\n",
      "3322:\tlearn: 0.6047163\ttest: 0.5985839\tbest: 0.5985839 (3320)\ttotal: 51.6s\tremaining: 26s\n",
      "3323:\tlearn: 0.6047163\ttest: 0.5985839\tbest: 0.5985839 (3320)\ttotal: 51.6s\tremaining: 26s\n",
      "3324:\tlearn: 0.6047163\ttest: 0.5985839\tbest: 0.5985839 (3320)\ttotal: 51.6s\tremaining: 26s\n",
      "3325:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.6s\tremaining: 26s\n",
      "3326:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.6s\tremaining: 26s\n",
      "3327:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.7s\tremaining: 26s\n",
      "3328:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.7s\tremaining: 25.9s\n",
      "3329:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.7s\tremaining: 25.9s\n",
      "3330:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.7s\tremaining: 25.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3331:\tlearn: 0.6046905\ttest: 0.5985589\tbest: 0.5985589 (3325)\ttotal: 51.7s\tremaining: 25.9s\n",
      "3332:\tlearn: 0.6046865\ttest: 0.5985583\tbest: 0.5985583 (3332)\ttotal: 51.7s\tremaining: 25.9s\n",
      "3333:\tlearn: 0.6046865\ttest: 0.5985583\tbest: 0.5985583 (3332)\ttotal: 51.8s\tremaining: 25.9s\n",
      "3334:\tlearn: 0.6046857\ttest: 0.5985572\tbest: 0.5985572 (3334)\ttotal: 51.8s\tremaining: 25.8s\n",
      "3335:\tlearn: 0.6046857\ttest: 0.5985572\tbest: 0.5985572 (3334)\ttotal: 51.8s\tremaining: 25.8s\n",
      "3336:\tlearn: 0.6046857\ttest: 0.5985572\tbest: 0.5985572 (3334)\ttotal: 51.8s\tremaining: 25.8s\n",
      "3337:\tlearn: 0.6046842\ttest: 0.5985578\tbest: 0.5985572 (3334)\ttotal: 51.8s\tremaining: 25.8s\n",
      "3338:\tlearn: 0.6046842\ttest: 0.5985578\tbest: 0.5985572 (3334)\ttotal: 51.8s\tremaining: 25.8s\n",
      "3339:\tlearn: 0.6046842\ttest: 0.5985578\tbest: 0.5985572 (3334)\ttotal: 51.8s\tremaining: 25.8s\n",
      "3340:\tlearn: 0.6046830\ttest: 0.5985581\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.8s\n",
      "3341:\tlearn: 0.6046830\ttest: 0.5985581\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.7s\n",
      "3342:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.7s\n",
      "3343:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.7s\n",
      "3344:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.7s\n",
      "3345:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.7s\n",
      "3346:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 51.9s\tremaining: 25.7s\n",
      "3347:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.6s\n",
      "3348:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.6s\n",
      "3349:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.6s\n",
      "3350:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.6s\n",
      "3351:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.6s\n",
      "3352:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.6s\n",
      "3353:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.5s\n",
      "3354:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52s\tremaining: 25.5s\n",
      "3355:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52.1s\tremaining: 25.5s\n",
      "3356:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52.1s\tremaining: 25.5s\n",
      "3357:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52.1s\tremaining: 25.5s\n",
      "3358:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52.1s\tremaining: 25.5s\n",
      "3359:\tlearn: 0.6046830\ttest: 0.5985583\tbest: 0.5985572 (3334)\ttotal: 52.1s\tremaining: 25.4s\n",
      "3360:\tlearn: 0.6046732\ttest: 0.5985499\tbest: 0.5985499 (3360)\ttotal: 52.2s\tremaining: 25.4s\n",
      "3361:\tlearn: 0.6046732\ttest: 0.5985499\tbest: 0.5985499 (3360)\ttotal: 52.2s\tremaining: 25.4s\n",
      "3362:\tlearn: 0.6046732\ttest: 0.5985499\tbest: 0.5985499 (3360)\ttotal: 52.2s\tremaining: 25.4s\n",
      "3363:\tlearn: 0.6046713\ttest: 0.5985482\tbest: 0.5985482 (3363)\ttotal: 52.2s\tremaining: 25.4s\n",
      "3364:\tlearn: 0.6046631\ttest: 0.5985389\tbest: 0.5985389 (3364)\ttotal: 52.2s\tremaining: 25.4s\n",
      "3365:\tlearn: 0.6046609\ttest: 0.5985355\tbest: 0.5985355 (3365)\ttotal: 52.2s\tremaining: 25.4s\n",
      "3366:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.3s\n",
      "3367:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.3s\n",
      "3368:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.3s\n",
      "3369:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.3s\n",
      "3370:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.3s\n",
      "3371:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.3s\n",
      "3372:\tlearn: 0.6046609\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.3s\tremaining: 25.2s\n",
      "3373:\tlearn: 0.6046608\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.4s\tremaining: 25.2s\n",
      "3374:\tlearn: 0.6046608\ttest: 0.5985356\tbest: 0.5985355 (3365)\ttotal: 52.4s\tremaining: 25.2s\n",
      "3375:\tlearn: 0.6046597\ttest: 0.5985333\tbest: 0.5985333 (3375)\ttotal: 52.4s\tremaining: 25.2s\n",
      "3376:\tlearn: 0.6046574\ttest: 0.5985321\tbest: 0.5985321 (3376)\ttotal: 52.4s\tremaining: 25.2s\n",
      "3377:\tlearn: 0.6046574\ttest: 0.5985321\tbest: 0.5985321 (3376)\ttotal: 52.4s\tremaining: 25.2s\n",
      "3378:\tlearn: 0.6046561\ttest: 0.5985310\tbest: 0.5985310 (3378)\ttotal: 52.4s\tremaining: 25.2s\n",
      "3379:\tlearn: 0.6046561\ttest: 0.5985310\tbest: 0.5985310 (3378)\ttotal: 52.4s\tremaining: 25.1s\n",
      "3380:\tlearn: 0.6046561\ttest: 0.5985310\tbest: 0.5985310 (3378)\ttotal: 52.5s\tremaining: 25.1s\n",
      "3381:\tlearn: 0.6046556\ttest: 0.5985303\tbest: 0.5985303 (3381)\ttotal: 52.5s\tremaining: 25.1s\n",
      "3382:\tlearn: 0.6046556\ttest: 0.5985303\tbest: 0.5985303 (3381)\ttotal: 52.5s\tremaining: 25.1s\n",
      "3383:\tlearn: 0.6046555\ttest: 0.5985303\tbest: 0.5985303 (3383)\ttotal: 52.5s\tremaining: 25.1s\n",
      "3384:\tlearn: 0.6046555\ttest: 0.5985303\tbest: 0.5985303 (3383)\ttotal: 52.5s\tremaining: 25.1s\n",
      "3385:\tlearn: 0.6046221\ttest: 0.5984932\tbest: 0.5984932 (3385)\ttotal: 52.5s\tremaining: 25s\n",
      "3386:\tlearn: 0.6046221\ttest: 0.5984932\tbest: 0.5984932 (3385)\ttotal: 52.5s\tremaining: 25s\n",
      "3387:\tlearn: 0.6046221\ttest: 0.5984932\tbest: 0.5984932 (3385)\ttotal: 52.6s\tremaining: 25s\n",
      "3388:\tlearn: 0.6046186\ttest: 0.5984905\tbest: 0.5984905 (3388)\ttotal: 52.6s\tremaining: 25s\n",
      "3389:\tlearn: 0.6046186\ttest: 0.5984905\tbest: 0.5984905 (3388)\ttotal: 52.6s\tremaining: 25s\n",
      "3390:\tlearn: 0.6046185\ttest: 0.5984906\tbest: 0.5984905 (3388)\ttotal: 52.6s\tremaining: 25s\n",
      "3391:\tlearn: 0.6046185\ttest: 0.5984906\tbest: 0.5984905 (3388)\ttotal: 52.7s\tremaining: 25s\n",
      "3392:\tlearn: 0.6046084\ttest: 0.5984830\tbest: 0.5984830 (3392)\ttotal: 52.7s\tremaining: 25s\n",
      "3393:\tlearn: 0.6046084\ttest: 0.5984830\tbest: 0.5984830 (3392)\ttotal: 52.7s\tremaining: 24.9s\n",
      "3394:\tlearn: 0.6046084\ttest: 0.5984830\tbest: 0.5984830 (3392)\ttotal: 52.7s\tremaining: 24.9s\n",
      "3395:\tlearn: 0.6046072\ttest: 0.5984807\tbest: 0.5984807 (3395)\ttotal: 52.7s\tremaining: 24.9s\n",
      "3396:\tlearn: 0.6046072\ttest: 0.5984807\tbest: 0.5984807 (3395)\ttotal: 52.8s\tremaining: 24.9s\n",
      "3397:\tlearn: 0.6046072\ttest: 0.5984807\tbest: 0.5984807 (3395)\ttotal: 52.8s\tremaining: 24.9s\n",
      "3398:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.8s\tremaining: 24.9s\n",
      "3399:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.8s\tremaining: 24.9s\n",
      "3400:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.8s\tremaining: 24.8s\n",
      "3401:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.8s\tremaining: 24.8s\n",
      "3402:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.8s\tremaining: 24.8s\n",
      "3403:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.9s\tremaining: 24.8s\n",
      "3404:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.9s\tremaining: 24.8s\n",
      "3405:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.9s\tremaining: 24.7s\n",
      "3406:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.9s\tremaining: 24.7s\n",
      "3407:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.9s\tremaining: 24.7s\n",
      "3408:\tlearn: 0.6046048\ttest: 0.5984782\tbest: 0.5984782 (3398)\ttotal: 52.9s\tremaining: 24.7s\n",
      "3409:\tlearn: 0.6046009\ttest: 0.5984752\tbest: 0.5984752 (3409)\ttotal: 52.9s\tremaining: 24.7s\n",
      "3410:\tlearn: 0.6046009\ttest: 0.5984752\tbest: 0.5984752 (3410)\ttotal: 53s\tremaining: 24.7s\n",
      "3411:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53s\tremaining: 24.7s\n",
      "3412:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53s\tremaining: 24.6s\n",
      "3413:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53s\tremaining: 24.6s\n",
      "3414:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53s\tremaining: 24.6s\n",
      "3415:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53s\tremaining: 24.6s\n",
      "3416:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53s\tremaining: 24.6s\n",
      "3417:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53.1s\tremaining: 24.6s\n",
      "3418:\tlearn: 0.6045975\ttest: 0.5984718\tbest: 0.5984718 (3411)\ttotal: 53.1s\tremaining: 24.5s\n",
      "3419:\tlearn: 0.6045975\ttest: 0.5984710\tbest: 0.5984710 (3419)\ttotal: 53.1s\tremaining: 24.5s\n",
      "3420:\tlearn: 0.6045975\ttest: 0.5984710\tbest: 0.5984710 (3419)\ttotal: 53.1s\tremaining: 24.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3421:\tlearn: 0.6045975\ttest: 0.5984710\tbest: 0.5984710 (3419)\ttotal: 53.1s\tremaining: 24.5s\n",
      "3422:\tlearn: 0.6045704\ttest: 0.5984403\tbest: 0.5984403 (3422)\ttotal: 53.1s\tremaining: 24.5s\n",
      "3423:\tlearn: 0.6045704\ttest: 0.5984403\tbest: 0.5984403 (3422)\ttotal: 53.2s\tremaining: 24.5s\n",
      "3424:\tlearn: 0.6045704\ttest: 0.5984403\tbest: 0.5984403 (3422)\ttotal: 53.2s\tremaining: 24.5s\n",
      "3425:\tlearn: 0.6045693\ttest: 0.5984386\tbest: 0.5984386 (3425)\ttotal: 53.2s\tremaining: 24.4s\n",
      "3426:\tlearn: 0.6045693\ttest: 0.5984386\tbest: 0.5984386 (3425)\ttotal: 53.2s\tremaining: 24.4s\n",
      "3427:\tlearn: 0.6045684\ttest: 0.5984386\tbest: 0.5984386 (3425)\ttotal: 53.2s\tremaining: 24.4s\n",
      "3428:\tlearn: 0.6045679\ttest: 0.5984386\tbest: 0.5984386 (3425)\ttotal: 53.3s\tremaining: 24.4s\n",
      "3429:\tlearn: 0.6045535\ttest: 0.5984242\tbest: 0.5984242 (3429)\ttotal: 53.3s\tremaining: 24.4s\n",
      "3430:\tlearn: 0.6045535\ttest: 0.5984242\tbest: 0.5984242 (3429)\ttotal: 53.3s\tremaining: 24.4s\n",
      "3431:\tlearn: 0.6045535\ttest: 0.5984242\tbest: 0.5984242 (3429)\ttotal: 53.3s\tremaining: 24.4s\n",
      "3432:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.3s\tremaining: 24.3s\n",
      "3433:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.4s\tremaining: 24.3s\n",
      "3434:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.4s\tremaining: 24.3s\n",
      "3435:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.4s\tremaining: 24.3s\n",
      "3436:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.4s\tremaining: 24.3s\n",
      "3437:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.4s\tremaining: 24.3s\n",
      "3438:\tlearn: 0.6045131\ttest: 0.5983800\tbest: 0.5983800 (3432)\ttotal: 53.4s\tremaining: 24.3s\n",
      "3439:\tlearn: 0.6045129\ttest: 0.5983792\tbest: 0.5983792 (3439)\ttotal: 53.4s\tremaining: 24.2s\n",
      "3440:\tlearn: 0.6045129\ttest: 0.5983792\tbest: 0.5983792 (3439)\ttotal: 53.5s\tremaining: 24.2s\n",
      "3441:\tlearn: 0.6045129\ttest: 0.5983792\tbest: 0.5983792 (3439)\ttotal: 53.5s\tremaining: 24.2s\n",
      "3442:\tlearn: 0.6045088\ttest: 0.5983769\tbest: 0.5983769 (3442)\ttotal: 53.5s\tremaining: 24.2s\n",
      "3443:\tlearn: 0.6045088\ttest: 0.5983769\tbest: 0.5983769 (3442)\ttotal: 53.5s\tremaining: 24.2s\n",
      "3444:\tlearn: 0.6045088\ttest: 0.5983769\tbest: 0.5983769 (3442)\ttotal: 53.5s\tremaining: 24.2s\n",
      "3445:\tlearn: 0.6044976\ttest: 0.5983650\tbest: 0.5983650 (3445)\ttotal: 53.5s\tremaining: 24.1s\n",
      "3446:\tlearn: 0.6044942\ttest: 0.5983628\tbest: 0.5983628 (3446)\ttotal: 53.6s\tremaining: 24.1s\n",
      "3447:\tlearn: 0.6044618\ttest: 0.5983234\tbest: 0.5983234 (3447)\ttotal: 53.6s\tremaining: 24.1s\n",
      "3448:\tlearn: 0.6044618\ttest: 0.5983234\tbest: 0.5983234 (3447)\ttotal: 53.6s\tremaining: 24.1s\n",
      "3449:\tlearn: 0.6044582\ttest: 0.5983206\tbest: 0.5983206 (3449)\ttotal: 53.6s\tremaining: 24.1s\n",
      "3450:\tlearn: 0.6044582\ttest: 0.5983206\tbest: 0.5983206 (3449)\ttotal: 53.6s\tremaining: 24.1s\n",
      "3451:\tlearn: 0.6044582\ttest: 0.5983206\tbest: 0.5983206 (3449)\ttotal: 53.6s\tremaining: 24.1s\n",
      "3452:\tlearn: 0.6044582\ttest: 0.5983206\tbest: 0.5983206 (3449)\ttotal: 53.7s\tremaining: 24s\n",
      "3453:\tlearn: 0.6044500\ttest: 0.5983114\tbest: 0.5983114 (3453)\ttotal: 53.7s\tremaining: 24s\n",
      "3454:\tlearn: 0.6044190\ttest: 0.5982809\tbest: 0.5982809 (3454)\ttotal: 53.7s\tremaining: 24s\n",
      "3455:\tlearn: 0.6044189\ttest: 0.5982809\tbest: 0.5982809 (3455)\ttotal: 53.7s\tremaining: 24s\n",
      "3456:\tlearn: 0.6044155\ttest: 0.5982753\tbest: 0.5982753 (3456)\ttotal: 53.8s\tremaining: 24s\n",
      "3457:\tlearn: 0.6044155\ttest: 0.5982753\tbest: 0.5982753 (3456)\ttotal: 53.8s\tremaining: 24s\n",
      "3458:\tlearn: 0.6044155\ttest: 0.5982753\tbest: 0.5982753 (3456)\ttotal: 53.8s\tremaining: 24s\n",
      "3459:\tlearn: 0.6044155\ttest: 0.5982753\tbest: 0.5982753 (3456)\ttotal: 53.8s\tremaining: 24s\n",
      "3460:\tlearn: 0.6044148\ttest: 0.5982742\tbest: 0.5982742 (3460)\ttotal: 53.8s\tremaining: 23.9s\n",
      "3461:\tlearn: 0.6044148\ttest: 0.5982742\tbest: 0.5982742 (3460)\ttotal: 53.8s\tremaining: 23.9s\n",
      "3462:\tlearn: 0.6044148\ttest: 0.5982742\tbest: 0.5982742 (3460)\ttotal: 53.9s\tremaining: 23.9s\n",
      "3463:\tlearn: 0.6044128\ttest: 0.5982694\tbest: 0.5982694 (3463)\ttotal: 53.9s\tremaining: 23.9s\n",
      "3464:\tlearn: 0.6044128\ttest: 0.5982694\tbest: 0.5982694 (3463)\ttotal: 53.9s\tremaining: 23.9s\n",
      "3465:\tlearn: 0.6044128\ttest: 0.5982694\tbest: 0.5982694 (3463)\ttotal: 53.9s\tremaining: 23.9s\n",
      "3466:\tlearn: 0.6043996\ttest: 0.5982545\tbest: 0.5982545 (3466)\ttotal: 53.9s\tremaining: 23.8s\n",
      "3467:\tlearn: 0.6043996\ttest: 0.5982545\tbest: 0.5982545 (3466)\ttotal: 53.9s\tremaining: 23.8s\n",
      "3468:\tlearn: 0.6043996\ttest: 0.5982545\tbest: 0.5982545 (3466)\ttotal: 54s\tremaining: 23.8s\n",
      "3469:\tlearn: 0.6043650\ttest: 0.5982267\tbest: 0.5982267 (3469)\ttotal: 54s\tremaining: 23.8s\n",
      "3470:\tlearn: 0.6043650\ttest: 0.5982267\tbest: 0.5982267 (3469)\ttotal: 54s\tremaining: 23.8s\n",
      "3471:\tlearn: 0.6043650\ttest: 0.5982267\tbest: 0.5982267 (3469)\ttotal: 54s\tremaining: 23.8s\n",
      "3472:\tlearn: 0.6043650\ttest: 0.5982267\tbest: 0.5982267 (3469)\ttotal: 54s\tremaining: 23.8s\n",
      "3473:\tlearn: 0.6043643\ttest: 0.5982252\tbest: 0.5982252 (3473)\ttotal: 54s\tremaining: 23.7s\n",
      "3474:\tlearn: 0.6043643\ttest: 0.5982252\tbest: 0.5982252 (3473)\ttotal: 54.1s\tremaining: 23.7s\n",
      "3475:\tlearn: 0.6043639\ttest: 0.5982245\tbest: 0.5982245 (3475)\ttotal: 54.1s\tremaining: 23.7s\n",
      "3476:\tlearn: 0.6043639\ttest: 0.5982245\tbest: 0.5982245 (3475)\ttotal: 54.1s\tremaining: 23.7s\n",
      "3477:\tlearn: 0.6043635\ttest: 0.5982245\tbest: 0.5982245 (3477)\ttotal: 54.1s\tremaining: 23.7s\n",
      "3478:\tlearn: 0.6043635\ttest: 0.5982245\tbest: 0.5982245 (3477)\ttotal: 54.1s\tremaining: 23.7s\n",
      "3479:\tlearn: 0.6043635\ttest: 0.5982245\tbest: 0.5982245 (3477)\ttotal: 54.1s\tremaining: 23.7s\n",
      "3480:\tlearn: 0.6043635\ttest: 0.5982245\tbest: 0.5982245 (3477)\ttotal: 54.2s\tremaining: 23.6s\n",
      "3481:\tlearn: 0.6043633\ttest: 0.5982242\tbest: 0.5982242 (3481)\ttotal: 54.2s\tremaining: 23.6s\n",
      "3482:\tlearn: 0.6043633\ttest: 0.5982242\tbest: 0.5982242 (3481)\ttotal: 54.2s\tremaining: 23.6s\n",
      "3483:\tlearn: 0.6043633\ttest: 0.5982242\tbest: 0.5982242 (3481)\ttotal: 54.2s\tremaining: 23.6s\n",
      "3484:\tlearn: 0.6043633\ttest: 0.5982242\tbest: 0.5982242 (3481)\ttotal: 54.2s\tremaining: 23.6s\n",
      "3485:\tlearn: 0.6043633\ttest: 0.5982242\tbest: 0.5982242 (3481)\ttotal: 54.3s\tremaining: 23.6s\n",
      "3486:\tlearn: 0.6043633\ttest: 0.5982242\tbest: 0.5982242 (3481)\ttotal: 54.3s\tremaining: 23.5s\n",
      "3487:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3487)\ttotal: 54.3s\tremaining: 23.5s\n",
      "3488:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3487)\ttotal: 54.3s\tremaining: 23.5s\n",
      "3489:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3487)\ttotal: 54.3s\tremaining: 23.5s\n",
      "3490:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3487)\ttotal: 54.3s\tremaining: 23.5s\n",
      "3491:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3487)\ttotal: 54.3s\tremaining: 23.5s\n",
      "3492:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3487)\ttotal: 54.4s\tremaining: 23.5s\n",
      "3493:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3493)\ttotal: 54.4s\tremaining: 23.4s\n",
      "3494:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3493)\ttotal: 54.4s\tremaining: 23.4s\n",
      "3495:\tlearn: 0.6043612\ttest: 0.5982234\tbest: 0.5982234 (3493)\ttotal: 54.4s\tremaining: 23.4s\n",
      "3496:\tlearn: 0.6043373\ttest: 0.5981928\tbest: 0.5981928 (3496)\ttotal: 54.4s\tremaining: 23.4s\n",
      "3497:\tlearn: 0.6043334\ttest: 0.5981887\tbest: 0.5981887 (3497)\ttotal: 54.5s\tremaining: 23.4s\n",
      "3498:\tlearn: 0.6043330\ttest: 0.5981883\tbest: 0.5981883 (3498)\ttotal: 54.5s\tremaining: 23.4s\n",
      "3499:\tlearn: 0.6043326\ttest: 0.5981883\tbest: 0.5981883 (3498)\ttotal: 54.5s\tremaining: 23.4s\n",
      "3500:\tlearn: 0.6043326\ttest: 0.5981883\tbest: 0.5981883 (3498)\ttotal: 54.5s\tremaining: 23.3s\n",
      "3501:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.5s\tremaining: 23.3s\n",
      "3502:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.5s\tremaining: 23.3s\n",
      "3503:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.3s\n",
      "3504:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.3s\n",
      "3505:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.3s\n",
      "3506:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.2s\n",
      "3507:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.2s\n",
      "3508:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.2s\n",
      "3509:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3501)\ttotal: 54.6s\tremaining: 23.2s\n",
      "3510:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3510)\ttotal: 54.6s\tremaining: 23.2s\n",
      "3511:\tlearn: 0.6043307\ttest: 0.5981863\tbest: 0.5981863 (3510)\ttotal: 54.7s\tremaining: 23.2s\n",
      "3512:\tlearn: 0.6043265\ttest: 0.5981839\tbest: 0.5981839 (3512)\ttotal: 54.7s\tremaining: 23.1s\n",
      "3513:\tlearn: 0.6042946\ttest: 0.5981515\tbest: 0.5981515 (3513)\ttotal: 54.7s\tremaining: 23.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3514:\tlearn: 0.6042946\ttest: 0.5981515\tbest: 0.5981515 (3513)\ttotal: 54.7s\tremaining: 23.1s\n",
      "3515:\tlearn: 0.6042929\ttest: 0.5981521\tbest: 0.5981515 (3513)\ttotal: 54.7s\tremaining: 23.1s\n",
      "3516:\tlearn: 0.6042910\ttest: 0.5981493\tbest: 0.5981493 (3516)\ttotal: 54.8s\tremaining: 23.1s\n",
      "3517:\tlearn: 0.6042910\ttest: 0.5981493\tbest: 0.5981493 (3516)\ttotal: 54.8s\tremaining: 23.1s\n",
      "3518:\tlearn: 0.6042910\ttest: 0.5981493\tbest: 0.5981493 (3516)\ttotal: 54.8s\tremaining: 23.1s\n",
      "3519:\tlearn: 0.6042909\ttest: 0.5981491\tbest: 0.5981491 (3519)\ttotal: 54.8s\tremaining: 23s\n",
      "3520:\tlearn: 0.6042909\ttest: 0.5981491\tbest: 0.5981491 (3519)\ttotal: 54.8s\tremaining: 23s\n",
      "3521:\tlearn: 0.6042744\ttest: 0.5981298\tbest: 0.5981298 (3521)\ttotal: 54.8s\tremaining: 23s\n",
      "3522:\tlearn: 0.6042744\ttest: 0.5981298\tbest: 0.5981298 (3521)\ttotal: 54.8s\tremaining: 23s\n",
      "3523:\tlearn: 0.6042697\ttest: 0.5981236\tbest: 0.5981236 (3523)\ttotal: 54.9s\tremaining: 23s\n",
      "3524:\tlearn: 0.6042697\ttest: 0.5981236\tbest: 0.5981236 (3523)\ttotal: 54.9s\tremaining: 23s\n",
      "3525:\tlearn: 0.6042697\ttest: 0.5981236\tbest: 0.5981236 (3523)\ttotal: 54.9s\tremaining: 22.9s\n",
      "3526:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 54.9s\tremaining: 22.9s\n",
      "3527:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 54.9s\tremaining: 22.9s\n",
      "3528:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.9s\n",
      "3529:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.9s\n",
      "3530:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.9s\n",
      "3531:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.9s\n",
      "3532:\tlearn: 0.6042365\ttest: 0.5981016\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.8s\n",
      "3533:\tlearn: 0.6042344\ttest: 0.5981018\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.8s\n",
      "3534:\tlearn: 0.6042344\ttest: 0.5981018\tbest: 0.5981016 (3526)\ttotal: 55s\tremaining: 22.8s\n",
      "3535:\tlearn: 0.6042344\ttest: 0.5981018\tbest: 0.5981016 (3526)\ttotal: 55.1s\tremaining: 22.8s\n",
      "3536:\tlearn: 0.6042344\ttest: 0.5981018\tbest: 0.5981016 (3526)\ttotal: 55.1s\tremaining: 22.8s\n",
      "3537:\tlearn: 0.6042344\ttest: 0.5981018\tbest: 0.5981016 (3526)\ttotal: 55.1s\tremaining: 22.8s\n",
      "3538:\tlearn: 0.6042344\ttest: 0.5981018\tbest: 0.5981016 (3526)\ttotal: 55.1s\tremaining: 22.7s\n",
      "3539:\tlearn: 0.6042342\ttest: 0.5981012\tbest: 0.5981012 (3539)\ttotal: 55.1s\tremaining: 22.7s\n",
      "3540:\tlearn: 0.6042342\ttest: 0.5981012\tbest: 0.5981012 (3539)\ttotal: 55.1s\tremaining: 22.7s\n",
      "3541:\tlearn: 0.6042322\ttest: 0.5980995\tbest: 0.5980995 (3541)\ttotal: 55.1s\tremaining: 22.7s\n",
      "3542:\tlearn: 0.6042317\ttest: 0.5980991\tbest: 0.5980991 (3542)\ttotal: 55.2s\tremaining: 22.7s\n",
      "3543:\tlearn: 0.6042294\ttest: 0.5980971\tbest: 0.5980971 (3543)\ttotal: 55.2s\tremaining: 22.7s\n",
      "3544:\tlearn: 0.6042275\ttest: 0.5980953\tbest: 0.5980953 (3544)\ttotal: 55.2s\tremaining: 22.7s\n",
      "3545:\tlearn: 0.6042275\ttest: 0.5980953\tbest: 0.5980953 (3544)\ttotal: 55.2s\tremaining: 22.6s\n",
      "3546:\tlearn: 0.6042275\ttest: 0.5980953\tbest: 0.5980953 (3544)\ttotal: 55.2s\tremaining: 22.6s\n",
      "3547:\tlearn: 0.6042275\ttest: 0.5980953\tbest: 0.5980953 (3544)\ttotal: 55.2s\tremaining: 22.6s\n",
      "3548:\tlearn: 0.6042275\ttest: 0.5980953\tbest: 0.5980953 (3544)\ttotal: 55.2s\tremaining: 22.6s\n",
      "3549:\tlearn: 0.6042275\ttest: 0.5980947\tbest: 0.5980947 (3549)\ttotal: 55.3s\tremaining: 22.6s\n",
      "3550:\tlearn: 0.6042275\ttest: 0.5980947\tbest: 0.5980947 (3549)\ttotal: 55.3s\tremaining: 22.6s\n",
      "3551:\tlearn: 0.6042275\ttest: 0.5980947\tbest: 0.5980947 (3549)\ttotal: 55.3s\tremaining: 22.5s\n",
      "3552:\tlearn: 0.6042275\ttest: 0.5980947\tbest: 0.5980947 (3549)\ttotal: 55.3s\tremaining: 22.5s\n",
      "3553:\tlearn: 0.6042275\ttest: 0.5980947\tbest: 0.5980947 (3549)\ttotal: 55.3s\tremaining: 22.5s\n",
      "3554:\tlearn: 0.6042247\ttest: 0.5980955\tbest: 0.5980947 (3549)\ttotal: 55.4s\tremaining: 22.5s\n",
      "3555:\tlearn: 0.6042228\ttest: 0.5980930\tbest: 0.5980930 (3555)\ttotal: 55.4s\tremaining: 22.5s\n",
      "3556:\tlearn: 0.6041912\ttest: 0.5980590\tbest: 0.5980590 (3556)\ttotal: 55.4s\tremaining: 22.5s\n",
      "3557:\tlearn: 0.6041907\ttest: 0.5980586\tbest: 0.5980586 (3557)\ttotal: 55.4s\tremaining: 22.5s\n",
      "3558:\tlearn: 0.6041907\ttest: 0.5980586\tbest: 0.5980586 (3558)\ttotal: 55.4s\tremaining: 22.4s\n",
      "3559:\tlearn: 0.6041907\ttest: 0.5980586\tbest: 0.5980586 (3559)\ttotal: 55.4s\tremaining: 22.4s\n",
      "3560:\tlearn: 0.6041907\ttest: 0.5980586\tbest: 0.5980586 (3560)\ttotal: 55.5s\tremaining: 22.4s\n",
      "3561:\tlearn: 0.6041907\ttest: 0.5980586\tbest: 0.5980586 (3561)\ttotal: 55.5s\tremaining: 22.4s\n",
      "3562:\tlearn: 0.6041907\ttest: 0.5980586\tbest: 0.5980586 (3562)\ttotal: 55.5s\tremaining: 22.4s\n",
      "3563:\tlearn: 0.6041900\ttest: 0.5980572\tbest: 0.5980572 (3563)\ttotal: 55.5s\tremaining: 22.4s\n",
      "3564:\tlearn: 0.6041877\ttest: 0.5980551\tbest: 0.5980551 (3564)\ttotal: 55.5s\tremaining: 22.3s\n",
      "3565:\tlearn: 0.6041877\ttest: 0.5980551\tbest: 0.5980551 (3565)\ttotal: 55.5s\tremaining: 22.3s\n",
      "3566:\tlearn: 0.6041877\ttest: 0.5980551\tbest: 0.5980551 (3566)\ttotal: 55.5s\tremaining: 22.3s\n",
      "3567:\tlearn: 0.6041877\ttest: 0.5980551\tbest: 0.5980551 (3567)\ttotal: 55.6s\tremaining: 22.3s\n",
      "3568:\tlearn: 0.6041877\ttest: 0.5980551\tbest: 0.5980551 (3568)\ttotal: 55.6s\tremaining: 22.3s\n",
      "3569:\tlearn: 0.6041630\ttest: 0.5980420\tbest: 0.5980420 (3569)\ttotal: 55.6s\tremaining: 22.3s\n",
      "3570:\tlearn: 0.6041630\ttest: 0.5980420\tbest: 0.5980420 (3570)\ttotal: 55.6s\tremaining: 22.3s\n",
      "3571:\tlearn: 0.6041630\ttest: 0.5980420\tbest: 0.5980420 (3571)\ttotal: 55.6s\tremaining: 22.2s\n",
      "3572:\tlearn: 0.6041630\ttest: 0.5980420\tbest: 0.5980420 (3572)\ttotal: 55.6s\tremaining: 22.2s\n",
      "3573:\tlearn: 0.6041507\ttest: 0.5980303\tbest: 0.5980303 (3573)\ttotal: 55.7s\tremaining: 22.2s\n",
      "3574:\tlearn: 0.6041507\ttest: 0.5980303\tbest: 0.5980303 (3573)\ttotal: 55.7s\tremaining: 22.2s\n",
      "3575:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.7s\tremaining: 22.2s\n",
      "3576:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.7s\tremaining: 22.2s\n",
      "3577:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.7s\tremaining: 22.1s\n",
      "3578:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.7s\tremaining: 22.1s\n",
      "3579:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.7s\tremaining: 22.1s\n",
      "3580:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.8s\tremaining: 22.1s\n",
      "3581:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.8s\tremaining: 22.1s\n",
      "3582:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.8s\tremaining: 22.1s\n",
      "3583:\tlearn: 0.6041479\ttest: 0.5980290\tbest: 0.5980290 (3575)\ttotal: 55.8s\tremaining: 22s\n",
      "3584:\tlearn: 0.6041066\ttest: 0.5979765\tbest: 0.5979765 (3584)\ttotal: 55.8s\tremaining: 22s\n",
      "3585:\tlearn: 0.6041066\ttest: 0.5979765\tbest: 0.5979765 (3585)\ttotal: 55.8s\tremaining: 22s\n",
      "3586:\tlearn: 0.6041066\ttest: 0.5979765\tbest: 0.5979765 (3586)\ttotal: 55.9s\tremaining: 22s\n",
      "3587:\tlearn: 0.6041065\ttest: 0.5979764\tbest: 0.5979764 (3587)\ttotal: 55.9s\tremaining: 22s\n",
      "3588:\tlearn: 0.6041065\ttest: 0.5979764\tbest: 0.5979764 (3588)\ttotal: 55.9s\tremaining: 22s\n",
      "3589:\tlearn: 0.6041065\ttest: 0.5979764\tbest: 0.5979764 (3589)\ttotal: 55.9s\tremaining: 22s\n",
      "3590:\tlearn: 0.6041065\ttest: 0.5979764\tbest: 0.5979764 (3590)\ttotal: 55.9s\tremaining: 21.9s\n",
      "3591:\tlearn: 0.6041049\ttest: 0.5979765\tbest: 0.5979764 (3590)\ttotal: 55.9s\tremaining: 21.9s\n",
      "3592:\tlearn: 0.6041049\ttest: 0.5979765\tbest: 0.5979764 (3590)\ttotal: 56s\tremaining: 21.9s\n",
      "3593:\tlearn: 0.6041049\ttest: 0.5979765\tbest: 0.5979764 (3590)\ttotal: 56s\tremaining: 21.9s\n",
      "3594:\tlearn: 0.6041039\ttest: 0.5979758\tbest: 0.5979758 (3594)\ttotal: 56s\tremaining: 21.9s\n",
      "3595:\tlearn: 0.6041039\ttest: 0.5979758\tbest: 0.5979758 (3595)\ttotal: 56s\tremaining: 21.9s\n",
      "3596:\tlearn: 0.6041039\ttest: 0.5979758\tbest: 0.5979758 (3596)\ttotal: 56s\tremaining: 21.9s\n",
      "3597:\tlearn: 0.6041039\ttest: 0.5979758\tbest: 0.5979758 (3597)\ttotal: 56s\tremaining: 21.8s\n",
      "3598:\tlearn: 0.6041039\ttest: 0.5979758\tbest: 0.5979758 (3598)\ttotal: 56.1s\tremaining: 21.8s\n",
      "3599:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3599)\ttotal: 56.1s\tremaining: 21.8s\n",
      "3600:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3600)\ttotal: 56.1s\tremaining: 21.8s\n",
      "3601:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3601)\ttotal: 56.1s\tremaining: 21.8s\n",
      "3602:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3602)\ttotal: 56.1s\tremaining: 21.8s\n",
      "3603:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3603)\ttotal: 56.2s\tremaining: 21.8s\n",
      "3604:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3604)\ttotal: 56.2s\tremaining: 21.7s\n",
      "3605:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3605)\ttotal: 56.2s\tremaining: 21.7s\n",
      "3606:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3606)\ttotal: 56.2s\tremaining: 21.7s\n",
      "3607:\tlearn: 0.6041013\ttest: 0.5979702\tbest: 0.5979702 (3607)\ttotal: 56.2s\tremaining: 21.7s\n",
      "3608:\tlearn: 0.6041008\ttest: 0.5979698\tbest: 0.5979698 (3608)\ttotal: 56.2s\tremaining: 21.7s\n",
      "3609:\tlearn: 0.6041008\ttest: 0.5979698\tbest: 0.5979698 (3609)\ttotal: 56.3s\tremaining: 21.7s\n",
      "3610:\tlearn: 0.6041008\ttest: 0.5979698\tbest: 0.5979698 (3610)\ttotal: 56.3s\tremaining: 21.6s\n",
      "3611:\tlearn: 0.6041008\ttest: 0.5979698\tbest: 0.5979698 (3611)\ttotal: 56.3s\tremaining: 21.6s\n",
      "3612:\tlearn: 0.6041008\ttest: 0.5979698\tbest: 0.5979698 (3612)\ttotal: 56.3s\tremaining: 21.6s\n",
      "3613:\tlearn: 0.6041007\ttest: 0.5979693\tbest: 0.5979693 (3613)\ttotal: 56.3s\tremaining: 21.6s\n",
      "3614:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3614)\ttotal: 56.3s\tremaining: 21.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3615:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3615)\ttotal: 56.3s\tremaining: 21.6s\n",
      "3616:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3616)\ttotal: 56.4s\tremaining: 21.5s\n",
      "3617:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3617)\ttotal: 56.4s\tremaining: 21.5s\n",
      "3618:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3618)\ttotal: 56.4s\tremaining: 21.5s\n",
      "3619:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3619)\ttotal: 56.4s\tremaining: 21.5s\n",
      "3620:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3620)\ttotal: 56.4s\tremaining: 21.5s\n",
      "3621:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3621)\ttotal: 56.4s\tremaining: 21.5s\n",
      "3622:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3622)\ttotal: 56.4s\tremaining: 21.4s\n",
      "3623:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3623)\ttotal: 56.4s\tremaining: 21.4s\n",
      "3624:\tlearn: 0.6040987\ttest: 0.5979673\tbest: 0.5979673 (3624)\ttotal: 56.5s\tremaining: 21.4s\n",
      "3625:\tlearn: 0.6040987\ttest: 0.5979674\tbest: 0.5979673 (3624)\ttotal: 56.5s\tremaining: 21.4s\n",
      "3626:\tlearn: 0.6040987\ttest: 0.5979674\tbest: 0.5979673 (3624)\ttotal: 56.5s\tremaining: 21.4s\n",
      "3627:\tlearn: 0.6040987\ttest: 0.5979674\tbest: 0.5979673 (3624)\ttotal: 56.5s\tremaining: 21.4s\n",
      "3628:\tlearn: 0.6040987\ttest: 0.5979674\tbest: 0.5979673 (3624)\ttotal: 56.5s\tremaining: 21.4s\n",
      "3629:\tlearn: 0.6040987\ttest: 0.5979674\tbest: 0.5979673 (3624)\ttotal: 56.5s\tremaining: 21.3s\n",
      "3630:\tlearn: 0.6040967\ttest: 0.5979642\tbest: 0.5979642 (3630)\ttotal: 56.6s\tremaining: 21.3s\n",
      "3631:\tlearn: 0.6040967\ttest: 0.5979642\tbest: 0.5979642 (3631)\ttotal: 56.6s\tremaining: 21.3s\n",
      "3632:\tlearn: 0.6040967\ttest: 0.5979642\tbest: 0.5979642 (3632)\ttotal: 56.6s\tremaining: 21.3s\n",
      "3633:\tlearn: 0.6040957\ttest: 0.5979642\tbest: 0.5979642 (3633)\ttotal: 56.6s\tremaining: 21.3s\n",
      "3634:\tlearn: 0.6040957\ttest: 0.5979642\tbest: 0.5979642 (3634)\ttotal: 56.6s\tremaining: 21.3s\n",
      "3635:\tlearn: 0.6040957\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.6s\tremaining: 21.2s\n",
      "3636:\tlearn: 0.6040955\ttest: 0.5979643\tbest: 0.5979642 (3635)\ttotal: 56.6s\tremaining: 21.2s\n",
      "3637:\tlearn: 0.6040955\ttest: 0.5979643\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.2s\n",
      "3638:\tlearn: 0.6040955\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.2s\n",
      "3639:\tlearn: 0.6040955\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.2s\n",
      "3640:\tlearn: 0.6040955\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.2s\n",
      "3641:\tlearn: 0.6040955\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.1s\n",
      "3642:\tlearn: 0.6040955\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.1s\n",
      "3643:\tlearn: 0.6040955\ttest: 0.5979642\tbest: 0.5979642 (3635)\ttotal: 56.7s\tremaining: 21.1s\n",
      "3644:\tlearn: 0.6040954\ttest: 0.5979632\tbest: 0.5979632 (3644)\ttotal: 56.7s\tremaining: 21.1s\n",
      "3645:\tlearn: 0.6040954\ttest: 0.5979632\tbest: 0.5979632 (3645)\ttotal: 56.8s\tremaining: 21.1s\n",
      "3646:\tlearn: 0.6040954\ttest: 0.5979632\tbest: 0.5979632 (3646)\ttotal: 56.8s\tremaining: 21.1s\n",
      "3647:\tlearn: 0.6040951\ttest: 0.5979626\tbest: 0.5979626 (3647)\ttotal: 56.8s\tremaining: 21s\n",
      "3648:\tlearn: 0.6040951\ttest: 0.5979626\tbest: 0.5979626 (3648)\ttotal: 56.8s\tremaining: 21s\n",
      "3649:\tlearn: 0.6040951\ttest: 0.5979626\tbest: 0.5979626 (3649)\ttotal: 56.8s\tremaining: 21s\n",
      "3650:\tlearn: 0.6040950\ttest: 0.5979626\tbest: 0.5979626 (3649)\ttotal: 56.8s\tremaining: 21s\n",
      "3651:\tlearn: 0.6040950\ttest: 0.5979626\tbest: 0.5979626 (3649)\ttotal: 56.8s\tremaining: 21s\n",
      "3652:\tlearn: 0.6040950\ttest: 0.5979626\tbest: 0.5979626 (3649)\ttotal: 56.9s\tremaining: 21s\n",
      "3653:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3653)\ttotal: 56.9s\tremaining: 20.9s\n",
      "3654:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 56.9s\tremaining: 20.9s\n",
      "3655:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 56.9s\tremaining: 20.9s\n",
      "3656:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 56.9s\tremaining: 20.9s\n",
      "3657:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 56.9s\tremaining: 20.9s\n",
      "3658:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 56.9s\tremaining: 20.9s\n",
      "3659:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 57s\tremaining: 20.9s\n",
      "3660:\tlearn: 0.6040934\ttest: 0.5979616\tbest: 0.5979616 (3654)\ttotal: 57s\tremaining: 20.8s\n",
      "3661:\tlearn: 0.6040902\ttest: 0.5979570\tbest: 0.5979570 (3661)\ttotal: 57s\tremaining: 20.8s\n",
      "3662:\tlearn: 0.6040902\ttest: 0.5979570\tbest: 0.5979570 (3662)\ttotal: 57s\tremaining: 20.8s\n",
      "3663:\tlearn: 0.6040902\ttest: 0.5979570\tbest: 0.5979570 (3663)\ttotal: 57s\tremaining: 20.8s\n",
      "3664:\tlearn: 0.6040902\ttest: 0.5979570\tbest: 0.5979570 (3664)\ttotal: 57s\tremaining: 20.8s\n",
      "3665:\tlearn: 0.6040902\ttest: 0.5979567\tbest: 0.5979567 (3665)\ttotal: 57.1s\tremaining: 20.8s\n",
      "3666:\tlearn: 0.6040902\ttest: 0.5979567\tbest: 0.5979567 (3666)\ttotal: 57.1s\tremaining: 20.7s\n",
      "3667:\tlearn: 0.6040901\ttest: 0.5979568\tbest: 0.5979567 (3666)\ttotal: 57.1s\tremaining: 20.7s\n",
      "3668:\tlearn: 0.6040901\ttest: 0.5979568\tbest: 0.5979567 (3666)\ttotal: 57.1s\tremaining: 20.7s\n",
      "3669:\tlearn: 0.6040901\ttest: 0.5979570\tbest: 0.5979567 (3666)\ttotal: 57.1s\tremaining: 20.7s\n",
      "3670:\tlearn: 0.6040901\ttest: 0.5979570\tbest: 0.5979567 (3666)\ttotal: 57.1s\tremaining: 20.7s\n",
      "3671:\tlearn: 0.6040901\ttest: 0.5979570\tbest: 0.5979567 (3666)\ttotal: 57.2s\tremaining: 20.7s\n",
      "3672:\tlearn: 0.6040901\ttest: 0.5979570\tbest: 0.5979567 (3666)\ttotal: 57.2s\tremaining: 20.7s\n",
      "3673:\tlearn: 0.6040878\ttest: 0.5979530\tbest: 0.5979530 (3673)\ttotal: 57.2s\tremaining: 20.6s\n",
      "3674:\tlearn: 0.6040878\ttest: 0.5979530\tbest: 0.5979530 (3673)\ttotal: 57.2s\tremaining: 20.6s\n",
      "3675:\tlearn: 0.6040853\ttest: 0.5979507\tbest: 0.5979507 (3675)\ttotal: 57.2s\tremaining: 20.6s\n",
      "3676:\tlearn: 0.6040853\ttest: 0.5979507\tbest: 0.5979507 (3675)\ttotal: 57.3s\tremaining: 20.6s\n",
      "3677:\tlearn: 0.6040788\ttest: 0.5979463\tbest: 0.5979463 (3677)\ttotal: 57.3s\tremaining: 20.6s\n",
      "3678:\tlearn: 0.6040788\ttest: 0.5979463\tbest: 0.5979463 (3677)\ttotal: 57.3s\tremaining: 20.6s\n",
      "3679:\tlearn: 0.6040788\ttest: 0.5979463\tbest: 0.5979463 (3677)\ttotal: 57.3s\tremaining: 20.6s\n",
      "3680:\tlearn: 0.6040788\ttest: 0.5979463\tbest: 0.5979463 (3677)\ttotal: 57.3s\tremaining: 20.5s\n",
      "3681:\tlearn: 0.6040788\ttest: 0.5979462\tbest: 0.5979462 (3681)\ttotal: 57.3s\tremaining: 20.5s\n",
      "3682:\tlearn: 0.6040788\ttest: 0.5979462\tbest: 0.5979462 (3681)\ttotal: 57.3s\tremaining: 20.5s\n",
      "3683:\tlearn: 0.6040788\ttest: 0.5979462\tbest: 0.5979462 (3681)\ttotal: 57.4s\tremaining: 20.5s\n",
      "3684:\tlearn: 0.6040788\ttest: 0.5979462\tbest: 0.5979462 (3681)\ttotal: 57.4s\tremaining: 20.5s\n",
      "3685:\tlearn: 0.6040788\ttest: 0.5979462\tbest: 0.5979462 (3681)\ttotal: 57.4s\tremaining: 20.5s\n",
      "3686:\tlearn: 0.6040718\ttest: 0.5979366\tbest: 0.5979366 (3686)\ttotal: 57.4s\tremaining: 20.4s\n",
      "3687:\tlearn: 0.6040718\ttest: 0.5979366\tbest: 0.5979366 (3686)\ttotal: 57.4s\tremaining: 20.4s\n",
      "3688:\tlearn: 0.6040718\ttest: 0.5979366\tbest: 0.5979366 (3686)\ttotal: 57.4s\tremaining: 20.4s\n",
      "3689:\tlearn: 0.6040713\ttest: 0.5979362\tbest: 0.5979362 (3689)\ttotal: 57.5s\tremaining: 20.4s\n",
      "3690:\tlearn: 0.6040713\ttest: 0.5979362\tbest: 0.5979362 (3689)\ttotal: 57.5s\tremaining: 20.4s\n",
      "3691:\tlearn: 0.6040713\ttest: 0.5979362\tbest: 0.5979362 (3689)\ttotal: 57.5s\tremaining: 20.4s\n",
      "3692:\tlearn: 0.6040713\ttest: 0.5979362\tbest: 0.5979362 (3689)\ttotal: 57.5s\tremaining: 20.3s\n",
      "3693:\tlearn: 0.6040713\ttest: 0.5979362\tbest: 0.5979362 (3689)\ttotal: 57.5s\tremaining: 20.3s\n",
      "3694:\tlearn: 0.6040702\ttest: 0.5979360\tbest: 0.5979360 (3694)\ttotal: 57.5s\tremaining: 20.3s\n",
      "3695:\tlearn: 0.6040702\ttest: 0.5979360\tbest: 0.5979360 (3694)\ttotal: 57.5s\tremaining: 20.3s\n",
      "3696:\tlearn: 0.6040702\ttest: 0.5979360\tbest: 0.5979360 (3694)\ttotal: 57.5s\tremaining: 20.3s\n",
      "3697:\tlearn: 0.6040701\ttest: 0.5979361\tbest: 0.5979360 (3694)\ttotal: 57.6s\tremaining: 20.3s\n",
      "3698:\tlearn: 0.6040701\ttest: 0.5979361\tbest: 0.5979360 (3694)\ttotal: 57.6s\tremaining: 20.3s\n",
      "3699:\tlearn: 0.6040701\ttest: 0.5979361\tbest: 0.5979360 (3694)\ttotal: 57.6s\tremaining: 20.2s\n",
      "3700:\tlearn: 0.6040701\ttest: 0.5979361\tbest: 0.5979360 (3694)\ttotal: 57.6s\tremaining: 20.2s\n",
      "3701:\tlearn: 0.6040701\ttest: 0.5979361\tbest: 0.5979360 (3694)\ttotal: 57.6s\tremaining: 20.2s\n",
      "3702:\tlearn: 0.6040685\ttest: 0.5979358\tbest: 0.5979358 (3702)\ttotal: 57.6s\tremaining: 20.2s\n",
      "3703:\tlearn: 0.6040666\ttest: 0.5979325\tbest: 0.5979325 (3703)\ttotal: 57.6s\tremaining: 20.2s\n",
      "3704:\tlearn: 0.6040666\ttest: 0.5979325\tbest: 0.5979325 (3703)\ttotal: 57.7s\tremaining: 20.2s\n",
      "3705:\tlearn: 0.6040660\ttest: 0.5979324\tbest: 0.5979324 (3705)\ttotal: 57.7s\tremaining: 20.1s\n",
      "3706:\tlearn: 0.6040650\ttest: 0.5979309\tbest: 0.5979309 (3706)\ttotal: 57.7s\tremaining: 20.1s\n",
      "3707:\tlearn: 0.6040650\ttest: 0.5979309\tbest: 0.5979309 (3706)\ttotal: 57.7s\tremaining: 20.1s\n",
      "3708:\tlearn: 0.6040568\ttest: 0.5979222\tbest: 0.5979222 (3708)\ttotal: 57.7s\tremaining: 20.1s\n",
      "3709:\tlearn: 0.6040568\ttest: 0.5979222\tbest: 0.5979222 (3708)\ttotal: 57.7s\tremaining: 20.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3710:\tlearn: 0.6040568\ttest: 0.5979222\tbest: 0.5979222 (3708)\ttotal: 57.7s\tremaining: 20.1s\n",
      "3711:\tlearn: 0.6040568\ttest: 0.5979222\tbest: 0.5979222 (3708)\ttotal: 57.8s\tremaining: 20s\n",
      "3712:\tlearn: 0.6040568\ttest: 0.5979222\tbest: 0.5979222 (3708)\ttotal: 57.8s\tremaining: 20s\n",
      "3713:\tlearn: 0.6040568\ttest: 0.5979222\tbest: 0.5979222 (3708)\ttotal: 57.8s\tremaining: 20s\n",
      "3714:\tlearn: 0.6040564\ttest: 0.5979219\tbest: 0.5979219 (3714)\ttotal: 57.8s\tremaining: 20s\n",
      "3715:\tlearn: 0.6040564\ttest: 0.5979219\tbest: 0.5979219 (3714)\ttotal: 57.8s\tremaining: 20s\n",
      "3716:\tlearn: 0.6040564\ttest: 0.5979219\tbest: 0.5979219 (3714)\ttotal: 57.8s\tremaining: 20s\n",
      "3717:\tlearn: 0.6040237\ttest: 0.5978857\tbest: 0.5978857 (3717)\ttotal: 57.8s\tremaining: 19.9s\n",
      "3718:\tlearn: 0.6040237\ttest: 0.5978857\tbest: 0.5978857 (3718)\ttotal: 57.9s\tremaining: 19.9s\n",
      "3719:\tlearn: 0.6040237\ttest: 0.5978857\tbest: 0.5978857 (3719)\ttotal: 57.9s\tremaining: 19.9s\n",
      "3720:\tlearn: 0.6040237\ttest: 0.5978857\tbest: 0.5978857 (3720)\ttotal: 57.9s\tremaining: 19.9s\n",
      "3721:\tlearn: 0.6040225\ttest: 0.5978863\tbest: 0.5978857 (3720)\ttotal: 57.9s\tremaining: 19.9s\n",
      "3722:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3722)\ttotal: 57.9s\tremaining: 19.9s\n",
      "3723:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3723)\ttotal: 57.9s\tremaining: 19.8s\n",
      "3724:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3724)\ttotal: 57.9s\tremaining: 19.8s\n",
      "3725:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3725)\ttotal: 58s\tremaining: 19.8s\n",
      "3726:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3726)\ttotal: 58s\tremaining: 19.8s\n",
      "3727:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3727)\ttotal: 58s\tremaining: 19.8s\n",
      "3728:\tlearn: 0.6040210\ttest: 0.5978847\tbest: 0.5978847 (3728)\ttotal: 58s\tremaining: 19.8s\n",
      "3729:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3729)\ttotal: 58s\tremaining: 19.8s\n",
      "3730:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3730)\ttotal: 58s\tremaining: 19.7s\n",
      "3731:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3731)\ttotal: 58s\tremaining: 19.7s\n",
      "3732:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3731)\ttotal: 58s\tremaining: 19.7s\n",
      "3733:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3733)\ttotal: 58.1s\tremaining: 19.7s\n",
      "3734:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3734)\ttotal: 58.1s\tremaining: 19.7s\n",
      "3735:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3735)\ttotal: 58.1s\tremaining: 19.7s\n",
      "3736:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3736)\ttotal: 58.1s\tremaining: 19.6s\n",
      "3737:\tlearn: 0.6040210\ttest: 0.5978846\tbest: 0.5978846 (3737)\ttotal: 58.1s\tremaining: 19.6s\n",
      "3738:\tlearn: 0.6040175\ttest: 0.5978802\tbest: 0.5978802 (3738)\ttotal: 58.1s\tremaining: 19.6s\n",
      "3739:\tlearn: 0.6040175\ttest: 0.5978802\tbest: 0.5978802 (3739)\ttotal: 58.1s\tremaining: 19.6s\n",
      "3740:\tlearn: 0.6040171\ttest: 0.5978796\tbest: 0.5978796 (3740)\ttotal: 58.2s\tremaining: 19.6s\n",
      "3741:\tlearn: 0.6040132\ttest: 0.5978774\tbest: 0.5978774 (3741)\ttotal: 58.2s\tremaining: 19.6s\n",
      "3742:\tlearn: 0.6040132\ttest: 0.5978774\tbest: 0.5978774 (3742)\ttotal: 58.2s\tremaining: 19.5s\n",
      "3743:\tlearn: 0.6040108\ttest: 0.5978737\tbest: 0.5978737 (3743)\ttotal: 58.2s\tremaining: 19.5s\n",
      "3744:\tlearn: 0.6040108\ttest: 0.5978737\tbest: 0.5978737 (3744)\ttotal: 58.2s\tremaining: 19.5s\n",
      "3745:\tlearn: 0.6040108\ttest: 0.5978737\tbest: 0.5978737 (3745)\ttotal: 58.2s\tremaining: 19.5s\n",
      "3746:\tlearn: 0.6040108\ttest: 0.5978737\tbest: 0.5978737 (3746)\ttotal: 58.3s\tremaining: 19.5s\n",
      "3747:\tlearn: 0.6040068\ttest: 0.5978703\tbest: 0.5978703 (3747)\ttotal: 58.3s\tremaining: 19.5s\n",
      "3748:\tlearn: 0.6040068\ttest: 0.5978703\tbest: 0.5978703 (3748)\ttotal: 58.3s\tremaining: 19.4s\n",
      "3749:\tlearn: 0.6040068\ttest: 0.5978703\tbest: 0.5978703 (3749)\ttotal: 58.3s\tremaining: 19.4s\n",
      "3750:\tlearn: 0.6040068\ttest: 0.5978703\tbest: 0.5978703 (3750)\ttotal: 58.3s\tremaining: 19.4s\n",
      "3751:\tlearn: 0.6040068\ttest: 0.5978703\tbest: 0.5978703 (3751)\ttotal: 58.3s\tremaining: 19.4s\n",
      "3752:\tlearn: 0.6040020\ttest: 0.5978638\tbest: 0.5978638 (3752)\ttotal: 58.4s\tremaining: 19.4s\n",
      "3753:\tlearn: 0.6040020\ttest: 0.5978638\tbest: 0.5978638 (3753)\ttotal: 58.4s\tremaining: 19.4s\n",
      "3754:\tlearn: 0.6040020\ttest: 0.5978638\tbest: 0.5978638 (3754)\ttotal: 58.4s\tremaining: 19.4s\n",
      "3755:\tlearn: 0.6040020\ttest: 0.5978638\tbest: 0.5978638 (3755)\ttotal: 58.4s\tremaining: 19.3s\n",
      "3756:\tlearn: 0.6040020\ttest: 0.5978638\tbest: 0.5978638 (3756)\ttotal: 58.4s\tremaining: 19.3s\n",
      "3757:\tlearn: 0.6040020\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.4s\tremaining: 19.3s\n",
      "3758:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.4s\tremaining: 19.3s\n",
      "3759:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.3s\n",
      "3760:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.3s\n",
      "3761:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.2s\n",
      "3762:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.2s\n",
      "3763:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.2s\n",
      "3764:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.2s\n",
      "3765:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.2s\n",
      "3766:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.2s\n",
      "3767:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.5s\tremaining: 19.1s\n",
      "3768:\tlearn: 0.6040016\ttest: 0.5978638\tbest: 0.5978638 (3757)\ttotal: 58.6s\tremaining: 19.1s\n",
      "3769:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3769)\ttotal: 58.6s\tremaining: 19.1s\n",
      "3770:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3770)\ttotal: 58.6s\tremaining: 19.1s\n",
      "3771:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3771)\ttotal: 58.6s\tremaining: 19.1s\n",
      "3772:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3772)\ttotal: 58.6s\tremaining: 19.1s\n",
      "3773:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3773)\ttotal: 58.6s\tremaining: 19s\n",
      "3774:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3774)\ttotal: 58.6s\tremaining: 19s\n",
      "3775:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3775)\ttotal: 58.7s\tremaining: 19s\n",
      "3776:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3776)\ttotal: 58.7s\tremaining: 19s\n",
      "3777:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3777)\ttotal: 58.7s\tremaining: 19s\n",
      "3778:\tlearn: 0.6040014\ttest: 0.5978633\tbest: 0.5978633 (3778)\ttotal: 58.7s\tremaining: 19s\n",
      "3779:\tlearn: 0.6040012\ttest: 0.5978627\tbest: 0.5978627 (3779)\ttotal: 58.7s\tremaining: 18.9s\n",
      "3780:\tlearn: 0.6040005\ttest: 0.5978617\tbest: 0.5978617 (3780)\ttotal: 58.7s\tremaining: 18.9s\n",
      "3781:\tlearn: 0.6039990\ttest: 0.5978606\tbest: 0.5978606 (3781)\ttotal: 58.7s\tremaining: 18.9s\n",
      "3782:\tlearn: 0.6039990\ttest: 0.5978606\tbest: 0.5978606 (3782)\ttotal: 58.8s\tremaining: 18.9s\n",
      "3783:\tlearn: 0.6039990\ttest: 0.5978606\tbest: 0.5978606 (3783)\ttotal: 58.8s\tremaining: 18.9s\n",
      "3784:\tlearn: 0.6039990\ttest: 0.5978606\tbest: 0.5978606 (3784)\ttotal: 58.8s\tremaining: 18.9s\n",
      "3785:\tlearn: 0.6039929\ttest: 0.5978515\tbest: 0.5978515 (3785)\ttotal: 58.8s\tremaining: 18.9s\n",
      "3786:\tlearn: 0.6039929\ttest: 0.5978515\tbest: 0.5978515 (3786)\ttotal: 58.8s\tremaining: 18.8s\n",
      "3787:\tlearn: 0.6039929\ttest: 0.5978515\tbest: 0.5978515 (3787)\ttotal: 58.8s\tremaining: 18.8s\n",
      "3788:\tlearn: 0.6039929\ttest: 0.5978515\tbest: 0.5978515 (3788)\ttotal: 58.8s\tremaining: 18.8s\n",
      "3789:\tlearn: 0.6039913\ttest: 0.5978500\tbest: 0.5978500 (3789)\ttotal: 58.9s\tremaining: 18.8s\n",
      "3790:\tlearn: 0.6039913\ttest: 0.5978500\tbest: 0.5978500 (3789)\ttotal: 58.9s\tremaining: 18.8s\n",
      "3791:\tlearn: 0.6039894\ttest: 0.5978485\tbest: 0.5978485 (3791)\ttotal: 58.9s\tremaining: 18.8s\n",
      "3792:\tlearn: 0.6039894\ttest: 0.5978485\tbest: 0.5978485 (3791)\ttotal: 58.9s\tremaining: 18.7s\n",
      "3793:\tlearn: 0.6039894\ttest: 0.5978485\tbest: 0.5978485 (3791)\ttotal: 58.9s\tremaining: 18.7s\n",
      "3794:\tlearn: 0.6039894\ttest: 0.5978485\tbest: 0.5978485 (3791)\ttotal: 58.9s\tremaining: 18.7s\n",
      "3795:\tlearn: 0.6039894\ttest: 0.5978485\tbest: 0.5978485 (3791)\ttotal: 58.9s\tremaining: 18.7s\n",
      "3796:\tlearn: 0.6039878\ttest: 0.5978476\tbest: 0.5978476 (3796)\ttotal: 59s\tremaining: 18.7s\n",
      "3797:\tlearn: 0.6039878\ttest: 0.5978476\tbest: 0.5978476 (3796)\ttotal: 59s\tremaining: 18.7s\n",
      "3798:\tlearn: 0.6039878\ttest: 0.5978476\tbest: 0.5978476 (3796)\ttotal: 59s\tremaining: 18.6s\n",
      "3799:\tlearn: 0.6039878\ttest: 0.5978476\tbest: 0.5978476 (3796)\ttotal: 59s\tremaining: 18.6s\n",
      "3800:\tlearn: 0.6039878\ttest: 0.5978476\tbest: 0.5978476 (3796)\ttotal: 59s\tremaining: 18.6s\n",
      "3801:\tlearn: 0.6039037\ttest: 0.5977604\tbest: 0.5977604 (3801)\ttotal: 59.1s\tremaining: 18.6s\n",
      "3802:\tlearn: 0.6039037\ttest: 0.5977605\tbest: 0.5977604 (3801)\ttotal: 59.1s\tremaining: 18.6s\n",
      "3803:\tlearn: 0.6039036\ttest: 0.5977601\tbest: 0.5977601 (3803)\ttotal: 59.1s\tremaining: 18.6s\n",
      "3804:\tlearn: 0.6039029\ttest: 0.5977588\tbest: 0.5977588 (3804)\ttotal: 59.1s\tremaining: 18.6s\n",
      "3805:\tlearn: 0.6039029\ttest: 0.5977588\tbest: 0.5977588 (3805)\ttotal: 59.1s\tremaining: 18.5s\n",
      "3806:\tlearn: 0.6039029\ttest: 0.5977588\tbest: 0.5977588 (3806)\ttotal: 59.1s\tremaining: 18.5s\n",
      "3807:\tlearn: 0.6039018\ttest: 0.5977583\tbest: 0.5977583 (3807)\ttotal: 59.1s\tremaining: 18.5s\n",
      "3808:\tlearn: 0.6038980\ttest: 0.5977545\tbest: 0.5977545 (3808)\ttotal: 59.2s\tremaining: 18.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3809:\tlearn: 0.6038980\ttest: 0.5977545\tbest: 0.5977545 (3809)\ttotal: 59.2s\tremaining: 18.5s\n",
      "3810:\tlearn: 0.6038980\ttest: 0.5977547\tbest: 0.5977545 (3809)\ttotal: 59.2s\tremaining: 18.5s\n",
      "3811:\tlearn: 0.6038980\ttest: 0.5977547\tbest: 0.5977545 (3809)\ttotal: 59.2s\tremaining: 18.4s\n",
      "3812:\tlearn: 0.6038980\ttest: 0.5977547\tbest: 0.5977545 (3809)\ttotal: 59.2s\tremaining: 18.4s\n",
      "3813:\tlearn: 0.6038980\ttest: 0.5977547\tbest: 0.5977545 (3809)\ttotal: 59.2s\tremaining: 18.4s\n",
      "3814:\tlearn: 0.6038980\ttest: 0.5977547\tbest: 0.5977545 (3809)\ttotal: 59.2s\tremaining: 18.4s\n",
      "3815:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.4s\n",
      "3816:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.4s\n",
      "3817:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.4s\n",
      "3818:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.3s\n",
      "3819:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.3s\n",
      "3820:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.3s\n",
      "3821:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.3s\tremaining: 18.3s\n",
      "3822:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.4s\tremaining: 18.3s\n",
      "3823:\tlearn: 0.6038980\ttest: 0.5977546\tbest: 0.5977545 (3809)\ttotal: 59.4s\tremaining: 18.3s\n",
      "3824:\tlearn: 0.6038980\ttest: 0.5977545\tbest: 0.5977545 (3824)\ttotal: 59.4s\tremaining: 18.2s\n",
      "3825:\tlearn: 0.6038979\ttest: 0.5977546\tbest: 0.5977545 (3824)\ttotal: 59.4s\tremaining: 18.2s\n",
      "3826:\tlearn: 0.6038979\ttest: 0.5977546\tbest: 0.5977545 (3824)\ttotal: 59.4s\tremaining: 18.2s\n",
      "3827:\tlearn: 0.6038979\ttest: 0.5977546\tbest: 0.5977545 (3824)\ttotal: 59.4s\tremaining: 18.2s\n",
      "3828:\tlearn: 0.6038979\ttest: 0.5977546\tbest: 0.5977545 (3824)\ttotal: 59.5s\tremaining: 18.2s\n",
      "3829:\tlearn: 0.6038911\ttest: 0.5977450\tbest: 0.5977450 (3829)\ttotal: 59.5s\tremaining: 18.2s\n",
      "3830:\tlearn: 0.6038911\ttest: 0.5977450\tbest: 0.5977450 (3830)\ttotal: 59.5s\tremaining: 18.2s\n",
      "3831:\tlearn: 0.6038911\ttest: 0.5977450\tbest: 0.5977450 (3831)\ttotal: 59.5s\tremaining: 18.1s\n",
      "3832:\tlearn: 0.6038911\ttest: 0.5977450\tbest: 0.5977450 (3832)\ttotal: 59.5s\tremaining: 18.1s\n",
      "3833:\tlearn: 0.6038910\ttest: 0.5977452\tbest: 0.5977450 (3832)\ttotal: 59.6s\tremaining: 18.1s\n",
      "3834:\tlearn: 0.6038910\ttest: 0.5977452\tbest: 0.5977450 (3832)\ttotal: 59.6s\tremaining: 18.1s\n",
      "3835:\tlearn: 0.6038910\ttest: 0.5977452\tbest: 0.5977450 (3832)\ttotal: 59.6s\tremaining: 18.1s\n",
      "3836:\tlearn: 0.6038908\ttest: 0.5977446\tbest: 0.5977446 (3836)\ttotal: 59.6s\tremaining: 18.1s\n",
      "3837:\tlearn: 0.6038908\ttest: 0.5977446\tbest: 0.5977446 (3837)\ttotal: 59.6s\tremaining: 18.1s\n",
      "3838:\tlearn: 0.6038908\ttest: 0.5977446\tbest: 0.5977446 (3838)\ttotal: 59.6s\tremaining: 18s\n",
      "3839:\tlearn: 0.6038908\ttest: 0.5977446\tbest: 0.5977446 (3839)\ttotal: 59.7s\tremaining: 18s\n",
      "3840:\tlearn: 0.6038908\ttest: 0.5977446\tbest: 0.5977446 (3840)\ttotal: 59.7s\tremaining: 18s\n",
      "3841:\tlearn: 0.6038542\ttest: 0.5977056\tbest: 0.5977056 (3841)\ttotal: 59.7s\tremaining: 18s\n",
      "3842:\tlearn: 0.6038542\ttest: 0.5977056\tbest: 0.5977056 (3841)\ttotal: 59.7s\tremaining: 18s\n",
      "3843:\tlearn: 0.6038514\ttest: 0.5977039\tbest: 0.5977039 (3843)\ttotal: 59.7s\tremaining: 18s\n",
      "3844:\tlearn: 0.6038514\ttest: 0.5977039\tbest: 0.5977039 (3843)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3845:\tlearn: 0.6038514\ttest: 0.5977039\tbest: 0.5977039 (3843)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3846:\tlearn: 0.6038505\ttest: 0.5977039\tbest: 0.5977039 (3846)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3847:\tlearn: 0.6038505\ttest: 0.5977039\tbest: 0.5977039 (3846)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3848:\tlearn: 0.6038505\ttest: 0.5977039\tbest: 0.5977039 (3846)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3849:\tlearn: 0.6038082\ttest: 0.5976710\tbest: 0.5976710 (3849)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3850:\tlearn: 0.6038082\ttest: 0.5976710\tbest: 0.5976710 (3849)\ttotal: 59.8s\tremaining: 17.9s\n",
      "3851:\tlearn: 0.6038061\ttest: 0.5976694\tbest: 0.5976694 (3851)\ttotal: 59.9s\tremaining: 17.8s\n",
      "3852:\tlearn: 0.6038061\ttest: 0.5976694\tbest: 0.5976694 (3851)\ttotal: 59.9s\tremaining: 17.8s\n",
      "3853:\tlearn: 0.6038061\ttest: 0.5976692\tbest: 0.5976692 (3853)\ttotal: 59.9s\tremaining: 17.8s\n",
      "3854:\tlearn: 0.6038025\ttest: 0.5976641\tbest: 0.5976641 (3854)\ttotal: 59.9s\tremaining: 17.8s\n",
      "3855:\tlearn: 0.6038025\ttest: 0.5976641\tbest: 0.5976641 (3854)\ttotal: 59.9s\tremaining: 17.8s\n",
      "3856:\tlearn: 0.6038020\ttest: 0.5976636\tbest: 0.5976636 (3856)\ttotal: 59.9s\tremaining: 17.8s\n",
      "3857:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 60s\tremaining: 17.8s\n",
      "3858:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 60s\tremaining: 17.7s\n",
      "3859:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 60s\tremaining: 17.7s\n",
      "3860:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 1m\tremaining: 17.7s\n",
      "3861:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 1m\tremaining: 17.7s\n",
      "3862:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 1m\tremaining: 17.7s\n",
      "3863:\tlearn: 0.6038006\ttest: 0.5976624\tbest: 0.5976624 (3857)\ttotal: 1m\tremaining: 17.7s\n",
      "3864:\tlearn: 0.6038004\ttest: 0.5976623\tbest: 0.5976623 (3864)\ttotal: 1m\tremaining: 17.6s\n",
      "3865:\tlearn: 0.6038004\ttest: 0.5976623\tbest: 0.5976623 (3864)\ttotal: 1m\tremaining: 17.6s\n",
      "3866:\tlearn: 0.6037980\ttest: 0.5976578\tbest: 0.5976578 (3866)\ttotal: 1m\tremaining: 17.6s\n",
      "3867:\tlearn: 0.6037980\ttest: 0.5976578\tbest: 0.5976578 (3866)\ttotal: 1m\tremaining: 17.6s\n",
      "3868:\tlearn: 0.6037980\ttest: 0.5976578\tbest: 0.5976578 (3866)\ttotal: 1m\tremaining: 17.6s\n",
      "3869:\tlearn: 0.6037980\ttest: 0.5976578\tbest: 0.5976578 (3866)\ttotal: 1m\tremaining: 17.6s\n",
      "3870:\tlearn: 0.6037980\ttest: 0.5976578\tbest: 0.5976578 (3866)\ttotal: 1m\tremaining: 17.6s\n",
      "3871:\tlearn: 0.6037940\ttest: 0.5976555\tbest: 0.5976555 (3871)\ttotal: 1m\tremaining: 17.5s\n",
      "3872:\tlearn: 0.6037908\ttest: 0.5976488\tbest: 0.5976488 (3872)\ttotal: 1m\tremaining: 17.5s\n",
      "3873:\tlearn: 0.6037908\ttest: 0.5976488\tbest: 0.5976488 (3872)\ttotal: 1m\tremaining: 17.5s\n",
      "3874:\tlearn: 0.6037908\ttest: 0.5976488\tbest: 0.5976488 (3872)\ttotal: 1m\tremaining: 17.5s\n",
      "3875:\tlearn: 0.6037906\ttest: 0.5976482\tbest: 0.5976482 (3875)\ttotal: 1m\tremaining: 17.5s\n",
      "3876:\tlearn: 0.6037902\ttest: 0.5976479\tbest: 0.5976479 (3876)\ttotal: 1m\tremaining: 17.5s\n",
      "3877:\tlearn: 0.6037902\ttest: 0.5976479\tbest: 0.5976479 (3876)\ttotal: 1m\tremaining: 17.4s\n",
      "3878:\tlearn: 0.6037902\ttest: 0.5976479\tbest: 0.5976479 (3876)\ttotal: 1m\tremaining: 17.4s\n",
      "3879:\tlearn: 0.6037823\ttest: 0.5976445\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.4s\n",
      "3880:\tlearn: 0.6037823\ttest: 0.5976445\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.4s\n",
      "3881:\tlearn: 0.6037823\ttest: 0.5976445\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.4s\n",
      "3882:\tlearn: 0.6037809\ttest: 0.5976452\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.4s\n",
      "3883:\tlearn: 0.6037803\ttest: 0.5976453\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.4s\n",
      "3884:\tlearn: 0.6037803\ttest: 0.5976454\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.3s\n",
      "3885:\tlearn: 0.6037803\ttest: 0.5976454\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.3s\n",
      "3886:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.3s\n",
      "3887:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.3s\n",
      "3888:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.3s\n",
      "3889:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.3s\n",
      "3890:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.2s\n",
      "3891:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.2s\n",
      "3892:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.2s\n",
      "3893:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.2s\n",
      "3894:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.2s\n",
      "3895:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.2s\n",
      "3896:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.1s\n",
      "3897:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.1s\n",
      "3898:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.1s\n",
      "3899:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.1s\n",
      "3900:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.1s\n",
      "3901:\tlearn: 0.6037789\ttest: 0.5976447\tbest: 0.5976445 (3879)\ttotal: 1m\tremaining: 17.1s\n",
      "3902:\tlearn: 0.6037772\ttest: 0.5976427\tbest: 0.5976427 (3902)\ttotal: 1m\tremaining: 17.1s\n",
      "3903:\tlearn: 0.6037768\ttest: 0.5976427\tbest: 0.5976427 (3903)\ttotal: 1m\tremaining: 17s\n",
      "3904:\tlearn: 0.6037768\ttest: 0.5976427\tbest: 0.5976427 (3903)\ttotal: 1m\tremaining: 17s\n",
      "3905:\tlearn: 0.6037768\ttest: 0.5976427\tbest: 0.5976427 (3903)\ttotal: 1m\tremaining: 17s\n",
      "3906:\tlearn: 0.6037768\ttest: 0.5976427\tbest: 0.5976427 (3903)\ttotal: 1m\tremaining: 17s\n",
      "3907:\tlearn: 0.6037768\ttest: 0.5976427\tbest: 0.5976427 (3903)\ttotal: 1m\tremaining: 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3908:\tlearn: 0.6037768\ttest: 0.5976427\tbest: 0.5976427 (3903)\ttotal: 1m\tremaining: 17s\n",
      "3909:\tlearn: 0.6037753\ttest: 0.5976411\tbest: 0.5976411 (3909)\ttotal: 1m\tremaining: 16.9s\n",
      "3910:\tlearn: 0.6037753\ttest: 0.5976412\tbest: 0.5976411 (3909)\ttotal: 1m\tremaining: 16.9s\n",
      "3911:\tlearn: 0.6037752\ttest: 0.5976408\tbest: 0.5976408 (3911)\ttotal: 1m\tremaining: 16.9s\n",
      "3912:\tlearn: 0.6037743\ttest: 0.5976402\tbest: 0.5976402 (3912)\ttotal: 1m\tremaining: 16.9s\n",
      "3913:\tlearn: 0.6037743\ttest: 0.5976402\tbest: 0.5976402 (3912)\ttotal: 1m\tremaining: 16.9s\n",
      "3914:\tlearn: 0.6037743\ttest: 0.5976402\tbest: 0.5976402 (3912)\ttotal: 1m\tremaining: 16.9s\n",
      "3915:\tlearn: 0.6037743\ttest: 0.5976402\tbest: 0.5976402 (3912)\ttotal: 1m\tremaining: 16.9s\n",
      "3916:\tlearn: 0.6037743\ttest: 0.5976402\tbest: 0.5976402 (3912)\ttotal: 1m\tremaining: 16.8s\n",
      "3917:\tlearn: 0.6037743\ttest: 0.5976398\tbest: 0.5976398 (3917)\ttotal: 1m\tremaining: 16.8s\n",
      "3918:\tlearn: 0.6037467\ttest: 0.5976122\tbest: 0.5976122 (3918)\ttotal: 1m\tremaining: 16.8s\n",
      "3919:\tlearn: 0.6037467\ttest: 0.5976122\tbest: 0.5976122 (3918)\ttotal: 1m\tremaining: 16.8s\n",
      "3920:\tlearn: 0.6037467\ttest: 0.5976122\tbest: 0.5976122 (3918)\ttotal: 1m\tremaining: 16.8s\n",
      "3921:\tlearn: 0.6037467\ttest: 0.5976122\tbest: 0.5976122 (3918)\ttotal: 1m\tremaining: 16.8s\n",
      "3922:\tlearn: 0.6037467\ttest: 0.5976124\tbest: 0.5976122 (3918)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3923:\tlearn: 0.6037467\ttest: 0.5976124\tbest: 0.5976122 (3918)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3924:\tlearn: 0.6037467\ttest: 0.5976124\tbest: 0.5976122 (3918)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3925:\tlearn: 0.6037318\ttest: 0.5975898\tbest: 0.5975898 (3925)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3926:\tlearn: 0.6037318\ttest: 0.5975898\tbest: 0.5975898 (3925)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3927:\tlearn: 0.6037318\ttest: 0.5975898\tbest: 0.5975898 (3925)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3928:\tlearn: 0.6037308\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.7s\n",
      "3929:\tlearn: 0.6037308\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3930:\tlearn: 0.6037308\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3931:\tlearn: 0.6037308\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3932:\tlearn: 0.6037308\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3933:\tlearn: 0.6037308\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3934:\tlearn: 0.6037307\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3935:\tlearn: 0.6037307\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.6s\n",
      "3936:\tlearn: 0.6037307\ttest: 0.5975885\tbest: 0.5975885 (3928)\ttotal: 1m 1s\tremaining: 16.5s\n",
      "3937:\tlearn: 0.6037284\ttest: 0.5975876\tbest: 0.5975876 (3937)\ttotal: 1m 1s\tremaining: 16.5s\n",
      "3938:\tlearn: 0.6037284\ttest: 0.5975876\tbest: 0.5975876 (3937)\ttotal: 1m 1s\tremaining: 16.5s\n",
      "3939:\tlearn: 0.6037284\ttest: 0.5975876\tbest: 0.5975876 (3937)\ttotal: 1m 1s\tremaining: 16.5s\n",
      "3940:\tlearn: 0.6037273\ttest: 0.5975856\tbest: 0.5975856 (3940)\ttotal: 1m 1s\tremaining: 16.5s\n",
      "3941:\tlearn: 0.6037273\ttest: 0.5975856\tbest: 0.5975856 (3940)\ttotal: 1m 1s\tremaining: 16.5s\n",
      "3942:\tlearn: 0.6037273\ttest: 0.5975856\tbest: 0.5975856 (3940)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3943:\tlearn: 0.6037273\ttest: 0.5975856\tbest: 0.5975856 (3940)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3944:\tlearn: 0.6037248\ttest: 0.5975791\tbest: 0.5975791 (3944)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3945:\tlearn: 0.6037248\ttest: 0.5975790\tbest: 0.5975790 (3945)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3946:\tlearn: 0.6037248\ttest: 0.5975790\tbest: 0.5975790 (3945)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3947:\tlearn: 0.6037248\ttest: 0.5975790\tbest: 0.5975790 (3945)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3948:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.4s\n",
      "3949:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.3s\n",
      "3950:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.3s\n",
      "3951:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.3s\n",
      "3952:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.3s\n",
      "3953:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.3s\n",
      "3954:\tlearn: 0.6037221\ttest: 0.5975773\tbest: 0.5975773 (3948)\ttotal: 1m 1s\tremaining: 16.3s\n",
      "3955:\tlearn: 0.6037220\ttest: 0.5975768\tbest: 0.5975768 (3955)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3956:\tlearn: 0.6037220\ttest: 0.5975768\tbest: 0.5975768 (3955)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3957:\tlearn: 0.6037020\ttest: 0.5975597\tbest: 0.5975597 (3957)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3958:\tlearn: 0.6036813\ttest: 0.5975484\tbest: 0.5975484 (3958)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3959:\tlearn: 0.6036771\ttest: 0.5975450\tbest: 0.5975450 (3959)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3960:\tlearn: 0.6036771\ttest: 0.5975451\tbest: 0.5975450 (3959)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3961:\tlearn: 0.6036771\ttest: 0.5975451\tbest: 0.5975450 (3959)\ttotal: 1m 1s\tremaining: 16.2s\n",
      "3962:\tlearn: 0.6036771\ttest: 0.5975451\tbest: 0.5975450 (3959)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3963:\tlearn: 0.6036771\ttest: 0.5975451\tbest: 0.5975450 (3959)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3964:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3965:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3966:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3967:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3968:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16.1s\n",
      "3969:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16s\n",
      "3970:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16s\n",
      "3971:\tlearn: 0.6036738\ttest: 0.5975423\tbest: 0.5975423 (3964)\ttotal: 1m 1s\tremaining: 16s\n",
      "3972:\tlearn: 0.6036617\ttest: 0.5975280\tbest: 0.5975280 (3972)\ttotal: 1m 1s\tremaining: 16s\n",
      "3973:\tlearn: 0.6036575\ttest: 0.5975237\tbest: 0.5975237 (3973)\ttotal: 1m 1s\tremaining: 16s\n",
      "3974:\tlearn: 0.6036575\ttest: 0.5975237\tbest: 0.5975237 (3973)\ttotal: 1m 1s\tremaining: 16s\n",
      "3975:\tlearn: 0.6036575\ttest: 0.5975237\tbest: 0.5975237 (3973)\ttotal: 1m 1s\tremaining: 16s\n",
      "3976:\tlearn: 0.6036571\ttest: 0.5975228\tbest: 0.5975228 (3976)\ttotal: 1m 1s\tremaining: 15.9s\n",
      "3977:\tlearn: 0.6036571\ttest: 0.5975228\tbest: 0.5975228 (3976)\ttotal: 1m 1s\tremaining: 15.9s\n",
      "3978:\tlearn: 0.6036571\ttest: 0.5975228\tbest: 0.5975228 (3976)\ttotal: 1m 1s\tremaining: 15.9s\n",
      "3979:\tlearn: 0.6036555\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.9s\n",
      "3980:\tlearn: 0.6036555\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.9s\n",
      "3981:\tlearn: 0.6036555\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.9s\n",
      "3982:\tlearn: 0.6036555\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.8s\n",
      "3983:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.8s\n",
      "3984:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.8s\n",
      "3985:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.8s\n",
      "3986:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.8s\n",
      "3987:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.8s\n",
      "3988:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3989:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3990:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3991:\tlearn: 0.6036552\ttest: 0.5975220\tbest: 0.5975220 (3979)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3992:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3993:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3994:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.7s\n",
      "3995:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "3996:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "3997:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "3998:\tlearn: 0.6036550\ttest: 0.5975215\tbest: 0.5975215 (3992)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "3999:\tlearn: 0.6036513\ttest: 0.5975183\tbest: 0.5975183 (3999)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "4000:\tlearn: 0.6036513\ttest: 0.5975183\tbest: 0.5975183 (3999)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "4001:\tlearn: 0.6036513\ttest: 0.5975183\tbest: 0.5975183 (3999)\ttotal: 1m 2s\tremaining: 15.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4002:\tlearn: 0.6036513\ttest: 0.5975183\tbest: 0.5975183 (3999)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "4003:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "4004:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "4005:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "4006:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "4007:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.5s\n",
      "4008:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.4s\n",
      "4009:\tlearn: 0.6036467\ttest: 0.5975129\tbest: 0.5975129 (4003)\ttotal: 1m 2s\tremaining: 15.4s\n",
      "4010:\tlearn: 0.6036446\ttest: 0.5975100\tbest: 0.5975100 (4010)\ttotal: 1m 2s\tremaining: 15.4s\n",
      "4011:\tlearn: 0.6036446\ttest: 0.5975100\tbest: 0.5975100 (4010)\ttotal: 1m 2s\tremaining: 15.4s\n",
      "4012:\tlearn: 0.6036446\ttest: 0.5975100\tbest: 0.5975100 (4010)\ttotal: 1m 2s\tremaining: 15.4s\n",
      "4013:\tlearn: 0.6036444\ttest: 0.5975100\tbest: 0.5975100 (4013)\ttotal: 1m 2s\tremaining: 15.4s\n",
      "4014:\tlearn: 0.6036444\ttest: 0.5975100\tbest: 0.5975100 (4013)\ttotal: 1m 2s\tremaining: 15.3s\n",
      "4015:\tlearn: 0.6036444\ttest: 0.5975100\tbest: 0.5975100 (4013)\ttotal: 1m 2s\tremaining: 15.3s\n",
      "4016:\tlearn: 0.6036440\ttest: 0.5975097\tbest: 0.5975097 (4016)\ttotal: 1m 2s\tremaining: 15.3s\n",
      "4017:\tlearn: 0.6036440\ttest: 0.5975097\tbest: 0.5975097 (4016)\ttotal: 1m 2s\tremaining: 15.3s\n",
      "4018:\tlearn: 0.6036429\ttest: 0.5975095\tbest: 0.5975095 (4018)\ttotal: 1m 2s\tremaining: 15.3s\n",
      "4019:\tlearn: 0.6036429\ttest: 0.5975095\tbest: 0.5975095 (4018)\ttotal: 1m 2s\tremaining: 15.3s\n",
      "4020:\tlearn: 0.6036429\ttest: 0.5975095\tbest: 0.5975095 (4018)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4021:\tlearn: 0.6036425\ttest: 0.5975094\tbest: 0.5975094 (4021)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4022:\tlearn: 0.6036425\ttest: 0.5975094\tbest: 0.5975094 (4021)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4023:\tlearn: 0.6036418\ttest: 0.5975095\tbest: 0.5975094 (4021)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4024:\tlearn: 0.6036417\ttest: 0.5975094\tbest: 0.5975094 (4024)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4025:\tlearn: 0.6036416\ttest: 0.5975094\tbest: 0.5975094 (4024)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4026:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.2s\n",
      "4027:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.1s\n",
      "4028:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.1s\n",
      "4029:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.1s\n",
      "4030:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.1s\n",
      "4031:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.1s\n",
      "4032:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15.1s\n",
      "4033:\tlearn: 0.6036389\ttest: 0.5975050\tbest: 0.5975050 (4026)\ttotal: 1m 2s\tremaining: 15s\n",
      "4034:\tlearn: 0.6036389\ttest: 0.5975048\tbest: 0.5975048 (4034)\ttotal: 1m 2s\tremaining: 15s\n",
      "4035:\tlearn: 0.6036389\ttest: 0.5975048\tbest: 0.5975048 (4034)\ttotal: 1m 2s\tremaining: 15s\n",
      "4036:\tlearn: 0.6036389\ttest: 0.5975048\tbest: 0.5975048 (4034)\ttotal: 1m 2s\tremaining: 15s\n",
      "4037:\tlearn: 0.6036389\ttest: 0.5975048\tbest: 0.5975048 (4034)\ttotal: 1m 2s\tremaining: 15s\n",
      "4038:\tlearn: 0.6036389\ttest: 0.5975048\tbest: 0.5975048 (4034)\ttotal: 1m 2s\tremaining: 15s\n",
      "4039:\tlearn: 0.6036389\ttest: 0.5975048\tbest: 0.5975048 (4034)\ttotal: 1m 2s\tremaining: 15s\n",
      "4040:\tlearn: 0.6036283\ttest: 0.5974970\tbest: 0.5974970 (4040)\ttotal: 1m 2s\tremaining: 14.9s\n",
      "4041:\tlearn: 0.6036283\ttest: 0.5974970\tbest: 0.5974970 (4040)\ttotal: 1m 2s\tremaining: 14.9s\n",
      "4042:\tlearn: 0.6036283\ttest: 0.5974970\tbest: 0.5974970 (4040)\ttotal: 1m 2s\tremaining: 14.9s\n",
      "4043:\tlearn: 0.6036283\ttest: 0.5974970\tbest: 0.5974970 (4040)\ttotal: 1m 3s\tremaining: 14.9s\n",
      "4044:\tlearn: 0.6036283\ttest: 0.5974970\tbest: 0.5974970 (4040)\ttotal: 1m 3s\tremaining: 14.9s\n",
      "4045:\tlearn: 0.6036248\ttest: 0.5974938\tbest: 0.5974938 (4045)\ttotal: 1m 3s\tremaining: 14.9s\n",
      "4046:\tlearn: 0.6036247\ttest: 0.5974937\tbest: 0.5974937 (4046)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4047:\tlearn: 0.6036243\ttest: 0.5974934\tbest: 0.5974934 (4047)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4048:\tlearn: 0.6036243\ttest: 0.5974934\tbest: 0.5974934 (4047)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4049:\tlearn: 0.6036170\ttest: 0.5974832\tbest: 0.5974832 (4049)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4050:\tlearn: 0.6036137\ttest: 0.5974789\tbest: 0.5974789 (4050)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4051:\tlearn: 0.6036060\ttest: 0.5974769\tbest: 0.5974769 (4051)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4052:\tlearn: 0.6036060\ttest: 0.5974770\tbest: 0.5974769 (4051)\ttotal: 1m 3s\tremaining: 14.8s\n",
      "4053:\tlearn: 0.6036060\ttest: 0.5974770\tbest: 0.5974769 (4051)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4054:\tlearn: 0.6036060\ttest: 0.5974770\tbest: 0.5974769 (4051)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4055:\tlearn: 0.6036060\ttest: 0.5974770\tbest: 0.5974769 (4051)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4056:\tlearn: 0.6036060\ttest: 0.5974770\tbest: 0.5974769 (4051)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4057:\tlearn: 0.6036026\ttest: 0.5974754\tbest: 0.5974754 (4057)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4058:\tlearn: 0.6036026\ttest: 0.5974754\tbest: 0.5974754 (4057)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4059:\tlearn: 0.6036026\ttest: 0.5974754\tbest: 0.5974754 (4057)\ttotal: 1m 3s\tremaining: 14.7s\n",
      "4060:\tlearn: 0.6036007\ttest: 0.5974709\tbest: 0.5974709 (4060)\ttotal: 1m 3s\tremaining: 14.6s\n",
      "4061:\tlearn: 0.6035994\ttest: 0.5974705\tbest: 0.5974705 (4061)\ttotal: 1m 3s\tremaining: 14.6s\n",
      "4062:\tlearn: 0.6035978\ttest: 0.5974674\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.6s\n",
      "4063:\tlearn: 0.6035978\ttest: 0.5974674\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.6s\n",
      "4064:\tlearn: 0.6035978\ttest: 0.5974674\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.6s\n",
      "4065:\tlearn: 0.6035978\ttest: 0.5974674\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.6s\n",
      "4066:\tlearn: 0.6035978\ttest: 0.5974674\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4067:\tlearn: 0.6035977\ttest: 0.5974675\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4068:\tlearn: 0.6035977\ttest: 0.5974675\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4069:\tlearn: 0.6035977\ttest: 0.5974676\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4070:\tlearn: 0.6035977\ttest: 0.5974676\tbest: 0.5974674 (4062)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4071:\tlearn: 0.6035960\ttest: 0.5974672\tbest: 0.5974672 (4071)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4072:\tlearn: 0.6035943\ttest: 0.5974672\tbest: 0.5974672 (4071)\ttotal: 1m 3s\tremaining: 14.5s\n",
      "4073:\tlearn: 0.6035943\ttest: 0.5974672\tbest: 0.5974672 (4071)\ttotal: 1m 3s\tremaining: 14.4s\n",
      "4074:\tlearn: 0.6035931\ttest: 0.5974667\tbest: 0.5974667 (4074)\ttotal: 1m 3s\tremaining: 14.4s\n",
      "4075:\tlearn: 0.6035931\ttest: 0.5974667\tbest: 0.5974667 (4074)\ttotal: 1m 3s\tremaining: 14.4s\n",
      "4076:\tlearn: 0.6035931\ttest: 0.5974667\tbest: 0.5974667 (4074)\ttotal: 1m 3s\tremaining: 14.4s\n",
      "4077:\tlearn: 0.6035931\ttest: 0.5974667\tbest: 0.5974667 (4074)\ttotal: 1m 3s\tremaining: 14.4s\n",
      "4078:\tlearn: 0.6035931\ttest: 0.5974667\tbest: 0.5974667 (4074)\ttotal: 1m 3s\tremaining: 14.4s\n",
      "4079:\tlearn: 0.6035899\ttest: 0.5974600\tbest: 0.5974600 (4079)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4080:\tlearn: 0.6035879\ttest: 0.5974585\tbest: 0.5974585 (4080)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4081:\tlearn: 0.6035879\ttest: 0.5974585\tbest: 0.5974585 (4080)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4082:\tlearn: 0.6035838\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4083:\tlearn: 0.6035838\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4084:\tlearn: 0.6035836\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4085:\tlearn: 0.6035836\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.3s\n",
      "4086:\tlearn: 0.6035836\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.2s\n",
      "4087:\tlearn: 0.6035836\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.2s\n",
      "4088:\tlearn: 0.6035836\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.2s\n",
      "4089:\tlearn: 0.6035836\ttest: 0.5974559\tbest: 0.5974559 (4082)\ttotal: 1m 3s\tremaining: 14.2s\n",
      "4090:\tlearn: 0.6035789\ttest: 0.5974546\tbest: 0.5974546 (4090)\ttotal: 1m 3s\tremaining: 14.2s\n",
      "4091:\tlearn: 0.6035789\ttest: 0.5974546\tbest: 0.5974546 (4090)\ttotal: 1m 3s\tremaining: 14.2s\n",
      "4092:\tlearn: 0.6035789\ttest: 0.5974546\tbest: 0.5974546 (4090)\ttotal: 1m 3s\tremaining: 14.1s\n",
      "4093:\tlearn: 0.6035789\ttest: 0.5974547\tbest: 0.5974546 (4090)\ttotal: 1m 3s\tremaining: 14.1s\n",
      "4094:\tlearn: 0.6035789\ttest: 0.5974546\tbest: 0.5974546 (4094)\ttotal: 1m 3s\tremaining: 14.1s\n",
      "4095:\tlearn: 0.6035789\ttest: 0.5974546\tbest: 0.5974546 (4094)\ttotal: 1m 3s\tremaining: 14.1s\n",
      "4096:\tlearn: 0.6035774\ttest: 0.5974538\tbest: 0.5974538 (4096)\ttotal: 1m 3s\tremaining: 14.1s\n",
      "4097:\tlearn: 0.6035774\ttest: 0.5974538\tbest: 0.5974538 (4096)\ttotal: 1m 3s\tremaining: 14.1s\n",
      "4098:\tlearn: 0.6035771\ttest: 0.5974536\tbest: 0.5974536 (4098)\ttotal: 1m 3s\tremaining: 14.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4099:\tlearn: 0.6035547\ttest: 0.5974204\tbest: 0.5974204 (4099)\ttotal: 1m 3s\tremaining: 14s\n",
      "4100:\tlearn: 0.6035547\ttest: 0.5974204\tbest: 0.5974204 (4099)\ttotal: 1m 3s\tremaining: 14s\n",
      "4101:\tlearn: 0.6035547\ttest: 0.5974204\tbest: 0.5974204 (4099)\ttotal: 1m 3s\tremaining: 14s\n",
      "4102:\tlearn: 0.6035547\ttest: 0.5974204\tbest: 0.5974204 (4099)\ttotal: 1m 4s\tremaining: 14s\n",
      "4103:\tlearn: 0.6035547\ttest: 0.5974204\tbest: 0.5974204 (4099)\ttotal: 1m 4s\tremaining: 14s\n",
      "4104:\tlearn: 0.6035547\ttest: 0.5974204\tbest: 0.5974204 (4099)\ttotal: 1m 4s\tremaining: 14s\n",
      "4105:\tlearn: 0.6035516\ttest: 0.5974156\tbest: 0.5974156 (4105)\ttotal: 1m 4s\tremaining: 14s\n",
      "4106:\tlearn: 0.6035516\ttest: 0.5974156\tbest: 0.5974156 (4105)\ttotal: 1m 4s\tremaining: 13.9s\n",
      "4107:\tlearn: 0.6035516\ttest: 0.5974156\tbest: 0.5974156 (4105)\ttotal: 1m 4s\tremaining: 13.9s\n",
      "4108:\tlearn: 0.6035502\ttest: 0.5974158\tbest: 0.5974156 (4105)\ttotal: 1m 4s\tremaining: 13.9s\n",
      "4109:\tlearn: 0.6035502\ttest: 0.5974158\tbest: 0.5974156 (4105)\ttotal: 1m 4s\tremaining: 13.9s\n",
      "4110:\tlearn: 0.6035502\ttest: 0.5974158\tbest: 0.5974156 (4105)\ttotal: 1m 4s\tremaining: 13.9s\n",
      "4111:\tlearn: 0.6035239\ttest: 0.5973842\tbest: 0.5973842 (4111)\ttotal: 1m 4s\tremaining: 13.9s\n",
      "4112:\tlearn: 0.6035239\ttest: 0.5973842\tbest: 0.5973842 (4111)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4113:\tlearn: 0.6035239\ttest: 0.5973842\tbest: 0.5973842 (4111)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4114:\tlearn: 0.6035236\ttest: 0.5973828\tbest: 0.5973828 (4114)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4115:\tlearn: 0.6035235\ttest: 0.5973830\tbest: 0.5973828 (4114)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4116:\tlearn: 0.6035235\ttest: 0.5973830\tbest: 0.5973828 (4114)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4117:\tlearn: 0.6035235\ttest: 0.5973830\tbest: 0.5973828 (4114)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4118:\tlearn: 0.6035217\ttest: 0.5973787\tbest: 0.5973787 (4118)\ttotal: 1m 4s\tremaining: 13.8s\n",
      "4119:\tlearn: 0.6035217\ttest: 0.5973787\tbest: 0.5973787 (4118)\ttotal: 1m 4s\tremaining: 13.7s\n",
      "4120:\tlearn: 0.6035217\ttest: 0.5973787\tbest: 0.5973787 (4118)\ttotal: 1m 4s\tremaining: 13.7s\n",
      "4121:\tlearn: 0.6035217\ttest: 0.5973787\tbest: 0.5973787 (4118)\ttotal: 1m 4s\tremaining: 13.7s\n",
      "4122:\tlearn: 0.6035217\ttest: 0.5973787\tbest: 0.5973787 (4118)\ttotal: 1m 4s\tremaining: 13.7s\n",
      "4123:\tlearn: 0.6035215\ttest: 0.5973782\tbest: 0.5973782 (4123)\ttotal: 1m 4s\tremaining: 13.7s\n",
      "4124:\tlearn: 0.6035215\ttest: 0.5973782\tbest: 0.5973782 (4123)\ttotal: 1m 4s\tremaining: 13.7s\n",
      "4125:\tlearn: 0.6034921\ttest: 0.5973517\tbest: 0.5973517 (4125)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4126:\tlearn: 0.6034921\ttest: 0.5973517\tbest: 0.5973517 (4125)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4127:\tlearn: 0.6034921\ttest: 0.5973517\tbest: 0.5973517 (4125)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4128:\tlearn: 0.6034921\ttest: 0.5973517\tbest: 0.5973517 (4125)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4129:\tlearn: 0.6034914\ttest: 0.5973510\tbest: 0.5973510 (4129)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4130:\tlearn: 0.6034875\ttest: 0.5973479\tbest: 0.5973479 (4130)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4131:\tlearn: 0.6034872\ttest: 0.5973477\tbest: 0.5973477 (4131)\ttotal: 1m 4s\tremaining: 13.6s\n",
      "4132:\tlearn: 0.6034872\ttest: 0.5973477\tbest: 0.5973477 (4131)\ttotal: 1m 4s\tremaining: 13.5s\n",
      "4133:\tlearn: 0.6034872\ttest: 0.5973477\tbest: 0.5973477 (4131)\ttotal: 1m 4s\tremaining: 13.5s\n",
      "4134:\tlearn: 0.6034872\ttest: 0.5973477\tbest: 0.5973477 (4131)\ttotal: 1m 4s\tremaining: 13.5s\n",
      "4135:\tlearn: 0.6034872\ttest: 0.5973477\tbest: 0.5973477 (4131)\ttotal: 1m 4s\tremaining: 13.5s\n",
      "4136:\tlearn: 0.6034355\ttest: 0.5973055\tbest: 0.5973055 (4136)\ttotal: 1m 4s\tremaining: 13.5s\n",
      "4137:\tlearn: 0.6034355\ttest: 0.5973055\tbest: 0.5973055 (4136)\ttotal: 1m 4s\tremaining: 13.5s\n",
      "4138:\tlearn: 0.6034275\ttest: 0.5972996\tbest: 0.5972996 (4138)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4139:\tlearn: 0.6034275\ttest: 0.5972996\tbest: 0.5972996 (4138)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4140:\tlearn: 0.6034275\ttest: 0.5972996\tbest: 0.5972996 (4138)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4141:\tlearn: 0.6034268\ttest: 0.5973002\tbest: 0.5972996 (4138)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4142:\tlearn: 0.6034054\ttest: 0.5972819\tbest: 0.5972819 (4142)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4143:\tlearn: 0.6034036\ttest: 0.5972817\tbest: 0.5972817 (4143)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4144:\tlearn: 0.6034036\ttest: 0.5972817\tbest: 0.5972817 (4143)\ttotal: 1m 4s\tremaining: 13.4s\n",
      "4145:\tlearn: 0.6033851\ttest: 0.5972626\tbest: 0.5972626 (4145)\ttotal: 1m 4s\tremaining: 13.3s\n",
      "4146:\tlearn: 0.6033851\ttest: 0.5972626\tbest: 0.5972626 (4145)\ttotal: 1m 4s\tremaining: 13.3s\n",
      "4147:\tlearn: 0.6033661\ttest: 0.5972505\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.3s\n",
      "4148:\tlearn: 0.6033661\ttest: 0.5972505\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.3s\n",
      "4149:\tlearn: 0.6033661\ttest: 0.5972505\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.3s\n",
      "4150:\tlearn: 0.6033661\ttest: 0.5972505\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.3s\n",
      "4151:\tlearn: 0.6033661\ttest: 0.5972505\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4152:\tlearn: 0.6033661\ttest: 0.5972505\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4153:\tlearn: 0.6033661\ttest: 0.5972506\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4154:\tlearn: 0.6033661\ttest: 0.5972506\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4155:\tlearn: 0.6033661\ttest: 0.5972506\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4156:\tlearn: 0.6033661\ttest: 0.5972506\tbest: 0.5972505 (4147)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4157:\tlearn: 0.6033248\ttest: 0.5972140\tbest: 0.5972140 (4157)\ttotal: 1m 4s\tremaining: 13.2s\n",
      "4158:\tlearn: 0.6033245\ttest: 0.5972140\tbest: 0.5972140 (4157)\ttotal: 1m 4s\tremaining: 13.1s\n",
      "4159:\tlearn: 0.6033230\ttest: 0.5972118\tbest: 0.5972118 (4159)\ttotal: 1m 4s\tremaining: 13.1s\n",
      "4160:\tlearn: 0.6033228\ttest: 0.5972114\tbest: 0.5972114 (4160)\ttotal: 1m 5s\tremaining: 13.1s\n",
      "4161:\tlearn: 0.6033228\ttest: 0.5972114\tbest: 0.5972114 (4160)\ttotal: 1m 5s\tremaining: 13.1s\n",
      "4162:\tlearn: 0.6033228\ttest: 0.5972114\tbest: 0.5972114 (4160)\ttotal: 1m 5s\tremaining: 13.1s\n",
      "4163:\tlearn: 0.6033228\ttest: 0.5972114\tbest: 0.5972114 (4160)\ttotal: 1m 5s\tremaining: 13.1s\n",
      "4164:\tlearn: 0.6033204\ttest: 0.5972104\tbest: 0.5972104 (4164)\ttotal: 1m 5s\tremaining: 13s\n",
      "4165:\tlearn: 0.6033204\ttest: 0.5972108\tbest: 0.5972104 (4164)\ttotal: 1m 5s\tremaining: 13s\n",
      "4166:\tlearn: 0.6033204\ttest: 0.5972108\tbest: 0.5972104 (4164)\ttotal: 1m 5s\tremaining: 13s\n",
      "4167:\tlearn: 0.6033204\ttest: 0.5972108\tbest: 0.5972104 (4164)\ttotal: 1m 5s\tremaining: 13s\n",
      "4168:\tlearn: 0.6033204\ttest: 0.5972108\tbest: 0.5972104 (4164)\ttotal: 1m 5s\tremaining: 13s\n",
      "4169:\tlearn: 0.6033198\ttest: 0.5972109\tbest: 0.5972104 (4164)\ttotal: 1m 5s\tremaining: 13s\n",
      "4170:\tlearn: 0.6032866\ttest: 0.5971667\tbest: 0.5971667 (4170)\ttotal: 1m 5s\tremaining: 13s\n",
      "4171:\tlearn: 0.6032866\ttest: 0.5971667\tbest: 0.5971667 (4170)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4172:\tlearn: 0.6032866\ttest: 0.5971667\tbest: 0.5971667 (4170)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4173:\tlearn: 0.6032632\ttest: 0.5971346\tbest: 0.5971346 (4173)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4174:\tlearn: 0.6032632\ttest: 0.5971346\tbest: 0.5971346 (4173)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4175:\tlearn: 0.6032598\ttest: 0.5971296\tbest: 0.5971296 (4175)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4176:\tlearn: 0.6032598\ttest: 0.5971296\tbest: 0.5971296 (4175)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4177:\tlearn: 0.6032598\ttest: 0.5971296\tbest: 0.5971296 (4175)\ttotal: 1m 5s\tremaining: 12.9s\n",
      "4178:\tlearn: 0.6032583\ttest: 0.5971280\tbest: 0.5971280 (4178)\ttotal: 1m 5s\tremaining: 12.8s\n",
      "4179:\tlearn: 0.6032583\ttest: 0.5971280\tbest: 0.5971280 (4178)\ttotal: 1m 5s\tremaining: 12.8s\n",
      "4180:\tlearn: 0.6032583\ttest: 0.5971280\tbest: 0.5971280 (4178)\ttotal: 1m 5s\tremaining: 12.8s\n",
      "4181:\tlearn: 0.6032583\ttest: 0.5971280\tbest: 0.5971280 (4178)\ttotal: 1m 5s\tremaining: 12.8s\n",
      "4182:\tlearn: 0.6032583\ttest: 0.5971280\tbest: 0.5971280 (4178)\ttotal: 1m 5s\tremaining: 12.8s\n",
      "4183:\tlearn: 0.6032547\ttest: 0.5971262\tbest: 0.5971262 (4183)\ttotal: 1m 5s\tremaining: 12.8s\n",
      "4184:\tlearn: 0.6032547\ttest: 0.5971262\tbest: 0.5971262 (4183)\ttotal: 1m 5s\tremaining: 12.7s\n",
      "4185:\tlearn: 0.6032547\ttest: 0.5971262\tbest: 0.5971262 (4183)\ttotal: 1m 5s\tremaining: 12.7s\n",
      "4186:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.7s\n",
      "4187:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.7s\n",
      "4188:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.7s\n",
      "4189:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4190:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4191:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4192:\tlearn: 0.6032547\ttest: 0.5971261\tbest: 0.5971261 (4186)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4193:\tlearn: 0.6032402\ttest: 0.5971087\tbest: 0.5971087 (4193)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4194:\tlearn: 0.6032402\ttest: 0.5971087\tbest: 0.5971087 (4193)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4195:\tlearn: 0.6032402\ttest: 0.5971087\tbest: 0.5971087 (4193)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4196:\tlearn: 0.6032402\ttest: 0.5971087\tbest: 0.5971087 (4193)\ttotal: 1m 5s\tremaining: 12.6s\n",
      "4197:\tlearn: 0.6032353\ttest: 0.5971016\tbest: 0.5971016 (4197)\ttotal: 1m 5s\tremaining: 12.5s\n",
      "4198:\tlearn: 0.6032353\ttest: 0.5971016\tbest: 0.5971016 (4197)\ttotal: 1m 5s\tremaining: 12.5s\n",
      "4199:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.5s\n",
      "4200:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.5s\n",
      "4201:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.5s\n",
      "4202:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.5s\n",
      "4203:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4204:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4205:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4206:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4207:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4208:\tlearn: 0.6032351\ttest: 0.5971015\tbest: 0.5971015 (4199)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4209:\tlearn: 0.6032342\ttest: 0.5971008\tbest: 0.5971008 (4209)\ttotal: 1m 5s\tremaining: 12.4s\n",
      "4210:\tlearn: 0.6032342\ttest: 0.5971008\tbest: 0.5971008 (4209)\ttotal: 1m 5s\tremaining: 12.3s\n",
      "4211:\tlearn: 0.6032342\ttest: 0.5971007\tbest: 0.5971007 (4211)\ttotal: 1m 5s\tremaining: 12.3s\n",
      "4212:\tlearn: 0.6032342\ttest: 0.5971007\tbest: 0.5971007 (4211)\ttotal: 1m 5s\tremaining: 12.3s\n",
      "4213:\tlearn: 0.6032342\ttest: 0.5971007\tbest: 0.5971007 (4211)\ttotal: 1m 5s\tremaining: 12.3s\n",
      "4214:\tlearn: 0.6032342\ttest: 0.5971007\tbest: 0.5971007 (4211)\ttotal: 1m 5s\tremaining: 12.3s\n",
      "4215:\tlearn: 0.6032338\ttest: 0.5971002\tbest: 0.5971002 (4215)\ttotal: 1m 5s\tremaining: 12.3s\n",
      "4216:\tlearn: 0.6032338\ttest: 0.5971002\tbest: 0.5971002 (4215)\ttotal: 1m 5s\tremaining: 12.2s\n",
      "4217:\tlearn: 0.6032304\ttest: 0.5970972\tbest: 0.5970972 (4217)\ttotal: 1m 5s\tremaining: 12.2s\n",
      "4218:\tlearn: 0.6032304\ttest: 0.5970972\tbest: 0.5970972 (4218)\ttotal: 1m 5s\tremaining: 12.2s\n",
      "4219:\tlearn: 0.6032304\ttest: 0.5970972\tbest: 0.5970972 (4218)\ttotal: 1m 5s\tremaining: 12.2s\n",
      "4220:\tlearn: 0.6032304\ttest: 0.5970972\tbest: 0.5970972 (4218)\ttotal: 1m 6s\tremaining: 12.2s\n",
      "4221:\tlearn: 0.6032266\ttest: 0.5970941\tbest: 0.5970941 (4221)\ttotal: 1m 6s\tremaining: 12.2s\n",
      "4222:\tlearn: 0.6032266\ttest: 0.5970941\tbest: 0.5970941 (4221)\ttotal: 1m 6s\tremaining: 12.2s\n",
      "4223:\tlearn: 0.6032211\ttest: 0.5970885\tbest: 0.5970885 (4223)\ttotal: 1m 6s\tremaining: 12.1s\n",
      "4224:\tlearn: 0.6032211\ttest: 0.5970885\tbest: 0.5970885 (4223)\ttotal: 1m 6s\tremaining: 12.1s\n",
      "4225:\tlearn: 0.6031614\ttest: 0.5970163\tbest: 0.5970163 (4225)\ttotal: 1m 6s\tremaining: 12.1s\n",
      "4226:\tlearn: 0.6031567\ttest: 0.5970103\tbest: 0.5970103 (4226)\ttotal: 1m 6s\tremaining: 12.1s\n",
      "4227:\tlearn: 0.6031566\ttest: 0.5970103\tbest: 0.5970103 (4227)\ttotal: 1m 6s\tremaining: 12.1s\n",
      "4228:\tlearn: 0.6031566\ttest: 0.5970103\tbest: 0.5970103 (4227)\ttotal: 1m 6s\tremaining: 12.1s\n",
      "4229:\tlearn: 0.6031537\ttest: 0.5970093\tbest: 0.5970093 (4229)\ttotal: 1m 6s\tremaining: 12s\n",
      "4230:\tlearn: 0.6031537\ttest: 0.5970093\tbest: 0.5970093 (4229)\ttotal: 1m 6s\tremaining: 12s\n",
      "4231:\tlearn: 0.6031528\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 12s\n",
      "4232:\tlearn: 0.6031528\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 12s\n",
      "4233:\tlearn: 0.6031528\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 12s\n",
      "4234:\tlearn: 0.6031528\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 12s\n",
      "4235:\tlearn: 0.6031528\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4236:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4237:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4238:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4239:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4240:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4241:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.9s\n",
      "4242:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.8s\n",
      "4243:\tlearn: 0.6031525\ttest: 0.5970062\tbest: 0.5970062 (4231)\ttotal: 1m 6s\tremaining: 11.8s\n",
      "4244:\tlearn: 0.6031264\ttest: 0.5969891\tbest: 0.5969891 (4244)\ttotal: 1m 6s\tremaining: 11.8s\n",
      "4245:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.8s\n",
      "4246:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.8s\n",
      "4247:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.8s\n",
      "4248:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4249:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4250:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4251:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4252:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4253:\tlearn: 0.6031261\ttest: 0.5969889\tbest: 0.5969889 (4245)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4254:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "4255:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.6s\n",
      "4256:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.6s\n",
      "4257:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.6s\n",
      "4258:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.6s\n",
      "4259:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.6s\n",
      "4260:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.6s\n",
      "4261:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.5s\n",
      "4262:\tlearn: 0.6030699\ttest: 0.5969371\tbest: 0.5969371 (4254)\ttotal: 1m 6s\tremaining: 11.5s\n",
      "4263:\tlearn: 0.6030286\ttest: 0.5969069\tbest: 0.5969069 (4263)\ttotal: 1m 6s\tremaining: 11.5s\n",
      "4264:\tlearn: 0.6030286\ttest: 0.5969069\tbest: 0.5969069 (4263)\ttotal: 1m 6s\tremaining: 11.5s\n",
      "4265:\tlearn: 0.6030286\ttest: 0.5969069\tbest: 0.5969069 (4263)\ttotal: 1m 6s\tremaining: 11.5s\n",
      "4266:\tlearn: 0.6030285\ttest: 0.5969068\tbest: 0.5969068 (4266)\ttotal: 1m 6s\tremaining: 11.5s\n",
      "4267:\tlearn: 0.6030285\ttest: 0.5969068\tbest: 0.5969068 (4266)\ttotal: 1m 6s\tremaining: 11.4s\n",
      "4268:\tlearn: 0.6030285\ttest: 0.5969068\tbest: 0.5969068 (4266)\ttotal: 1m 6s\tremaining: 11.4s\n",
      "4269:\tlearn: 0.6030285\ttest: 0.5969068\tbest: 0.5969068 (4266)\ttotal: 1m 6s\tremaining: 11.4s\n",
      "4270:\tlearn: 0.6030285\ttest: 0.5969068\tbest: 0.5969068 (4266)\ttotal: 1m 6s\tremaining: 11.4s\n",
      "4271:\tlearn: 0.6030273\ttest: 0.5969058\tbest: 0.5969058 (4271)\ttotal: 1m 6s\tremaining: 11.4s\n",
      "4272:\tlearn: 0.6030273\ttest: 0.5969058\tbest: 0.5969058 (4271)\ttotal: 1m 6s\tremaining: 11.4s\n",
      "4273:\tlearn: 0.6030264\ttest: 0.5969051\tbest: 0.5969051 (4273)\ttotal: 1m 6s\tremaining: 11.3s\n",
      "4274:\tlearn: 0.6030116\ttest: 0.5968850\tbest: 0.5968850 (4274)\ttotal: 1m 6s\tremaining: 11.3s\n",
      "4275:\tlearn: 0.6030116\ttest: 0.5968850\tbest: 0.5968850 (4274)\ttotal: 1m 6s\tremaining: 11.3s\n",
      "4276:\tlearn: 0.6030116\ttest: 0.5968850\tbest: 0.5968850 (4274)\ttotal: 1m 6s\tremaining: 11.3s\n",
      "4277:\tlearn: 0.6029992\ttest: 0.5968696\tbest: 0.5968696 (4277)\ttotal: 1m 6s\tremaining: 11.3s\n",
      "4278:\tlearn: 0.6029977\ttest: 0.5968679\tbest: 0.5968679 (4278)\ttotal: 1m 6s\tremaining: 11.3s\n",
      "4279:\tlearn: 0.6029977\ttest: 0.5968679\tbest: 0.5968679 (4278)\ttotal: 1m 6s\tremaining: 11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280:\tlearn: 0.6029977\ttest: 0.5968679\tbest: 0.5968679 (4278)\ttotal: 1m 6s\tremaining: 11.2s\n",
      "4281:\tlearn: 0.6029977\ttest: 0.5968679\tbest: 0.5968679 (4278)\ttotal: 1m 6s\tremaining: 11.2s\n",
      "4282:\tlearn: 0.6029962\ttest: 0.5968663\tbest: 0.5968663 (4282)\ttotal: 1m 6s\tremaining: 11.2s\n",
      "4283:\tlearn: 0.6029953\ttest: 0.5968638\tbest: 0.5968638 (4283)\ttotal: 1m 6s\tremaining: 11.2s\n",
      "4284:\tlearn: 0.6029531\ttest: 0.5968173\tbest: 0.5968173 (4284)\ttotal: 1m 7s\tremaining: 11.2s\n",
      "4285:\tlearn: 0.6029531\ttest: 0.5968173\tbest: 0.5968173 (4284)\ttotal: 1m 7s\tremaining: 11.2s\n",
      "4286:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.2s\n",
      "4287:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.1s\n",
      "4288:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.1s\n",
      "4289:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.1s\n",
      "4290:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.1s\n",
      "4291:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.1s\n",
      "4292:\tlearn: 0.6029459\ttest: 0.5968085\tbest: 0.5968085 (4286)\ttotal: 1m 7s\tremaining: 11.1s\n",
      "4293:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 11s\n",
      "4294:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 11s\n",
      "4295:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 11s\n",
      "4296:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 11s\n",
      "4297:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 11s\n",
      "4298:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 11s\n",
      "4299:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 10.9s\n",
      "4300:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 10.9s\n",
      "4301:\tlearn: 0.6029295\ttest: 0.5967968\tbest: 0.5967968 (4293)\ttotal: 1m 7s\tremaining: 10.9s\n",
      "4302:\tlearn: 0.6029294\ttest: 0.5967967\tbest: 0.5967967 (4302)\ttotal: 1m 7s\tremaining: 10.9s\n",
      "4303:\tlearn: 0.6029294\ttest: 0.5967967\tbest: 0.5967967 (4302)\ttotal: 1m 7s\tremaining: 10.9s\n",
      "4304:\tlearn: 0.6029294\ttest: 0.5967967\tbest: 0.5967967 (4302)\ttotal: 1m 7s\tremaining: 10.9s\n",
      "4305:\tlearn: 0.6029293\ttest: 0.5967970\tbest: 0.5967967 (4302)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4306:\tlearn: 0.6029131\ttest: 0.5967724\tbest: 0.5967724 (4306)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4307:\tlearn: 0.6029131\ttest: 0.5967724\tbest: 0.5967724 (4306)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4308:\tlearn: 0.6029106\ttest: 0.5967714\tbest: 0.5967714 (4308)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4309:\tlearn: 0.6029102\ttest: 0.5967705\tbest: 0.5967705 (4309)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4310:\tlearn: 0.6029102\ttest: 0.5967705\tbest: 0.5967705 (4309)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4311:\tlearn: 0.6029102\ttest: 0.5967705\tbest: 0.5967705 (4309)\ttotal: 1m 7s\tremaining: 10.8s\n",
      "4312:\tlearn: 0.6029102\ttest: 0.5967705\tbest: 0.5967705 (4309)\ttotal: 1m 7s\tremaining: 10.7s\n",
      "4313:\tlearn: 0.6029102\ttest: 0.5967705\tbest: 0.5967705 (4309)\ttotal: 1m 7s\tremaining: 10.7s\n",
      "4314:\tlearn: 0.6028839\ttest: 0.5967429\tbest: 0.5967429 (4314)\ttotal: 1m 7s\tremaining: 10.7s\n",
      "4315:\tlearn: 0.6028839\ttest: 0.5967429\tbest: 0.5967429 (4314)\ttotal: 1m 7s\tremaining: 10.7s\n",
      "4316:\tlearn: 0.6028839\ttest: 0.5967429\tbest: 0.5967429 (4314)\ttotal: 1m 7s\tremaining: 10.7s\n",
      "4317:\tlearn: 0.6028839\ttest: 0.5967429\tbest: 0.5967429 (4314)\ttotal: 1m 7s\tremaining: 10.7s\n",
      "4318:\tlearn: 0.6028813\ttest: 0.5967402\tbest: 0.5967402 (4318)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4319:\tlearn: 0.6028813\ttest: 0.5967402\tbest: 0.5967402 (4318)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4320:\tlearn: 0.6028777\ttest: 0.5967366\tbest: 0.5967366 (4320)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4321:\tlearn: 0.6028757\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4322:\tlearn: 0.6028757\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4323:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4324:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.6s\n",
      "4325:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.5s\n",
      "4326:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.5s\n",
      "4327:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.5s\n",
      "4328:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.5s\n",
      "4329:\tlearn: 0.6028754\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.5s\n",
      "4330:\tlearn: 0.6028735\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.5s\n",
      "4331:\tlearn: 0.6028727\ttest: 0.5967362\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.4s\n",
      "4332:\tlearn: 0.6028720\ttest: 0.5967357\tbest: 0.5967357 (4321)\ttotal: 1m 7s\tremaining: 10.4s\n",
      "4333:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.4s\n",
      "4334:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.4s\n",
      "4335:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.4s\n",
      "4336:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.4s\n",
      "4337:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4338:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4339:\tlearn: 0.6028515\ttest: 0.5967204\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4340:\tlearn: 0.6028515\ttest: 0.5967205\tbest: 0.5967204 (4333)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4341:\tlearn: 0.6028041\ttest: 0.5966717\tbest: 0.5966717 (4341)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4342:\tlearn: 0.6027980\ttest: 0.5966646\tbest: 0.5966646 (4342)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4343:\tlearn: 0.6027980\ttest: 0.5966646\tbest: 0.5966646 (4342)\ttotal: 1m 7s\tremaining: 10.3s\n",
      "4344:\tlearn: 0.6027980\ttest: 0.5966646\tbest: 0.5966646 (4342)\ttotal: 1m 7s\tremaining: 10.2s\n",
      "4345:\tlearn: 0.6027969\ttest: 0.5966632\tbest: 0.5966632 (4345)\ttotal: 1m 7s\tremaining: 10.2s\n",
      "4346:\tlearn: 0.6027969\ttest: 0.5966632\tbest: 0.5966632 (4345)\ttotal: 1m 7s\tremaining: 10.2s\n",
      "4347:\tlearn: 0.6027969\ttest: 0.5966632\tbest: 0.5966632 (4345)\ttotal: 1m 7s\tremaining: 10.2s\n",
      "4348:\tlearn: 0.6027969\ttest: 0.5966632\tbest: 0.5966632 (4345)\ttotal: 1m 7s\tremaining: 10.2s\n",
      "4349:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.2s\n",
      "4350:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4351:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4352:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4353:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4354:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4355:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4356:\tlearn: 0.6027968\ttest: 0.5966631\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10.1s\n",
      "4357:\tlearn: 0.6027966\ttest: 0.5966633\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10s\n",
      "4358:\tlearn: 0.6027966\ttest: 0.5966633\tbest: 0.5966631 (4349)\ttotal: 1m 8s\tremaining: 10s\n",
      "4359:\tlearn: 0.6027594\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 10s\n",
      "4360:\tlearn: 0.6027594\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.99s\n",
      "4361:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.97s\n",
      "4362:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.96s\n",
      "4363:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.94s\n",
      "4364:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.93s\n",
      "4365:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.91s\n",
      "4366:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.89s\n",
      "4367:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.88s\n",
      "4368:\tlearn: 0.6027590\ttest: 0.5966134\tbest: 0.5966134 (4359)\ttotal: 1m 8s\tremaining: 9.86s\n",
      "4369:\tlearn: 0.6027562\ttest: 0.5966092\tbest: 0.5966092 (4369)\ttotal: 1m 8s\tremaining: 9.85s\n",
      "4370:\tlearn: 0.6027562\ttest: 0.5966092\tbest: 0.5966092 (4369)\ttotal: 1m 8s\tremaining: 9.83s\n",
      "4371:\tlearn: 0.6027536\ttest: 0.5966074\tbest: 0.5966074 (4371)\ttotal: 1m 8s\tremaining: 9.81s\n",
      "4372:\tlearn: 0.6027536\ttest: 0.5966074\tbest: 0.5966074 (4371)\ttotal: 1m 8s\tremaining: 9.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373:\tlearn: 0.6027535\ttest: 0.5966073\tbest: 0.5966073 (4373)\ttotal: 1m 8s\tremaining: 9.78s\n",
      "4374:\tlearn: 0.6027535\ttest: 0.5966073\tbest: 0.5966073 (4373)\ttotal: 1m 8s\tremaining: 9.77s\n",
      "4375:\tlearn: 0.6027535\ttest: 0.5966073\tbest: 0.5966073 (4373)\ttotal: 1m 8s\tremaining: 9.75s\n",
      "4376:\tlearn: 0.6027535\ttest: 0.5966073\tbest: 0.5966073 (4373)\ttotal: 1m 8s\tremaining: 9.73s\n",
      "4377:\tlearn: 0.6027535\ttest: 0.5966073\tbest: 0.5966073 (4373)\ttotal: 1m 8s\tremaining: 9.72s\n",
      "4378:\tlearn: 0.6027522\ttest: 0.5966049\tbest: 0.5966049 (4378)\ttotal: 1m 8s\tremaining: 9.7s\n",
      "4379:\tlearn: 0.6027494\ttest: 0.5966013\tbest: 0.5966013 (4379)\ttotal: 1m 8s\tremaining: 9.69s\n",
      "4380:\tlearn: 0.6027494\ttest: 0.5966013\tbest: 0.5966013 (4379)\ttotal: 1m 8s\tremaining: 9.68s\n",
      "4381:\tlearn: 0.6027473\ttest: 0.5965995\tbest: 0.5965995 (4381)\ttotal: 1m 8s\tremaining: 9.66s\n",
      "4382:\tlearn: 0.6027473\ttest: 0.5965995\tbest: 0.5965995 (4381)\ttotal: 1m 8s\tremaining: 9.64s\n",
      "4383:\tlearn: 0.6027461\ttest: 0.5965983\tbest: 0.5965983 (4383)\ttotal: 1m 8s\tremaining: 9.63s\n",
      "4384:\tlearn: 0.6027461\ttest: 0.5965983\tbest: 0.5965983 (4383)\ttotal: 1m 8s\tremaining: 9.62s\n",
      "4385:\tlearn: 0.6027446\ttest: 0.5965943\tbest: 0.5965943 (4385)\ttotal: 1m 8s\tremaining: 9.6s\n",
      "4386:\tlearn: 0.6027444\ttest: 0.5965949\tbest: 0.5965943 (4385)\ttotal: 1m 8s\tremaining: 9.59s\n",
      "4387:\tlearn: 0.6027444\ttest: 0.5965949\tbest: 0.5965943 (4385)\ttotal: 1m 8s\tremaining: 9.57s\n",
      "4388:\tlearn: 0.6027444\ttest: 0.5965949\tbest: 0.5965943 (4385)\ttotal: 1m 8s\tremaining: 9.55s\n",
      "4389:\tlearn: 0.6027443\ttest: 0.5965949\tbest: 0.5965943 (4385)\ttotal: 1m 8s\tremaining: 9.54s\n",
      "4390:\tlearn: 0.6027425\ttest: 0.5965935\tbest: 0.5965935 (4390)\ttotal: 1m 8s\tremaining: 9.53s\n",
      "4391:\tlearn: 0.6027425\ttest: 0.5965935\tbest: 0.5965935 (4390)\ttotal: 1m 8s\tremaining: 9.51s\n",
      "4392:\tlearn: 0.6027419\ttest: 0.5965911\tbest: 0.5965911 (4392)\ttotal: 1m 8s\tremaining: 9.49s\n",
      "4393:\tlearn: 0.6027419\ttest: 0.5965911\tbest: 0.5965911 (4392)\ttotal: 1m 8s\tremaining: 9.48s\n",
      "4394:\tlearn: 0.6027379\ttest: 0.5965884\tbest: 0.5965884 (4394)\ttotal: 1m 8s\tremaining: 9.46s\n",
      "4395:\tlearn: 0.6027379\ttest: 0.5965884\tbest: 0.5965884 (4394)\ttotal: 1m 8s\tremaining: 9.45s\n",
      "4396:\tlearn: 0.6027379\ttest: 0.5965884\tbest: 0.5965884 (4394)\ttotal: 1m 8s\tremaining: 9.43s\n",
      "4397:\tlearn: 0.6027379\ttest: 0.5965884\tbest: 0.5965884 (4394)\ttotal: 1m 8s\tremaining: 9.41s\n",
      "4398:\tlearn: 0.6027379\ttest: 0.5965884\tbest: 0.5965884 (4394)\ttotal: 1m 8s\tremaining: 9.4s\n",
      "4399:\tlearn: 0.6027379\ttest: 0.5965884\tbest: 0.5965884 (4394)\ttotal: 1m 8s\tremaining: 9.38s\n",
      "4400:\tlearn: 0.6027341\ttest: 0.5965852\tbest: 0.5965852 (4400)\ttotal: 1m 8s\tremaining: 9.37s\n",
      "4401:\tlearn: 0.6027340\ttest: 0.5965853\tbest: 0.5965852 (4400)\ttotal: 1m 8s\tremaining: 9.35s\n",
      "4402:\tlearn: 0.6027203\ttest: 0.5965753\tbest: 0.5965753 (4402)\ttotal: 1m 8s\tremaining: 9.34s\n",
      "4403:\tlearn: 0.6027203\ttest: 0.5965753\tbest: 0.5965753 (4402)\ttotal: 1m 8s\tremaining: 9.32s\n",
      "4404:\tlearn: 0.6027190\ttest: 0.5965747\tbest: 0.5965747 (4404)\ttotal: 1m 8s\tremaining: 9.31s\n",
      "4405:\tlearn: 0.6027190\ttest: 0.5965747\tbest: 0.5965747 (4404)\ttotal: 1m 8s\tremaining: 9.29s\n",
      "4406:\tlearn: 0.6027190\ttest: 0.5965747\tbest: 0.5965747 (4404)\ttotal: 1m 8s\tremaining: 9.28s\n",
      "4407:\tlearn: 0.6027190\ttest: 0.5965747\tbest: 0.5965747 (4404)\ttotal: 1m 8s\tremaining: 9.26s\n",
      "4408:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 8s\tremaining: 9.25s\n",
      "4409:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.23s\n",
      "4410:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.21s\n",
      "4411:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.2s\n",
      "4412:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.18s\n",
      "4413:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.17s\n",
      "4414:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.15s\n",
      "4415:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.14s\n",
      "4416:\tlearn: 0.6027160\ttest: 0.5965742\tbest: 0.5965742 (4408)\ttotal: 1m 9s\tremaining: 9.12s\n",
      "4417:\tlearn: 0.6027120\ttest: 0.5965708\tbest: 0.5965708 (4417)\ttotal: 1m 9s\tremaining: 9.1s\n",
      "4418:\tlearn: 0.6027120\ttest: 0.5965708\tbest: 0.5965708 (4417)\ttotal: 1m 9s\tremaining: 9.09s\n",
      "4419:\tlearn: 0.6027120\ttest: 0.5965708\tbest: 0.5965708 (4417)\ttotal: 1m 9s\tremaining: 9.07s\n",
      "4420:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4420)\ttotal: 1m 9s\tremaining: 9.06s\n",
      "4421:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 9.04s\n",
      "4422:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 9.03s\n",
      "4423:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 9.01s\n",
      "4424:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.99s\n",
      "4425:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.98s\n",
      "4426:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.96s\n",
      "4427:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.95s\n",
      "4428:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.93s\n",
      "4429:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.91s\n",
      "4430:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.9s\n",
      "4431:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.88s\n",
      "4432:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.87s\n",
      "4433:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.85s\n",
      "4434:\tlearn: 0.6027097\ttest: 0.5965700\tbest: 0.5965700 (4421)\ttotal: 1m 9s\tremaining: 8.84s\n",
      "4435:\tlearn: 0.6027068\ttest: 0.5965675\tbest: 0.5965675 (4435)\ttotal: 1m 9s\tremaining: 8.82s\n",
      "4436:\tlearn: 0.6027068\ttest: 0.5965675\tbest: 0.5965675 (4435)\ttotal: 1m 9s\tremaining: 8.8s\n",
      "4437:\tlearn: 0.6027068\ttest: 0.5965675\tbest: 0.5965675 (4437)\ttotal: 1m 9s\tremaining: 8.79s\n",
      "4438:\tlearn: 0.6027068\ttest: 0.5965675\tbest: 0.5965675 (4437)\ttotal: 1m 9s\tremaining: 8.77s\n",
      "4439:\tlearn: 0.6027068\ttest: 0.5965675\tbest: 0.5965675 (4437)\ttotal: 1m 9s\tremaining: 8.76s\n",
      "4440:\tlearn: 0.6027068\ttest: 0.5965675\tbest: 0.5965675 (4437)\ttotal: 1m 9s\tremaining: 8.74s\n",
      "4441:\tlearn: 0.6026964\ttest: 0.5965604\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.73s\n",
      "4442:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.71s\n",
      "4443:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.7s\n",
      "4444:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.68s\n",
      "4445:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.66s\n",
      "4446:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.65s\n",
      "4447:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.63s\n",
      "4448:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.62s\n",
      "4449:\tlearn: 0.6026956\ttest: 0.5965606\tbest: 0.5965604 (4441)\ttotal: 1m 9s\tremaining: 8.6s\n",
      "4450:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.59s\n",
      "4451:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.57s\n",
      "4452:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.55s\n",
      "4453:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.54s\n",
      "4454:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.52s\n",
      "4455:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.51s\n",
      "4456:\tlearn: 0.6026950\ttest: 0.5965583\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.49s\n",
      "4457:\tlearn: 0.6026950\ttest: 0.5965584\tbest: 0.5965583 (4450)\ttotal: 1m 9s\tremaining: 8.48s\n",
      "4458:\tlearn: 0.6026885\ttest: 0.5965520\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.46s\n",
      "4459:\tlearn: 0.6026885\ttest: 0.5965521\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.45s\n",
      "4460:\tlearn: 0.6026885\ttest: 0.5965521\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.43s\n",
      "4461:\tlearn: 0.6026885\ttest: 0.5965521\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.42s\n",
      "4462:\tlearn: 0.6026885\ttest: 0.5965521\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.4s\n",
      "4463:\tlearn: 0.6026885\ttest: 0.5965521\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.38s\n",
      "4464:\tlearn: 0.6026884\ttest: 0.5965520\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.37s\n",
      "4465:\tlearn: 0.6026884\ttest: 0.5965520\tbest: 0.5965520 (4458)\ttotal: 1m 9s\tremaining: 8.35s\n",
      "4466:\tlearn: 0.6026352\ttest: 0.5964878\tbest: 0.5964878 (4466)\ttotal: 1m 9s\tremaining: 8.34s\n",
      "4467:\tlearn: 0.6026352\ttest: 0.5964878\tbest: 0.5964878 (4466)\ttotal: 1m 9s\tremaining: 8.32s\n",
      "4468:\tlearn: 0.6026339\ttest: 0.5964880\tbest: 0.5964878 (4466)\ttotal: 1m 9s\tremaining: 8.31s\n",
      "4469:\tlearn: 0.6026335\ttest: 0.5964871\tbest: 0.5964871 (4469)\ttotal: 1m 9s\tremaining: 8.29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4470:\tlearn: 0.6026335\ttest: 0.5964871\tbest: 0.5964871 (4469)\ttotal: 1m 9s\tremaining: 8.28s\n",
      "4471:\tlearn: 0.6026335\ttest: 0.5964871\tbest: 0.5964871 (4471)\ttotal: 1m 9s\tremaining: 8.26s\n",
      "4472:\tlearn: 0.6026335\ttest: 0.5964871\tbest: 0.5964871 (4471)\ttotal: 1m 9s\tremaining: 8.24s\n",
      "4473:\tlearn: 0.6026335\ttest: 0.5964871\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.23s\n",
      "4474:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.21s\n",
      "4475:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.2s\n",
      "4476:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.18s\n",
      "4477:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.16s\n",
      "4478:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.15s\n",
      "4479:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.13s\n",
      "4480:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.12s\n",
      "4481:\tlearn: 0.6026335\ttest: 0.5964872\tbest: 0.5964871 (4471)\ttotal: 1m 10s\tremaining: 8.1s\n",
      "4482:\tlearn: 0.6026333\ttest: 0.5964870\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 8.09s\n",
      "4483:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 8.07s\n",
      "4484:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 8.05s\n",
      "4485:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 8.04s\n",
      "4486:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 8.02s\n",
      "4487:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 8.01s\n",
      "4488:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.99s\n",
      "4489:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.97s\n",
      "4490:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.96s\n",
      "4491:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.94s\n",
      "4492:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.93s\n",
      "4493:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.91s\n",
      "4494:\tlearn: 0.6026321\ttest: 0.5964873\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.89s\n",
      "4495:\tlearn: 0.6026321\ttest: 0.5964875\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.88s\n",
      "4496:\tlearn: 0.6026321\ttest: 0.5964875\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.86s\n",
      "4497:\tlearn: 0.6026321\ttest: 0.5964875\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.85s\n",
      "4498:\tlearn: 0.6026320\ttest: 0.5964875\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.83s\n",
      "4499:\tlearn: 0.6026320\ttest: 0.5964875\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.82s\n",
      "4500:\tlearn: 0.6026320\ttest: 0.5964875\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.8s\n",
      "4501:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.78s\n",
      "4502:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.77s\n",
      "4503:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.75s\n",
      "4504:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.74s\n",
      "4505:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.72s\n",
      "4506:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.7s\n",
      "4507:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.69s\n",
      "4508:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.67s\n",
      "4509:\tlearn: 0.6026308\ttest: 0.5964878\tbest: 0.5964870 (4482)\ttotal: 1m 10s\tremaining: 7.66s\n",
      "4510:\tlearn: 0.6026268\ttest: 0.5964846\tbest: 0.5964846 (4510)\ttotal: 1m 10s\tremaining: 7.64s\n",
      "4511:\tlearn: 0.6026241\ttest: 0.5964833\tbest: 0.5964833 (4511)\ttotal: 1m 10s\tremaining: 7.63s\n",
      "4512:\tlearn: 0.6026241\ttest: 0.5964833\tbest: 0.5964833 (4511)\ttotal: 1m 10s\tremaining: 7.61s\n",
      "4513:\tlearn: 0.6026241\ttest: 0.5964833\tbest: 0.5964833 (4511)\ttotal: 1m 10s\tremaining: 7.59s\n",
      "4514:\tlearn: 0.6026241\ttest: 0.5964833\tbest: 0.5964833 (4511)\ttotal: 1m 10s\tremaining: 7.58s\n",
      "4515:\tlearn: 0.6026240\ttest: 0.5964831\tbest: 0.5964831 (4515)\ttotal: 1m 10s\tremaining: 7.56s\n",
      "4516:\tlearn: 0.6026240\ttest: 0.5964831\tbest: 0.5964831 (4515)\ttotal: 1m 10s\tremaining: 7.54s\n",
      "4517:\tlearn: 0.6026240\ttest: 0.5964831\tbest: 0.5964831 (4515)\ttotal: 1m 10s\tremaining: 7.53s\n",
      "4518:\tlearn: 0.6026240\ttest: 0.5964831\tbest: 0.5964831 (4515)\ttotal: 1m 10s\tremaining: 7.51s\n",
      "4519:\tlearn: 0.6025743\ttest: 0.5964357\tbest: 0.5964357 (4519)\ttotal: 1m 10s\tremaining: 7.5s\n",
      "4520:\tlearn: 0.6025743\ttest: 0.5964357\tbest: 0.5964357 (4519)\ttotal: 1m 10s\tremaining: 7.48s\n",
      "4521:\tlearn: 0.6025727\ttest: 0.5964362\tbest: 0.5964357 (4519)\ttotal: 1m 10s\tremaining: 7.47s\n",
      "4522:\tlearn: 0.6025718\ttest: 0.5964350\tbest: 0.5964350 (4522)\ttotal: 1m 10s\tremaining: 7.45s\n",
      "4523:\tlearn: 0.6025718\ttest: 0.5964350\tbest: 0.5964350 (4522)\ttotal: 1m 10s\tremaining: 7.44s\n",
      "4524:\tlearn: 0.6025507\ttest: 0.5964226\tbest: 0.5964226 (4524)\ttotal: 1m 10s\tremaining: 7.42s\n",
      "4525:\tlearn: 0.6025474\ttest: 0.5964215\tbest: 0.5964215 (4525)\ttotal: 1m 10s\tremaining: 7.41s\n",
      "4526:\tlearn: 0.6025469\ttest: 0.5964207\tbest: 0.5964207 (4526)\ttotal: 1m 10s\tremaining: 7.39s\n",
      "4527:\tlearn: 0.6025469\ttest: 0.5964207\tbest: 0.5964207 (4526)\ttotal: 1m 10s\tremaining: 7.38s\n",
      "4528:\tlearn: 0.6025469\ttest: 0.5964207\tbest: 0.5964207 (4526)\ttotal: 1m 10s\tremaining: 7.36s\n",
      "4529:\tlearn: 0.6025469\ttest: 0.5964207\tbest: 0.5964207 (4526)\ttotal: 1m 10s\tremaining: 7.34s\n",
      "4530:\tlearn: 0.6025469\ttest: 0.5964207\tbest: 0.5964207 (4526)\ttotal: 1m 10s\tremaining: 7.33s\n",
      "4531:\tlearn: 0.6025398\ttest: 0.5964136\tbest: 0.5964136 (4531)\ttotal: 1m 10s\tremaining: 7.31s\n",
      "4532:\tlearn: 0.6025398\ttest: 0.5964136\tbest: 0.5964136 (4531)\ttotal: 1m 10s\tremaining: 7.3s\n",
      "4533:\tlearn: 0.6025398\ttest: 0.5964136\tbest: 0.5964136 (4531)\ttotal: 1m 10s\tremaining: 7.28s\n",
      "4534:\tlearn: 0.6025398\ttest: 0.5964136\tbest: 0.5964136 (4531)\ttotal: 1m 10s\tremaining: 7.27s\n",
      "4535:\tlearn: 0.6025398\ttest: 0.5964136\tbest: 0.5964136 (4531)\ttotal: 1m 10s\tremaining: 7.25s\n",
      "4536:\tlearn: 0.6025379\ttest: 0.5964122\tbest: 0.5964122 (4536)\ttotal: 1m 10s\tremaining: 7.24s\n",
      "4537:\tlearn: 0.6025130\ttest: 0.5963916\tbest: 0.5963916 (4537)\ttotal: 1m 10s\tremaining: 7.22s\n",
      "4538:\tlearn: 0.6025130\ttest: 0.5963916\tbest: 0.5963916 (4537)\ttotal: 1m 10s\tremaining: 7.21s\n",
      "4539:\tlearn: 0.6025130\ttest: 0.5963916\tbest: 0.5963916 (4537)\ttotal: 1m 10s\tremaining: 7.19s\n",
      "4540:\tlearn: 0.6024895\ttest: 0.5963723\tbest: 0.5963723 (4540)\ttotal: 1m 10s\tremaining: 7.17s\n",
      "4541:\tlearn: 0.6024888\ttest: 0.5963712\tbest: 0.5963712 (4541)\ttotal: 1m 11s\tremaining: 7.16s\n",
      "4542:\tlearn: 0.6024888\ttest: 0.5963712\tbest: 0.5963712 (4541)\ttotal: 1m 11s\tremaining: 7.14s\n",
      "4543:\tlearn: 0.6024863\ttest: 0.5963686\tbest: 0.5963686 (4543)\ttotal: 1m 11s\tremaining: 7.13s\n",
      "4544:\tlearn: 0.6024863\ttest: 0.5963686\tbest: 0.5963686 (4543)\ttotal: 1m 11s\tremaining: 7.12s\n",
      "4545:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7.1s\n",
      "4546:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7.08s\n",
      "4547:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7.07s\n",
      "4548:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7.05s\n",
      "4549:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7.04s\n",
      "4550:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7.02s\n",
      "4551:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 7s\n",
      "4552:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 6.99s\n",
      "4553:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 6.97s\n",
      "4554:\tlearn: 0.6024841\ttest: 0.5963667\tbest: 0.5963667 (4545)\ttotal: 1m 11s\tremaining: 6.96s\n",
      "4555:\tlearn: 0.6024816\ttest: 0.5963652\tbest: 0.5963652 (4555)\ttotal: 1m 11s\tremaining: 6.94s\n",
      "4556:\tlearn: 0.6024815\ttest: 0.5963653\tbest: 0.5963652 (4555)\ttotal: 1m 11s\tremaining: 6.92s\n",
      "4557:\tlearn: 0.6024815\ttest: 0.5963653\tbest: 0.5963652 (4555)\ttotal: 1m 11s\tremaining: 6.91s\n",
      "4558:\tlearn: 0.6024815\ttest: 0.5963653\tbest: 0.5963652 (4555)\ttotal: 1m 11s\tremaining: 6.89s\n",
      "4559:\tlearn: 0.6024815\ttest: 0.5963653\tbest: 0.5963652 (4555)\ttotal: 1m 11s\tremaining: 6.88s\n",
      "4560:\tlearn: 0.6024803\ttest: 0.5963630\tbest: 0.5963630 (4560)\ttotal: 1m 11s\tremaining: 6.86s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4561:\tlearn: 0.6024802\ttest: 0.5963632\tbest: 0.5963630 (4560)\ttotal: 1m 11s\tremaining: 6.85s\n",
      "4562:\tlearn: 0.6024802\ttest: 0.5963632\tbest: 0.5963630 (4560)\ttotal: 1m 11s\tremaining: 6.83s\n",
      "4563:\tlearn: 0.6024789\ttest: 0.5963626\tbest: 0.5963626 (4563)\ttotal: 1m 11s\tremaining: 6.82s\n",
      "4564:\tlearn: 0.6024789\ttest: 0.5963626\tbest: 0.5963626 (4563)\ttotal: 1m 11s\tremaining: 6.8s\n",
      "4565:\tlearn: 0.6024738\ttest: 0.5963579\tbest: 0.5963579 (4565)\ttotal: 1m 11s\tremaining: 6.79s\n",
      "4566:\tlearn: 0.6024736\ttest: 0.5963575\tbest: 0.5963575 (4566)\ttotal: 1m 11s\tremaining: 6.77s\n",
      "4567:\tlearn: 0.6024736\ttest: 0.5963575\tbest: 0.5963575 (4566)\ttotal: 1m 11s\tremaining: 6.75s\n",
      "4568:\tlearn: 0.6024736\ttest: 0.5963575\tbest: 0.5963575 (4566)\ttotal: 1m 11s\tremaining: 6.74s\n",
      "4569:\tlearn: 0.6024732\ttest: 0.5963569\tbest: 0.5963569 (4569)\ttotal: 1m 11s\tremaining: 6.72s\n",
      "4570:\tlearn: 0.6024732\ttest: 0.5963569\tbest: 0.5963569 (4569)\ttotal: 1m 11s\tremaining: 6.71s\n",
      "4571:\tlearn: 0.6024732\ttest: 0.5963570\tbest: 0.5963569 (4569)\ttotal: 1m 11s\tremaining: 6.69s\n",
      "4572:\tlearn: 0.6024701\ttest: 0.5963505\tbest: 0.5963505 (4572)\ttotal: 1m 11s\tremaining: 6.67s\n",
      "4573:\tlearn: 0.6024701\ttest: 0.5963505\tbest: 0.5963505 (4572)\ttotal: 1m 11s\tremaining: 6.66s\n",
      "4574:\tlearn: 0.6024684\ttest: 0.5963489\tbest: 0.5963489 (4574)\ttotal: 1m 11s\tremaining: 6.64s\n",
      "4575:\tlearn: 0.6024684\ttest: 0.5963489\tbest: 0.5963489 (4574)\ttotal: 1m 11s\tremaining: 6.63s\n",
      "4576:\tlearn: 0.6024684\ttest: 0.5963489\tbest: 0.5963489 (4574)\ttotal: 1m 11s\tremaining: 6.61s\n",
      "4577:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4577)\ttotal: 1m 11s\tremaining: 6.6s\n",
      "4578:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4577)\ttotal: 1m 11s\tremaining: 6.58s\n",
      "4579:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4579)\ttotal: 1m 11s\tremaining: 6.57s\n",
      "4580:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4579)\ttotal: 1m 11s\tremaining: 6.55s\n",
      "4581:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4579)\ttotal: 1m 11s\tremaining: 6.54s\n",
      "4582:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4579)\ttotal: 1m 11s\tremaining: 6.52s\n",
      "4583:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4579)\ttotal: 1m 11s\tremaining: 6.5s\n",
      "4584:\tlearn: 0.6024671\ttest: 0.5963478\tbest: 0.5963478 (4579)\ttotal: 1m 11s\tremaining: 6.49s\n",
      "4585:\tlearn: 0.6024607\ttest: 0.5963383\tbest: 0.5963383 (4585)\ttotal: 1m 11s\tremaining: 6.47s\n",
      "4586:\tlearn: 0.6024607\ttest: 0.5963383\tbest: 0.5963383 (4585)\ttotal: 1m 11s\tremaining: 6.46s\n",
      "4587:\tlearn: 0.6024605\ttest: 0.5963383\tbest: 0.5963383 (4585)\ttotal: 1m 11s\tremaining: 6.44s\n",
      "4588:\tlearn: 0.6024605\ttest: 0.5963383\tbest: 0.5963383 (4585)\ttotal: 1m 11s\tremaining: 6.43s\n",
      "4589:\tlearn: 0.6024456\ttest: 0.5963253\tbest: 0.5963253 (4589)\ttotal: 1m 11s\tremaining: 6.41s\n",
      "4590:\tlearn: 0.6024456\ttest: 0.5963253\tbest: 0.5963253 (4590)\ttotal: 1m 11s\tremaining: 6.4s\n",
      "4591:\tlearn: 0.6024456\ttest: 0.5963253\tbest: 0.5963253 (4590)\ttotal: 1m 11s\tremaining: 6.38s\n",
      "4592:\tlearn: 0.6024454\ttest: 0.5963254\tbest: 0.5963253 (4590)\ttotal: 1m 11s\tremaining: 6.37s\n",
      "4593:\tlearn: 0.6024454\ttest: 0.5963254\tbest: 0.5963253 (4590)\ttotal: 1m 11s\tremaining: 6.35s\n",
      "4594:\tlearn: 0.6024426\ttest: 0.5963211\tbest: 0.5963211 (4594)\ttotal: 1m 11s\tremaining: 6.33s\n",
      "4595:\tlearn: 0.6024426\ttest: 0.5963211\tbest: 0.5963211 (4594)\ttotal: 1m 11s\tremaining: 6.32s\n",
      "4596:\tlearn: 0.6024426\ttest: 0.5963211\tbest: 0.5963211 (4594)\ttotal: 1m 11s\tremaining: 6.3s\n",
      "4597:\tlearn: 0.6024426\ttest: 0.5963211\tbest: 0.5963211 (4594)\ttotal: 1m 11s\tremaining: 6.29s\n",
      "4598:\tlearn: 0.6024425\ttest: 0.5963210\tbest: 0.5963210 (4598)\ttotal: 1m 11s\tremaining: 6.27s\n",
      "4599:\tlearn: 0.6024424\ttest: 0.5963205\tbest: 0.5963205 (4599)\ttotal: 1m 11s\tremaining: 6.26s\n",
      "4600:\tlearn: 0.6024424\ttest: 0.5963205\tbest: 0.5963205 (4599)\ttotal: 1m 11s\tremaining: 6.24s\n",
      "4601:\tlearn: 0.6024424\ttest: 0.5963205\tbest: 0.5963205 (4599)\ttotal: 1m 11s\tremaining: 6.22s\n",
      "4602:\tlearn: 0.6024419\ttest: 0.5963205\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.21s\n",
      "4603:\tlearn: 0.6024418\ttest: 0.5963210\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.19s\n",
      "4604:\tlearn: 0.6024418\ttest: 0.5963210\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.18s\n",
      "4605:\tlearn: 0.6024418\ttest: 0.5963210\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.16s\n",
      "4606:\tlearn: 0.6024418\ttest: 0.5963210\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.15s\n",
      "4607:\tlearn: 0.6024416\ttest: 0.5963207\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.13s\n",
      "4608:\tlearn: 0.6024416\ttest: 0.5963207\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.12s\n",
      "4609:\tlearn: 0.6024416\ttest: 0.5963207\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.1s\n",
      "4610:\tlearn: 0.6024416\ttest: 0.5963207\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.08s\n",
      "4611:\tlearn: 0.6024416\ttest: 0.5963207\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.07s\n",
      "4612:\tlearn: 0.6024416\ttest: 0.5963207\tbest: 0.5963205 (4599)\ttotal: 1m 12s\tremaining: 6.05s\n",
      "4613:\tlearn: 0.6024402\ttest: 0.5963182\tbest: 0.5963182 (4613)\ttotal: 1m 12s\tremaining: 6.04s\n",
      "4614:\tlearn: 0.6024402\ttest: 0.5963182\tbest: 0.5963182 (4613)\ttotal: 1m 12s\tremaining: 6.02s\n",
      "4615:\tlearn: 0.6024402\ttest: 0.5963182\tbest: 0.5963182 (4613)\ttotal: 1m 12s\tremaining: 6.01s\n",
      "4616:\tlearn: 0.6024402\ttest: 0.5963181\tbest: 0.5963181 (4616)\ttotal: 1m 12s\tremaining: 5.99s\n",
      "4617:\tlearn: 0.6024402\ttest: 0.5963181\tbest: 0.5963181 (4616)\ttotal: 1m 12s\tremaining: 5.97s\n",
      "4618:\tlearn: 0.6024398\ttest: 0.5963179\tbest: 0.5963179 (4618)\ttotal: 1m 12s\tremaining: 5.96s\n",
      "4619:\tlearn: 0.6024398\ttest: 0.5963179\tbest: 0.5963179 (4618)\ttotal: 1m 12s\tremaining: 5.94s\n",
      "4620:\tlearn: 0.6024363\ttest: 0.5963160\tbest: 0.5963160 (4620)\ttotal: 1m 12s\tremaining: 5.93s\n",
      "4621:\tlearn: 0.6024299\ttest: 0.5963113\tbest: 0.5963113 (4621)\ttotal: 1m 12s\tremaining: 5.91s\n",
      "4622:\tlearn: 0.6024299\ttest: 0.5963113\tbest: 0.5963113 (4621)\ttotal: 1m 12s\tremaining: 5.9s\n",
      "4623:\tlearn: 0.6024299\ttest: 0.5963113\tbest: 0.5963113 (4621)\ttotal: 1m 12s\tremaining: 5.88s\n",
      "4624:\tlearn: 0.6024299\ttest: 0.5963113\tbest: 0.5963113 (4621)\ttotal: 1m 12s\tremaining: 5.86s\n",
      "4625:\tlearn: 0.6024298\ttest: 0.5963113\tbest: 0.5963113 (4621)\ttotal: 1m 12s\tremaining: 5.85s\n",
      "4626:\tlearn: 0.6024298\ttest: 0.5963113\tbest: 0.5963113 (4621)\ttotal: 1m 12s\tremaining: 5.83s\n",
      "4627:\tlearn: 0.6024271\ttest: 0.5963102\tbest: 0.5963102 (4627)\ttotal: 1m 12s\tremaining: 5.82s\n",
      "4628:\tlearn: 0.6024271\ttest: 0.5963102\tbest: 0.5963102 (4627)\ttotal: 1m 12s\tremaining: 5.8s\n",
      "4629:\tlearn: 0.6024260\ttest: 0.5963093\tbest: 0.5963093 (4629)\ttotal: 1m 12s\tremaining: 5.79s\n",
      "4630:\tlearn: 0.6024125\ttest: 0.5963003\tbest: 0.5963003 (4630)\ttotal: 1m 12s\tremaining: 5.77s\n",
      "4631:\tlearn: 0.6024125\ttest: 0.5963003\tbest: 0.5963003 (4630)\ttotal: 1m 12s\tremaining: 5.75s\n",
      "4632:\tlearn: 0.6024083\ttest: 0.5962949\tbest: 0.5962949 (4632)\ttotal: 1m 12s\tremaining: 5.74s\n",
      "4633:\tlearn: 0.6024083\ttest: 0.5962949\tbest: 0.5962949 (4632)\ttotal: 1m 12s\tremaining: 5.72s\n",
      "4634:\tlearn: 0.6024083\ttest: 0.5962949\tbest: 0.5962949 (4632)\ttotal: 1m 12s\tremaining: 5.71s\n",
      "4635:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4635)\ttotal: 1m 12s\tremaining: 5.69s\n",
      "4636:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4635)\ttotal: 1m 12s\tremaining: 5.67s\n",
      "4637:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4635)\ttotal: 1m 12s\tremaining: 5.66s\n",
      "4638:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4638)\ttotal: 1m 12s\tremaining: 5.64s\n",
      "4639:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4638)\ttotal: 1m 12s\tremaining: 5.63s\n",
      "4640:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4638)\ttotal: 1m 12s\tremaining: 5.61s\n",
      "4641:\tlearn: 0.6024049\ttest: 0.5962885\tbest: 0.5962885 (4638)\ttotal: 1m 12s\tremaining: 5.6s\n",
      "4642:\tlearn: 0.6024028\ttest: 0.5962868\tbest: 0.5962868 (4642)\ttotal: 1m 12s\tremaining: 5.58s\n",
      "4643:\tlearn: 0.6024028\ttest: 0.5962868\tbest: 0.5962868 (4642)\ttotal: 1m 12s\tremaining: 5.57s\n",
      "4644:\tlearn: 0.6024028\ttest: 0.5962868\tbest: 0.5962868 (4642)\ttotal: 1m 12s\tremaining: 5.55s\n",
      "4645:\tlearn: 0.6023988\ttest: 0.5962831\tbest: 0.5962831 (4645)\ttotal: 1m 12s\tremaining: 5.53s\n",
      "4646:\tlearn: 0.6023985\ttest: 0.5962831\tbest: 0.5962831 (4646)\ttotal: 1m 12s\tremaining: 5.52s\n",
      "4647:\tlearn: 0.6023985\ttest: 0.5962831\tbest: 0.5962831 (4646)\ttotal: 1m 12s\tremaining: 5.5s\n",
      "4648:\tlearn: 0.6023985\ttest: 0.5962831\tbest: 0.5962831 (4648)\ttotal: 1m 12s\tremaining: 5.49s\n",
      "4649:\tlearn: 0.6023985\ttest: 0.5962831\tbest: 0.5962831 (4648)\ttotal: 1m 12s\tremaining: 5.47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4650:\tlearn: 0.6023985\ttest: 0.5962831\tbest: 0.5962831 (4648)\ttotal: 1m 12s\tremaining: 5.46s\n",
      "4651:\tlearn: 0.6023985\ttest: 0.5962831\tbest: 0.5962831 (4648)\ttotal: 1m 12s\tremaining: 5.44s\n",
      "4652:\tlearn: 0.6023955\ttest: 0.5962788\tbest: 0.5962788 (4652)\ttotal: 1m 12s\tremaining: 5.42s\n",
      "4653:\tlearn: 0.6023955\ttest: 0.5962788\tbest: 0.5962788 (4652)\ttotal: 1m 12s\tremaining: 5.41s\n",
      "4654:\tlearn: 0.6023955\ttest: 0.5962788\tbest: 0.5962788 (4652)\ttotal: 1m 12s\tremaining: 5.39s\n",
      "4655:\tlearn: 0.6023955\ttest: 0.5962788\tbest: 0.5962788 (4652)\ttotal: 1m 12s\tremaining: 5.38s\n",
      "4656:\tlearn: 0.6023854\ttest: 0.5962751\tbest: 0.5962751 (4656)\ttotal: 1m 12s\tremaining: 5.36s\n",
      "4657:\tlearn: 0.6023834\ttest: 0.5962739\tbest: 0.5962739 (4657)\ttotal: 1m 12s\tremaining: 5.35s\n",
      "4658:\tlearn: 0.6023834\ttest: 0.5962739\tbest: 0.5962739 (4657)\ttotal: 1m 12s\tremaining: 5.33s\n",
      "4659:\tlearn: 0.6023834\ttest: 0.5962739\tbest: 0.5962739 (4657)\ttotal: 1m 12s\tremaining: 5.31s\n",
      "4660:\tlearn: 0.6023807\ttest: 0.5962700\tbest: 0.5962700 (4660)\ttotal: 1m 12s\tremaining: 5.3s\n",
      "4661:\tlearn: 0.6023795\ttest: 0.5962681\tbest: 0.5962681 (4661)\ttotal: 1m 12s\tremaining: 5.28s\n",
      "4662:\tlearn: 0.6023795\ttest: 0.5962681\tbest: 0.5962681 (4661)\ttotal: 1m 12s\tremaining: 5.27s\n",
      "4663:\tlearn: 0.6023795\ttest: 0.5962681\tbest: 0.5962681 (4661)\ttotal: 1m 12s\tremaining: 5.25s\n",
      "4664:\tlearn: 0.6023793\ttest: 0.5962681\tbest: 0.5962681 (4664)\ttotal: 1m 12s\tremaining: 5.24s\n",
      "4665:\tlearn: 0.6023793\ttest: 0.5962681\tbest: 0.5962681 (4664)\ttotal: 1m 12s\tremaining: 5.22s\n",
      "4666:\tlearn: 0.6023793\ttest: 0.5962681\tbest: 0.5962681 (4664)\ttotal: 1m 12s\tremaining: 5.21s\n",
      "4667:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 12s\tremaining: 5.19s\n",
      "4668:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 12s\tremaining: 5.17s\n",
      "4669:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 13s\tremaining: 5.16s\n",
      "4670:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 13s\tremaining: 5.14s\n",
      "4671:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 13s\tremaining: 5.13s\n",
      "4672:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 13s\tremaining: 5.11s\n",
      "4673:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 13s\tremaining: 5.1s\n",
      "4674:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4667)\ttotal: 1m 13s\tremaining: 5.08s\n",
      "4675:\tlearn: 0.6023671\ttest: 0.5962558\tbest: 0.5962558 (4675)\ttotal: 1m 13s\tremaining: 5.07s\n",
      "4676:\tlearn: 0.6023671\ttest: 0.5962557\tbest: 0.5962557 (4676)\ttotal: 1m 13s\tremaining: 5.05s\n",
      "4677:\tlearn: 0.6023671\ttest: 0.5962557\tbest: 0.5962557 (4676)\ttotal: 1m 13s\tremaining: 5.04s\n",
      "4678:\tlearn: 0.6023671\ttest: 0.5962557\tbest: 0.5962557 (4676)\ttotal: 1m 13s\tremaining: 5.02s\n",
      "4679:\tlearn: 0.6023671\ttest: 0.5962557\tbest: 0.5962557 (4676)\ttotal: 1m 13s\tremaining: 5s\n",
      "4680:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.99s\n",
      "4681:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.97s\n",
      "4682:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.96s\n",
      "4683:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.94s\n",
      "4684:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.92s\n",
      "4685:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.91s\n",
      "4686:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.89s\n",
      "4687:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.88s\n",
      "4688:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.86s\n",
      "4689:\tlearn: 0.6023570\ttest: 0.5962468\tbest: 0.5962468 (4680)\ttotal: 1m 13s\tremaining: 4.84s\n",
      "4690:\tlearn: 0.6023552\ttest: 0.5962461\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.83s\n",
      "4691:\tlearn: 0.6023552\ttest: 0.5962461\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.81s\n",
      "4692:\tlearn: 0.6023552\ttest: 0.5962461\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.8s\n",
      "4693:\tlearn: 0.6023542\ttest: 0.5962467\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.78s\n",
      "4694:\tlearn: 0.6023542\ttest: 0.5962467\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.77s\n",
      "4695:\tlearn: 0.6023542\ttest: 0.5962467\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.75s\n",
      "4696:\tlearn: 0.6023542\ttest: 0.5962467\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.73s\n",
      "4697:\tlearn: 0.6023540\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.72s\n",
      "4698:\tlearn: 0.6023539\ttest: 0.5962462\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.7s\n",
      "4699:\tlearn: 0.6023539\ttest: 0.5962462\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.69s\n",
      "4700:\tlearn: 0.6023473\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.67s\n",
      "4701:\tlearn: 0.6023473\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.66s\n",
      "4702:\tlearn: 0.6023473\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.64s\n",
      "4703:\tlearn: 0.6023473\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.63s\n",
      "4704:\tlearn: 0.6023472\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.61s\n",
      "4705:\tlearn: 0.6023472\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.59s\n",
      "4706:\tlearn: 0.6023472\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.58s\n",
      "4707:\tlearn: 0.6023472\ttest: 0.5962463\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.56s\n",
      "4708:\tlearn: 0.6023469\ttest: 0.5962464\tbest: 0.5962461 (4690)\ttotal: 1m 13s\tremaining: 4.55s\n",
      "4709:\tlearn: 0.6023440\ttest: 0.5962440\tbest: 0.5962440 (4709)\ttotal: 1m 13s\tremaining: 4.53s\n",
      "4710:\tlearn: 0.6023427\ttest: 0.5962408\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.52s\n",
      "4711:\tlearn: 0.6023427\ttest: 0.5962408\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.5s\n",
      "4712:\tlearn: 0.6023427\ttest: 0.5962408\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.49s\n",
      "4713:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.47s\n",
      "4714:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.45s\n",
      "4715:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.44s\n",
      "4716:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.42s\n",
      "4717:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.41s\n",
      "4718:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.39s\n",
      "4719:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.38s\n",
      "4720:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.36s\n",
      "4721:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.34s\n",
      "4722:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.33s\n",
      "4723:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.31s\n",
      "4724:\tlearn: 0.6023427\ttest: 0.5962409\tbest: 0.5962408 (4710)\ttotal: 1m 13s\tremaining: 4.3s\n",
      "4725:\tlearn: 0.6023418\ttest: 0.5962387\tbest: 0.5962387 (4725)\ttotal: 1m 13s\tremaining: 4.28s\n",
      "4726:\tlearn: 0.6023393\ttest: 0.5962377\tbest: 0.5962377 (4726)\ttotal: 1m 13s\tremaining: 4.27s\n",
      "4727:\tlearn: 0.6023393\ttest: 0.5962377\tbest: 0.5962377 (4726)\ttotal: 1m 13s\tremaining: 4.25s\n",
      "4728:\tlearn: 0.6023393\ttest: 0.5962377\tbest: 0.5962377 (4726)\ttotal: 1m 13s\tremaining: 4.23s\n",
      "4729:\tlearn: 0.6023393\ttest: 0.5962377\tbest: 0.5962377 (4726)\ttotal: 1m 13s\tremaining: 4.22s\n",
      "4730:\tlearn: 0.6023393\ttest: 0.5962377\tbest: 0.5962377 (4726)\ttotal: 1m 13s\tremaining: 4.2s\n",
      "4731:\tlearn: 0.6022879\ttest: 0.5961955\tbest: 0.5961955 (4731)\ttotal: 1m 13s\tremaining: 4.19s\n",
      "4732:\tlearn: 0.6022879\ttest: 0.5961955\tbest: 0.5961955 (4731)\ttotal: 1m 13s\tremaining: 4.17s\n",
      "4733:\tlearn: 0.6022879\ttest: 0.5961955\tbest: 0.5961955 (4731)\ttotal: 1m 13s\tremaining: 4.16s\n",
      "4734:\tlearn: 0.6022879\ttest: 0.5961955\tbest: 0.5961955 (4731)\ttotal: 1m 13s\tremaining: 4.14s\n",
      "4735:\tlearn: 0.6022879\ttest: 0.5961955\tbest: 0.5961955 (4735)\ttotal: 1m 14s\tremaining: 4.13s\n",
      "4736:\tlearn: 0.6022675\ttest: 0.5961820\tbest: 0.5961820 (4736)\ttotal: 1m 14s\tremaining: 4.11s\n",
      "4737:\tlearn: 0.6022656\ttest: 0.5961793\tbest: 0.5961793 (4737)\ttotal: 1m 14s\tremaining: 4.09s\n",
      "4738:\tlearn: 0.6022652\ttest: 0.5961786\tbest: 0.5961786 (4738)\ttotal: 1m 14s\tremaining: 4.08s\n",
      "4739:\tlearn: 0.6022652\ttest: 0.5961786\tbest: 0.5961786 (4738)\ttotal: 1m 14s\tremaining: 4.06s\n",
      "4740:\tlearn: 0.6022652\ttest: 0.5961786\tbest: 0.5961786 (4738)\ttotal: 1m 14s\tremaining: 4.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4741:\tlearn: 0.6022652\ttest: 0.5961786\tbest: 0.5961786 (4738)\ttotal: 1m 14s\tremaining: 4.03s\n",
      "4742:\tlearn: 0.6022652\ttest: 0.5961786\tbest: 0.5961786 (4738)\ttotal: 1m 14s\tremaining: 4.01s\n",
      "4743:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 4s\n",
      "4744:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.98s\n",
      "4745:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.97s\n",
      "4746:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.95s\n",
      "4747:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.94s\n",
      "4748:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.92s\n",
      "4749:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.9s\n",
      "4750:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.89s\n",
      "4751:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961785 (4743)\ttotal: 1m 14s\tremaining: 3.87s\n",
      "4752:\tlearn: 0.6022651\ttest: 0.5961784\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.86s\n",
      "4753:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.84s\n",
      "4754:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.83s\n",
      "4755:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.81s\n",
      "4756:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.8s\n",
      "4757:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.78s\n",
      "4758:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.76s\n",
      "4759:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.75s\n",
      "4760:\tlearn: 0.6022651\ttest: 0.5961785\tbest: 0.5961784 (4752)\ttotal: 1m 14s\tremaining: 3.73s\n",
      "4761:\tlearn: 0.6022617\ttest: 0.5961766\tbest: 0.5961766 (4761)\ttotal: 1m 14s\tremaining: 3.72s\n",
      "4762:\tlearn: 0.6022617\ttest: 0.5961766\tbest: 0.5961766 (4761)\ttotal: 1m 14s\tremaining: 3.7s\n",
      "4763:\tlearn: 0.6022592\ttest: 0.5961755\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.69s\n",
      "4764:\tlearn: 0.6022592\ttest: 0.5961755\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.67s\n",
      "4765:\tlearn: 0.6022592\ttest: 0.5961755\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.65s\n",
      "4766:\tlearn: 0.6022584\ttest: 0.5961756\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.64s\n",
      "4767:\tlearn: 0.6022555\ttest: 0.5961757\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.62s\n",
      "4768:\tlearn: 0.6022555\ttest: 0.5961758\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.61s\n",
      "4769:\tlearn: 0.6022555\ttest: 0.5961758\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.59s\n",
      "4770:\tlearn: 0.6022555\ttest: 0.5961758\tbest: 0.5961755 (4763)\ttotal: 1m 14s\tremaining: 3.58s\n",
      "4771:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.56s\n",
      "4772:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.55s\n",
      "4773:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.53s\n",
      "4774:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.51s\n",
      "4775:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.5s\n",
      "4776:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.48s\n",
      "4777:\tlearn: 0.6022295\ttest: 0.5961538\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.47s\n",
      "4778:\tlearn: 0.6022295\ttest: 0.5961539\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.45s\n",
      "4779:\tlearn: 0.6022295\ttest: 0.5961539\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.44s\n",
      "4780:\tlearn: 0.6022295\ttest: 0.5961539\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.42s\n",
      "4781:\tlearn: 0.6022295\ttest: 0.5961539\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.4s\n",
      "4782:\tlearn: 0.6022295\ttest: 0.5961539\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.39s\n",
      "4783:\tlearn: 0.6022294\ttest: 0.5961545\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.37s\n",
      "4784:\tlearn: 0.6022291\ttest: 0.5961551\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.36s\n",
      "4785:\tlearn: 0.6022291\ttest: 0.5961551\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.34s\n",
      "4786:\tlearn: 0.6022291\ttest: 0.5961551\tbest: 0.5961538 (4771)\ttotal: 1m 14s\tremaining: 3.33s\n",
      "4787:\tlearn: 0.6022108\ttest: 0.5961268\tbest: 0.5961268 (4787)\ttotal: 1m 14s\tremaining: 3.31s\n",
      "4788:\tlearn: 0.6022108\ttest: 0.5961268\tbest: 0.5961268 (4788)\ttotal: 1m 14s\tremaining: 3.3s\n",
      "4789:\tlearn: 0.6022108\ttest: 0.5961268\tbest: 0.5961268 (4788)\ttotal: 1m 14s\tremaining: 3.28s\n",
      "4790:\tlearn: 0.6022108\ttest: 0.5961268\tbest: 0.5961268 (4788)\ttotal: 1m 14s\tremaining: 3.27s\n",
      "4791:\tlearn: 0.6022108\ttest: 0.5961268\tbest: 0.5961268 (4788)\ttotal: 1m 14s\tremaining: 3.25s\n",
      "4792:\tlearn: 0.6022096\ttest: 0.5961238\tbest: 0.5961238 (4792)\ttotal: 1m 14s\tremaining: 3.23s\n",
      "4793:\tlearn: 0.6022096\ttest: 0.5961238\tbest: 0.5961238 (4792)\ttotal: 1m 14s\tremaining: 3.22s\n",
      "4794:\tlearn: 0.6022096\ttest: 0.5961240\tbest: 0.5961238 (4792)\ttotal: 1m 14s\tremaining: 3.2s\n",
      "4795:\tlearn: 0.6022096\ttest: 0.5961240\tbest: 0.5961238 (4792)\ttotal: 1m 14s\tremaining: 3.19s\n",
      "4796:\tlearn: 0.6022093\ttest: 0.5961235\tbest: 0.5961235 (4796)\ttotal: 1m 14s\tremaining: 3.17s\n",
      "4797:\tlearn: 0.6022090\ttest: 0.5961227\tbest: 0.5961227 (4797)\ttotal: 1m 14s\tremaining: 3.16s\n",
      "4798:\tlearn: 0.6022090\ttest: 0.5961227\tbest: 0.5961227 (4797)\ttotal: 1m 14s\tremaining: 3.14s\n",
      "4799:\tlearn: 0.6022090\ttest: 0.5961227\tbest: 0.5961227 (4797)\ttotal: 1m 15s\tremaining: 3.12s\n",
      "4800:\tlearn: 0.6022068\ttest: 0.5961218\tbest: 0.5961218 (4800)\ttotal: 1m 15s\tremaining: 3.11s\n",
      "4801:\tlearn: 0.6022068\ttest: 0.5961218\tbest: 0.5961218 (4800)\ttotal: 1m 15s\tremaining: 3.09s\n",
      "4802:\tlearn: 0.6022068\ttest: 0.5961218\tbest: 0.5961218 (4800)\ttotal: 1m 15s\tremaining: 3.08s\n",
      "4803:\tlearn: 0.6022068\ttest: 0.5961218\tbest: 0.5961218 (4800)\ttotal: 1m 15s\tremaining: 3.06s\n",
      "4804:\tlearn: 0.6022061\ttest: 0.5961217\tbest: 0.5961217 (4804)\ttotal: 1m 15s\tremaining: 3.05s\n",
      "4805:\tlearn: 0.6022061\ttest: 0.5961217\tbest: 0.5961217 (4804)\ttotal: 1m 15s\tremaining: 3.03s\n",
      "4806:\tlearn: 0.6022061\ttest: 0.5961217\tbest: 0.5961217 (4804)\ttotal: 1m 15s\tremaining: 3.02s\n",
      "4807:\tlearn: 0.6022042\ttest: 0.5961198\tbest: 0.5961198 (4807)\ttotal: 1m 15s\tremaining: 3s\n",
      "4808:\tlearn: 0.6022042\ttest: 0.5961198\tbest: 0.5961198 (4807)\ttotal: 1m 15s\tremaining: 2.98s\n",
      "4809:\tlearn: 0.6022042\ttest: 0.5961197\tbest: 0.5961197 (4809)\ttotal: 1m 15s\tremaining: 2.97s\n",
      "4810:\tlearn: 0.6022042\ttest: 0.5961197\tbest: 0.5961197 (4809)\ttotal: 1m 15s\tremaining: 2.95s\n",
      "4811:\tlearn: 0.6022013\ttest: 0.5961169\tbest: 0.5961169 (4811)\ttotal: 1m 15s\tremaining: 2.94s\n",
      "4812:\tlearn: 0.6022013\ttest: 0.5961169\tbest: 0.5961169 (4811)\ttotal: 1m 15s\tremaining: 2.92s\n",
      "4813:\tlearn: 0.6022013\ttest: 0.5961169\tbest: 0.5961169 (4811)\ttotal: 1m 15s\tremaining: 2.9s\n",
      "4814:\tlearn: 0.6022013\ttest: 0.5961169\tbest: 0.5961169 (4811)\ttotal: 1m 15s\tremaining: 2.89s\n",
      "4815:\tlearn: 0.6022013\ttest: 0.5961169\tbest: 0.5961169 (4811)\ttotal: 1m 15s\tremaining: 2.87s\n",
      "4816:\tlearn: 0.6021984\ttest: 0.5961125\tbest: 0.5961125 (4816)\ttotal: 1m 15s\tremaining: 2.86s\n",
      "4817:\tlearn: 0.6021984\ttest: 0.5961125\tbest: 0.5961125 (4816)\ttotal: 1m 15s\tremaining: 2.84s\n",
      "4818:\tlearn: 0.6021984\ttest: 0.5961125\tbest: 0.5961125 (4816)\ttotal: 1m 15s\tremaining: 2.83s\n",
      "4819:\tlearn: 0.6021947\ttest: 0.5961119\tbest: 0.5961119 (4819)\ttotal: 1m 15s\tremaining: 2.81s\n",
      "4820:\tlearn: 0.6021947\ttest: 0.5961119\tbest: 0.5961119 (4819)\ttotal: 1m 15s\tremaining: 2.8s\n",
      "4821:\tlearn: 0.6021599\ttest: 0.5960843\tbest: 0.5960843 (4821)\ttotal: 1m 15s\tremaining: 2.78s\n",
      "4822:\tlearn: 0.6021599\ttest: 0.5960843\tbest: 0.5960843 (4821)\ttotal: 1m 15s\tremaining: 2.77s\n",
      "4823:\tlearn: 0.6021599\ttest: 0.5960843\tbest: 0.5960843 (4821)\ttotal: 1m 15s\tremaining: 2.75s\n",
      "4824:\tlearn: 0.6021599\ttest: 0.5960843\tbest: 0.5960843 (4821)\ttotal: 1m 15s\tremaining: 2.73s\n",
      "4825:\tlearn: 0.6021599\ttest: 0.5960843\tbest: 0.5960843 (4821)\ttotal: 1m 15s\tremaining: 2.72s\n",
      "4826:\tlearn: 0.6021583\ttest: 0.5960832\tbest: 0.5960832 (4826)\ttotal: 1m 15s\tremaining: 2.7s\n",
      "4827:\tlearn: 0.6021583\ttest: 0.5960832\tbest: 0.5960832 (4826)\ttotal: 1m 15s\tremaining: 2.69s\n",
      "4828:\tlearn: 0.6021583\ttest: 0.5960832\tbest: 0.5960832 (4826)\ttotal: 1m 15s\tremaining: 2.67s\n",
      "4829:\tlearn: 0.6021505\ttest: 0.5960721\tbest: 0.5960721 (4829)\ttotal: 1m 15s\tremaining: 2.66s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4830:\tlearn: 0.6021505\ttest: 0.5960721\tbest: 0.5960721 (4829)\ttotal: 1m 15s\tremaining: 2.64s\n",
      "4831:\tlearn: 0.6021505\ttest: 0.5960721\tbest: 0.5960721 (4829)\ttotal: 1m 15s\tremaining: 2.63s\n",
      "4832:\tlearn: 0.6021505\ttest: 0.5960721\tbest: 0.5960721 (4829)\ttotal: 1m 15s\tremaining: 2.61s\n",
      "4833:\tlearn: 0.6021505\ttest: 0.5960721\tbest: 0.5960721 (4829)\ttotal: 1m 15s\tremaining: 2.59s\n",
      "4834:\tlearn: 0.6021505\ttest: 0.5960722\tbest: 0.5960721 (4829)\ttotal: 1m 15s\tremaining: 2.58s\n",
      "4835:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.56s\n",
      "4836:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.55s\n",
      "4837:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.53s\n",
      "4838:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.52s\n",
      "4839:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.5s\n",
      "4840:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.48s\n",
      "4841:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.47s\n",
      "4842:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.45s\n",
      "4843:\tlearn: 0.6021475\ttest: 0.5960659\tbest: 0.5960659 (4835)\ttotal: 1m 15s\tremaining: 2.44s\n",
      "4844:\tlearn: 0.6021473\ttest: 0.5960654\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.42s\n",
      "4845:\tlearn: 0.6021473\ttest: 0.5960654\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.41s\n",
      "4846:\tlearn: 0.6021469\ttest: 0.5960655\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.39s\n",
      "4847:\tlearn: 0.6021469\ttest: 0.5960655\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.38s\n",
      "4848:\tlearn: 0.6021469\ttest: 0.5960655\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.36s\n",
      "4849:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.34s\n",
      "4850:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.33s\n",
      "4851:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.31s\n",
      "4852:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.3s\n",
      "4853:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.28s\n",
      "4854:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.27s\n",
      "4855:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.25s\n",
      "4856:\tlearn: 0.6021469\ttest: 0.5960658\tbest: 0.5960654 (4844)\ttotal: 1m 15s\tremaining: 2.23s\n",
      "4857:\tlearn: 0.6021120\ttest: 0.5960403\tbest: 0.5960403 (4857)\ttotal: 1m 15s\tremaining: 2.22s\n",
      "4858:\tlearn: 0.6021112\ttest: 0.5960379\tbest: 0.5960379 (4858)\ttotal: 1m 15s\tremaining: 2.2s\n",
      "4859:\tlearn: 0.6021112\ttest: 0.5960379\tbest: 0.5960379 (4858)\ttotal: 1m 15s\tremaining: 2.19s\n",
      "4860:\tlearn: 0.6021112\ttest: 0.5960379\tbest: 0.5960379 (4858)\ttotal: 1m 15s\tremaining: 2.17s\n",
      "4861:\tlearn: 0.6021112\ttest: 0.5960380\tbest: 0.5960379 (4858)\ttotal: 1m 15s\tremaining: 2.16s\n",
      "4862:\tlearn: 0.6021094\ttest: 0.5960361\tbest: 0.5960361 (4862)\ttotal: 1m 15s\tremaining: 2.14s\n",
      "4863:\tlearn: 0.6020573\ttest: 0.5959763\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.13s\n",
      "4864:\tlearn: 0.6020573\ttest: 0.5959763\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.11s\n",
      "4865:\tlearn: 0.6020573\ttest: 0.5959763\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.09s\n",
      "4866:\tlearn: 0.6020573\ttest: 0.5959763\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.08s\n",
      "4867:\tlearn: 0.6020555\ttest: 0.5959765\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.06s\n",
      "4868:\tlearn: 0.6020555\ttest: 0.5959765\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.05s\n",
      "4869:\tlearn: 0.6020555\ttest: 0.5959765\tbest: 0.5959763 (4863)\ttotal: 1m 16s\tremaining: 2.03s\n",
      "4870:\tlearn: 0.6020554\ttest: 0.5959761\tbest: 0.5959761 (4870)\ttotal: 1m 16s\tremaining: 2.02s\n",
      "4871:\tlearn: 0.6020554\ttest: 0.5959761\tbest: 0.5959761 (4870)\ttotal: 1m 16s\tremaining: 2s\n",
      "4872:\tlearn: 0.6020553\ttest: 0.5959766\tbest: 0.5959761 (4870)\ttotal: 1m 16s\tremaining: 1.98s\n",
      "4873:\tlearn: 0.6020553\ttest: 0.5959766\tbest: 0.5959761 (4870)\ttotal: 1m 16s\tremaining: 1.97s\n",
      "4874:\tlearn: 0.6020551\ttest: 0.5959762\tbest: 0.5959761 (4870)\ttotal: 1m 16s\tremaining: 1.95s\n",
      "4875:\tlearn: 0.6020512\ttest: 0.5959730\tbest: 0.5959730 (4875)\ttotal: 1m 16s\tremaining: 1.94s\n",
      "4876:\tlearn: 0.6020504\ttest: 0.5959728\tbest: 0.5959728 (4876)\ttotal: 1m 16s\tremaining: 1.92s\n",
      "4877:\tlearn: 0.6020504\ttest: 0.5959728\tbest: 0.5959728 (4876)\ttotal: 1m 16s\tremaining: 1.91s\n",
      "4878:\tlearn: 0.6020464\ttest: 0.5959698\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.89s\n",
      "4879:\tlearn: 0.6020464\ttest: 0.5959698\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.88s\n",
      "4880:\tlearn: 0.6020464\ttest: 0.5959698\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.86s\n",
      "4881:\tlearn: 0.6020459\ttest: 0.5959703\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.84s\n",
      "4882:\tlearn: 0.6020459\ttest: 0.5959703\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.83s\n",
      "4883:\tlearn: 0.6020459\ttest: 0.5959703\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.81s\n",
      "4884:\tlearn: 0.6020459\ttest: 0.5959703\tbest: 0.5959698 (4878)\ttotal: 1m 16s\tremaining: 1.8s\n",
      "4885:\tlearn: 0.6020273\ttest: 0.5959558\tbest: 0.5959558 (4885)\ttotal: 1m 16s\tremaining: 1.78s\n",
      "4886:\tlearn: 0.6020132\ttest: 0.5959396\tbest: 0.5959396 (4886)\ttotal: 1m 16s\tremaining: 1.76s\n",
      "4887:\tlearn: 0.6020132\ttest: 0.5959396\tbest: 0.5959396 (4886)\ttotal: 1m 16s\tremaining: 1.75s\n",
      "4888:\tlearn: 0.6020132\ttest: 0.5959396\tbest: 0.5959396 (4886)\ttotal: 1m 16s\tremaining: 1.73s\n",
      "4889:\tlearn: 0.6020132\ttest: 0.5959396\tbest: 0.5959396 (4886)\ttotal: 1m 16s\tremaining: 1.72s\n",
      "4890:\tlearn: 0.6020132\ttest: 0.5959396\tbest: 0.5959396 (4886)\ttotal: 1m 16s\tremaining: 1.7s\n",
      "4891:\tlearn: 0.6020124\ttest: 0.5959393\tbest: 0.5959393 (4891)\ttotal: 1m 16s\tremaining: 1.69s\n",
      "4892:\tlearn: 0.6020105\ttest: 0.5959351\tbest: 0.5959351 (4892)\ttotal: 1m 16s\tremaining: 1.67s\n",
      "4893:\tlearn: 0.6020105\ttest: 0.5959351\tbest: 0.5959351 (4892)\ttotal: 1m 16s\tremaining: 1.66s\n",
      "4894:\tlearn: 0.6020105\ttest: 0.5959351\tbest: 0.5959351 (4892)\ttotal: 1m 16s\tremaining: 1.64s\n",
      "4895:\tlearn: 0.6020104\ttest: 0.5959352\tbest: 0.5959351 (4892)\ttotal: 1m 16s\tremaining: 1.62s\n",
      "4896:\tlearn: 0.6020068\ttest: 0.5959306\tbest: 0.5959306 (4896)\ttotal: 1m 16s\tremaining: 1.61s\n",
      "4897:\tlearn: 0.6020068\ttest: 0.5959307\tbest: 0.5959306 (4896)\ttotal: 1m 16s\tremaining: 1.59s\n",
      "4898:\tlearn: 0.6020068\ttest: 0.5959307\tbest: 0.5959306 (4896)\ttotal: 1m 16s\tremaining: 1.58s\n",
      "4899:\tlearn: 0.6020068\ttest: 0.5959307\tbest: 0.5959306 (4896)\ttotal: 1m 16s\tremaining: 1.56s\n",
      "4900:\tlearn: 0.6020068\ttest: 0.5959307\tbest: 0.5959306 (4896)\ttotal: 1m 16s\tremaining: 1.55s\n",
      "4901:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.53s\n",
      "4902:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.51s\n",
      "4903:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.5s\n",
      "4904:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.48s\n",
      "4905:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.47s\n",
      "4906:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.45s\n",
      "4907:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.44s\n",
      "4908:\tlearn: 0.6020065\ttest: 0.5959299\tbest: 0.5959299 (4901)\ttotal: 1m 16s\tremaining: 1.42s\n",
      "4909:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4909)\ttotal: 1m 16s\tremaining: 1.41s\n",
      "4910:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4909)\ttotal: 1m 16s\tremaining: 1.39s\n",
      "4911:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.37s\n",
      "4912:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.36s\n",
      "4913:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.34s\n",
      "4914:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.33s\n",
      "4915:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.31s\n",
      "4916:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.3s\n",
      "4917:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.28s\n",
      "4918:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.26s\n",
      "4919:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.25s\n",
      "4920:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4921:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.22s\n",
      "4922:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.2s\n",
      "4923:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.19s\n",
      "4924:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.17s\n",
      "4925:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.16s\n",
      "4926:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.14s\n",
      "4927:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.12s\n",
      "4928:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.11s\n",
      "4929:\tlearn: 0.6020027\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.09s\n",
      "4930:\tlearn: 0.6020026\ttest: 0.5959278\tbest: 0.5959278 (4911)\ttotal: 1m 16s\tremaining: 1.08s\n",
      "4931:\tlearn: 0.6020011\ttest: 0.5959268\tbest: 0.5959268 (4931)\ttotal: 1m 16s\tremaining: 1.06s\n",
      "4932:\tlearn: 0.6019838\ttest: 0.5959167\tbest: 0.5959167 (4932)\ttotal: 1m 17s\tremaining: 1.05s\n",
      "4933:\tlearn: 0.6019838\ttest: 0.5959167\tbest: 0.5959167 (4932)\ttotal: 1m 17s\tremaining: 1.03s\n",
      "4934:\tlearn: 0.6019830\ttest: 0.5959165\tbest: 0.5959165 (4934)\ttotal: 1m 17s\tremaining: 1.01s\n",
      "4935:\tlearn: 0.6019830\ttest: 0.5959165\tbest: 0.5959165 (4934)\ttotal: 1m 17s\tremaining: 999ms\n",
      "4936:\tlearn: 0.6019700\ttest: 0.5958978\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 984ms\n",
      "4937:\tlearn: 0.6019700\ttest: 0.5958978\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 968ms\n",
      "4938:\tlearn: 0.6019700\ttest: 0.5958978\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 952ms\n",
      "4939:\tlearn: 0.6019700\ttest: 0.5958978\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 937ms\n",
      "4940:\tlearn: 0.6019699\ttest: 0.5958978\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 921ms\n",
      "4941:\tlearn: 0.6019699\ttest: 0.5958978\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 905ms\n",
      "4942:\tlearn: 0.6019695\ttest: 0.5958979\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 890ms\n",
      "4943:\tlearn: 0.6019695\ttest: 0.5958979\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 874ms\n",
      "4944:\tlearn: 0.6019695\ttest: 0.5958979\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 859ms\n",
      "4945:\tlearn: 0.6019695\ttest: 0.5958979\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 843ms\n",
      "4946:\tlearn: 0.6019695\ttest: 0.5958979\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 827ms\n",
      "4947:\tlearn: 0.6019695\ttest: 0.5958979\tbest: 0.5958978 (4936)\ttotal: 1m 17s\tremaining: 812ms\n",
      "4948:\tlearn: 0.6019677\ttest: 0.5958964\tbest: 0.5958964 (4948)\ttotal: 1m 17s\tremaining: 796ms\n",
      "4949:\tlearn: 0.6019677\ttest: 0.5958964\tbest: 0.5958964 (4948)\ttotal: 1m 17s\tremaining: 781ms\n",
      "4950:\tlearn: 0.6019677\ttest: 0.5958964\tbest: 0.5958964 (4948)\ttotal: 1m 17s\tremaining: 765ms\n",
      "4951:\tlearn: 0.6019677\ttest: 0.5958964\tbest: 0.5958964 (4948)\ttotal: 1m 17s\tremaining: 749ms\n",
      "4952:\tlearn: 0.6019677\ttest: 0.5958965\tbest: 0.5958964 (4948)\ttotal: 1m 17s\tremaining: 734ms\n",
      "4953:\tlearn: 0.6019585\ttest: 0.5958893\tbest: 0.5958893 (4953)\ttotal: 1m 17s\tremaining: 718ms\n",
      "4954:\tlearn: 0.6019585\ttest: 0.5958893\tbest: 0.5958893 (4953)\ttotal: 1m 17s\tremaining: 703ms\n",
      "4955:\tlearn: 0.6019585\ttest: 0.5958893\tbest: 0.5958893 (4955)\ttotal: 1m 17s\tremaining: 687ms\n",
      "4956:\tlearn: 0.6019547\ttest: 0.5958861\tbest: 0.5958861 (4956)\ttotal: 1m 17s\tremaining: 671ms\n",
      "4957:\tlearn: 0.6019547\ttest: 0.5958861\tbest: 0.5958861 (4956)\ttotal: 1m 17s\tremaining: 656ms\n",
      "4958:\tlearn: 0.6019535\ttest: 0.5958841\tbest: 0.5958841 (4958)\ttotal: 1m 17s\tremaining: 640ms\n",
      "4959:\tlearn: 0.6019535\ttest: 0.5958841\tbest: 0.5958841 (4958)\ttotal: 1m 17s\tremaining: 625ms\n",
      "4960:\tlearn: 0.6019535\ttest: 0.5958841\tbest: 0.5958841 (4958)\ttotal: 1m 17s\tremaining: 609ms\n",
      "4961:\tlearn: 0.6019535\ttest: 0.5958841\tbest: 0.5958841 (4958)\ttotal: 1m 17s\tremaining: 593ms\n",
      "4962:\tlearn: 0.6019535\ttest: 0.5958841\tbest: 0.5958841 (4958)\ttotal: 1m 17s\tremaining: 578ms\n",
      "4963:\tlearn: 0.6019532\ttest: 0.5958848\tbest: 0.5958841 (4958)\ttotal: 1m 17s\tremaining: 562ms\n",
      "4964:\tlearn: 0.6019511\ttest: 0.5958836\tbest: 0.5958836 (4964)\ttotal: 1m 17s\tremaining: 547ms\n",
      "4965:\tlearn: 0.6019510\ttest: 0.5958832\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 531ms\n",
      "4966:\tlearn: 0.6019510\ttest: 0.5958832\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 515ms\n",
      "4967:\tlearn: 0.6019510\ttest: 0.5958832\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 500ms\n",
      "4968:\tlearn: 0.6019510\ttest: 0.5958832\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 484ms\n",
      "4969:\tlearn: 0.6019510\ttest: 0.5958832\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 469ms\n",
      "4970:\tlearn: 0.6019509\ttest: 0.5958840\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 453ms\n",
      "4971:\tlearn: 0.6019509\ttest: 0.5958840\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 437ms\n",
      "4972:\tlearn: 0.6019509\ttest: 0.5958840\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 422ms\n",
      "4973:\tlearn: 0.6019509\ttest: 0.5958840\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 406ms\n",
      "4974:\tlearn: 0.6019509\ttest: 0.5958840\tbest: 0.5958832 (4965)\ttotal: 1m 17s\tremaining: 390ms\n",
      "4975:\tlearn: 0.6018953\ttest: 0.5958452\tbest: 0.5958452 (4975)\ttotal: 1m 17s\tremaining: 375ms\n",
      "4976:\tlearn: 0.6018953\ttest: 0.5958452\tbest: 0.5958452 (4975)\ttotal: 1m 17s\tremaining: 359ms\n",
      "4977:\tlearn: 0.6018937\ttest: 0.5958419\tbest: 0.5958419 (4977)\ttotal: 1m 17s\tremaining: 344ms\n",
      "4978:\tlearn: 0.6018937\ttest: 0.5958419\tbest: 0.5958419 (4977)\ttotal: 1m 17s\tremaining: 328ms\n",
      "4979:\tlearn: 0.6018861\ttest: 0.5958373\tbest: 0.5958373 (4979)\ttotal: 1m 17s\tremaining: 312ms\n",
      "4980:\tlearn: 0.6018861\ttest: 0.5958373\tbest: 0.5958373 (4979)\ttotal: 1m 17s\tremaining: 297ms\n",
      "4981:\tlearn: 0.6018861\ttest: 0.5958373\tbest: 0.5958373 (4979)\ttotal: 1m 17s\tremaining: 281ms\n",
      "4982:\tlearn: 0.6018861\ttest: 0.5958373\tbest: 0.5958373 (4979)\ttotal: 1m 17s\tremaining: 266ms\n",
      "4983:\tlearn: 0.6018861\ttest: 0.5958373\tbest: 0.5958373 (4979)\ttotal: 1m 17s\tremaining: 250ms\n",
      "4984:\tlearn: 0.6018835\ttest: 0.5958351\tbest: 0.5958351 (4984)\ttotal: 1m 17s\tremaining: 234ms\n",
      "4985:\tlearn: 0.6018835\ttest: 0.5958351\tbest: 0.5958351 (4984)\ttotal: 1m 17s\tremaining: 219ms\n",
      "4986:\tlearn: 0.6018835\ttest: 0.5958351\tbest: 0.5958351 (4984)\ttotal: 1m 17s\tremaining: 203ms\n",
      "4987:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 17s\tremaining: 187ms\n",
      "4988:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 17s\tremaining: 172ms\n",
      "4989:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 17s\tremaining: 156ms\n",
      "4990:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 17s\tremaining: 141ms\n",
      "4991:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 17s\tremaining: 125ms\n",
      "4992:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 17s\tremaining: 109ms\n",
      "4993:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 18s\tremaining: 93.7ms\n",
      "4994:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 18s\tremaining: 78.1ms\n",
      "4995:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 18s\tremaining: 62.5ms\n",
      "4996:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4987)\ttotal: 1m 18s\tremaining: 46.8ms\n",
      "4997:\tlearn: 0.6018460\ttest: 0.5957938\tbest: 0.5957938 (4997)\ttotal: 1m 18s\tremaining: 31.2ms\n",
      "4998:\tlearn: 0.6018459\ttest: 0.5957938\tbest: 0.5957938 (4998)\ttotal: 1m 18s\tremaining: 15.6ms\n",
      "4999:\tlearn: 0.6018459\ttest: 0.5957938\tbest: 0.5957938 (4998)\ttotal: 1m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5957937747\n",
      "bestIteration = 4998\n",
      "\n",
      "Shrink model to first 4999 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x184a7d9e288>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_, y_train_, cat_features=cate_features_index,eval_set=(X_test_, y_test_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "expressed-importance",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "imf82bbP4RJvb4IVIYql",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict_proba(all_test_data)\n",
    "preds= np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "respected-shell",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "V5TaJ9n7tWqjDI9NyVcG",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "preds=[\"TRUE\" if x==1 else 'FALSE' for x in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "opposed-rally",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jhWGzj0sBu54vLay6S3n",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data_test.csv')\n",
    "submission['Labels']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vietnamese-tender",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "OdTRVCYV3TiqQ679hsKU",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "aSbfhd9TQR3FB9dBJksJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6992a84_2020-11-25_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e68e62f4_2020-11-29_20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e68e81a4_2020-11-27_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69eec04_2020-11-24_7</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e698e4a4_2020-11-27_8</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2e68dd414_2020-11-26_5</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2e698541c_2020-11-24_22</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2e69e8e0c_2020-11-24_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2e699a1cc_2020-11-24_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2e698d804_2020-11-25_19</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids Labels\n",
       "0      2e6992a84_2020-11-25_18   TRUE\n",
       "1      2e68e62f4_2020-11-29_20   TRUE\n",
       "2      2e68e81a4_2020-11-27_10   TRUE\n",
       "3       2e69eec04_2020-11-24_7   TRUE\n",
       "4       2e698e4a4_2020-11-27_8   TRUE\n",
       "...                        ...    ...\n",
       "13836   2e68dd414_2020-11-26_5  FALSE\n",
       "13837  2e698541c_2020-11-24_22  FALSE\n",
       "13838  2e69e8e0c_2020-11-24_10   TRUE\n",
       "13839  2e699a1cc_2020-11-24_18   TRUE\n",
       "13840  2e698d804_2020-11-25_19   TRUE\n",
       "\n",
       "[13841 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "alike-jones",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jq3zH3Yvk7k0W3NUKXjb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission.to_csv('test-catboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-infection",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "8sUZ8iSq5DXFXo5FYMzO",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "# Training LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "japanese-surprise",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "UMPzpRTRRSbsUQkUM2ge",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# import optuna.integration.lightgbm as lgb\n",
    "import optuna\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "nuclear-agenda",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "gySKXWApO89TAmfiPV9f",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "vzb4BHqlzIMcdFXYvSDd",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64557</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.288459</td>\n",
       "      <td>106.952093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16662</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.193291</td>\n",
       "      <td>106.972755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62922</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.956332</td>\n",
       "      <td>107.581583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.906395</td>\n",
       "      <td>107.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17177</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.276950</td>\n",
       "      <td>106.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21762</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.404998</td>\n",
       "      <td>106.757375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64388</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.898450</td>\n",
       "      <td>107.614134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69948</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.428860</td>\n",
       "      <td>106.733784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28491</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.888380</td>\n",
       "      <td>107.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32161</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.263309</td>\n",
       "      <td>107.017036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57068 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour  day  latitude   longitude\n",
       "64557    15    0 -6.288459  106.952093\n",
       "16662    22    0 -6.193291  106.972755\n",
       "62922    10    6 -6.956332  107.581583\n",
       "6597     21    2 -6.906395  107.608215\n",
       "17177    12    6 -6.276950  106.913727\n",
       "...     ...  ...       ...         ...\n",
       "21762    10    0 -6.404998  106.757375\n",
       "64388    14    0 -6.898450  107.614134\n",
       "69948    16    4 -6.428860  106.733784\n",
       "28491     9    5 -6.888380  107.608215\n",
       "32161    17    0 -6.263309  107.017036\n",
       "\n",
       "[57068 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "greater-municipality",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "wIFrwrhhOyjIhlfNNsX1",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "Ealwgt72aBahf6cUfNWW",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64557    0\n",
       "16662    1\n",
       "62922    1\n",
       "6597     1\n",
       "17177    1\n",
       "        ..\n",
       "21762    1\n",
       "64388    0\n",
       "69948    1\n",
       "28491    1\n",
       "32161    1\n",
       "Name: Labels, Length: 57068, dtype: int8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "written-reducing",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "F3a6nLsQz1WaoPjcf3mS",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "LcMLbA7JIYjXOWyU9fZk",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:56,579]\u001b[0m A new study created in memory with name: no-name-90879fa5-92ad-4af3-bfff-9ec4216c0eb6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:56,830]\u001b[0m Trial 0 finished with value: 0.7166386319035604 and parameters: {'learning_rate': 0.02707415484602406, 'max_depth': 81}. Best is trial 0 with value: 0.7166386319035604.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:29:57,020]\u001b[0m Trial 1 finished with value: 0.727291841883936 and parameters: {'learning_rate': 0.07377804572349547, 'max_depth': 38}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:57,248]\u001b[0m Trial 2 finished with value: 0.7234370619568264 and parameters: {'learning_rate': 0.050712419694350426, 'max_depth': 70}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:57,465]\u001b[0m Trial 3 finished with value: 0.7207737594617325 and parameters: {'learning_rate': 0.03744512906261066, 'max_depth': 91}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:57,693]\u001b[0m Trial 4 finished with value: 0.709349593495935 and parameters: {'learning_rate': 0.013895167915224674, 'max_depth': 55}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:57,951]\u001b[0m Trial 5 finished with value: 0.7188814129520605 and parameters: {'learning_rate': 0.034563736251334465, 'max_depth': 8}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:58,175]\u001b[0m Trial 6 finished with value: 0.7138351555929352 and parameters: {'learning_rate': 0.02070304428085852, 'max_depth': 18}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:58,404]\u001b[0m Trial 7 finished with value: 0.7109615923745445 and parameters: {'learning_rate': 0.015956876938145445, 'max_depth': 23}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:58,613]\u001b[0m Trial 8 finished with value: 0.7271516680684048 and parameters: {'learning_rate': 0.0773195211385162, 'max_depth': 51}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:58,827]\u001b[0m Trial 9 finished with value: 0.7246285393888422 and parameters: {'learning_rate': 0.05197085753590159, 'max_depth': 64}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:59,053]\u001b[0m Trial 10 finished with value: 0.7261003644519204 and parameters: {'learning_rate': 0.07405874846562006, 'max_depth': 35}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:29:59,242]\u001b[0m Trial 11 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.07399865653876218, 'max_depth': 43}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:59,464]\u001b[0m Trial 12 finished with value: 0.7253994953742641 and parameters: {'learning_rate': 0.06273621825016394, 'max_depth': 35}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:59,683]\u001b[0m Trial 13 finished with value: 0.7270114942528736 and parameters: {'learning_rate': 0.07731099076366847, 'max_depth': 51}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:29:59,900]\u001b[0m Trial 14 finished with value: 0.7248388001121391 and parameters: {'learning_rate': 0.06347991271814638, 'max_depth': 26}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:00,091]\u001b[0m Trial 15 finished with value: 0.725049060835436 and parameters: {'learning_rate': 0.06456682251544102, 'max_depth': 63}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:00,234]\u001b[0m Trial 16 finished with value: 0.7122932436220913 and parameters: {'learning_rate': 0.0795164945863946, 'max_depth': 3}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:00,420]\u001b[0m Trial 17 finished with value: 0.7258901037286235 and parameters: {'learning_rate': 0.06937977927507147, 'max_depth': 42}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:00,619]\u001b[0m Trial 18 finished with value: 0.7246285393888422 and parameters: {'learning_rate': 0.05514617942146492, 'max_depth': 78}. Best is trial 1 with value: 0.727291841883936.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:00,835]\u001b[0m Trial 19 finished with value: 0.7277123633305299 and parameters: {'learning_rate': 0.07990639970669305, 'max_depth': 55}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:01,056]\u001b[0m Trial 20 finished with value: 0.7230165405102327 and parameters: {'learning_rate': 0.04429666103150057, 'max_depth': 35}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:01,235]\u001b[0m Trial 21 finished with value: 0.7272217549761705 and parameters: {'learning_rate': 0.07851997275865705, 'max_depth': 51}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:01,470]\u001b[0m Trial 22 finished with value: 0.7277123633305299 and parameters: {'learning_rate': 0.07990832209440295, 'max_depth': 61}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:01,669]\u001b[0m Trial 23 finished with value: 0.7263106251752173 and parameters: {'learning_rate': 0.06943190047551125, 'max_depth': 60}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:01,887]\u001b[0m Trial 24 finished with value: 0.7263106251752173 and parameters: {'learning_rate': 0.06974047374580822, 'max_depth': 71}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:02,104]\u001b[0m Trial 25 finished with value: 0.725609756097561 and parameters: {'learning_rate': 0.059407167903738706, 'max_depth': 43}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:02,302]\u001b[0m Trial 26 finished with value: 0.7272217549761705 and parameters: {'learning_rate': 0.07329618514943456, 'max_depth': 91}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:02,560]\u001b[0m Trial 27 finished with value: 0.7260302775441547 and parameters: {'learning_rate': 0.07863707395500348, 'max_depth': 76}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:02,752]\u001b[0m Trial 28 finished with value: 0.7266610597140454 and parameters: {'learning_rate': 0.06887127207357274, 'max_depth': 58}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:02,964]\u001b[0m Trial 29 finished with value: 0.7276422764227642 and parameters: {'learning_rate': 0.07974532619035626, 'max_depth': 66}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:03,189]\u001b[0m Trial 30 finished with value: 0.7253294084664984 and parameters: {'learning_rate': 0.059639630140292915, 'max_depth': 97}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:03,397]\u001b[0m Trial 31 finished with value: 0.7275021026072329 and parameters: {'learning_rate': 0.07980106885167099, 'max_depth': 68}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:03,650]\u001b[0m Trial 32 finished with value: 0.7264507989907485 and parameters: {'learning_rate': 0.07591384241402788, 'max_depth': 69}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:03,878]\u001b[0m Trial 33 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.07960108719140992, 'max_depth': 84}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:04,087]\u001b[0m Trial 34 finished with value: 0.7270815811606391 and parameters: {'learning_rate': 0.0720724575909429, 'max_depth': 68}. Best is trial 19 with value: 0.7277123633305299.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:04,293]\u001b[0m Trial 35 finished with value: 0.7279927109615923 and parameters: {'learning_rate': 0.07985137890308451, 'max_depth': 85}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:04,500]\u001b[0m Trial 36 finished with value: 0.7265909728062798 and parameters: {'learning_rate': 0.06867859420663434, 'max_depth': 84}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:04,724]\u001b[0m Trial 37 finished with value: 0.7226661059714046 and parameters: {'learning_rate': 0.04358721475834185, 'max_depth': 91}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:04,952]\u001b[0m Trial 38 finished with value: 0.7171993271656855 and parameters: {'learning_rate': 0.027828062499041132, 'max_depth': 75}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:05,143]\u001b[0m Trial 39 finished with value: 0.726170451359686 and parameters: {'learning_rate': 0.06586854333789922, 'max_depth': 100}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:05,322]\u001b[0m Trial 40 finished with value: 0.726731146621811 and parameters: {'learning_rate': 0.0755580161494856, 'max_depth': 56}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:05,507]\u001b[0m Trial 41 finished with value: 0.7253994953742641 and parameters: {'learning_rate': 0.07876877730710044, 'max_depth': 63}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:05,693]\u001b[0m Trial 42 finished with value: 0.7279927109615923 and parameters: {'learning_rate': 0.07985679858013772, 'max_depth': 84}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:05,935]\u001b[0m Trial 43 finished with value: 0.7273619287917017 and parameters: {'learning_rate': 0.072168584936914, 'max_depth': 83}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:06,115]\u001b[0m Trial 44 finished with value: 0.725609756097561 and parameters: {'learning_rate': 0.07567778580858667, 'max_depth': 87}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:06,319]\u001b[0m Trial 45 finished with value: 0.7080880291561537 and parameters: {'learning_rate': 0.010739392262575156, 'max_depth': 73}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:06,522]\u001b[0m Trial 46 finished with value: 0.726170451359686 and parameters: {'learning_rate': 0.07223931641362764, 'max_depth': 80}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:06,710]\u001b[0m Trial 47 finished with value: 0.7275021026072329 and parameters: {'learning_rate': 0.07988789365211887, 'max_depth': 47}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:06,929]\u001b[0m Trial 48 finished with value: 0.7214045416316233 and parameters: {'learning_rate': 0.03963515514017566, 'max_depth': 97}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:07,147]\u001b[0m Trial 49 finished with value: 0.727291841883936 and parameters: {'learning_rate': 0.07604803256373636, 'max_depth': 65}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:07,374]\u001b[0m Trial 50 finished with value: 0.7252593215587329 and parameters: {'learning_rate': 0.06580821955863814, 'max_depth': 54}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:07,577]\u001b[0m Trial 51 finished with value: 0.7274320156994674 and parameters: {'learning_rate': 0.0796984497082475, 'max_depth': 49}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:07,771]\u001b[0m Trial 52 finished with value: 0.7277123633305299 and parameters: {'learning_rate': 0.07991611923012372, 'max_depth': 67}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:07,961]\u001b[0m Trial 53 finished with value: 0.725609756097561 and parameters: {'learning_rate': 0.0741940559335461, 'max_depth': 60}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:08,198]\u001b[0m Trial 54 finished with value: 0.7265208858985142 and parameters: {'learning_rate': 0.07707382484188978, 'max_depth': 54}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:08,381]\u001b[0m Trial 55 finished with value: 0.7265208858985142 and parameters: {'learning_rate': 0.07143860347377348, 'max_depth': 89}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:08,588]\u001b[0m Trial 56 finished with value: 0.7276422764227642 and parameters: {'learning_rate': 0.07973890931112604, 'max_depth': 65}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:08,773]\u001b[0m Trial 57 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.07695843611792492, 'max_depth': 73}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:08,962]\u001b[0m Trial 58 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.06694651671390585, 'max_depth': 79}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:09,155]\u001b[0m Trial 59 finished with value: 0.7243481917577796 and parameters: {'learning_rate': 0.0517996953678722, 'max_depth': 95}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:09,388]\u001b[0m Trial 60 finished with value: 0.7271516680684048 and parameters: {'learning_rate': 0.0739523251931739, 'max_depth': 60}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:09,596]\u001b[0m Trial 61 finished with value: 0.7269414073451079 and parameters: {'learning_rate': 0.0799005567314357, 'max_depth': 65}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:09,780]\u001b[0m Trial 62 finished with value: 0.7265208858985142 and parameters: {'learning_rate': 0.0775674272610069, 'max_depth': 46}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:09,960]\u001b[0m Trial 63 finished with value: 0.7263807120829829 and parameters: {'learning_rate': 0.074970568856294, 'max_depth': 71}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:10,151]\u001b[0m Trial 64 finished with value: 0.7263106251752173 and parameters: {'learning_rate': 0.0711216190748687, 'max_depth': 66}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:10,336]\u001b[0m Trial 65 finished with value: 0.7249789739276703 and parameters: {'learning_rate': 0.061382462500741544, 'max_depth': 57}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:10,563]\u001b[0m Trial 66 finished with value: 0.725609756097561 and parameters: {'learning_rate': 0.0554367616251073, 'max_depth': 61}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:10,744]\u001b[0m Trial 67 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.07745738955166498, 'max_depth': 53}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:10,927]\u001b[0m Trial 68 finished with value: 0.7269414073451079 and parameters: {'learning_rate': 0.07948681956210035, 'max_depth': 75}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:11,108]\u001b[0m Trial 69 finished with value: 0.7270815811606391 and parameters: {'learning_rate': 0.07336474118327962, 'max_depth': 68}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:11,305]\u001b[0m Trial 70 finished with value: 0.7264507989907485 and parameters: {'learning_rate': 0.06792289345138554, 'max_depth': 77}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:11,483]\u001b[0m Trial 71 finished with value: 0.7275021026072329 and parameters: {'learning_rate': 0.07978231882522635, 'max_depth': 62}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:11,697]\u001b[0m Trial 72 finished with value: 0.7278525371460611 and parameters: {'learning_rate': 0.07986643804296818, 'max_depth': 47}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:11,880]\u001b[0m Trial 73 finished with value: 0.7271516680684048 and parameters: {'learning_rate': 0.07793866251178216, 'max_depth': 58}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:12,064]\u001b[0m Trial 74 finished with value: 0.7259601906363892 and parameters: {'learning_rate': 0.07470766483453703, 'max_depth': 43}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:12,239]\u001b[0m Trial 75 finished with value: 0.7253994953742641 and parameters: {'learning_rate': 0.07677927960499004, 'max_depth': 31}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:12,438]\u001b[0m Trial 76 finished with value: 0.7155172413793104 and parameters: {'learning_rate': 0.022185970818563595, 'max_depth': 49}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:12,628]\u001b[0m Trial 77 finished with value: 0.7269414073451079 and parameters: {'learning_rate': 0.07104992644881353, 'max_depth': 39}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:12,857]\u001b[0m Trial 78 finished with value: 0.7272217549761705 and parameters: {'learning_rate': 0.0782657551954699, 'max_depth': 86}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:13,048]\u001b[0m Trial 79 finished with value: 0.7231567143257639 and parameters: {'learning_rate': 0.04817222523629298, 'max_depth': 52}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:13,225]\u001b[0m Trial 80 finished with value: 0.7277123633305299 and parameters: {'learning_rate': 0.07991148339355345, 'max_depth': 81}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:13,408]\u001b[0m Trial 81 finished with value: 0.7265909728062798 and parameters: {'learning_rate': 0.07562751712616352, 'max_depth': 82}. Best is trial 35 with value: 0.7279927109615923.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:13,594]\u001b[0m Trial 82 finished with value: 0.7289038407625456 and parameters: {'learning_rate': 0.07977814878621976, 'max_depth': 72}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:13,773]\u001b[0m Trial 83 finished with value: 0.726731146621811 and parameters: {'learning_rate': 0.07831939987128414, 'max_depth': 73}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:13,985]\u001b[0m Trial 84 finished with value: 0.7264507989907485 and parameters: {'learning_rate': 0.07590800117777324, 'max_depth': 93}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:14,159]\u001b[0m Trial 85 finished with value: 0.7277123633305299 and parameters: {'learning_rate': 0.07990976889970344, 'max_depth': 79}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:14,337]\u001b[0m Trial 86 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.07304658812640547, 'max_depth': 88}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:14,534]\u001b[0m Trial 87 finished with value: 0.7258901037286235 and parameters: {'learning_rate': 0.06996183281934941, 'max_depth': 81}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:14,734]\u001b[0m Trial 88 finished with value: 0.7193019343986543 and parameters: {'learning_rate': 0.03236101665231443, 'max_depth': 85}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:14,921]\u001b[0m Trial 89 finished with value: 0.7278525371460611 and parameters: {'learning_rate': 0.0798682533211076, 'max_depth': 77}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:15,120]\u001b[0m Trial 90 finished with value: 0.7278525371460611 and parameters: {'learning_rate': 0.07448494017230324, 'max_depth': 78}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:15,303]\u001b[0m Trial 91 finished with value: 0.7251892346509672 and parameters: {'learning_rate': 0.07787091810220348, 'max_depth': 78}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:15,483]\u001b[0m Trial 92 finished with value: 0.7268713204373423 and parameters: {'learning_rate': 0.07997812550284132, 'max_depth': 71}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:15,668]\u001b[0m Trial 93 finished with value: 0.7265208858985142 and parameters: {'learning_rate': 0.07420777485882707, 'max_depth': 80}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:15,851]\u001b[0m Trial 94 finished with value: 0.7277123633305299 and parameters: {'learning_rate': 0.07651103662140277, 'max_depth': 77}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:16,034]\u001b[0m Trial 95 finished with value: 0.727291841883936 and parameters: {'learning_rate': 0.0760594055741158, 'max_depth': 83}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:16,232]\u001b[0m Trial 96 finished with value: 0.7262405382674516 and parameters: {'learning_rate': 0.0726767417229619, 'max_depth': 74}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n",
      "\u001b[32m[I 2021-03-26 15:30:16,413]\u001b[0m Trial 97 finished with value: 0.7268713204373423 and parameters: {'learning_rate': 0.07859839775353865, 'max_depth': 69}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:16,599]\u001b[0m Trial 98 finished with value: 0.7278525371460611 and parameters: {'learning_rate': 0.07994433260428035, 'max_depth': 71}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-26 15:30:16,786]\u001b[0m Trial 99 finished with value: 0.7270114942528736 and parameters: {'learning_rate': 0.074900875705323, 'max_depth': 90}. Best is trial 82 with value: 0.7289038407625456.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 37684, number of negative: 19384\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.660335 -> initscore=0.664788\n",
      "[LightGBM] [Info] Start training from score 0.664788\n",
      "Number of finished trials: 100\n",
      "Best trial: {'learning_rate': 0.07977814878621976, 'max_depth': 72}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    dtrain = lgb.Dataset(X_train_, label=y_train_)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "#         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "#         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'learning_rate':trial.suggest_uniform('learning_rate', 0.01, 0.08),\n",
    "        'boosting_type':'gbdt',\n",
    "        'max_depth' :trial.suggest_int('max_depth', 1, 100),\n",
    "\n",
    "    }\n",
    " \n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(X_test_)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test_, pred_labels)\n",
    "    return accuracy\n",
    " \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    " \n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "reduced-medicaid",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "v7Zx7jh12Jt4TQK02eH8",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "params=study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "polished-brass",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "NBhfA0geK5I9l75yV6fU",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "ylenOK8hcw3CGoOOhgqF",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.07977814878621976, 'max_depth': 72}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fleet-asset",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "lP0UIErDw4SuavE8uOHO",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "nYFfXfiZ01TfOvdUwKiw",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 57068, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 0.660335\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_train_, label=y_train_)\n",
    "clf = lgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "minute-motivation",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "wuJPMv8oajWLxlVZUSbz",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "DSt65Bj8KXk9LLy6xun8",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752519197191501"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Error Training\n",
    "\n",
    "#prediction on the training set\n",
    "y_pred_train=clf.predict(X_train_)\n",
    "\n",
    "#rounding the values\n",
    "y_pred_train=y_pred_train.round(0)\n",
    "#converting from float to integer\n",
    "y_pred_train=y_pred_train.astype(int)\n",
    "#roc_auc_score metric\n",
    "roc_auc_score(y_pred_train,y_train_)\n",
    "#0.9672167056074766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "textile-anthropology",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "3Y73b3O6a1MLEPFyL77Z",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "Tbfod9EyE2pYntW36W9g",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615694715740546"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction on the test set\n",
    "y_pred=clf.predict(X_test_)\n",
    "\n",
    "#rounding the values\n",
    "y_pred=y_pred.round(0)\n",
    "#converting from float to integer\n",
    "y_pred=y_pred.astype(int)\n",
    "#roc_auc_score metric\n",
    "roc_auc_score(y_pred,y_test_)\n",
    "#0.9672167056074766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "excellent-commitment",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "zpjDwbdztNMdAAgfZves",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "pred_lgbm =clf.predict(all_test_data)\n",
    "pred_lgbm=[\"TRUE\" if x>0.5 else 'FALSE' for x in pred_lgbm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "treated-military",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "RIMxYG9FC1JINZDRdV0Y",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "abLiHuqY7O9fwlDX4TFw",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "naked-nickname",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Hukf3nmjmYQfzSOt55po",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission_LGBM = pd.read_csv('data_test.csv')\n",
    "submission_LGBM['Labels']=pred_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "lesbian-porcelain",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "WPuEDIcceWuLzf8CdMV6",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "Pv3AJWdZWRD9fZnHva7d",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6992a84_2020-11-25_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e68e62f4_2020-11-29_20</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e68e81a4_2020-11-27_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69eec04_2020-11-24_7</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e698e4a4_2020-11-27_8</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2e68dd414_2020-11-26_5</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2e698541c_2020-11-24_22</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2e69e8e0c_2020-11-24_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2e699a1cc_2020-11-24_18</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2e698d804_2020-11-25_19</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids Labels\n",
       "0      2e6992a84_2020-11-25_18   TRUE\n",
       "1      2e68e62f4_2020-11-29_20  FALSE\n",
       "2      2e68e81a4_2020-11-27_10   TRUE\n",
       "3       2e69eec04_2020-11-24_7   TRUE\n",
       "4       2e698e4a4_2020-11-27_8   TRUE\n",
       "...                        ...    ...\n",
       "13836   2e68dd414_2020-11-26_5  FALSE\n",
       "13837  2e698541c_2020-11-24_22  FALSE\n",
       "13838  2e69e8e0c_2020-11-24_10   TRUE\n",
       "13839  2e699a1cc_2020-11-24_18  FALSE\n",
       "13840  2e698d804_2020-11-25_19   TRUE\n",
       "\n",
       "[13841 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sustainable-brunswick",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "VHzFFAndC3puJICjopjL",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission_LGBM.to_csv('test-lgbm.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-inventory",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "pXflv33rUkq5WDwpAtEf",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "# Using NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "contrary-spain",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "yQEvFnQIxMbE6XQnNdBc",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pregnant-blood",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "1xSdUrPZakmvmFzY3gqJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "# Installation\n",
    "# !git clone https://github.com/Qwicen/node.git\n",
    "# os.chdir('node')\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "familiar-plaintiff",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "bZihqc1tDAnu4OsxjRsK",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from qhoptim.pyt import QHAdam\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# We access the NODE functionality through the lib/ subfolder.\n",
    "from node import lib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "excited-domain",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "I7iqgt0ytOloC5Tc2uLX",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "9a5EzrdTNMpYvBVspnB1",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "rocky-ribbon",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "afU9NeHSijZfVmQMp0Ra",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "GHUfinCLYxdgc8cQ0qXS",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hutom\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\core\\frame.py:3188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import LeaveOneOutEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_train_data, y_train_all, test_size=0.2)\n",
    " \n",
    "cat_features = ['hour', 'day', 'latitude', 'longitude']  \n",
    "\n",
    "cat_encoder = LeaveOneOutEncoder()\n",
    "cat_encoder.fit(X_train[cat_features], y_train)\n",
    "X_train[cat_features] = cat_encoder.transform(X_train[cat_features])\n",
    "X_val[cat_features] = cat_encoder.transform(X_val[cat_features])\n",
    "\n",
    "# Node is going to want to have the values as float32 at some points\n",
    "X_train_NODE = X_train.values.astype('float32')\n",
    "X_val_NODE = X_val.values.astype('float32')\n",
    "y_train_NODE = np.array(y_train)\n",
    "y_val_NODE = np.array(y_val)\n",
    "test_data_NODE=np.array(all_test_data).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-french",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "xtIxyOImxX3hYlVoGicF",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "Initialize a NODE model. There are some parameters here to be aware of:\n",
    "\n",
    "- layer_dim (how many \"trees\" should be used in each layer)\n",
    "- num_layers (how many layers, i.e. how many stacked tree ensembles)\n",
    "- depth (how many levels should each tree have)\n",
    "\n",
    "I am not sure what the significance of 'flatten_output' is. In the example notebook, they set the tree_dim to no_classes+1, but here I do not add 1. The 'choice_function' and 'bin_function' parameters should be left as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "literary-meter",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "G8OgfvWSY0A74d3A78aO",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "num_features = X_train_NODE.shape[1]\n",
    "num_classes = len(set(y_train_NODE))\n",
    "ts = math.floor(time.time())\n",
    "experiment_name = f'node{ts}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cordless-theme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "capital-discount",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "85HlkErfY4EHZkTFEXJQ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "kDZMWtd6cGPWt3EnOe9h",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    lib.DenseBlock(num_features,\n",
    "                   layer_dim=9,\n",
    "                   num_layers=5,\n",
    "                   tree_dim=num_classes,\n",
    "                   flatten_output=False,\n",
    "                   depth=7,\n",
    "                   choice_function=lib.entmax15,\n",
    "                   bin_function=lib.entmoid15),\n",
    "    lib.Lambda(lambda x: x[..., :num_classes].mean(dim=-2)),\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    res = model(torch.as_tensor(X_train_NODE[:2000], device=device))\n",
    "    # trigger data-aware init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baking-arnold",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "P1HpKHgKiA8qLr0B2ViE",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "ejo2KyPRDnfODytBw5ir",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.       ,   5.       ,  -6.258103 , 107.01999  ],\n",
       "       [ 14.       ,   4.       ,  -6.921165 , 107.62597  ],\n",
       "       [ 23.       ,   2.       ,  -6.2346153, 106.958    ],\n",
       "       ...,\n",
       "       [ 10.       ,   5.       ,  -6.885584 , 107.614136 ],\n",
       "       [ 15.       ,   0.       ,  -6.3162746, 107.037704 ],\n",
       "       [ 19.       ,   3.       ,  -6.26694  , 106.984566 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "statewide-stack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "champion-gates",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "TtjhLe99udl7VJyjIpd7",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "trainer = lib.Trainer(\n",
    "    model=model, loss_function=F.cross_entropy,\n",
    "    experiment_name=experiment_name,\n",
    "    warm_start=False,\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
    "    verbose=True,\n",
    "    n_last_checkpoints=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-writer",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "bG6hlZ5aLNy562gYvISN",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "## Define parameters for the training loop.\n",
    "\n",
    "Let's use 2500 batches as the early stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dirty-showcase",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "0QrIY4we8uiImBgPBlf6",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "loss_history, err_history = [], []\n",
    "best_val_err = 1.0\n",
    "best_step = 0\n",
    "early_stopping_rounds = 3000\n",
    "report_frequency = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "affecting-paragraph",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "ZsbwMoHyvow4SIcQlwOC",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "0iV3lq8nhEeo1qyZI8wJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Char for argument #2 'target' in call to _thnn_nll_loss_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-5bba51c0cc04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                      \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                      epochs=float('inf')):\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Data Science Weekend\\Danthon\\node\\lib\\trainer.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, device, *batch)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Char for argument #2 'target' in call to _thnn_nll_loss_forward"
     ]
    }
   ],
   "source": [
    "for batch in lib.iterate_minibatches(X_train_NODE,\n",
    "                                     y_train_NODE,\n",
    "                                     batch_size=512, \n",
    "                                     shuffle=False,\n",
    "                                     epochs=float('inf')):\n",
    "    metrics = trainer.train_on_batch(*batch, device=device)\n",
    "    \n",
    "    loss_history.append(metrics['loss'])\n",
    "\n",
    "    if trainer.step % report_frequency == 0:\n",
    "        trainer.save_checkpoint()\n",
    "        trainer.average_checkpoints(out_tag='avg')\n",
    "        trainer.load_checkpoint(tag='avg')\n",
    "        err = trainer.evaluate_classification_error(\n",
    "            X_val_NODE,\n",
    "            y_val_NODE,\n",
    "            device=device,\n",
    "            batch_size=512)\n",
    "        \n",
    "        if err < best_val_err:\n",
    "            best_val_err = err\n",
    "            best_step = trainer.step\n",
    "            trainer.save_checkpoint(tag='best')\n",
    "        \n",
    "        err_history.append(err)\n",
    "        trainer.load_checkpoint()  # last\n",
    "        trainer.remove_old_temp_checkpoints()\n",
    "            \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=[12, 6])\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(loss_history)\n",
    "        plt.grid()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(err_history)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Loss %.5f\" % (metrics['loss']))\n",
    "        print(\"Val Error Rate: %0.5f\" % (err))\n",
    "        \n",
    "    if trainer.step > best_step + early_stopping_rounds:\n",
    "        print('BREAK. There is no improvement for {} steps'.format(early_stopping_rounds))\n",
    "        print(\"Best step: \", best_step)\n",
    "        print(\"Best Val Error Rate: %0.5f\" % (best_val_err))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "nuclear-sierra",
   "metadata": {
    "collapsed": true,
    "iooxa": {
     "id": {
      "block": "p8pt60lf7OHbaEZLujOf",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     },
     "outputId": {
      "block": "xjkflXbK199EXICDJkZp",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 4
     }
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/node1616744492\\\\checkpoint_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-9b3b6a20f40f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0merror_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_classification_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_NODE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val_NODE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best step: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Error rate: %0.5f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0merror_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Data Science Weekend\\Danthon\\node\\lib\\trainer.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[1;34m(self, tag, path, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"checkpoint_{}.pth\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/node1616744492\\\\checkpoint_best.pth'"
     ]
    }
   ],
   "source": [
    "trainer.load_checkpoint(tag='best')\n",
    "error_rate = trainer.evaluate_classification_error(X_val_NODE,y_val_NODE, device=device, batch_size=1024)\n",
    "print('Best step: ', trainer.step)\n",
    "print(\"Test Error rate: %0.5f\" % (error_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-threat",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "qReULlC5cu6QalFrOp0l",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_NODE = trainer.model(torch.as_tensor(test_data_NODE[:], device=device))\n",
    "    # trigger data-aware init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-genius",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "HvcOWPj5HBCrZgcQ8ZIl",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "CXetbuG5Mzt4j6T92jBk",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [],
   "source": [
    "prediction_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-martial",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "HjUPSOfZ3M9vgUxsHhlA",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "prediction_NODE=prediction_NODE.detach().cpu().numpy()\n",
    "prediction_NODE=np.argmax(prediction_NODE, axis=1)\n",
    "prediction_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sacred-leeds",
   "metadata": {
    "collapsed": true,
    "iooxa": {
     "id": {
      "block": "tPeZum83DkAmVqaopA6m",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": null
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_NODE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-7aa2f219caec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction_NODE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TRUE\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'FALSE'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprediction_NODE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_NODE' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_NODE=[\"TRUE\" if x==1 else 'FALSE' for x in prediction_NODE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "minute-entry",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "7QR8tquUHtHt2NOFr9i8",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "49dmmJBuG4M75EowqgVH",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "analyzed-france",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "9badRpp3zI7MCqXhJoJM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission_NODE= pd.read_csv('data_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "human-techno",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "UHYBd49nqIncNAkEYm4f",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission_NODE['Labels']=prediction_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "foreign-front",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "3oRcFtO3e6RlF1SDRePM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": {
      "block": "wFt2VYYHDKG223JIDgZw",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6992a84_2020-11-25_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e68e62f4_2020-11-29_20</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e68e81a4_2020-11-27_10</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69eec04_2020-11-24_7</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e698e4a4_2020-11-27_8</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2e68dd414_2020-11-26_5</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2e698541c_2020-11-24_22</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2e69e8e0c_2020-11-24_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2e699a1cc_2020-11-24_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2e698d804_2020-11-25_19</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids Labels\n",
       "0      2e6992a84_2020-11-25_18   TRUE\n",
       "1      2e68e62f4_2020-11-29_20   TRUE\n",
       "2      2e68e81a4_2020-11-27_10  FALSE\n",
       "3       2e69eec04_2020-11-24_7   TRUE\n",
       "4       2e698e4a4_2020-11-27_8   TRUE\n",
       "...                        ...    ...\n",
       "13836   2e68dd414_2020-11-26_5  FALSE\n",
       "13837  2e698541c_2020-11-24_22  FALSE\n",
       "13838  2e69e8e0c_2020-11-24_10   TRUE\n",
       "13839  2e699a1cc_2020-11-24_18   TRUE\n",
       "13840  2e698d804_2020-11-25_19   TRUE\n",
       "\n",
       "[13841 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "velvet-guatemala",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "WQpitUNhWHDC2wyajs1K",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission_NODE.to_csv('test-NODE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "authorized-season",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "CzLBpweh1oonI4KDf2L1",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "GTmb108cXuf0t8e2jjhk",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, STATUS_OK, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "swedish-brooklyn",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "70eTTP9WqJSNInop8O8t",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "def opt_fn(search_space):\n",
    "  print(search_space)\n",
    "  best_val_err = 1.0\n",
    "  best_step = 0\n",
    "  early_stopping_rounds = 2500\n",
    "  report_frequency = 1000\n",
    "  experiment_name = 'debug' # this bypasses some code that will be executed each time otherwise\n",
    "  \n",
    "  model = nn.Sequential(\n",
    "      lib.DenseBlock(num_features,\n",
    "                     layer_dim=int(search_space['layer_dim']),\n",
    "                     num_layers=int(search_space['num_layers']),\n",
    "                     tree_dim=num_classes,\n",
    "                     flatten_output=False,\n",
    "                     depth=int(search_space['depth']),\n",
    "                     choice_function=lib.entmax15,\n",
    "                     bin_function=lib.entmoid15),\n",
    "      lib.Lambda(lambda x: x[..., :num_classes].mean(dim=-2)),\n",
    "    ).to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    res = model(torch.as_tensor(X_train_NODE[:], device=device))\n",
    "    # trigger data-aware init\n",
    "\n",
    "  trainer = lib.Trainer(\n",
    "    model=model, loss_function=F.cross_entropy,\n",
    "    experiment_name=experiment_name,\n",
    "    warm_start=False,\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
    "    verbose=True,\n",
    "    n_last_checkpoints=5\n",
    "  )\n",
    "\n",
    "  for batch in lib.iterate_minibatches(X_train_NODE,\n",
    "                                     y_train_NODE,\n",
    "                                     batch_size=512, \n",
    "                                     shuffle=True,\n",
    "                                     epochs=float('inf')):\n",
    "    \n",
    "    metrics = trainer.train_on_batch(*batch, device=device)\n",
    "    \n",
    "\n",
    "    if trainer.step % report_frequency == 0:\n",
    "          err = trainer.evaluate_classification_error(\n",
    "              X_val_NODE,\n",
    "              y_val_NODE,\n",
    "              device=device,\n",
    "              batch_size=64)\n",
    "        \n",
    "          if err < best_val_err:\n",
    "              best_val_err = err\n",
    "              best_step = trainer.step\n",
    "\n",
    "          print(\"Loss %.5f\" % (metrics['loss']))\n",
    "          print(\"Val Error Rate: %0.5f\" % (err))\n",
    "        \n",
    "    if trainer.step > best_step + early_stopping_rounds:\n",
    "          opt_metric = best_val_err\n",
    "          break\n",
    "          \n",
    "  return {'loss': opt_metric, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "parental-discipline",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "QYTn0peNLnQ0Y2uFNYpU",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "search_space = {'layer_dim': hp.quniform('layer_dim', 1, 10, 1),\n",
    "                'num_layers': hp.quniform('num_layers', 1, 10,1),\n",
    "                'depth': hp.quniform('depth', 1, 7, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-cookie",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "d6nkVI5iqzVo3rddUCpZ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     },
     "outputId": {
      "block": "rk8lpLRGSWIRyn0q9Mju",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 3
     }
    }
   },
   "outputs": [],
   "source": [
    "best = fmin(fn=opt_fn, \n",
    "            space=search_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "numerous-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('best_params_NODE.pickle', 'wb') as handle:\n",
    "    pickle.dump(best, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('best_params_NODE.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "print (best == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-daughter",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "RVbU7nSyk9Re9grdwROP",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "source": [
    "# Using PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "resident-light",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "EPutI8gjZqCnD6H0PlFW",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "chief-lincoln",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "V9oP9HnaKDDxgl9Y9eOv",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_PYTORCH = scaler.fit_transform(X_train_)\n",
    "# X_train_PYTORCH = scaler.fit_transform(all_train_data)\n",
    "\n",
    "X_val_PYTORCH = scaler.transform(X_test_)\n",
    "X_tes_PYTORCH = scaler.transform(all_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "medical-price",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "JEzjqi2rjog2wiOBppFf",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "y_train_PYTORCH= torch.Tensor(y_train_.to_numpy())\n",
    "# y_train_PYTORCH= torch.Tensor(y_train_all.to_numpy())\n",
    "\n",
    "y_val_PYTORCH= torch.Tensor(y_test_.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "exempt-immune",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "aNj5oQR1BWVgvwZh51FM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 8192\n",
    "LEARNING_RATE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "communist-incentive",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "7rY2mAq1TCyer3WwvrGF",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train_PYTORCH), \n",
    "                       torch.FloatTensor(y_train_PYTORCH))\n",
    "\n",
    "val_data =trainData(torch.FloatTensor(X_val_PYTORCH),\n",
    "                    torch.FloatTensor(y_val_PYTORCH))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_tes_PYTORCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "surprised-demographic",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "PooJ8rCnmK3C6lFPs9rG",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "abroad-maintenance",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "zLzpoLTkiXBJ51riOZoG",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": {
      "block": "obARQv8kKN1PQgm9c6c9",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1085, -1.4147,  0.8886, -0.5486],\n",
       "        [ 1.9003, -1.4147,  1.2345, -0.4878],\n",
       "        [-1.1714,  1.6789, -1.5385,  1.3017],\n",
       "        ...,\n",
       "        [ 0.3645,  0.6477,  0.3784, -1.1902],\n",
       "        [-1.4274,  1.1633, -1.2916,  1.3800],\n",
       "        [ 0.6205, -1.4147,  0.9800, -0.3577]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "banner-harbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "american-parade",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "FIuUtxfYutskrJ5LXOTy",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": {
      "block": "2CQ3oYWTNgzT4M12qs4D",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8764,  1.6789,  0.8572, -0.6353],\n",
       "        [ 1.3884,  0.1321, -1.4128,  1.3887],\n",
       "        [-1.1714, -1.4147, -1.4810,  1.5278],\n",
       "        ...,\n",
       "        [-1.1714,  1.1633,  0.4662, -1.0949],\n",
       "        [ 0.8764,  1.1633,  0.6019, -0.0712],\n",
       "        [ 1.1324,  1.6789,  0.8711, -0.5225]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "modified-spokesman",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Qxl3bAojzkoCkThu2TYL",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 4.\n",
    "        self.layer_1 = nn.Linear(4, 64) \n",
    "        self.layer_2 = nn.Linear(64, 128)\n",
    "        self.layer_3 = nn.Linear(128, 128)\n",
    "        self.layer_4 = nn.Linear(128, 64)\n",
    "        self.layer_5 = nn.Linear(64, 64)\n",
    "        self.layer_6 = nn.Linear(64, 4)\n",
    "        self.layer_out = nn.Linear(4, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(4)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.dropout(x)        \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)   \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "instrumental-reliance",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "yb6iFO7Yoqq6ID5KhreE",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": {
      "block": "s1Qw05ILmKyDkHTmNG0q",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "lined-journal",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "ohji6NLxhSIidR8UenpJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": {
      "block": "c0bjLU9nSTyKNK4AZNoe",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (layer_4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_5): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_6): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (layer_out): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm6): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "religious-express",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "hCURWi1De9uGLxu4Sl7m",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "electronic-privilege",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "7m7kRPzo9dvjeKe5L2O3",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": {
      "block": "mQRvjEu9cOCbPRi8FbsK",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model on best loss val..\n",
      "saving best model on best acc val..\n",
      "Epoch 001: | Loss: 0.64073 | Val_Loss: 0.61566| Acc: 66.143| Val_Acc: 69.0\n",
      "saving best model on best loss val..\n",
      "Epoch 002: | Loss: 0.62190 | Val_Loss: 0.61395| Acc: 68.000| Val_Acc: 69.0\n",
      "saving best model on best loss val..\n",
      "Epoch 003: | Loss: 0.61987 | Val_Loss: 0.61212| Acc: 68.143| Val_Acc: 69.0\n",
      "saving best model on best loss val..\n",
      "Epoch 004: | Loss: 0.61845 | Val_Loss: 0.61001| Acc: 68.429| Val_Acc: 69.0\n",
      "Epoch 005: | Loss: 0.61675 | Val_Loss: 0.61023| Acc: 68.429| Val_Acc: 69.0\n",
      "saving best model on best loss val..\n",
      "saving best model on best acc val..\n",
      "Epoch 006: | Loss: 0.61507 | Val_Loss: 0.60792| Acc: 68.429| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 007: | Loss: 0.61377 | Val_Loss: 0.60719| Acc: 68.714| Val_Acc: 69.0\n",
      "Epoch 008: | Loss: 0.61300 | Val_Loss: 0.60785| Acc: 68.714| Val_Acc: 69.0\n",
      "saving best model on best loss val..\n",
      "Epoch 009: | Loss: 0.61196 | Val_Loss: 0.60556| Acc: 68.857| Val_Acc: 70.0\n",
      "Epoch 010: | Loss: 0.61210 | Val_Loss: 0.60564| Acc: 68.857| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 011: | Loss: 0.61114 | Val_Loss: 0.60454| Acc: 69.143| Val_Acc: 70.0\n",
      "Epoch 012: | Loss: 0.61081 | Val_Loss: 0.60482| Acc: 69.000| Val_Acc: 70.0\n",
      "Epoch 013: | Loss: 0.61002 | Val_Loss: 0.60457| Acc: 69.000| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 014: | Loss: 0.61021 | Val_Loss: 0.60435| Acc: 69.000| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 015: | Loss: 0.60933 | Val_Loss: 0.60236| Acc: 69.000| Val_Acc: 70.0\n",
      "Epoch 016: | Loss: 0.60901 | Val_Loss: 0.60327| Acc: 69.143| Val_Acc: 70.0\n",
      "Epoch 017: | Loss: 0.60831 | Val_Loss: 0.60294| Acc: 68.857| Val_Acc: 70.0\n",
      "Epoch 018: | Loss: 0.60873 | Val_Loss: 0.60298| Acc: 69.000| Val_Acc: 70.0\n",
      "Epoch 019: | Loss: 0.60939 | Val_Loss: 0.60320| Acc: 68.857| Val_Acc: 70.0\n",
      "Epoch 020: | Loss: 0.60787 | Val_Loss: 0.60260| Acc: 69.000| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 021: | Loss: 0.60579 | Val_Loss: 0.59871| Acc: 69.286| Val_Acc: 70.0\n",
      "Epoch 022: | Loss: 0.60710 | Val_Loss: 0.60144| Acc: 69.143| Val_Acc: 70.0\n",
      "Epoch 023: | Loss: 0.60691 | Val_Loss: 0.60133| Acc: 69.143| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 024: | Loss: 0.60596 | Val_Loss: 0.59852| Acc: 69.286| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 025: | Loss: 0.60419 | Val_Loss: 0.59729| Acc: 69.286| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 026: | Loss: 0.60303 | Val_Loss: 0.59666| Acc: 69.571| Val_Acc: 70.0\n",
      "Epoch 027: | Loss: 0.60277 | Val_Loss: 0.59901| Acc: 69.714| Val_Acc: 70.0\n",
      "Epoch 028: | Loss: 0.60375 | Val_Loss: 0.59742| Acc: 69.429| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "saving best model on best acc val..\n",
      "Epoch 029: | Loss: 0.60114 | Val_Loss: 0.59453| Acc: 69.857| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 030: | Loss: 0.59971 | Val_Loss: 0.59394| Acc: 70.000| Val_Acc: 70.0\n",
      "Epoch 031: | Loss: 0.60039 | Val_Loss: 0.59412| Acc: 69.714| Val_Acc: 71.0\n",
      "Epoch 032: | Loss: 0.60228 | Val_Loss: 0.59763| Acc: 69.571| Val_Acc: 70.0\n",
      "saving best model on best loss val..\n",
      "Epoch 033: | Loss: 0.60090 | Val_Loss: 0.59353| Acc: 69.714| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 034: | Loss: 0.59842 | Val_Loss: 0.59053| Acc: 69.857| Val_Acc: 71.0\n",
      "Epoch 035: | Loss: 0.59786 | Val_Loss: 0.59120| Acc: 70.000| Val_Acc: 71.0\n",
      "Epoch 036: | Loss: 0.59707 | Val_Loss: 0.59179| Acc: 70.000| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 037: | Loss: 0.59640 | Val_Loss: 0.58989| Acc: 70.000| Val_Acc: 71.0\n",
      "Epoch 038: | Loss: 0.59685 | Val_Loss: 0.59162| Acc: 70.000| Val_Acc: 71.0\n",
      "Epoch 039: | Loss: 0.59727 | Val_Loss: 0.58997| Acc: 70.000| Val_Acc: 71.0\n",
      "Epoch 040: | Loss: 0.59623 | Val_Loss: 0.59178| Acc: 70.000| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 041: | Loss: 0.59692 | Val_Loss: 0.58946| Acc: 69.857| Val_Acc: 71.0\n",
      "Epoch 042: | Loss: 0.59583 | Val_Loss: 0.59154| Acc: 70.000| Val_Acc: 71.0\n",
      "Epoch 043: | Loss: 0.59548 | Val_Loss: 0.59047| Acc: 70.000| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 044: | Loss: 0.59441 | Val_Loss: 0.58803| Acc: 70.286| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 045: | Loss: 0.59481 | Val_Loss: 0.58767| Acc: 70.143| Val_Acc: 71.0\n",
      "Epoch 046: | Loss: 0.59409 | Val_Loss: 0.58874| Acc: 70.143| Val_Acc: 71.0\n",
      "Epoch 047: | Loss: 0.59585 | Val_Loss: 0.58855| Acc: 69.857| Val_Acc: 71.0\n",
      "Epoch 048: | Loss: 0.59445 | Val_Loss: 0.58797| Acc: 70.286| Val_Acc: 71.0\n",
      "Epoch 049: | Loss: 0.59649 | Val_Loss: 0.59121| Acc: 69.857| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 050: | Loss: 0.59507 | Val_Loss: 0.58698| Acc: 70.143| Val_Acc: 71.0\n",
      "Epoch 051: | Loss: 0.59558 | Val_Loss: 0.58809| Acc: 70.143| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 052: | Loss: 0.59279 | Val_Loss: 0.58602| Acc: 70.000| Val_Acc: 71.0\n",
      "Epoch 053: | Loss: 0.59373 | Val_Loss: 0.58791| Acc: 70.143| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 054: | Loss: 0.59292 | Val_Loss: 0.58463| Acc: 70.286| Val_Acc: 71.0\n",
      "Epoch 055: | Loss: 0.59170 | Val_Loss: 0.58499| Acc: 70.429| Val_Acc: 71.0\n",
      "Epoch 056: | Loss: 0.59028 | Val_Loss: 0.58846| Acc: 70.286| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 057: | Loss: 0.58951 | Val_Loss: 0.58455| Acc: 70.429| Val_Acc: 71.0\n",
      "Epoch 058: | Loss: 0.59109 | Val_Loss: 0.58635| Acc: 70.143| Val_Acc: 71.0\n",
      "Epoch 059: | Loss: 0.59197 | Val_Loss: 0.58531| Acc: 70.429| Val_Acc: 71.0\n",
      "Epoch 060: | Loss: 0.59071 | Val_Loss: 0.58638| Acc: 70.286| Val_Acc: 71.0\n",
      "Epoch 061: | Loss: 0.58954 | Val_Loss: 0.58621| Acc: 70.286| Val_Acc: 71.0\n",
      "Epoch 062: | Loss: 0.58963 | Val_Loss: 0.58551| Acc: 70.429| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 063: | Loss: 0.58981 | Val_Loss: 0.58208| Acc: 70.143| Val_Acc: 71.0\n",
      "Epoch 064: | Loss: 0.59032 | Val_Loss: 0.58332| Acc: 70.286| Val_Acc: 71.0\n",
      "Epoch 065: | Loss: 0.58938 | Val_Loss: 0.58381| Acc: 70.571| Val_Acc: 71.0\n",
      "saving best model on best acc val..\n",
      "Epoch 066: | Loss: 0.58906 | Val_Loss: 0.58214| Acc: 70.429| Val_Acc: 72.0\n",
      "Epoch 067: | Loss: 0.58974 | Val_Loss: 0.58325| Acc: 70.429| Val_Acc: 71.0\n",
      "Epoch 068: | Loss: 0.58922 | Val_Loss: 0.58350| Acc: 70.429| Val_Acc: 71.0\n",
      "Epoch 069: | Loss: 0.58739 | Val_Loss: 0.58384| Acc: 70.571| Val_Acc: 71.0\n",
      "Epoch 070: | Loss: 0.58929 | Val_Loss: 0.58316| Acc: 70.429| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 071: | Loss: 0.58866 | Val_Loss: 0.58174| Acc: 70.571| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 072: | Loss: 0.58604 | Val_Loss: 0.58037| Acc: 70.714| Val_Acc: 72.0\n",
      "Epoch 073: | Loss: 0.58702 | Val_Loss: 0.58213| Acc: 70.571| Val_Acc: 71.0\n",
      "Epoch 074: | Loss: 0.58811 | Val_Loss: 0.58225| Acc: 70.429| Val_Acc: 71.0\n",
      "Epoch 075: | Loss: 0.58894 | Val_Loss: 0.58281| Acc: 70.286| Val_Acc: 71.0\n",
      "Epoch 076: | Loss: 0.58933 | Val_Loss: 0.58319| Acc: 70.571| Val_Acc: 71.0\n",
      "Epoch 077: | Loss: 0.58603 | Val_Loss: 0.58224| Acc: 70.714| Val_Acc: 71.0\n",
      "Epoch 078: | Loss: 0.58646 | Val_Loss: 0.58307| Acc: 70.714| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 079: | Loss: 0.58723 | Val_Loss: 0.57993| Acc: 70.714| Val_Acc: 71.0\n",
      "Epoch 080: | Loss: 0.58513 | Val_Loss: 0.58013| Acc: 70.571| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 081: | Loss: 0.58496 | Val_Loss: 0.57970| Acc: 70.714| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 082: | Loss: 0.58574 | Val_Loss: 0.57825| Acc: 70.571| Val_Acc: 72.0\n",
      "Epoch 083: | Loss: 0.58225 | Val_Loss: 0.57859| Acc: 71.000| Val_Acc: 71.0\n",
      "Epoch 084: | Loss: 0.58253 | Val_Loss: 0.57865| Acc: 70.857| Val_Acc: 72.0\n",
      "Epoch 085: | Loss: 0.58237 | Val_Loss: 0.57921| Acc: 71.000| Val_Acc: 71.0\n",
      "Epoch 086: | Loss: 0.58427 | Val_Loss: 0.57849| Acc: 70.857| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 087: | Loss: 0.58284 | Val_Loss: 0.57813| Acc: 71.143| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 088: | Loss: 0.58119 | Val_Loss: 0.57611| Acc: 71.000| Val_Acc: 72.0\n",
      "Epoch 089: | Loss: 0.58315 | Val_Loss: 0.57925| Acc: 70.857| Val_Acc: 71.0\n",
      "Epoch 090: | Loss: 0.58518 | Val_Loss: 0.57874| Acc: 70.714| Val_Acc: 71.0\n",
      "saving best model on best loss val..\n",
      "Epoch 091: | Loss: 0.58274 | Val_Loss: 0.57438| Acc: 70.571| Val_Acc: 72.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 092: | Loss: 0.58045 | Val_Loss: 0.57720| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 093: | Loss: 0.57876 | Val_Loss: 0.57530| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 094: | Loss: 0.57810 | Val_Loss: 0.57567| Acc: 71.000| Val_Acc: 72.0\n",
      "Epoch 095: | Loss: 0.58104 | Val_Loss: 0.57631| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 096: | Loss: 0.57986 | Val_Loss: 0.57668| Acc: 71.000| Val_Acc: 71.0\n",
      "Epoch 097: | Loss: 0.58065 | Val_Loss: 0.57963| Acc: 70.857| Val_Acc: 71.0\n",
      "Epoch 098: | Loss: 0.57768 | Val_Loss: 0.57562| Acc: 71.143| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 099: | Loss: 0.57859 | Val_Loss: 0.57408| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 100: | Loss: 0.58062 | Val_Loss: 0.57698| Acc: 70.857| Val_Acc: 72.0\n",
      "Epoch 101: | Loss: 0.58303 | Val_Loss: 0.57861| Acc: 70.857| Val_Acc: 72.0\n",
      "Epoch 102: | Loss: 0.58013 | Val_Loss: 0.57526| Acc: 71.143| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 103: | Loss: 0.57945 | Val_Loss: 0.57370| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 104: | Loss: 0.57651 | Val_Loss: 0.57532| Acc: 71.429| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 105: | Loss: 0.57539 | Val_Loss: 0.57256| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 106: | Loss: 0.57520 | Val_Loss: 0.57390| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 107: | Loss: 0.57638 | Val_Loss: 0.57509| Acc: 71.286| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 108: | Loss: 0.57842 | Val_Loss: 0.57238| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 109: | Loss: 0.57703 | Val_Loss: 0.57403| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 110: | Loss: 0.57622 | Val_Loss: 0.57271| Acc: 71.143| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 111: | Loss: 0.57480 | Val_Loss: 0.57089| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 112: | Loss: 0.57560 | Val_Loss: 0.57446| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 113: | Loss: 0.57496 | Val_Loss: 0.57267| Acc: 71.571| Val_Acc: 71.0\n",
      "Epoch 114: | Loss: 0.57292 | Val_Loss: 0.57226| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 115: | Loss: 0.57412 | Val_Loss: 0.57163| Acc: 71.429| Val_Acc: 72.0\n",
      "Epoch 116: | Loss: 0.57369 | Val_Loss: 0.57316| Acc: 71.286| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 117: | Loss: 0.57393 | Val_Loss: 0.57038| Acc: 71.429| Val_Acc: 72.0\n",
      "Epoch 118: | Loss: 0.57421 | Val_Loss: 0.57501| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 119: | Loss: 0.57744 | Val_Loss: 0.57258| Acc: 71.000| Val_Acc: 72.0\n",
      "Epoch 120: | Loss: 0.57428 | Val_Loss: 0.57218| Acc: 71.429| Val_Acc: 71.0\n",
      "Epoch 121: | Loss: 0.57342 | Val_Loss: 0.57039| Acc: 71.429| Val_Acc: 72.0\n",
      "Epoch 122: | Loss: 0.57302 | Val_Loss: 0.57265| Acc: 71.286| Val_Acc: 71.0\n",
      "Epoch 123: | Loss: 0.57303 | Val_Loss: 0.57276| Acc: 71.429| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 124: | Loss: 0.57415 | Val_Loss: 0.56773| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 125: | Loss: 0.57364 | Val_Loss: 0.57162| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 126: | Loss: 0.57160 | Val_Loss: 0.57049| Acc: 71.429| Val_Acc: 72.0\n",
      "Epoch 127: | Loss: 0.57139 | Val_Loss: 0.56999| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 128: | Loss: 0.57467 | Val_Loss: 0.57047| Acc: 71.143| Val_Acc: 72.0\n",
      "Epoch 129: | Loss: 0.57336 | Val_Loss: 0.57291| Acc: 71.286| Val_Acc: 71.0\n",
      "Epoch 130: | Loss: 0.57327 | Val_Loss: 0.57111| Acc: 71.286| Val_Acc: 72.0\n",
      "Epoch 131: | Loss: 0.57054 | Val_Loss: 0.56922| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 132: | Loss: 0.57049 | Val_Loss: 0.56907| Acc: 71.429| Val_Acc: 72.0\n",
      "Epoch 133: | Loss: 0.57218 | Val_Loss: 0.56900| Acc: 71.714| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 134: | Loss: 0.56894 | Val_Loss: 0.56585| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 135: | Loss: 0.56785 | Val_Loss: 0.56783| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 136: | Loss: 0.56816 | Val_Loss: 0.56773| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 137: | Loss: 0.56727 | Val_Loss: 0.56821| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 138: | Loss: 0.56754 | Val_Loss: 0.56812| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 139: | Loss: 0.56739 | Val_Loss: 0.56604| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 140: | Loss: 0.56936 | Val_Loss: 0.56696| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 141: | Loss: 0.56849 | Val_Loss: 0.57065| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 142: | Loss: 0.57135 | Val_Loss: 0.56850| Acc: 71.429| Val_Acc: 72.0\n",
      "Epoch 143: | Loss: 0.56960 | Val_Loss: 0.56918| Acc: 71.714| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 144: | Loss: 0.56725 | Val_Loss: 0.56556| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 145: | Loss: 0.56694 | Val_Loss: 0.56946| Acc: 71.714| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 146: | Loss: 0.56629 | Val_Loss: 0.56451| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 147: | Loss: 0.56423 | Val_Loss: 0.56590| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 148: | Loss: 0.56506 | Val_Loss: 0.56758| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 149: | Loss: 0.56561 | Val_Loss: 0.56528| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 150: | Loss: 0.56361 | Val_Loss: 0.56594| Acc: 72.000| Val_Acc: 72.0\n",
      "Epoch 151: | Loss: 0.56489 | Val_Loss: 0.56824| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 152: | Loss: 0.56497 | Val_Loss: 0.56639| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 153: | Loss: 0.56538 | Val_Loss: 0.56631| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 154: | Loss: 0.56568 | Val_Loss: 0.56461| Acc: 72.000| Val_Acc: 72.0\n",
      "Epoch 155: | Loss: 0.56437 | Val_Loss: 0.56537| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 156: | Loss: 0.56650 | Val_Loss: 0.56641| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 157: | Loss: 0.56675 | Val_Loss: 0.56923| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 158: | Loss: 0.56862 | Val_Loss: 0.56833| Acc: 71.571| Val_Acc: 72.0\n",
      "Epoch 159: | Loss: 0.56518 | Val_Loss: 0.56700| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 160: | Loss: 0.56553 | Val_Loss: 0.56583| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 161: | Loss: 0.56657 | Val_Loss: 0.56621| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 162: | Loss: 0.56410 | Val_Loss: 0.56577| Acc: 72.000| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 163: | Loss: 0.56321 | Val_Loss: 0.56445| Acc: 72.143| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 164: | Loss: 0.56267 | Val_Loss: 0.56403| Acc: 72.000| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 165: | Loss: 0.56459 | Val_Loss: 0.56287| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 166: | Loss: 0.56106 | Val_Loss: 0.56334| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 167: | Loss: 0.56375 | Val_Loss: 0.56461| Acc: 72.000| Val_Acc: 72.0\n",
      "Epoch 168: | Loss: 0.56353 | Val_Loss: 0.56875| Acc: 72.000| Val_Acc: 72.0\n",
      "Epoch 169: | Loss: 0.56262 | Val_Loss: 0.56664| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 170: | Loss: 0.56299 | Val_Loss: 0.56385| Acc: 71.714| Val_Acc: 72.0\n",
      "Epoch 171: | Loss: 0.56256 | Val_Loss: 0.56504| Acc: 72.000| Val_Acc: 72.0\n",
      "saving best model on best acc val..\n",
      "Epoch 172: | Loss: 0.56213 | Val_Loss: 0.56374| Acc: 72.143| Val_Acc: 73.0\n",
      "Epoch 173: | Loss: 0.56094 | Val_Loss: 0.56544| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 174: | Loss: 0.56055 | Val_Loss: 0.56410| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 175: | Loss: 0.56026 | Val_Loss: 0.56554| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 176: | Loss: 0.56099 | Val_Loss: 0.56378| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 177: | Loss: 0.56223 | Val_Loss: 0.56566| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 178: | Loss: 0.56438 | Val_Loss: 0.56666| Acc: 71.857| Val_Acc: 72.0\n",
      "Epoch 179: | Loss: 0.56083 | Val_Loss: 0.56405| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 180: | Loss: 0.56142 | Val_Loss: 0.56459| Acc: 72.286| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 181: | Loss: 0.55926 | Val_Loss: 0.56239| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 182: | Loss: 0.55848 | Val_Loss: 0.56405| Acc: 72.143| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 183: | Loss: 0.55928 | Val_Loss: 0.56144| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 184: | Loss: 0.55926 | Val_Loss: 0.56293| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 185: | Loss: 0.56335 | Val_Loss: 0.56494| Acc: 72.000| Val_Acc: 73.0\n",
      "Epoch 186: | Loss: 0.56054 | Val_Loss: 0.56213| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 187: | Loss: 0.55989 | Val_Loss: 0.56353| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 188: | Loss: 0.55768 | Val_Loss: 0.56188| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 189: | Loss: 0.55787 | Val_Loss: 0.56369| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 190: | Loss: 0.55804 | Val_Loss: 0.56423| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 191: | Loss: 0.55906 | Val_Loss: 0.56339| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 192: | Loss: 0.55986 | Val_Loss: 0.56429| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 193: | Loss: 0.55965 | Val_Loss: 0.56198| Acc: 72.143| Val_Acc: 73.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194: | Loss: 0.55650 | Val_Loss: 0.56218| Acc: 72.429| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 195: | Loss: 0.55728 | Val_Loss: 0.55696| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 196: | Loss: 0.55819 | Val_Loss: 0.55795| Acc: 72.429| Val_Acc: 73.0\n",
      "Epoch 197: | Loss: 0.55961 | Val_Loss: 0.56306| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 198: | Loss: 0.55987 | Val_Loss: 0.56608| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 199: | Loss: 0.55691 | Val_Loss: 0.56074| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 200: | Loss: 0.55945 | Val_Loss: 0.56177| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 201: | Loss: 0.56127 | Val_Loss: 0.56008| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 202: | Loss: 0.55945 | Val_Loss: 0.56456| Acc: 72.286| Val_Acc: 72.0\n",
      "Epoch 203: | Loss: 0.55854 | Val_Loss: 0.56038| Acc: 72.286| Val_Acc: 73.0\n",
      "Epoch 204: | Loss: 0.55631 | Val_Loss: 0.56000| Acc: 72.714| Val_Acc: 72.0\n",
      "Epoch 205: | Loss: 0.55549 | Val_Loss: 0.56197| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 206: | Loss: 0.55732 | Val_Loss: 0.56078| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 207: | Loss: 0.55848 | Val_Loss: 0.56340| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 208: | Loss: 0.55744 | Val_Loss: 0.56253| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 209: | Loss: 0.55936 | Val_Loss: 0.55850| Acc: 72.143| Val_Acc: 73.0\n",
      "Epoch 210: | Loss: 0.55711 | Val_Loss: 0.56059| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 211: | Loss: 0.55289 | Val_Loss: 0.56091| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 212: | Loss: 0.55342 | Val_Loss: 0.55819| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 213: | Loss: 0.55719 | Val_Loss: 0.55860| Acc: 72.286| Val_Acc: 73.0\n",
      "Epoch 214: | Loss: 0.55748 | Val_Loss: 0.55993| Acc: 72.286| Val_Acc: 73.0\n",
      "Epoch 215: | Loss: 0.55245 | Val_Loss: 0.56220| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 216: | Loss: 0.55418 | Val_Loss: 0.56233| Acc: 72.714| Val_Acc: 72.0\n",
      "saving best model on best loss val..\n",
      "Epoch 217: | Loss: 0.55590 | Val_Loss: 0.55677| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 218: | Loss: 0.55499 | Val_Loss: 0.56188| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 219: | Loss: 0.55629 | Val_Loss: 0.55911| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 220: | Loss: 0.55504 | Val_Loss: 0.56010| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 221: | Loss: 0.55671 | Val_Loss: 0.56045| Acc: 72.714| Val_Acc: 73.0\n",
      "Epoch 222: | Loss: 0.55482 | Val_Loss: 0.56140| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 223: | Loss: 0.55689 | Val_Loss: 0.56038| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 224: | Loss: 0.55604 | Val_Loss: 0.55955| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 225: | Loss: 0.55259 | Val_Loss: 0.55810| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 226: | Loss: 0.55547 | Val_Loss: 0.55989| Acc: 72.429| Val_Acc: 73.0\n",
      "Epoch 227: | Loss: 0.55387 | Val_Loss: 0.55752| Acc: 72.857| Val_Acc: 73.0\n",
      "Epoch 228: | Loss: 0.55257 | Val_Loss: 0.55884| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 229: | Loss: 0.55324 | Val_Loss: 0.55865| Acc: 72.714| Val_Acc: 73.0\n",
      "Epoch 230: | Loss: 0.55387 | Val_Loss: 0.55990| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 231: | Loss: 0.55543 | Val_Loss: 0.56083| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 232: | Loss: 0.55305 | Val_Loss: 0.55914| Acc: 72.714| Val_Acc: 72.0\n",
      "Epoch 233: | Loss: 0.55325 | Val_Loss: 0.55981| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 234: | Loss: 0.55786 | Val_Loss: 0.55961| Acc: 72.143| Val_Acc: 72.0\n",
      "Epoch 235: | Loss: 0.55716 | Val_Loss: 0.56373| Acc: 72.429| Val_Acc: 72.0\n",
      "Epoch 236: | Loss: 0.55548 | Val_Loss: 0.55899| Acc: 72.429| Val_Acc: 73.0\n",
      "Epoch 237: | Loss: 0.55309 | Val_Loss: 0.56237| Acc: 72.714| Val_Acc: 72.0\n",
      "Epoch 238: | Loss: 0.55257 | Val_Loss: 0.55798| Acc: 72.571| Val_Acc: 73.0\n",
      "Epoch 239: | Loss: 0.55173 | Val_Loss: 0.55867| Acc: 72.714| Val_Acc: 73.0\n",
      "saving best model on best loss val..\n",
      "Epoch 240: | Loss: 0.54984 | Val_Loss: 0.55610| Acc: 72.857| Val_Acc: 73.0\n",
      "saving best model on best loss val..\n",
      "Epoch 241: | Loss: 0.54848 | Val_Loss: 0.55500| Acc: 73.000| Val_Acc: 73.0\n",
      "Epoch 242: | Loss: 0.54867 | Val_Loss: 0.55873| Acc: 73.000| Val_Acc: 73.0\n",
      "Epoch 243: | Loss: 0.54838 | Val_Loss: 0.55676| Acc: 72.857| Val_Acc: 73.0\n",
      "Epoch 244: | Loss: 0.55006 | Val_Loss: 0.55859| Acc: 72.857| Val_Acc: 73.0\n",
      "Epoch 245: | Loss: 0.55376 | Val_Loss: 0.56001| Acc: 72.571| Val_Acc: 72.0\n",
      "Epoch 246: | Loss: 0.55221 | Val_Loss: 0.55742| Acc: 72.714| Val_Acc: 72.0\n",
      "Epoch 247: | Loss: 0.55002 | Val_Loss: 0.55712| Acc: 73.000| Val_Acc: 73.0\n",
      "Epoch 248: | Loss: 0.54848 | Val_Loss: 0.55592| Acc: 73.000| Val_Acc: 73.0\n",
      "Epoch 249: | Loss: 0.54941 | Val_Loss: 0.55824| Acc: 73.000| Val_Acc: 72.0\n",
      "Epoch 250: | Loss: 0.54895 | Val_Loss: 0.55747| Acc: 73.000| Val_Acc: 73.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-48410ce268dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mepoch_acc_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-c26bddb6075c>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "val_train=val_data.X_data.to(device)\n",
    "val_label=val_data.y_data.to(device)\n",
    "PATH_LOSS = \"model_best_loss.pt\"\n",
    "PATH_ACC= \"model_best_acc.pt\"\n",
    "best_loss_val=10\n",
    "best_acc_val=0\n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_val = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_acc_val = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "    prediction_val=model(val_train)\n",
    "    loss_val = criterion(prediction_val, val_label.unsqueeze(1))\n",
    "    val_acc=binary_acc(prediction_val, val_label.unsqueeze(1))\n",
    "   \n",
    "\n",
    "    if best_loss_val > loss_val:\n",
    "        best_loss_val = loss_val\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'val_loss': loss_val,\n",
    "\n",
    "                }, PATH_LOSS)\n",
    "        print(\"saving best model on best loss val..\")\n",
    "        \n",
    "    if best_acc_val < val_acc:\n",
    "        best_acc_val = val_acc\n",
    "        torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'val_loss': loss_val,\n",
    "\n",
    "                }, PATH_ACC)\n",
    "        print(\"saving best model on best acc val..\")\n",
    "    \n",
    "    \n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Val_Loss: {loss_val:.5f}| Acc: {epoch_acc/len(train_loader):.3f}| Val_Acc: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "exceptional-emission",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "P3HJuKZiInS3yiidHlc9",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binaryClassification(\n",
       "  (layer_1): Linear(in_features=4, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (layer_3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (layer_4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer_5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer_6): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (layer_out): Linear(in_features=4, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm6): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Best model\n",
    "checkpoint = torch.load(PATH_LOSS)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "norman-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=test_data.X_data.to(device)\n",
    "with torch.no_grad():\n",
    "    prediction_TORCH=model(data)\n",
    "        \n",
    "prediction_TORCH = torch.round(torch.sigmoid(prediction_TORCH))\n",
    "prediction_TORCH=[\"TRUE\" if x==1 else 'FALSE' for x in prediction_TORCH]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "herbal-faculty",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "7QR8tquUHtHt2NOFr9i8",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "49dmmJBuG4M75EowqgVH",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " ...]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "protected-mauritius",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "9badRpp3zI7MCqXhJoJM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": null
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-453c0eb53ab0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission_TORCH\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msubmission_TORCH\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction_TORCH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_test.csv'"
     ]
    }
   ],
   "source": [
    "submission_TORCH= pd.read_csv('data_test.csv')\n",
    "submission_TORCH['Labels']=prediction_TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "plain-discretion",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "UHYBd49nqIncNAkEYm4f",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "tNMC2QyNuNKtxyn6h35s",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6992a84_2020-11-25_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e68e62f4_2020-11-29_20</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e68e81a4_2020-11-27_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69eec04_2020-11-24_7</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e698e4a4_2020-11-27_8</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2e68dd414_2020-11-26_5</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2e698541c_2020-11-24_22</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2e69e8e0c_2020-11-24_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2e699a1cc_2020-11-24_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2e698d804_2020-11-25_19</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids Labels\n",
       "0      2e6992a84_2020-11-25_18   TRUE\n",
       "1      2e68e62f4_2020-11-29_20  FALSE\n",
       "2      2e68e81a4_2020-11-27_10   TRUE\n",
       "3       2e69eec04_2020-11-24_7   TRUE\n",
       "4       2e698e4a4_2020-11-27_8   TRUE\n",
       "...                        ...    ...\n",
       "13836   2e68dd414_2020-11-26_5   TRUE\n",
       "13837  2e698541c_2020-11-24_22  FALSE\n",
       "13838  2e69e8e0c_2020-11-24_10   TRUE\n",
       "13839  2e699a1cc_2020-11-24_18   TRUE\n",
       "13840  2e698d804_2020-11-25_19   TRUE\n",
       "\n",
       "[13841 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "weighted-declaration",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "WQpitUNhWHDC2wyajs1K",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission_TORCH.to_csv('test-TORCH_Upsample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-creator",
   "metadata": {},
   "source": [
    "# Extract Intermediate Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "figured-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "covered-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_intermediate=val_data.X_data.to(device)\n",
    "train_intermediate=train_data.X_data.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.layer_6.register_forward_hook(get_activation('layer_6'))\n",
    "output = model(train_intermediate)\n",
    "activation['layer_6']\n",
    "\n",
    "train_PYTORCH_Features = activation['layer_6']\n",
    "\n",
    "\n",
    "model.layer_6.register_forward_hook(get_activation('layer_6'))\n",
    "output = model(eval_intermediate)\n",
    "activation['layer_6']\n",
    "\n",
    "eval_PYTORCH_Features = activation['layer_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fatty-hello",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57068, 4])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_PYTORCH_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "medium-motivation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14268, 4])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_PYTORCH_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "national-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PYTORCH_Features=train_PYTORCH_Features.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "civic-exhibition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57068, 4)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_PYTORCH_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dying-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57068,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cathedral-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_PYTORCH_Features=eval_PYTORCH_Features.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "finnish-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.767557 ,  26.353224 ,  19.468735 ,   5.6594706],\n",
       "       [ 22.56114  ,  45.945038 ,  38.186737 , -16.58173  ],\n",
       "       [ 76.006645 ,  95.19206  ,  82.9929   , -91.299706 ],\n",
       "       ...,\n",
       "       [  1.0894821,  25.041176 ,  18.75055  ,   8.189186 ],\n",
       "       [-18.98473  ,  32.80518  ,  25.131659 , -20.165289 ],\n",
       "       [-20.129011 ,  28.01364  ,  21.905846 ,   7.6164474]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_PYTORCH_Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-flooring",
   "metadata": {},
   "source": [
    "# Add catboost to pytorch features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "drawn-samoa",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "adKL10sTjCZjF8B3Ysvs",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "model_catboost = CatBoostClassifier(**trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "given-conjunction",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "35fJy1NYpcjF3XIPerVM",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "lyiASAWUpiIlRpVNTIcQ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6899992\ttest: 0.6898911\tbest: 0.6898911 (0)\ttotal: 7.45ms\tremaining: 7.44s\n",
      "1:\tlearn: 0.6797423\ttest: 0.6808210\tbest: 0.6808210 (1)\ttotal: 14.9ms\tremaining: 7.45s\n",
      "2:\tlearn: 0.6701844\ttest: 0.6723663\tbest: 0.6723663 (2)\ttotal: 22.9ms\tremaining: 7.6s\n",
      "3:\tlearn: 0.6617791\ttest: 0.6648954\tbest: 0.6648954 (3)\ttotal: 31ms\tremaining: 7.72s\n",
      "4:\tlearn: 0.6593563\ttest: 0.6623863\tbest: 0.6623863 (4)\ttotal: 38.8ms\tremaining: 7.72s\n",
      "5:\tlearn: 0.6570796\ttest: 0.6600259\tbest: 0.6600259 (5)\ttotal: 46.1ms\tremaining: 7.64s\n",
      "6:\tlearn: 0.6549400\ttest: 0.6578051\tbest: 0.6578051 (6)\ttotal: 53.3ms\tremaining: 7.56s\n",
      "7:\tlearn: 0.6529295\ttest: 0.6557158\tbest: 0.6557158 (7)\ttotal: 60.9ms\tremaining: 7.55s\n",
      "8:\tlearn: 0.6510401\ttest: 0.6537500\tbest: 0.6537500 (8)\ttotal: 68.3ms\tremaining: 7.52s\n",
      "9:\tlearn: 0.6492646\ttest: 0.6519004\tbest: 0.6519004 (9)\ttotal: 75.2ms\tremaining: 7.45s\n",
      "10:\tlearn: 0.6385481\ttest: 0.6428096\tbest: 0.6428096 (10)\ttotal: 84.3ms\tremaining: 7.58s\n",
      "11:\tlearn: 0.6369873\ttest: 0.6411813\tbest: 0.6411813 (11)\ttotal: 91.6ms\tremaining: 7.54s\n",
      "12:\tlearn: 0.6267953\ttest: 0.6324795\tbest: 0.6324795 (12)\ttotal: 102ms\tremaining: 7.71s\n",
      "13:\tlearn: 0.6254669\ttest: 0.6310924\tbest: 0.6310924 (13)\ttotal: 110ms\tremaining: 7.72s\n",
      "14:\tlearn: 0.6242152\ttest: 0.6297836\tbest: 0.6297836 (14)\ttotal: 117ms\tremaining: 7.71s\n",
      "15:\tlearn: 0.6230356\ttest: 0.6285486\tbest: 0.6285486 (15)\ttotal: 125ms\tremaining: 7.68s\n",
      "16:\tlearn: 0.6219239\ttest: 0.6273831\tbest: 0.6273831 (16)\ttotal: 132ms\tremaining: 7.64s\n",
      "17:\tlearn: 0.6208763\ttest: 0.6262832\tbest: 0.6262832 (17)\ttotal: 145ms\tremaining: 7.9s\n",
      "18:\tlearn: 0.6198890\ttest: 0.6252451\tbest: 0.6252451 (18)\ttotal: 153ms\tremaining: 7.88s\n",
      "19:\tlearn: 0.6189585\ttest: 0.6242652\tbest: 0.6242652 (19)\ttotal: 160ms\tremaining: 7.84s\n",
      "20:\tlearn: 0.6134136\ttest: 0.6196131\tbest: 0.6196131 (20)\ttotal: 170ms\tremaining: 7.94s\n",
      "21:\tlearn: 0.6125914\ttest: 0.6187454\tbest: 0.6187454 (21)\ttotal: 178ms\tremaining: 7.9s\n",
      "22:\tlearn: 0.6075363\ttest: 0.6145234\tbest: 0.6145234 (22)\ttotal: 185ms\tremaining: 7.84s\n",
      "23:\tlearn: 0.6068122\ttest: 0.6137575\tbest: 0.6137575 (23)\ttotal: 190ms\tremaining: 7.74s\n",
      "24:\tlearn: 0.6061298\ttest: 0.6130343\tbest: 0.6130343 (24)\ttotal: 195ms\tremaining: 7.62s\n",
      "25:\tlearn: 0.6005805\ttest: 0.6086226\tbest: 0.6086226 (25)\ttotal: 205ms\tremaining: 7.69s\n",
      "26:\tlearn: 0.5999832\ttest: 0.6079880\tbest: 0.6079880 (26)\ttotal: 214ms\tremaining: 7.69s\n",
      "27:\tlearn: 0.5994203\ttest: 0.6073887\tbest: 0.6073887 (27)\ttotal: 221ms\tremaining: 7.66s\n",
      "28:\tlearn: 0.5988898\ttest: 0.6068229\tbest: 0.6068229 (28)\ttotal: 228ms\tremaining: 7.62s\n",
      "29:\tlearn: 0.5983858\ttest: 0.6062844\tbest: 0.6062844 (29)\ttotal: 235ms\tremaining: 7.6s\n",
      "30:\tlearn: 0.5979001\ttest: 0.6057643\tbest: 0.6057643 (30)\ttotal: 242ms\tremaining: 7.58s\n",
      "31:\tlearn: 0.5928599\ttest: 0.6018187\tbest: 0.6018187 (31)\ttotal: 251ms\tremaining: 7.59s\n",
      "32:\tlearn: 0.5886059\ttest: 0.5983824\tbest: 0.5983824 (32)\ttotal: 259ms\tremaining: 7.58s\n",
      "33:\tlearn: 0.5882048\ttest: 0.5979517\tbest: 0.5979517 (33)\ttotal: 270ms\tremaining: 7.67s\n",
      "34:\tlearn: 0.5844075\ttest: 0.5949971\tbest: 0.5949971 (34)\ttotal: 276ms\tremaining: 7.61s\n",
      "35:\tlearn: 0.5840565\ttest: 0.5946187\tbest: 0.5946187 (35)\ttotal: 282ms\tremaining: 7.54s\n",
      "36:\tlearn: 0.5778600\ttest: 0.5896958\tbest: 0.5896958 (36)\ttotal: 288ms\tremaining: 7.51s\n",
      "37:\tlearn: 0.5775460\ttest: 0.5893570\tbest: 0.5893570 (37)\ttotal: 297ms\tremaining: 7.53s\n",
      "38:\tlearn: 0.5733770\ttest: 0.5861819\tbest: 0.5861819 (38)\ttotal: 303ms\tremaining: 7.46s\n",
      "39:\tlearn: 0.5695115\ttest: 0.5832812\tbest: 0.5832812 (39)\ttotal: 311ms\tremaining: 7.46s\n",
      "40:\tlearn: 0.5692567\ttest: 0.5830054\tbest: 0.5830054 (40)\ttotal: 317ms\tremaining: 7.41s\n",
      "41:\tlearn: 0.5690173\ttest: 0.5827454\tbest: 0.5827454 (41)\ttotal: 322ms\tremaining: 7.33s\n",
      "42:\tlearn: 0.5687921\ttest: 0.5825004\tbest: 0.5825004 (42)\ttotal: 327ms\tremaining: 7.27s\n",
      "43:\tlearn: 0.5637960\ttest: 0.5786559\tbest: 0.5786559 (43)\ttotal: 333ms\tremaining: 7.23s\n",
      "44:\tlearn: 0.5636004\ttest: 0.5784419\tbest: 0.5784419 (44)\ttotal: 339ms\tremaining: 7.19s\n",
      "45:\tlearn: 0.5608754\ttest: 0.5764581\tbest: 0.5764581 (45)\ttotal: 344ms\tremaining: 7.14s\n",
      "46:\tlearn: 0.5607044\ttest: 0.5762702\tbest: 0.5762702 (46)\ttotal: 349ms\tremaining: 7.07s\n",
      "47:\tlearn: 0.5605437\ttest: 0.5760930\tbest: 0.5760930 (47)\ttotal: 354ms\tremaining: 7.02s\n",
      "48:\tlearn: 0.5603925\ttest: 0.5759259\tbest: 0.5759259 (48)\ttotal: 359ms\tremaining: 6.96s\n",
      "49:\tlearn: 0.5602504\ttest: 0.5757683\tbest: 0.5757683 (49)\ttotal: 363ms\tremaining: 6.91s\n",
      "50:\tlearn: 0.5555269\ttest: 0.5722054\tbest: 0.5722054 (50)\ttotal: 374ms\tremaining: 6.96s\n",
      "51:\tlearn: 0.5554017\ttest: 0.5720660\tbest: 0.5720660 (51)\ttotal: 382ms\tremaining: 6.96s\n",
      "52:\tlearn: 0.5552839\ttest: 0.5719344\tbest: 0.5719344 (52)\ttotal: 389ms\tremaining: 6.96s\n",
      "53:\tlearn: 0.5551731\ttest: 0.5718103\tbest: 0.5718103 (53)\ttotal: 396ms\tremaining: 6.93s\n",
      "54:\tlearn: 0.5550689\ttest: 0.5716931\tbest: 0.5716931 (54)\ttotal: 401ms\tremaining: 6.9s\n",
      "55:\tlearn: 0.5549710\ttest: 0.5715826\tbest: 0.5715826 (55)\ttotal: 407ms\tremaining: 6.85s\n",
      "56:\tlearn: 0.5548788\ttest: 0.5714783\tbest: 0.5714783 (56)\ttotal: 412ms\tremaining: 6.81s\n",
      "57:\tlearn: 0.5547922\ttest: 0.5713798\tbest: 0.5713798 (57)\ttotal: 417ms\tremaining: 6.77s\n",
      "58:\tlearn: 0.5547107\ttest: 0.5712868\tbest: 0.5712868 (58)\ttotal: 425ms\tremaining: 6.77s\n",
      "59:\tlearn: 0.5546341\ttest: 0.5711991\tbest: 0.5711991 (59)\ttotal: 433ms\tremaining: 6.78s\n",
      "60:\tlearn: 0.5522833\ttest: 0.5695465\tbest: 0.5695465 (60)\ttotal: 440ms\tremaining: 6.78s\n",
      "61:\tlearn: 0.5496825\ttest: 0.5676253\tbest: 0.5676253 (61)\ttotal: 449ms\tremaining: 6.79s\n",
      "62:\tlearn: 0.5475866\ttest: 0.5662086\tbest: 0.5662086 (62)\ttotal: 457ms\tremaining: 6.79s\n",
      "63:\tlearn: 0.5475262\ttest: 0.5661388\tbest: 0.5661388 (63)\ttotal: 465ms\tremaining: 6.8s\n",
      "64:\tlearn: 0.5474694\ttest: 0.5660729\tbest: 0.5660729 (64)\ttotal: 473ms\tremaining: 6.81s\n",
      "65:\tlearn: 0.5420472\ttest: 0.5620647\tbest: 0.5620647 (65)\ttotal: 486ms\tremaining: 6.87s\n",
      "66:\tlearn: 0.5419981\ttest: 0.5620073\tbest: 0.5620073 (66)\ttotal: 491ms\tremaining: 6.83s\n",
      "67:\tlearn: 0.5419520\ttest: 0.5619530\tbest: 0.5619530 (67)\ttotal: 496ms\tremaining: 6.8s\n",
      "68:\tlearn: 0.5419086\ttest: 0.5619018\tbest: 0.5619018 (68)\ttotal: 505ms\tremaining: 6.81s\n",
      "69:\tlearn: 0.5380714\ttest: 0.5592575\tbest: 0.5592575 (69)\ttotal: 511ms\tremaining: 6.79s\n",
      "70:\tlearn: 0.5380333\ttest: 0.5592124\tbest: 0.5592124 (70)\ttotal: 522ms\tremaining: 6.83s\n",
      "71:\tlearn: 0.5379974\ttest: 0.5591697\tbest: 0.5591697 (71)\ttotal: 527ms\tremaining: 6.79s\n",
      "72:\tlearn: 0.5353340\ttest: 0.5573678\tbest: 0.5573678 (72)\ttotal: 537ms\tremaining: 6.82s\n",
      "73:\tlearn: 0.5327565\ttest: 0.5555688\tbest: 0.5555688 (73)\ttotal: 547ms\tremaining: 6.84s\n",
      "74:\tlearn: 0.5305448\ttest: 0.5541548\tbest: 0.5541548 (74)\ttotal: 554ms\tremaining: 6.83s\n",
      "75:\tlearn: 0.5305196\ttest: 0.5541239\tbest: 0.5541239 (75)\ttotal: 558ms\tremaining: 6.79s\n",
      "76:\tlearn: 0.5304958\ttest: 0.5540947\tbest: 0.5540947 (76)\ttotal: 567ms\tremaining: 6.8s\n",
      "77:\tlearn: 0.5304735\ttest: 0.5540670\tbest: 0.5540670 (77)\ttotal: 572ms\tremaining: 6.76s\n",
      "78:\tlearn: 0.5282322\ttest: 0.5526236\tbest: 0.5526236 (78)\ttotal: 577ms\tremaining: 6.73s\n",
      "79:\tlearn: 0.5282139\ttest: 0.5526005\tbest: 0.5526005 (79)\ttotal: 590ms\tremaining: 6.78s\n",
      "80:\tlearn: 0.5281967\ttest: 0.5525786\tbest: 0.5525786 (80)\ttotal: 600ms\tremaining: 6.81s\n",
      "81:\tlearn: 0.5281805\ttest: 0.5525578\tbest: 0.5525578 (81)\ttotal: 608ms\tremaining: 6.8s\n",
      "82:\tlearn: 0.5281653\ttest: 0.5525382\tbest: 0.5525382 (82)\ttotal: 634ms\tremaining: 7s\n",
      "83:\tlearn: 0.5251591\ttest: 0.5505724\tbest: 0.5505724 (83)\ttotal: 647ms\tremaining: 7.05s\n",
      "84:\tlearn: 0.5221207\ttest: 0.5483434\tbest: 0.5483434 (84)\ttotal: 654ms\tremaining: 7.04s\n",
      "85:\tlearn: 0.5204862\ttest: 0.5472201\tbest: 0.5472201 (85)\ttotal: 661ms\tremaining: 7.02s\n",
      "86:\tlearn: 0.5191471\ttest: 0.5463932\tbest: 0.5463932 (86)\ttotal: 668ms\tremaining: 7s\n",
      "87:\tlearn: 0.5191343\ttest: 0.5463767\tbest: 0.5463767 (87)\ttotal: 675ms\tremaining: 7s\n",
      "88:\tlearn: 0.5172825\ttest: 0.5452487\tbest: 0.5452487 (88)\ttotal: 685ms\tremaining: 7.01s\n",
      "89:\tlearn: 0.5153790\ttest: 0.5440731\tbest: 0.5440731 (89)\ttotal: 690ms\tremaining: 6.98s\n",
      "90:\tlearn: 0.5153704\ttest: 0.5440614\tbest: 0.5440614 (90)\ttotal: 697ms\tremaining: 6.97s\n",
      "91:\tlearn: 0.5128704\ttest: 0.5424657\tbest: 0.5424657 (91)\ttotal: 704ms\tremaining: 6.95s\n",
      "92:\tlearn: 0.5128628\ttest: 0.5424553\tbest: 0.5424553 (92)\ttotal: 711ms\tremaining: 6.94s\n",
      "93:\tlearn: 0.5128557\ttest: 0.5424455\tbest: 0.5424455 (93)\ttotal: 718ms\tremaining: 6.92s\n",
      "94:\tlearn: 0.5128490\ttest: 0.5424361\tbest: 0.5424361 (94)\ttotal: 725ms\tremaining: 6.91s\n",
      "95:\tlearn: 0.5110912\ttest: 0.5413116\tbest: 0.5413116 (95)\ttotal: 733ms\tremaining: 6.9s\n",
      "96:\tlearn: 0.5110862\ttest: 0.5413042\tbest: 0.5413042 (96)\ttotal: 739ms\tremaining: 6.87s\n",
      "97:\tlearn: 0.5110815\ttest: 0.5412973\tbest: 0.5412973 (97)\ttotal: 751ms\tremaining: 6.91s\n",
      "98:\tlearn: 0.5110770\ttest: 0.5412906\tbest: 0.5412906 (98)\ttotal: 756ms\tremaining: 6.88s\n",
      "99:\tlearn: 0.5094915\ttest: 0.5403132\tbest: 0.5403132 (99)\ttotal: 763ms\tremaining: 6.87s\n",
      "100:\tlearn: 0.5094882\ttest: 0.5403080\tbest: 0.5403080 (100)\ttotal: 770ms\tremaining: 6.85s\n",
      "101:\tlearn: 0.5085244\ttest: 0.5397758\tbest: 0.5397758 (101)\ttotal: 778ms\tremaining: 6.85s\n",
      "102:\tlearn: 0.5085213\ttest: 0.5397709\tbest: 0.5397709 (102)\ttotal: 784ms\tremaining: 6.83s\n",
      "103:\tlearn: 0.5085184\ttest: 0.5397663\tbest: 0.5397663 (103)\ttotal: 789ms\tremaining: 6.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104:\tlearn: 0.5074037\ttest: 0.5390621\tbest: 0.5390621 (104)\ttotal: 796ms\tremaining: 6.78s\n",
      "105:\tlearn: 0.5074008\ttest: 0.5390575\tbest: 0.5390575 (105)\ttotal: 802ms\tremaining: 6.77s\n",
      "106:\tlearn: 0.5073981\ttest: 0.5390531\tbest: 0.5390531 (106)\ttotal: 810ms\tremaining: 6.76s\n",
      "107:\tlearn: 0.5059927\ttest: 0.5382285\tbest: 0.5382285 (107)\ttotal: 817ms\tremaining: 6.75s\n",
      "108:\tlearn: 0.5059907\ttest: 0.5382250\tbest: 0.5382250 (108)\ttotal: 824ms\tremaining: 6.74s\n",
      "109:\tlearn: 0.5059889\ttest: 0.5382218\tbest: 0.5382218 (109)\ttotal: 832ms\tremaining: 6.73s\n",
      "110:\tlearn: 0.5059871\ttest: 0.5382186\tbest: 0.5382186 (110)\ttotal: 839ms\tremaining: 6.72s\n",
      "111:\tlearn: 0.5034791\ttest: 0.5365232\tbest: 0.5365232 (111)\ttotal: 848ms\tremaining: 6.72s\n",
      "112:\tlearn: 0.5011318\ttest: 0.5350604\tbest: 0.5350604 (112)\ttotal: 856ms\tremaining: 6.72s\n",
      "113:\tlearn: 0.5011304\ttest: 0.5350578\tbest: 0.5350578 (113)\ttotal: 866ms\tremaining: 6.73s\n",
      "114:\tlearn: 0.5004580\ttest: 0.5347717\tbest: 0.5347717 (114)\ttotal: 874ms\tremaining: 6.73s\n",
      "115:\tlearn: 0.5004567\ttest: 0.5347694\tbest: 0.5347694 (115)\ttotal: 881ms\tremaining: 6.71s\n",
      "116:\tlearn: 0.5004556\ttest: 0.5347671\tbest: 0.5347671 (116)\ttotal: 886ms\tremaining: 6.68s\n",
      "117:\tlearn: 0.4991689\ttest: 0.5339777\tbest: 0.5339777 (117)\ttotal: 891ms\tremaining: 6.66s\n",
      "118:\tlearn: 0.4981386\ttest: 0.5334619\tbest: 0.5334619 (118)\ttotal: 897ms\tremaining: 6.64s\n",
      "119:\tlearn: 0.4967358\ttest: 0.5327635\tbest: 0.5327635 (119)\ttotal: 903ms\tremaining: 6.62s\n",
      "120:\tlearn: 0.4967357\ttest: 0.5327634\tbest: 0.5327634 (120)\ttotal: 908ms\tremaining: 6.59s\n",
      "121:\tlearn: 0.4967353\ttest: 0.5327624\tbest: 0.5327624 (121)\ttotal: 912ms\tremaining: 6.57s\n",
      "122:\tlearn: 0.4956658\ttest: 0.5321728\tbest: 0.5321728 (122)\ttotal: 919ms\tremaining: 6.55s\n",
      "123:\tlearn: 0.4947034\ttest: 0.5316929\tbest: 0.5316929 (123)\ttotal: 924ms\tremaining: 6.53s\n",
      "124:\tlearn: 0.4947034\ttest: 0.5316928\tbest: 0.5316928 (124)\ttotal: 929ms\tremaining: 6.5s\n",
      "125:\tlearn: 0.4947032\ttest: 0.5316924\tbest: 0.5316924 (125)\ttotal: 939ms\tremaining: 6.51s\n",
      "126:\tlearn: 0.4947031\ttest: 0.5316920\tbest: 0.5316920 (126)\ttotal: 946ms\tremaining: 6.5s\n",
      "127:\tlearn: 0.4947030\ttest: 0.5316918\tbest: 0.5316918 (127)\ttotal: 953ms\tremaining: 6.49s\n",
      "128:\tlearn: 0.4947029\ttest: 0.5316913\tbest: 0.5316913 (128)\ttotal: 961ms\tremaining: 6.49s\n",
      "129:\tlearn: 0.4936328\ttest: 0.5308997\tbest: 0.5308997 (129)\ttotal: 970ms\tremaining: 6.49s\n",
      "130:\tlearn: 0.4936325\ttest: 0.5308990\tbest: 0.5308990 (130)\ttotal: 978ms\tremaining: 6.49s\n",
      "131:\tlearn: 0.4936325\ttest: 0.5308989\tbest: 0.5308989 (131)\ttotal: 985ms\tremaining: 6.47s\n",
      "132:\tlearn: 0.4926113\ttest: 0.5301111\tbest: 0.5301111 (132)\ttotal: 998ms\tremaining: 6.5s\n",
      "133:\tlearn: 0.4926107\ttest: 0.5301099\tbest: 0.5301099 (133)\ttotal: 1s\tremaining: 6.5s\n",
      "134:\tlearn: 0.4926107\ttest: 0.5301099\tbest: 0.5301099 (134)\ttotal: 1.01s\tremaining: 6.47s\n",
      "135:\tlearn: 0.4926107\ttest: 0.5301099\tbest: 0.5301099 (135)\ttotal: 1.01s\tremaining: 6.45s\n",
      "136:\tlearn: 0.4926107\ttest: 0.5301098\tbest: 0.5301098 (136)\ttotal: 1.03s\tremaining: 6.47s\n",
      "137:\tlearn: 0.4915217\ttest: 0.5294369\tbest: 0.5294369 (137)\ttotal: 1.04s\tremaining: 6.48s\n",
      "138:\tlearn: 0.4905989\ttest: 0.5289718\tbest: 0.5289718 (138)\ttotal: 1.04s\tremaining: 6.48s\n",
      "139:\tlearn: 0.4890998\ttest: 0.5281059\tbest: 0.5281059 (139)\ttotal: 1.05s\tremaining: 6.48s\n",
      "140:\tlearn: 0.4890998\ttest: 0.5281059\tbest: 0.5281059 (139)\ttotal: 1.06s\tremaining: 6.47s\n",
      "141:\tlearn: 0.4890998\ttest: 0.5281059\tbest: 0.5281059 (139)\ttotal: 1.07s\tremaining: 6.45s\n",
      "142:\tlearn: 0.4890998\ttest: 0.5281059\tbest: 0.5281059 (139)\ttotal: 1.07s\tremaining: 6.43s\n",
      "143:\tlearn: 0.4872074\ttest: 0.5271111\tbest: 0.5271111 (143)\ttotal: 1.08s\tremaining: 6.44s\n",
      "144:\tlearn: 0.4872073\ttest: 0.5271108\tbest: 0.5271108 (144)\ttotal: 1.09s\tremaining: 6.43s\n",
      "145:\tlearn: 0.4872073\ttest: 0.5271107\tbest: 0.5271107 (145)\ttotal: 1.1s\tremaining: 6.45s\n",
      "146:\tlearn: 0.4865742\ttest: 0.5268830\tbest: 0.5268830 (146)\ttotal: 1.11s\tremaining: 6.44s\n",
      "147:\tlearn: 0.4865741\ttest: 0.5268825\tbest: 0.5268825 (147)\ttotal: 1.12s\tremaining: 6.43s\n",
      "148:\tlearn: 0.4865741\ttest: 0.5268825\tbest: 0.5268825 (148)\ttotal: 1.12s\tremaining: 6.42s\n",
      "149:\tlearn: 0.4853675\ttest: 0.5262677\tbest: 0.5262677 (149)\ttotal: 1.13s\tremaining: 6.43s\n",
      "150:\tlearn: 0.4847638\ttest: 0.5260656\tbest: 0.5260656 (150)\ttotal: 1.14s\tremaining: 6.42s\n",
      "151:\tlearn: 0.4847638\ttest: 0.5260655\tbest: 0.5260655 (151)\ttotal: 1.15s\tremaining: 6.41s\n",
      "152:\tlearn: 0.4839705\ttest: 0.5256812\tbest: 0.5256812 (152)\ttotal: 1.16s\tremaining: 6.4s\n",
      "153:\tlearn: 0.4839705\ttest: 0.5256812\tbest: 0.5256812 (153)\ttotal: 1.16s\tremaining: 6.39s\n",
      "154:\tlearn: 0.4839705\ttest: 0.5256811\tbest: 0.5256811 (154)\ttotal: 1.17s\tremaining: 6.38s\n",
      "155:\tlearn: 0.4832648\ttest: 0.5253482\tbest: 0.5253482 (155)\ttotal: 1.18s\tremaining: 6.38s\n",
      "156:\tlearn: 0.4826157\ttest: 0.5249587\tbest: 0.5249587 (156)\ttotal: 1.19s\tremaining: 6.38s\n",
      "157:\tlearn: 0.4826157\ttest: 0.5249586\tbest: 0.5249586 (157)\ttotal: 1.2s\tremaining: 6.37s\n",
      "158:\tlearn: 0.4826157\ttest: 0.5249586\tbest: 0.5249586 (158)\ttotal: 1.21s\tremaining: 6.38s\n",
      "159:\tlearn: 0.4819422\ttest: 0.5246041\tbest: 0.5246041 (159)\ttotal: 1.22s\tremaining: 6.38s\n",
      "160:\tlearn: 0.4819422\ttest: 0.5246041\tbest: 0.5246041 (160)\ttotal: 1.22s\tremaining: 6.37s\n",
      "161:\tlearn: 0.4814638\ttest: 0.5244863\tbest: 0.5244863 (161)\ttotal: 1.23s\tremaining: 6.36s\n",
      "162:\tlearn: 0.4814638\ttest: 0.5244863\tbest: 0.5244863 (162)\ttotal: 1.24s\tremaining: 6.35s\n",
      "163:\tlearn: 0.4802662\ttest: 0.5239603\tbest: 0.5239603 (163)\ttotal: 1.25s\tremaining: 6.36s\n",
      "164:\tlearn: 0.4802662\ttest: 0.5239603\tbest: 0.5239603 (163)\ttotal: 1.25s\tremaining: 6.35s\n",
      "165:\tlearn: 0.4802662\ttest: 0.5239603\tbest: 0.5239603 (163)\ttotal: 1.26s\tremaining: 6.34s\n",
      "166:\tlearn: 0.4802662\ttest: 0.5239603\tbest: 0.5239603 (163)\ttotal: 1.27s\tremaining: 6.33s\n",
      "167:\tlearn: 0.4802662\ttest: 0.5239603\tbest: 0.5239603 (163)\ttotal: 1.28s\tremaining: 6.32s\n",
      "168:\tlearn: 0.4802662\ttest: 0.5239603\tbest: 0.5239603 (163)\ttotal: 1.28s\tremaining: 6.3s\n",
      "169:\tlearn: 0.4796635\ttest: 0.5236612\tbest: 0.5236612 (169)\ttotal: 1.29s\tremaining: 6.31s\n",
      "170:\tlearn: 0.4792614\ttest: 0.5235973\tbest: 0.5235973 (170)\ttotal: 1.3s\tremaining: 6.3s\n",
      "171:\tlearn: 0.4792614\ttest: 0.5235973\tbest: 0.5235973 (170)\ttotal: 1.31s\tremaining: 6.29s\n",
      "172:\tlearn: 0.4786932\ttest: 0.5232334\tbest: 0.5232334 (172)\ttotal: 1.32s\tremaining: 6.29s\n",
      "173:\tlearn: 0.4781708\ttest: 0.5229073\tbest: 0.5229073 (173)\ttotal: 1.32s\tremaining: 6.29s\n",
      "174:\tlearn: 0.4781708\ttest: 0.5229072\tbest: 0.5229072 (174)\ttotal: 1.33s\tremaining: 6.29s\n",
      "175:\tlearn: 0.4781708\ttest: 0.5229071\tbest: 0.5229071 (175)\ttotal: 1.34s\tremaining: 6.29s\n",
      "176:\tlearn: 0.4781708\ttest: 0.5229071\tbest: 0.5229071 (176)\ttotal: 1.35s\tremaining: 6.27s\n",
      "177:\tlearn: 0.4781708\ttest: 0.5229071\tbest: 0.5229071 (177)\ttotal: 1.36s\tremaining: 6.28s\n",
      "178:\tlearn: 0.4781707\ttest: 0.5229070\tbest: 0.5229070 (178)\ttotal: 1.36s\tremaining: 6.25s\n",
      "179:\tlearn: 0.4781707\ttest: 0.5229070\tbest: 0.5229070 (179)\ttotal: 1.37s\tremaining: 6.24s\n",
      "180:\tlearn: 0.4781707\ttest: 0.5229070\tbest: 0.5229070 (180)\ttotal: 1.38s\tremaining: 6.23s\n",
      "181:\tlearn: 0.4781707\ttest: 0.5229070\tbest: 0.5229070 (181)\ttotal: 1.38s\tremaining: 6.21s\n",
      "182:\tlearn: 0.4770367\ttest: 0.5222889\tbest: 0.5222889 (182)\ttotal: 1.39s\tremaining: 6.2s\n",
      "183:\tlearn: 0.4765641\ttest: 0.5220003\tbest: 0.5220003 (183)\ttotal: 1.4s\tremaining: 6.19s\n",
      "184:\tlearn: 0.4760222\ttest: 0.5218019\tbest: 0.5218019 (184)\ttotal: 1.41s\tremaining: 6.2s\n",
      "185:\tlearn: 0.4760222\ttest: 0.5218019\tbest: 0.5218019 (185)\ttotal: 1.41s\tremaining: 6.19s\n",
      "186:\tlearn: 0.4760222\ttest: 0.5218018\tbest: 0.5218018 (186)\ttotal: 1.42s\tremaining: 6.18s\n",
      "187:\tlearn: 0.4750658\ttest: 0.5213890\tbest: 0.5213890 (187)\ttotal: 1.43s\tremaining: 6.19s\n",
      "188:\tlearn: 0.4750658\ttest: 0.5213889\tbest: 0.5213889 (188)\ttotal: 1.44s\tremaining: 6.18s\n",
      "189:\tlearn: 0.4750658\ttest: 0.5213889\tbest: 0.5213889 (189)\ttotal: 1.45s\tremaining: 6.17s\n",
      "190:\tlearn: 0.4747204\ttest: 0.5213542\tbest: 0.5213542 (190)\ttotal: 1.46s\tremaining: 6.19s\n",
      "191:\tlearn: 0.4743904\ttest: 0.5212101\tbest: 0.5212101 (191)\ttotal: 1.47s\tremaining: 6.18s\n",
      "192:\tlearn: 0.4743904\ttest: 0.5212100\tbest: 0.5212100 (192)\ttotal: 1.47s\tremaining: 6.16s\n",
      "193:\tlearn: 0.4743904\ttest: 0.5212100\tbest: 0.5212100 (193)\ttotal: 1.48s\tremaining: 6.14s\n",
      "194:\tlearn: 0.4743904\ttest: 0.5212100\tbest: 0.5212100 (194)\ttotal: 1.49s\tremaining: 6.15s\n",
      "195:\tlearn: 0.4743904\ttest: 0.5212100\tbest: 0.5212100 (195)\ttotal: 1.5s\tremaining: 6.13s\n",
      "196:\tlearn: 0.4743904\ttest: 0.5212100\tbest: 0.5212100 (196)\ttotal: 1.5s\tremaining: 6.13s\n",
      "197:\tlearn: 0.4740890\ttest: 0.5211968\tbest: 0.5211968 (197)\ttotal: 1.51s\tremaining: 6.11s\n",
      "198:\tlearn: 0.4740890\ttest: 0.5211967\tbest: 0.5211967 (198)\ttotal: 1.51s\tremaining: 6.1s\n",
      "199:\tlearn: 0.4736540\ttest: 0.5210605\tbest: 0.5210605 (199)\ttotal: 1.52s\tremaining: 6.08s\n",
      "200:\tlearn: 0.4736540\ttest: 0.5210605\tbest: 0.5210605 (200)\ttotal: 1.52s\tremaining: 6.06s\n",
      "201:\tlearn: 0.4736540\ttest: 0.5210605\tbest: 0.5210605 (201)\ttotal: 1.53s\tremaining: 6.04s\n",
      "202:\tlearn: 0.4732645\ttest: 0.5207588\tbest: 0.5207588 (202)\ttotal: 1.54s\tremaining: 6.04s\n",
      "203:\tlearn: 0.4732645\ttest: 0.5207587\tbest: 0.5207587 (203)\ttotal: 1.54s\tremaining: 6.02s\n",
      "204:\tlearn: 0.4729603\ttest: 0.5207332\tbest: 0.5207332 (204)\ttotal: 1.56s\tremaining: 6.03s\n",
      "205:\tlearn: 0.4729603\ttest: 0.5207332\tbest: 0.5207332 (205)\ttotal: 1.56s\tremaining: 6.01s\n",
      "206:\tlearn: 0.4729603\ttest: 0.5207331\tbest: 0.5207331 (206)\ttotal: 1.56s\tremaining: 6s\n",
      "207:\tlearn: 0.4729603\ttest: 0.5207331\tbest: 0.5207331 (207)\ttotal: 1.57s\tremaining: 5.99s\n",
      "208:\tlearn: 0.4729603\ttest: 0.5207331\tbest: 0.5207331 (208)\ttotal: 1.58s\tremaining: 5.97s\n",
      "209:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.59s\tremaining: 5.98s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.6s\tremaining: 5.98s\n",
      "211:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.61s\tremaining: 5.97s\n",
      "212:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.61s\tremaining: 5.96s\n",
      "213:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.62s\tremaining: 5.95s\n",
      "214:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.63s\tremaining: 5.94s\n",
      "215:\tlearn: 0.4722952\ttest: 0.5205479\tbest: 0.5205479 (209)\ttotal: 1.63s\tremaining: 5.93s\n",
      "216:\tlearn: 0.4717437\ttest: 0.5204290\tbest: 0.5204290 (216)\ttotal: 1.64s\tremaining: 5.91s\n",
      "217:\tlearn: 0.4717436\ttest: 0.5204291\tbest: 0.5204290 (216)\ttotal: 1.64s\tremaining: 5.9s\n",
      "218:\tlearn: 0.4713557\ttest: 0.5202505\tbest: 0.5202505 (218)\ttotal: 1.65s\tremaining: 5.88s\n",
      "219:\tlearn: 0.4709908\ttest: 0.5201270\tbest: 0.5201270 (219)\ttotal: 1.66s\tremaining: 5.87s\n",
      "220:\tlearn: 0.4709908\ttest: 0.5201271\tbest: 0.5201270 (219)\ttotal: 1.66s\tremaining: 5.85s\n",
      "221:\tlearn: 0.4706034\ttest: 0.5199508\tbest: 0.5199508 (221)\ttotal: 1.67s\tremaining: 5.84s\n",
      "222:\tlearn: 0.4706034\ttest: 0.5199508\tbest: 0.5199508 (221)\ttotal: 1.67s\tremaining: 5.82s\n",
      "223:\tlearn: 0.4706034\ttest: 0.5199508\tbest: 0.5199508 (221)\ttotal: 1.67s\tremaining: 5.8s\n",
      "224:\tlearn: 0.4706034\ttest: 0.5199509\tbest: 0.5199508 (221)\ttotal: 1.68s\tremaining: 5.78s\n",
      "225:\tlearn: 0.4706034\ttest: 0.5199509\tbest: 0.5199508 (221)\ttotal: 1.68s\tremaining: 5.76s\n",
      "226:\tlearn: 0.4701595\ttest: 0.5198807\tbest: 0.5198807 (226)\ttotal: 1.69s\tremaining: 5.75s\n",
      "227:\tlearn: 0.4699689\ttest: 0.5198999\tbest: 0.5198807 (226)\ttotal: 1.69s\tremaining: 5.74s\n",
      "228:\tlearn: 0.4699689\ttest: 0.5198999\tbest: 0.5198807 (226)\ttotal: 1.7s\tremaining: 5.72s\n",
      "229:\tlearn: 0.4696516\ttest: 0.5198290\tbest: 0.5198290 (229)\ttotal: 1.7s\tremaining: 5.71s\n",
      "230:\tlearn: 0.4696516\ttest: 0.5198290\tbest: 0.5198290 (229)\ttotal: 1.71s\tremaining: 5.69s\n",
      "231:\tlearn: 0.4693335\ttest: 0.5197403\tbest: 0.5197403 (231)\ttotal: 1.71s\tremaining: 5.68s\n",
      "232:\tlearn: 0.4693335\ttest: 0.5197403\tbest: 0.5197403 (231)\ttotal: 1.72s\tremaining: 5.66s\n",
      "233:\tlearn: 0.4693335\ttest: 0.5197403\tbest: 0.5197403 (231)\ttotal: 1.72s\tremaining: 5.64s\n",
      "234:\tlearn: 0.4691645\ttest: 0.5197919\tbest: 0.5197403 (231)\ttotal: 1.73s\tremaining: 5.64s\n",
      "235:\tlearn: 0.4689707\ttest: 0.5198228\tbest: 0.5197403 (231)\ttotal: 1.74s\tremaining: 5.63s\n",
      "236:\tlearn: 0.4689707\ttest: 0.5198229\tbest: 0.5197403 (231)\ttotal: 1.75s\tremaining: 5.62s\n",
      "237:\tlearn: 0.4686553\ttest: 0.5195220\tbest: 0.5195220 (237)\ttotal: 1.76s\tremaining: 5.64s\n",
      "238:\tlearn: 0.4686553\ttest: 0.5195220\tbest: 0.5195220 (237)\ttotal: 1.77s\tremaining: 5.63s\n",
      "239:\tlearn: 0.4686553\ttest: 0.5195220\tbest: 0.5195220 (237)\ttotal: 1.77s\tremaining: 5.62s\n",
      "240:\tlearn: 0.4686553\ttest: 0.5195220\tbest: 0.5195220 (237)\ttotal: 1.78s\tremaining: 5.61s\n",
      "241:\tlearn: 0.4686553\ttest: 0.5195220\tbest: 0.5195220 (237)\ttotal: 1.79s\tremaining: 5.6s\n",
      "242:\tlearn: 0.4686553\ttest: 0.5195220\tbest: 0.5195220 (237)\ttotal: 1.79s\tremaining: 5.59s\n",
      "243:\tlearn: 0.4683190\ttest: 0.5193531\tbest: 0.5193531 (243)\ttotal: 1.8s\tremaining: 5.59s\n",
      "244:\tlearn: 0.4683190\ttest: 0.5193531\tbest: 0.5193531 (243)\ttotal: 1.81s\tremaining: 5.58s\n",
      "245:\tlearn: 0.4683190\ttest: 0.5193532\tbest: 0.5193531 (243)\ttotal: 1.82s\tremaining: 5.57s\n",
      "246:\tlearn: 0.4683190\ttest: 0.5193532\tbest: 0.5193531 (243)\ttotal: 1.82s\tremaining: 5.56s\n",
      "247:\tlearn: 0.4683190\ttest: 0.5193532\tbest: 0.5193531 (243)\ttotal: 1.83s\tremaining: 5.55s\n",
      "248:\tlearn: 0.4683189\ttest: 0.5193532\tbest: 0.5193531 (243)\ttotal: 1.84s\tremaining: 5.55s\n",
      "249:\tlearn: 0.4683189\ttest: 0.5193532\tbest: 0.5193531 (243)\ttotal: 1.84s\tremaining: 5.53s\n",
      "250:\tlearn: 0.4683189\ttest: 0.5193533\tbest: 0.5193531 (243)\ttotal: 1.85s\tremaining: 5.53s\n",
      "251:\tlearn: 0.4677798\ttest: 0.5190293\tbest: 0.5190293 (251)\ttotal: 1.86s\tremaining: 5.53s\n",
      "252:\tlearn: 0.4677798\ttest: 0.5190293\tbest: 0.5190293 (251)\ttotal: 1.87s\tremaining: 5.52s\n",
      "253:\tlearn: 0.4677798\ttest: 0.5190294\tbest: 0.5190293 (251)\ttotal: 1.88s\tremaining: 5.51s\n",
      "254:\tlearn: 0.4677798\ttest: 0.5190294\tbest: 0.5190293 (251)\ttotal: 1.89s\tremaining: 5.51s\n",
      "255:\tlearn: 0.4674819\ttest: 0.5189260\tbest: 0.5189260 (255)\ttotal: 1.89s\tremaining: 5.5s\n",
      "256:\tlearn: 0.4674819\ttest: 0.5189260\tbest: 0.5189260 (255)\ttotal: 1.9s\tremaining: 5.48s\n",
      "257:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.9s\tremaining: 5.47s\n",
      "258:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.91s\tremaining: 5.46s\n",
      "259:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.92s\tremaining: 5.45s\n",
      "260:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.92s\tremaining: 5.44s\n",
      "261:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.93s\tremaining: 5.43s\n",
      "262:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.93s\tremaining: 5.42s\n",
      "263:\tlearn: 0.4674819\ttest: 0.5189261\tbest: 0.5189260 (255)\ttotal: 1.94s\tremaining: 5.4s\n",
      "264:\tlearn: 0.4668939\ttest: 0.5187839\tbest: 0.5187839 (264)\ttotal: 1.95s\tremaining: 5.41s\n",
      "265:\tlearn: 0.4668939\ttest: 0.5187839\tbest: 0.5187839 (264)\ttotal: 1.96s\tremaining: 5.4s\n",
      "266:\tlearn: 0.4668939\ttest: 0.5187839\tbest: 0.5187839 (264)\ttotal: 1.96s\tremaining: 5.38s\n",
      "267:\tlearn: 0.4668939\ttest: 0.5187839\tbest: 0.5187839 (264)\ttotal: 1.97s\tremaining: 5.37s\n",
      "268:\tlearn: 0.4668939\ttest: 0.5187839\tbest: 0.5187839 (264)\ttotal: 1.97s\tremaining: 5.36s\n",
      "269:\tlearn: 0.4668939\ttest: 0.5187840\tbest: 0.5187839 (264)\ttotal: 1.98s\tremaining: 5.34s\n",
      "270:\tlearn: 0.4668939\ttest: 0.5187840\tbest: 0.5187839 (264)\ttotal: 1.98s\tremaining: 5.33s\n",
      "271:\tlearn: 0.4668939\ttest: 0.5187840\tbest: 0.5187839 (264)\ttotal: 1.98s\tremaining: 5.31s\n",
      "272:\tlearn: 0.4668939\ttest: 0.5187841\tbest: 0.5187839 (264)\ttotal: 1.99s\tremaining: 5.3s\n",
      "273:\tlearn: 0.4668939\ttest: 0.5187841\tbest: 0.5187839 (264)\ttotal: 1.99s\tremaining: 5.28s\n",
      "274:\tlearn: 0.4668938\ttest: 0.5187841\tbest: 0.5187839 (264)\ttotal: 2s\tremaining: 5.27s\n",
      "275:\tlearn: 0.4663955\ttest: 0.5186947\tbest: 0.5186947 (275)\ttotal: 2.01s\tremaining: 5.27s\n",
      "276:\tlearn: 0.4663955\ttest: 0.5186947\tbest: 0.5186947 (275)\ttotal: 2.01s\tremaining: 5.26s\n",
      "277:\tlearn: 0.4663955\ttest: 0.5186947\tbest: 0.5186947 (275)\ttotal: 2.02s\tremaining: 5.25s\n",
      "278:\tlearn: 0.4663955\ttest: 0.5186947\tbest: 0.5186947 (275)\ttotal: 2.03s\tremaining: 5.24s\n",
      "279:\tlearn: 0.4663955\ttest: 0.5186948\tbest: 0.5186947 (275)\ttotal: 2.03s\tremaining: 5.23s\n",
      "280:\tlearn: 0.4662665\ttest: 0.5187552\tbest: 0.5186947 (275)\ttotal: 2.04s\tremaining: 5.22s\n",
      "281:\tlearn: 0.4662664\ttest: 0.5187553\tbest: 0.5186947 (275)\ttotal: 2.04s\tremaining: 5.21s\n",
      "282:\tlearn: 0.4660319\ttest: 0.5185102\tbest: 0.5185102 (282)\ttotal: 2.05s\tremaining: 5.2s\n",
      "283:\tlearn: 0.4657974\ttest: 0.5184293\tbest: 0.5184293 (283)\ttotal: 2.06s\tremaining: 5.2s\n",
      "284:\tlearn: 0.4657974\ttest: 0.5184294\tbest: 0.5184293 (283)\ttotal: 2.07s\tremaining: 5.18s\n",
      "285:\tlearn: 0.4657974\ttest: 0.5184294\tbest: 0.5184293 (283)\ttotal: 2.07s\tremaining: 5.17s\n",
      "286:\tlearn: 0.4657974\ttest: 0.5184294\tbest: 0.5184293 (283)\ttotal: 2.08s\tremaining: 5.16s\n",
      "287:\tlearn: 0.4655357\ttest: 0.5182912\tbest: 0.5182912 (287)\ttotal: 2.08s\tremaining: 5.15s\n",
      "288:\tlearn: 0.4655357\ttest: 0.5182912\tbest: 0.5182912 (287)\ttotal: 2.09s\tremaining: 5.15s\n",
      "289:\tlearn: 0.4655357\ttest: 0.5182912\tbest: 0.5182912 (287)\ttotal: 2.1s\tremaining: 5.13s\n",
      "290:\tlearn: 0.4651998\ttest: 0.5183238\tbest: 0.5182912 (287)\ttotal: 2.1s\tremaining: 5.13s\n",
      "291:\tlearn: 0.4650907\ttest: 0.5183906\tbest: 0.5182912 (287)\ttotal: 2.11s\tremaining: 5.12s\n",
      "292:\tlearn: 0.4649735\ttest: 0.5184608\tbest: 0.5182912 (287)\ttotal: 2.12s\tremaining: 5.11s\n",
      "293:\tlearn: 0.4649735\ttest: 0.5184608\tbest: 0.5182912 (287)\ttotal: 2.13s\tremaining: 5.1s\n",
      "294:\tlearn: 0.4649735\ttest: 0.5184608\tbest: 0.5182912 (287)\ttotal: 2.13s\tremaining: 5.09s\n",
      "295:\tlearn: 0.4647650\ttest: 0.5183744\tbest: 0.5182912 (287)\ttotal: 2.14s\tremaining: 5.09s\n",
      "296:\tlearn: 0.4647650\ttest: 0.5183744\tbest: 0.5182912 (287)\ttotal: 2.15s\tremaining: 5.08s\n",
      "297:\tlearn: 0.4647650\ttest: 0.5183744\tbest: 0.5182912 (287)\ttotal: 2.15s\tremaining: 5.07s\n",
      "298:\tlearn: 0.4647650\ttest: 0.5183744\tbest: 0.5182912 (287)\ttotal: 2.16s\tremaining: 5.06s\n",
      "299:\tlearn: 0.4647650\ttest: 0.5183744\tbest: 0.5182912 (287)\ttotal: 2.16s\tremaining: 5.05s\n",
      "300:\tlearn: 0.4645730\ttest: 0.5181670\tbest: 0.5181670 (300)\ttotal: 2.17s\tremaining: 5.05s\n",
      "301:\tlearn: 0.4645730\ttest: 0.5181670\tbest: 0.5181670 (300)\ttotal: 2.18s\tremaining: 5.04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302:\tlearn: 0.4645730\ttest: 0.5181670\tbest: 0.5181670 (300)\ttotal: 2.19s\tremaining: 5.04s\n",
      "303:\tlearn: 0.4645730\ttest: 0.5181671\tbest: 0.5181670 (300)\ttotal: 2.2s\tremaining: 5.03s\n",
      "304:\tlearn: 0.4645730\ttest: 0.5181671\tbest: 0.5181670 (300)\ttotal: 2.2s\tremaining: 5.02s\n",
      "305:\tlearn: 0.4644811\ttest: 0.5182289\tbest: 0.5181670 (300)\ttotal: 2.21s\tremaining: 5.01s\n",
      "306:\tlearn: 0.4644811\ttest: 0.5182289\tbest: 0.5181670 (300)\ttotal: 2.22s\tremaining: 5.01s\n",
      "307:\tlearn: 0.4644811\ttest: 0.5182290\tbest: 0.5181670 (300)\ttotal: 2.23s\tremaining: 5s\n",
      "308:\tlearn: 0.4644811\ttest: 0.5182290\tbest: 0.5181670 (300)\ttotal: 2.23s\tremaining: 4.99s\n",
      "309:\tlearn: 0.4644811\ttest: 0.5182290\tbest: 0.5181670 (300)\ttotal: 2.24s\tremaining: 4.98s\n",
      "310:\tlearn: 0.4644811\ttest: 0.5182290\tbest: 0.5181670 (300)\ttotal: 2.24s\tremaining: 4.97s\n",
      "311:\tlearn: 0.4644811\ttest: 0.5182290\tbest: 0.5181670 (300)\ttotal: 2.25s\tremaining: 4.96s\n",
      "312:\tlearn: 0.4644811\ttest: 0.5182290\tbest: 0.5181670 (300)\ttotal: 2.25s\tremaining: 4.94s\n",
      "313:\tlearn: 0.4643071\ttest: 0.5181436\tbest: 0.5181436 (313)\ttotal: 2.26s\tremaining: 4.93s\n",
      "314:\tlearn: 0.4643071\ttest: 0.5181436\tbest: 0.5181436 (313)\ttotal: 2.26s\tremaining: 4.92s\n",
      "315:\tlearn: 0.4643071\ttest: 0.5181436\tbest: 0.5181436 (313)\ttotal: 2.27s\tremaining: 4.91s\n",
      "316:\tlearn: 0.4643071\ttest: 0.5181436\tbest: 0.5181436 (313)\ttotal: 2.27s\tremaining: 4.89s\n",
      "317:\tlearn: 0.4643071\ttest: 0.5181437\tbest: 0.5181436 (313)\ttotal: 2.27s\tremaining: 4.88s\n",
      "318:\tlearn: 0.4643071\ttest: 0.5181437\tbest: 0.5181436 (313)\ttotal: 2.28s\tremaining: 4.87s\n",
      "319:\tlearn: 0.4639408\ttest: 0.5180089\tbest: 0.5180089 (319)\ttotal: 2.29s\tremaining: 4.86s\n",
      "320:\tlearn: 0.4639408\ttest: 0.5180089\tbest: 0.5180089 (319)\ttotal: 2.29s\tremaining: 4.85s\n",
      "321:\tlearn: 0.4639408\ttest: 0.5180089\tbest: 0.5180089 (319)\ttotal: 2.29s\tremaining: 4.83s\n",
      "322:\tlearn: 0.4637822\ttest: 0.5180181\tbest: 0.5180089 (319)\ttotal: 2.3s\tremaining: 4.82s\n",
      "323:\tlearn: 0.4637822\ttest: 0.5180181\tbest: 0.5180089 (319)\ttotal: 2.31s\tremaining: 4.81s\n",
      "324:\tlearn: 0.4634264\ttest: 0.5179813\tbest: 0.5179813 (324)\ttotal: 2.31s\tremaining: 4.8s\n",
      "325:\tlearn: 0.4632055\ttest: 0.5179850\tbest: 0.5179813 (324)\ttotal: 2.32s\tremaining: 4.8s\n",
      "326:\tlearn: 0.4629436\ttest: 0.5179800\tbest: 0.5179800 (326)\ttotal: 2.33s\tremaining: 4.79s\n",
      "327:\tlearn: 0.4629436\ttest: 0.5179800\tbest: 0.5179800 (326)\ttotal: 2.33s\tremaining: 4.77s\n",
      "328:\tlearn: 0.4629436\ttest: 0.5179801\tbest: 0.5179800 (326)\ttotal: 2.33s\tremaining: 4.76s\n",
      "329:\tlearn: 0.4629436\ttest: 0.5179801\tbest: 0.5179800 (326)\ttotal: 2.34s\tremaining: 4.75s\n",
      "330:\tlearn: 0.4628614\ttest: 0.5180505\tbest: 0.5179800 (326)\ttotal: 2.34s\tremaining: 4.74s\n",
      "331:\tlearn: 0.4628022\ttest: 0.5180797\tbest: 0.5179800 (326)\ttotal: 2.35s\tremaining: 4.73s\n",
      "332:\tlearn: 0.4628022\ttest: 0.5180797\tbest: 0.5179800 (326)\ttotal: 2.35s\tremaining: 4.72s\n",
      "333:\tlearn: 0.4628022\ttest: 0.5180797\tbest: 0.5179800 (326)\ttotal: 2.36s\tremaining: 4.71s\n",
      "334:\tlearn: 0.4627052\ttest: 0.5181274\tbest: 0.5179800 (326)\ttotal: 2.37s\tremaining: 4.7s\n",
      "335:\tlearn: 0.4626232\ttest: 0.5182012\tbest: 0.5179800 (326)\ttotal: 2.37s\tremaining: 4.69s\n",
      "336:\tlearn: 0.4626232\ttest: 0.5182013\tbest: 0.5179800 (326)\ttotal: 2.38s\tremaining: 4.68s\n",
      "337:\tlearn: 0.4624896\ttest: 0.5181146\tbest: 0.5179800 (326)\ttotal: 2.39s\tremaining: 4.69s\n",
      "338:\tlearn: 0.4624896\ttest: 0.5181146\tbest: 0.5179800 (326)\ttotal: 2.4s\tremaining: 4.68s\n",
      "339:\tlearn: 0.4624896\ttest: 0.5181146\tbest: 0.5179800 (326)\ttotal: 2.41s\tremaining: 4.67s\n",
      "340:\tlearn: 0.4624896\ttest: 0.5181147\tbest: 0.5179800 (326)\ttotal: 2.41s\tremaining: 4.66s\n",
      "341:\tlearn: 0.4621982\ttest: 0.5179668\tbest: 0.5179668 (341)\ttotal: 2.42s\tremaining: 4.67s\n",
      "342:\tlearn: 0.4621982\ttest: 0.5179668\tbest: 0.5179668 (341)\ttotal: 2.43s\tremaining: 4.66s\n",
      "343:\tlearn: 0.4620419\ttest: 0.5180330\tbest: 0.5179668 (341)\ttotal: 2.44s\tremaining: 4.66s\n",
      "344:\tlearn: 0.4620419\ttest: 0.5180331\tbest: 0.5179668 (341)\ttotal: 2.45s\tremaining: 4.65s\n",
      "345:\tlearn: 0.4620419\ttest: 0.5180331\tbest: 0.5179668 (341)\ttotal: 2.45s\tremaining: 4.63s\n",
      "346:\tlearn: 0.4620419\ttest: 0.5180332\tbest: 0.5179668 (341)\ttotal: 2.46s\tremaining: 4.63s\n",
      "347:\tlearn: 0.4620419\ttest: 0.5180332\tbest: 0.5179668 (341)\ttotal: 2.47s\tremaining: 4.62s\n",
      "348:\tlearn: 0.4620419\ttest: 0.5180332\tbest: 0.5179668 (341)\ttotal: 2.47s\tremaining: 4.62s\n",
      "349:\tlearn: 0.4620419\ttest: 0.5180332\tbest: 0.5179668 (341)\ttotal: 2.48s\tremaining: 4.61s\n",
      "350:\tlearn: 0.4620419\ttest: 0.5180332\tbest: 0.5179668 (341)\ttotal: 2.49s\tremaining: 4.6s\n",
      "351:\tlearn: 0.4620419\ttest: 0.5180333\tbest: 0.5179668 (341)\ttotal: 2.49s\tremaining: 4.59s\n",
      "352:\tlearn: 0.4620419\ttest: 0.5180333\tbest: 0.5179668 (341)\ttotal: 2.5s\tremaining: 4.58s\n",
      "353:\tlearn: 0.4620419\ttest: 0.5180333\tbest: 0.5179668 (341)\ttotal: 2.5s\tremaining: 4.57s\n",
      "354:\tlearn: 0.4620419\ttest: 0.5180334\tbest: 0.5179668 (341)\ttotal: 2.51s\tremaining: 4.56s\n",
      "355:\tlearn: 0.4620419\ttest: 0.5180334\tbest: 0.5179668 (341)\ttotal: 2.52s\tremaining: 4.55s\n",
      "356:\tlearn: 0.4620419\ttest: 0.5180334\tbest: 0.5179668 (341)\ttotal: 2.52s\tremaining: 4.54s\n",
      "357:\tlearn: 0.4619764\ttest: 0.5180902\tbest: 0.5179668 (341)\ttotal: 2.53s\tremaining: 4.54s\n",
      "358:\tlearn: 0.4619764\ttest: 0.5180902\tbest: 0.5179668 (341)\ttotal: 2.54s\tremaining: 4.53s\n",
      "359:\tlearn: 0.4619764\ttest: 0.5180902\tbest: 0.5179668 (341)\ttotal: 2.54s\tremaining: 4.52s\n",
      "360:\tlearn: 0.4619764\ttest: 0.5180903\tbest: 0.5179668 (341)\ttotal: 2.55s\tremaining: 4.51s\n",
      "361:\tlearn: 0.4619764\ttest: 0.5180903\tbest: 0.5179668 (341)\ttotal: 2.56s\tremaining: 4.5s\n",
      "362:\tlearn: 0.4619764\ttest: 0.5180903\tbest: 0.5179668 (341)\ttotal: 2.56s\tremaining: 4.49s\n",
      "363:\tlearn: 0.4619764\ttest: 0.5180904\tbest: 0.5179668 (341)\ttotal: 2.56s\tremaining: 4.48s\n",
      "364:\tlearn: 0.4619764\ttest: 0.5180904\tbest: 0.5179668 (341)\ttotal: 2.57s\tremaining: 4.47s\n",
      "365:\tlearn: 0.4619764\ttest: 0.5180904\tbest: 0.5179668 (341)\ttotal: 2.57s\tremaining: 4.46s\n",
      "366:\tlearn: 0.4619764\ttest: 0.5180904\tbest: 0.5179668 (341)\ttotal: 2.58s\tremaining: 4.45s\n",
      "367:\tlearn: 0.4619764\ttest: 0.5180904\tbest: 0.5179668 (341)\ttotal: 2.58s\tremaining: 4.44s\n",
      "368:\tlearn: 0.4618583\ttest: 0.5179971\tbest: 0.5179668 (341)\ttotal: 2.59s\tremaining: 4.43s\n",
      "369:\tlearn: 0.4618583\ttest: 0.5179972\tbest: 0.5179668 (341)\ttotal: 2.6s\tremaining: 4.42s\n",
      "370:\tlearn: 0.4617979\ttest: 0.5180710\tbest: 0.5179668 (341)\ttotal: 2.6s\tremaining: 4.41s\n",
      "371:\tlearn: 0.4617979\ttest: 0.5180710\tbest: 0.5179668 (341)\ttotal: 2.61s\tremaining: 4.4s\n",
      "372:\tlearn: 0.4617979\ttest: 0.5180710\tbest: 0.5179668 (341)\ttotal: 2.61s\tremaining: 4.39s\n",
      "373:\tlearn: 0.4617979\ttest: 0.5180711\tbest: 0.5179668 (341)\ttotal: 2.62s\tremaining: 4.39s\n",
      "374:\tlearn: 0.4617979\ttest: 0.5180711\tbest: 0.5179668 (341)\ttotal: 2.63s\tremaining: 4.38s\n",
      "375:\tlearn: 0.4617979\ttest: 0.5180711\tbest: 0.5179668 (341)\ttotal: 2.63s\tremaining: 4.37s\n",
      "376:\tlearn: 0.4617979\ttest: 0.5180711\tbest: 0.5179668 (341)\ttotal: 2.64s\tremaining: 4.36s\n",
      "377:\tlearn: 0.4617979\ttest: 0.5180711\tbest: 0.5179668 (341)\ttotal: 2.64s\tremaining: 4.35s\n",
      "378:\tlearn: 0.4616896\ttest: 0.5180477\tbest: 0.5179668 (341)\ttotal: 2.65s\tremaining: 4.34s\n",
      "379:\tlearn: 0.4616896\ttest: 0.5180478\tbest: 0.5179668 (341)\ttotal: 2.65s\tremaining: 4.33s\n",
      "380:\tlearn: 0.4615683\ttest: 0.5180540\tbest: 0.5179668 (341)\ttotal: 2.66s\tremaining: 4.32s\n",
      "381:\tlearn: 0.4615683\ttest: 0.5180540\tbest: 0.5179668 (341)\ttotal: 2.66s\tremaining: 4.31s\n",
      "382:\tlearn: 0.4613873\ttest: 0.5180832\tbest: 0.5179668 (341)\ttotal: 2.67s\tremaining: 4.3s\n",
      "383:\tlearn: 0.4612037\ttest: 0.5179872\tbest: 0.5179668 (341)\ttotal: 2.68s\tremaining: 4.3s\n",
      "384:\tlearn: 0.4612037\ttest: 0.5179872\tbest: 0.5179668 (341)\ttotal: 2.68s\tremaining: 4.29s\n",
      "385:\tlearn: 0.4612037\ttest: 0.5179872\tbest: 0.5179668 (341)\ttotal: 2.69s\tremaining: 4.28s\n",
      "386:\tlearn: 0.4612037\ttest: 0.5179872\tbest: 0.5179668 (341)\ttotal: 2.69s\tremaining: 4.26s\n",
      "387:\tlearn: 0.4610859\ttest: 0.5180640\tbest: 0.5179668 (341)\ttotal: 2.7s\tremaining: 4.26s\n",
      "388:\tlearn: 0.4610859\ttest: 0.5180640\tbest: 0.5179668 (341)\ttotal: 2.71s\tremaining: 4.25s\n",
      "389:\tlearn: 0.4610859\ttest: 0.5180640\tbest: 0.5179668 (341)\ttotal: 2.71s\tremaining: 4.24s\n",
      "390:\tlearn: 0.4610859\ttest: 0.5180640\tbest: 0.5179668 (341)\ttotal: 2.72s\tremaining: 4.23s\n",
      "391:\tlearn: 0.4610859\ttest: 0.5180640\tbest: 0.5179668 (341)\ttotal: 2.72s\tremaining: 4.22s\n",
      "392:\tlearn: 0.4610019\ttest: 0.5181318\tbest: 0.5179668 (341)\ttotal: 2.73s\tremaining: 4.21s\n",
      "393:\tlearn: 0.4610019\ttest: 0.5181318\tbest: 0.5179668 (341)\ttotal: 2.73s\tremaining: 4.2s\n",
      "394:\tlearn: 0.4608610\ttest: 0.5181900\tbest: 0.5179668 (341)\ttotal: 2.74s\tremaining: 4.2s\n",
      "395:\tlearn: 0.4608610\ttest: 0.5181901\tbest: 0.5179668 (341)\ttotal: 2.75s\tremaining: 4.19s\n",
      "396:\tlearn: 0.4608610\ttest: 0.5181901\tbest: 0.5179668 (341)\ttotal: 2.75s\tremaining: 4.18s\n",
      "397:\tlearn: 0.4608610\ttest: 0.5181902\tbest: 0.5179668 (341)\ttotal: 2.75s\tremaining: 4.17s\n",
      "398:\tlearn: 0.4607320\ttest: 0.5181121\tbest: 0.5179668 (341)\ttotal: 2.76s\tremaining: 4.16s\n",
      "399:\tlearn: 0.4607320\ttest: 0.5181121\tbest: 0.5179668 (341)\ttotal: 2.77s\tremaining: 4.15s\n",
      "400:\tlearn: 0.4607320\ttest: 0.5181121\tbest: 0.5179668 (341)\ttotal: 2.78s\tremaining: 4.15s\n",
      "401:\tlearn: 0.4607320\ttest: 0.5181121\tbest: 0.5179668 (341)\ttotal: 2.78s\tremaining: 4.14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402:\tlearn: 0.4606530\ttest: 0.5181527\tbest: 0.5179668 (341)\ttotal: 2.8s\tremaining: 4.15s\n",
      "403:\tlearn: 0.4606530\ttest: 0.5181527\tbest: 0.5179668 (341)\ttotal: 2.81s\tremaining: 4.15s\n",
      "404:\tlearn: 0.4606530\ttest: 0.5181528\tbest: 0.5179668 (341)\ttotal: 2.82s\tremaining: 4.14s\n",
      "405:\tlearn: 0.4606530\ttest: 0.5181528\tbest: 0.5179668 (341)\ttotal: 2.82s\tremaining: 4.13s\n",
      "406:\tlearn: 0.4606530\ttest: 0.5181528\tbest: 0.5179668 (341)\ttotal: 2.83s\tremaining: 4.12s\n",
      "407:\tlearn: 0.4606530\ttest: 0.5181528\tbest: 0.5179668 (341)\ttotal: 2.83s\tremaining: 4.11s\n",
      "408:\tlearn: 0.4605782\ttest: 0.5181505\tbest: 0.5179668 (341)\ttotal: 2.84s\tremaining: 4.1s\n",
      "409:\tlearn: 0.4605782\ttest: 0.5181505\tbest: 0.5179668 (341)\ttotal: 2.84s\tremaining: 4.09s\n",
      "410:\tlearn: 0.4605782\ttest: 0.5181505\tbest: 0.5179668 (341)\ttotal: 2.85s\tremaining: 4.08s\n",
      "411:\tlearn: 0.4605025\ttest: 0.5180682\tbest: 0.5179668 (341)\ttotal: 2.85s\tremaining: 4.07s\n",
      "412:\tlearn: 0.4605025\ttest: 0.5180682\tbest: 0.5179668 (341)\ttotal: 2.86s\tremaining: 4.06s\n",
      "413:\tlearn: 0.4605025\ttest: 0.5180682\tbest: 0.5179668 (341)\ttotal: 2.87s\tremaining: 4.06s\n",
      "414:\tlearn: 0.4605025\ttest: 0.5180682\tbest: 0.5179668 (341)\ttotal: 2.87s\tremaining: 4.05s\n",
      "415:\tlearn: 0.4604624\ttest: 0.5181386\tbest: 0.5179668 (341)\ttotal: 2.88s\tremaining: 4.04s\n",
      "416:\tlearn: 0.4604624\ttest: 0.5181386\tbest: 0.5179668 (341)\ttotal: 2.88s\tremaining: 4.03s\n",
      "417:\tlearn: 0.4604624\ttest: 0.5181386\tbest: 0.5179668 (341)\ttotal: 2.89s\tremaining: 4.02s\n",
      "418:\tlearn: 0.4603876\ttest: 0.5181464\tbest: 0.5179668 (341)\ttotal: 2.89s\tremaining: 4.01s\n",
      "419:\tlearn: 0.4603876\ttest: 0.5181464\tbest: 0.5179668 (341)\ttotal: 2.9s\tremaining: 4s\n",
      "420:\tlearn: 0.4603876\ttest: 0.5181464\tbest: 0.5179668 (341)\ttotal: 2.9s\tremaining: 3.99s\n",
      "421:\tlearn: 0.4603876\ttest: 0.5181464\tbest: 0.5179668 (341)\ttotal: 2.9s\tremaining: 3.98s\n",
      "422:\tlearn: 0.4603119\ttest: 0.5180920\tbest: 0.5179668 (341)\ttotal: 2.91s\tremaining: 3.97s\n",
      "423:\tlearn: 0.4603119\ttest: 0.5180920\tbest: 0.5179668 (341)\ttotal: 2.92s\tremaining: 3.96s\n",
      "424:\tlearn: 0.4603119\ttest: 0.5180920\tbest: 0.5179668 (341)\ttotal: 2.92s\tremaining: 3.95s\n",
      "425:\tlearn: 0.4603119\ttest: 0.5180920\tbest: 0.5179668 (341)\ttotal: 2.92s\tremaining: 3.94s\n",
      "426:\tlearn: 0.4602340\ttest: 0.5180596\tbest: 0.5179668 (341)\ttotal: 2.93s\tremaining: 3.93s\n",
      "427:\tlearn: 0.4602340\ttest: 0.5180596\tbest: 0.5179668 (341)\ttotal: 2.94s\tremaining: 3.92s\n",
      "428:\tlearn: 0.4602340\ttest: 0.5180596\tbest: 0.5179668 (341)\ttotal: 2.94s\tremaining: 3.91s\n",
      "429:\tlearn: 0.4602340\ttest: 0.5180597\tbest: 0.5179668 (341)\ttotal: 2.94s\tremaining: 3.9s\n",
      "430:\tlearn: 0.4602340\ttest: 0.5180597\tbest: 0.5179668 (341)\ttotal: 2.95s\tremaining: 3.89s\n",
      "431:\tlearn: 0.4602340\ttest: 0.5180597\tbest: 0.5179668 (341)\ttotal: 2.95s\tremaining: 3.88s\n",
      "432:\tlearn: 0.4602340\ttest: 0.5180597\tbest: 0.5179668 (341)\ttotal: 2.96s\tremaining: 3.87s\n",
      "433:\tlearn: 0.4602340\ttest: 0.5180598\tbest: 0.5179668 (341)\ttotal: 2.96s\tremaining: 3.86s\n",
      "434:\tlearn: 0.4601710\ttest: 0.5180759\tbest: 0.5179668 (341)\ttotal: 2.97s\tremaining: 3.85s\n",
      "435:\tlearn: 0.4601710\ttest: 0.5180760\tbest: 0.5179668 (341)\ttotal: 2.97s\tremaining: 3.84s\n",
      "436:\tlearn: 0.4601710\ttest: 0.5180760\tbest: 0.5179668 (341)\ttotal: 2.98s\tremaining: 3.83s\n",
      "437:\tlearn: 0.4601710\ttest: 0.5180760\tbest: 0.5179668 (341)\ttotal: 2.98s\tremaining: 3.83s\n",
      "438:\tlearn: 0.4601710\ttest: 0.5180760\tbest: 0.5179668 (341)\ttotal: 2.98s\tremaining: 3.81s\n",
      "439:\tlearn: 0.4600951\ttest: 0.5181101\tbest: 0.5179668 (341)\ttotal: 2.99s\tremaining: 3.81s\n",
      "440:\tlearn: 0.4599539\ttest: 0.5180993\tbest: 0.5179668 (341)\ttotal: 3s\tremaining: 3.81s\n",
      "441:\tlearn: 0.4599539\ttest: 0.5180993\tbest: 0.5179668 (341)\ttotal: 3.01s\tremaining: 3.8s\n",
      "442:\tlearn: 0.4599539\ttest: 0.5180993\tbest: 0.5179668 (341)\ttotal: 3.02s\tremaining: 3.79s\n",
      "443:\tlearn: 0.4599191\ttest: 0.5180937\tbest: 0.5179668 (341)\ttotal: 3.03s\tremaining: 3.79s\n",
      "444:\tlearn: 0.4599191\ttest: 0.5180937\tbest: 0.5179668 (341)\ttotal: 3.03s\tremaining: 3.78s\n",
      "445:\tlearn: 0.4599191\ttest: 0.5180937\tbest: 0.5179668 (341)\ttotal: 3.04s\tremaining: 3.77s\n",
      "446:\tlearn: 0.4599191\ttest: 0.5180938\tbest: 0.5179668 (341)\ttotal: 3.04s\tremaining: 3.77s\n",
      "447:\tlearn: 0.4599191\ttest: 0.5180938\tbest: 0.5179668 (341)\ttotal: 3.05s\tremaining: 3.76s\n",
      "448:\tlearn: 0.4598664\ttest: 0.5180811\tbest: 0.5179668 (341)\ttotal: 3.06s\tremaining: 3.75s\n",
      "449:\tlearn: 0.4598664\ttest: 0.5180811\tbest: 0.5179668 (341)\ttotal: 3.06s\tremaining: 3.75s\n",
      "450:\tlearn: 0.4598613\ttest: 0.5180905\tbest: 0.5179668 (341)\ttotal: 3.07s\tremaining: 3.74s\n",
      "451:\tlearn: 0.4597544\ttest: 0.5180869\tbest: 0.5179668 (341)\ttotal: 3.08s\tremaining: 3.73s\n",
      "452:\tlearn: 0.4597544\ttest: 0.5180869\tbest: 0.5179668 (341)\ttotal: 3.08s\tremaining: 3.72s\n",
      "453:\tlearn: 0.4597544\ttest: 0.5180869\tbest: 0.5179668 (341)\ttotal: 3.08s\tremaining: 3.71s\n",
      "454:\tlearn: 0.4597544\ttest: 0.5180869\tbest: 0.5179668 (341)\ttotal: 3.09s\tremaining: 3.7s\n",
      "455:\tlearn: 0.4597544\ttest: 0.5180869\tbest: 0.5179668 (341)\ttotal: 3.09s\tremaining: 3.69s\n",
      "456:\tlearn: 0.4596995\ttest: 0.5180259\tbest: 0.5179668 (341)\ttotal: 3.1s\tremaining: 3.68s\n",
      "457:\tlearn: 0.4596995\ttest: 0.5180259\tbest: 0.5179668 (341)\ttotal: 3.1s\tremaining: 3.67s\n",
      "458:\tlearn: 0.4596993\ttest: 0.5180259\tbest: 0.5179668 (341)\ttotal: 3.11s\tremaining: 3.67s\n",
      "459:\tlearn: 0.4596378\ttest: 0.5180644\tbest: 0.5179668 (341)\ttotal: 3.12s\tremaining: 3.66s\n",
      "460:\tlearn: 0.4596378\ttest: 0.5180644\tbest: 0.5179668 (341)\ttotal: 3.12s\tremaining: 3.65s\n",
      "461:\tlearn: 0.4595921\ttest: 0.5181380\tbest: 0.5179668 (341)\ttotal: 3.12s\tremaining: 3.64s\n",
      "462:\tlearn: 0.4595500\ttest: 0.5181273\tbest: 0.5179668 (341)\ttotal: 3.13s\tremaining: 3.63s\n",
      "463:\tlearn: 0.4595500\ttest: 0.5181273\tbest: 0.5179668 (341)\ttotal: 3.13s\tremaining: 3.62s\n",
      "464:\tlearn: 0.4595500\ttest: 0.5181273\tbest: 0.5179668 (341)\ttotal: 3.14s\tremaining: 3.61s\n",
      "465:\tlearn: 0.4595192\ttest: 0.5181256\tbest: 0.5179668 (341)\ttotal: 3.15s\tremaining: 3.6s\n",
      "466:\tlearn: 0.4595192\ttest: 0.5181257\tbest: 0.5179668 (341)\ttotal: 3.15s\tremaining: 3.6s\n",
      "467:\tlearn: 0.4595192\ttest: 0.5181257\tbest: 0.5179668 (341)\ttotal: 3.15s\tremaining: 3.59s\n",
      "468:\tlearn: 0.4594662\ttest: 0.5180714\tbest: 0.5179668 (341)\ttotal: 3.16s\tremaining: 3.58s\n",
      "469:\tlearn: 0.4594662\ttest: 0.5180714\tbest: 0.5179668 (341)\ttotal: 3.17s\tremaining: 3.57s\n",
      "470:\tlearn: 0.4593680\ttest: 0.5180908\tbest: 0.5179668 (341)\ttotal: 3.17s\tremaining: 3.56s\n",
      "471:\tlearn: 0.4593680\ttest: 0.5180908\tbest: 0.5179668 (341)\ttotal: 3.18s\tremaining: 3.55s\n",
      "472:\tlearn: 0.4593680\ttest: 0.5180908\tbest: 0.5179668 (341)\ttotal: 3.18s\tremaining: 3.54s\n",
      "473:\tlearn: 0.4593680\ttest: 0.5180908\tbest: 0.5179668 (341)\ttotal: 3.19s\tremaining: 3.54s\n",
      "474:\tlearn: 0.4593680\ttest: 0.5180908\tbest: 0.5179668 (341)\ttotal: 3.19s\tremaining: 3.53s\n",
      "475:\tlearn: 0.4593576\ttest: 0.5181056\tbest: 0.5179668 (341)\ttotal: 3.2s\tremaining: 3.53s\n",
      "476:\tlearn: 0.4593576\ttest: 0.5181056\tbest: 0.5179668 (341)\ttotal: 3.21s\tremaining: 3.52s\n",
      "477:\tlearn: 0.4593576\ttest: 0.5181056\tbest: 0.5179668 (341)\ttotal: 3.22s\tremaining: 3.51s\n",
      "478:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.23s\tremaining: 3.51s\n",
      "479:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.23s\tremaining: 3.5s\n",
      "480:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.24s\tremaining: 3.49s\n",
      "481:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.24s\tremaining: 3.48s\n",
      "482:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.25s\tremaining: 3.48s\n",
      "483:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.25s\tremaining: 3.47s\n",
      "484:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.26s\tremaining: 3.46s\n",
      "485:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.26s\tremaining: 3.45s\n",
      "486:\tlearn: 0.4592831\ttest: 0.5181261\tbest: 0.5179668 (341)\ttotal: 3.27s\tremaining: 3.44s\n",
      "487:\tlearn: 0.4592418\ttest: 0.5181273\tbest: 0.5179668 (341)\ttotal: 3.27s\tremaining: 3.44s\n",
      "488:\tlearn: 0.4592418\ttest: 0.5181273\tbest: 0.5179668 (341)\ttotal: 3.28s\tremaining: 3.43s\n",
      "489:\tlearn: 0.4592040\ttest: 0.5181511\tbest: 0.5179668 (341)\ttotal: 3.29s\tremaining: 3.42s\n",
      "490:\tlearn: 0.4592006\ttest: 0.5181595\tbest: 0.5179668 (341)\ttotal: 3.29s\tremaining: 3.41s\n",
      "491:\tlearn: 0.4592006\ttest: 0.5181596\tbest: 0.5179668 (341)\ttotal: 3.29s\tremaining: 3.4s\n",
      "492:\tlearn: 0.4592006\ttest: 0.5181596\tbest: 0.5179668 (341)\ttotal: 3.3s\tremaining: 3.39s\n",
      "493:\tlearn: 0.4592000\ttest: 0.5181592\tbest: 0.5179668 (341)\ttotal: 3.31s\tremaining: 3.38s\n",
      "494:\tlearn: 0.4592000\ttest: 0.5181592\tbest: 0.5179668 (341)\ttotal: 3.31s\tremaining: 3.38s\n",
      "495:\tlearn: 0.4591357\ttest: 0.5182414\tbest: 0.5179668 (341)\ttotal: 3.32s\tremaining: 3.38s\n",
      "496:\tlearn: 0.4591357\ttest: 0.5182414\tbest: 0.5179668 (341)\ttotal: 3.33s\tremaining: 3.37s\n",
      "497:\tlearn: 0.4591357\ttest: 0.5182414\tbest: 0.5179668 (341)\ttotal: 3.33s\tremaining: 3.36s\n",
      "498:\tlearn: 0.4590673\ttest: 0.5182751\tbest: 0.5179668 (341)\ttotal: 3.34s\tremaining: 3.36s\n",
      "499:\tlearn: 0.4590673\ttest: 0.5182751\tbest: 0.5179668 (341)\ttotal: 3.35s\tremaining: 3.35s\n",
      "500:\tlearn: 0.4590673\ttest: 0.5182751\tbest: 0.5179668 (341)\ttotal: 3.36s\tremaining: 3.34s\n",
      "501:\tlearn: 0.4590455\ttest: 0.5182794\tbest: 0.5179668 (341)\ttotal: 3.36s\tremaining: 3.34s\n",
      "502:\tlearn: 0.4590163\ttest: 0.5182786\tbest: 0.5179668 (341)\ttotal: 3.37s\tremaining: 3.33s\n",
      "503:\tlearn: 0.4589773\ttest: 0.5183001\tbest: 0.5179668 (341)\ttotal: 3.38s\tremaining: 3.32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504:\tlearn: 0.4589689\ttest: 0.5182974\tbest: 0.5179668 (341)\ttotal: 3.38s\tremaining: 3.31s\n",
      "505:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.39s\tremaining: 3.31s\n",
      "506:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.4s\tremaining: 3.3s\n",
      "507:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.4s\tremaining: 3.29s\n",
      "508:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.41s\tremaining: 3.29s\n",
      "509:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.42s\tremaining: 3.28s\n",
      "510:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.42s\tremaining: 3.27s\n",
      "511:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.43s\tremaining: 3.27s\n",
      "512:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.43s\tremaining: 3.26s\n",
      "513:\tlearn: 0.4589689\ttest: 0.5182975\tbest: 0.5179668 (341)\ttotal: 3.43s\tremaining: 3.25s\n",
      "514:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.44s\tremaining: 3.24s\n",
      "515:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.44s\tremaining: 3.23s\n",
      "516:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.45s\tremaining: 3.22s\n",
      "517:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.45s\tremaining: 3.21s\n",
      "518:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.46s\tremaining: 3.2s\n",
      "519:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.46s\tremaining: 3.19s\n",
      "520:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.46s\tremaining: 3.19s\n",
      "521:\tlearn: 0.4589689\ttest: 0.5182976\tbest: 0.5179668 (341)\ttotal: 3.47s\tremaining: 3.18s\n",
      "522:\tlearn: 0.4589251\ttest: 0.5182534\tbest: 0.5179668 (341)\ttotal: 3.48s\tremaining: 3.17s\n",
      "523:\tlearn: 0.4589251\ttest: 0.5182534\tbest: 0.5179668 (341)\ttotal: 3.48s\tremaining: 3.16s\n",
      "524:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.49s\tremaining: 3.15s\n",
      "525:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.49s\tremaining: 3.15s\n",
      "526:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.5s\tremaining: 3.14s\n",
      "527:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.5s\tremaining: 3.13s\n",
      "528:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.5s\tremaining: 3.12s\n",
      "529:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.51s\tremaining: 3.11s\n",
      "530:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.51s\tremaining: 3.1s\n",
      "531:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.52s\tremaining: 3.09s\n",
      "532:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.52s\tremaining: 3.08s\n",
      "533:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.53s\tremaining: 3.08s\n",
      "534:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.53s\tremaining: 3.07s\n",
      "535:\tlearn: 0.4588898\ttest: 0.5183195\tbest: 0.5179668 (341)\ttotal: 3.54s\tremaining: 3.06s\n",
      "536:\tlearn: 0.4588606\ttest: 0.5182874\tbest: 0.5179668 (341)\ttotal: 3.54s\tremaining: 3.06s\n",
      "537:\tlearn: 0.4588606\ttest: 0.5182874\tbest: 0.5179668 (341)\ttotal: 3.55s\tremaining: 3.05s\n",
      "538:\tlearn: 0.4588602\ttest: 0.5182871\tbest: 0.5179668 (341)\ttotal: 3.55s\tremaining: 3.04s\n",
      "539:\tlearn: 0.4588346\ttest: 0.5182590\tbest: 0.5179668 (341)\ttotal: 3.56s\tremaining: 3.03s\n",
      "540:\tlearn: 0.4588339\ttest: 0.5182585\tbest: 0.5179668 (341)\ttotal: 3.56s\tremaining: 3.02s\n",
      "541:\tlearn: 0.4587893\ttest: 0.5183063\tbest: 0.5179668 (341)\ttotal: 3.58s\tremaining: 3.02s\n",
      "542:\tlearn: 0.4587893\ttest: 0.5183063\tbest: 0.5179668 (341)\ttotal: 3.58s\tremaining: 3.01s\n",
      "543:\tlearn: 0.4587893\ttest: 0.5183063\tbest: 0.5179668 (341)\ttotal: 3.59s\tremaining: 3.01s\n",
      "544:\tlearn: 0.4587893\ttest: 0.5183063\tbest: 0.5179668 (341)\ttotal: 3.59s\tremaining: 3s\n",
      "545:\tlearn: 0.4587632\ttest: 0.5183010\tbest: 0.5179668 (341)\ttotal: 3.6s\tremaining: 3s\n",
      "546:\tlearn: 0.4587632\ttest: 0.5183010\tbest: 0.5179668 (341)\ttotal: 3.61s\tremaining: 2.99s\n",
      "547:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.62s\tremaining: 2.98s\n",
      "548:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.62s\tremaining: 2.98s\n",
      "549:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.63s\tremaining: 2.97s\n",
      "550:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.64s\tremaining: 2.96s\n",
      "551:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.64s\tremaining: 2.96s\n",
      "552:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.65s\tremaining: 2.95s\n",
      "553:\tlearn: 0.4587137\ttest: 0.5182733\tbest: 0.5179668 (341)\ttotal: 3.65s\tremaining: 2.94s\n",
      "554:\tlearn: 0.4586944\ttest: 0.5182519\tbest: 0.5179668 (341)\ttotal: 3.66s\tremaining: 2.94s\n",
      "555:\tlearn: 0.4586627\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.67s\tremaining: 2.93s\n",
      "556:\tlearn: 0.4586627\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.68s\tremaining: 2.92s\n",
      "557:\tlearn: 0.4586627\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.68s\tremaining: 2.92s\n",
      "558:\tlearn: 0.4586627\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.69s\tremaining: 2.91s\n",
      "559:\tlearn: 0.4586627\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.69s\tremaining: 2.9s\n",
      "560:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.7s\tremaining: 2.89s\n",
      "561:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.7s\tremaining: 2.89s\n",
      "562:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.71s\tremaining: 2.88s\n",
      "563:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.71s\tremaining: 2.87s\n",
      "564:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.72s\tremaining: 2.86s\n",
      "565:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.72s\tremaining: 2.85s\n",
      "566:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.73s\tremaining: 2.85s\n",
      "567:\tlearn: 0.4586414\ttest: 0.5182756\tbest: 0.5179668 (341)\ttotal: 3.73s\tremaining: 2.84s\n",
      "568:\tlearn: 0.4586154\ttest: 0.5182495\tbest: 0.5179668 (341)\ttotal: 3.74s\tremaining: 2.83s\n",
      "569:\tlearn: 0.4586154\ttest: 0.5182495\tbest: 0.5179668 (341)\ttotal: 3.74s\tremaining: 2.82s\n",
      "570:\tlearn: 0.4586154\ttest: 0.5182495\tbest: 0.5179668 (341)\ttotal: 3.75s\tremaining: 2.81s\n",
      "571:\tlearn: 0.4586154\ttest: 0.5182495\tbest: 0.5179668 (341)\ttotal: 3.75s\tremaining: 2.81s\n",
      "572:\tlearn: 0.4586154\ttest: 0.5182495\tbest: 0.5179668 (341)\ttotal: 3.76s\tremaining: 2.8s\n",
      "573:\tlearn: 0.4586154\ttest: 0.5182495\tbest: 0.5179668 (341)\ttotal: 3.76s\tremaining: 2.79s\n",
      "574:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.77s\tremaining: 2.79s\n",
      "575:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.78s\tremaining: 2.78s\n",
      "576:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.79s\tremaining: 2.78s\n",
      "577:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.79s\tremaining: 2.77s\n",
      "578:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.8s\tremaining: 2.76s\n",
      "579:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.81s\tremaining: 2.76s\n",
      "580:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.81s\tremaining: 2.75s\n",
      "581:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.82s\tremaining: 2.74s\n",
      "582:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.82s\tremaining: 2.73s\n",
      "583:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.83s\tremaining: 2.73s\n",
      "584:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.83s\tremaining: 2.72s\n",
      "585:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.83s\tremaining: 2.71s\n",
      "586:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.84s\tremaining: 2.7s\n",
      "587:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.85s\tremaining: 2.69s\n",
      "588:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.85s\tremaining: 2.69s\n",
      "589:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.86s\tremaining: 2.68s\n",
      "590:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.87s\tremaining: 2.68s\n",
      "591:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.88s\tremaining: 2.67s\n",
      "592:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.88s\tremaining: 2.66s\n",
      "593:\tlearn: 0.4586125\ttest: 0.5182550\tbest: 0.5179668 (341)\ttotal: 3.89s\tremaining: 2.66s\n",
      "594:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.9s\tremaining: 2.65s\n",
      "595:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.9s\tremaining: 2.65s\n",
      "596:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.91s\tremaining: 2.64s\n",
      "597:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.92s\tremaining: 2.63s\n",
      "598:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.92s\tremaining: 2.63s\n",
      "599:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.93s\tremaining: 2.62s\n",
      "600:\tlearn: 0.4585773\ttest: 0.5183215\tbest: 0.5179668 (341)\ttotal: 3.94s\tremaining: 2.61s\n",
      "601:\tlearn: 0.4585772\ttest: 0.5183245\tbest: 0.5179668 (341)\ttotal: 3.94s\tremaining: 2.61s\n",
      "602:\tlearn: 0.4585772\ttest: 0.5183245\tbest: 0.5179668 (341)\ttotal: 3.95s\tremaining: 2.6s\n",
      "603:\tlearn: 0.4585772\ttest: 0.5183245\tbest: 0.5179668 (341)\ttotal: 3.95s\tremaining: 2.59s\n",
      "604:\tlearn: 0.4585746\ttest: 0.5183300\tbest: 0.5179668 (341)\ttotal: 3.96s\tremaining: 2.59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605:\tlearn: 0.4585746\ttest: 0.5183300\tbest: 0.5179668 (341)\ttotal: 3.97s\tremaining: 2.58s\n",
      "606:\tlearn: 0.4585746\ttest: 0.5183300\tbest: 0.5179668 (341)\ttotal: 3.97s\tremaining: 2.57s\n",
      "607:\tlearn: 0.4585746\ttest: 0.5183300\tbest: 0.5179668 (341)\ttotal: 3.98s\tremaining: 2.57s\n",
      "608:\tlearn: 0.4585746\ttest: 0.5183300\tbest: 0.5179668 (341)\ttotal: 3.99s\tremaining: 2.56s\n",
      "609:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4s\tremaining: 2.56s\n",
      "610:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4s\tremaining: 2.55s\n",
      "611:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.03s\tremaining: 2.56s\n",
      "612:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.04s\tremaining: 2.55s\n",
      "613:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.05s\tremaining: 2.54s\n",
      "614:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.05s\tremaining: 2.54s\n",
      "615:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.06s\tremaining: 2.53s\n",
      "616:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.07s\tremaining: 2.52s\n",
      "617:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.07s\tremaining: 2.52s\n",
      "618:\tlearn: 0.4585585\ttest: 0.5183123\tbest: 0.5179668 (341)\ttotal: 4.08s\tremaining: 2.51s\n",
      "619:\tlearn: 0.4585031\ttest: 0.5183304\tbest: 0.5179668 (341)\ttotal: 4.1s\tremaining: 2.51s\n",
      "620:\tlearn: 0.4585031\ttest: 0.5183304\tbest: 0.5179668 (341)\ttotal: 4.1s\tremaining: 2.5s\n",
      "621:\tlearn: 0.4585031\ttest: 0.5183304\tbest: 0.5179668 (341)\ttotal: 4.11s\tremaining: 2.5s\n",
      "622:\tlearn: 0.4585031\ttest: 0.5183304\tbest: 0.5179668 (341)\ttotal: 4.11s\tremaining: 2.49s\n",
      "623:\tlearn: 0.4585031\ttest: 0.5183304\tbest: 0.5179668 (341)\ttotal: 4.12s\tremaining: 2.48s\n",
      "624:\tlearn: 0.4584983\ttest: 0.5183362\tbest: 0.5179668 (341)\ttotal: 4.13s\tremaining: 2.48s\n",
      "625:\tlearn: 0.4584974\ttest: 0.5183355\tbest: 0.5179668 (341)\ttotal: 4.13s\tremaining: 2.47s\n",
      "626:\tlearn: 0.4584844\ttest: 0.5183390\tbest: 0.5179668 (341)\ttotal: 4.14s\tremaining: 2.46s\n",
      "627:\tlearn: 0.4584844\ttest: 0.5183390\tbest: 0.5179668 (341)\ttotal: 4.14s\tremaining: 2.46s\n",
      "628:\tlearn: 0.4584844\ttest: 0.5183390\tbest: 0.5179668 (341)\ttotal: 4.15s\tremaining: 2.45s\n",
      "629:\tlearn: 0.4584844\ttest: 0.5183390\tbest: 0.5179668 (341)\ttotal: 4.16s\tremaining: 2.44s\n",
      "630:\tlearn: 0.4584814\ttest: 0.5183396\tbest: 0.5179668 (341)\ttotal: 4.16s\tremaining: 2.44s\n",
      "631:\tlearn: 0.4584814\ttest: 0.5183396\tbest: 0.5179668 (341)\ttotal: 4.17s\tremaining: 2.43s\n",
      "632:\tlearn: 0.4584814\ttest: 0.5183396\tbest: 0.5179668 (341)\ttotal: 4.18s\tremaining: 2.42s\n",
      "633:\tlearn: 0.4584634\ttest: 0.5183540\tbest: 0.5179668 (341)\ttotal: 4.19s\tremaining: 2.42s\n",
      "634:\tlearn: 0.4584634\ttest: 0.5183540\tbest: 0.5179668 (341)\ttotal: 4.19s\tremaining: 2.41s\n",
      "635:\tlearn: 0.4584634\ttest: 0.5183540\tbest: 0.5179668 (341)\ttotal: 4.2s\tremaining: 2.4s\n",
      "636:\tlearn: 0.4584634\ttest: 0.5183540\tbest: 0.5179668 (341)\ttotal: 4.21s\tremaining: 2.4s\n",
      "637:\tlearn: 0.4584634\ttest: 0.5183540\tbest: 0.5179668 (341)\ttotal: 4.21s\tremaining: 2.39s\n",
      "638:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.22s\tremaining: 2.38s\n",
      "639:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.23s\tremaining: 2.38s\n",
      "640:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.23s\tremaining: 2.37s\n",
      "641:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.24s\tremaining: 2.36s\n",
      "642:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.24s\tremaining: 2.35s\n",
      "643:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.25s\tremaining: 2.35s\n",
      "644:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.25s\tremaining: 2.34s\n",
      "645:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.26s\tremaining: 2.33s\n",
      "646:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.26s\tremaining: 2.32s\n",
      "647:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.26s\tremaining: 2.32s\n",
      "648:\tlearn: 0.4584614\ttest: 0.5183596\tbest: 0.5179668 (341)\ttotal: 4.27s\tremaining: 2.31s\n",
      "649:\tlearn: 0.4584614\ttest: 0.5183597\tbest: 0.5179668 (341)\ttotal: 4.27s\tremaining: 2.3s\n",
      "650:\tlearn: 0.4584600\ttest: 0.5183600\tbest: 0.5179668 (341)\ttotal: 4.28s\tremaining: 2.29s\n",
      "651:\tlearn: 0.4584554\ttest: 0.5183647\tbest: 0.5179668 (341)\ttotal: 4.29s\tremaining: 2.29s\n",
      "652:\tlearn: 0.4584554\ttest: 0.5183647\tbest: 0.5179668 (341)\ttotal: 4.29s\tremaining: 2.28s\n",
      "653:\tlearn: 0.4584549\ttest: 0.5183641\tbest: 0.5179668 (341)\ttotal: 4.29s\tremaining: 2.27s\n",
      "654:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.3s\tremaining: 2.27s\n",
      "655:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.3s\tremaining: 2.26s\n",
      "656:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.31s\tremaining: 2.25s\n",
      "657:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.31s\tremaining: 2.24s\n",
      "658:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.32s\tremaining: 2.23s\n",
      "659:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.32s\tremaining: 2.23s\n",
      "660:\tlearn: 0.4584097\ttest: 0.5183798\tbest: 0.5179668 (341)\ttotal: 4.33s\tremaining: 2.22s\n",
      "661:\tlearn: 0.4583862\ttest: 0.5183444\tbest: 0.5179668 (341)\ttotal: 4.34s\tremaining: 2.21s\n",
      "662:\tlearn: 0.4583862\ttest: 0.5183444\tbest: 0.5179668 (341)\ttotal: 4.34s\tremaining: 2.21s\n",
      "663:\tlearn: 0.4583862\ttest: 0.5183444\tbest: 0.5179668 (341)\ttotal: 4.35s\tremaining: 2.2s\n",
      "664:\tlearn: 0.4583862\ttest: 0.5183444\tbest: 0.5179668 (341)\ttotal: 4.35s\tremaining: 2.19s\n",
      "665:\tlearn: 0.4583862\ttest: 0.5183444\tbest: 0.5179668 (341)\ttotal: 4.35s\tremaining: 2.18s\n",
      "666:\tlearn: 0.4583824\ttest: 0.5183554\tbest: 0.5179668 (341)\ttotal: 4.36s\tremaining: 2.18s\n",
      "667:\tlearn: 0.4583824\ttest: 0.5183554\tbest: 0.5179668 (341)\ttotal: 4.37s\tremaining: 2.17s\n",
      "668:\tlearn: 0.4583824\ttest: 0.5183554\tbest: 0.5179668 (341)\ttotal: 4.37s\tremaining: 2.16s\n",
      "669:\tlearn: 0.4583824\ttest: 0.5183554\tbest: 0.5179668 (341)\ttotal: 4.37s\tremaining: 2.15s\n",
      "670:\tlearn: 0.4583665\ttest: 0.5183608\tbest: 0.5179668 (341)\ttotal: 4.38s\tremaining: 2.15s\n",
      "671:\tlearn: 0.4583634\ttest: 0.5183710\tbest: 0.5179668 (341)\ttotal: 4.39s\tremaining: 2.14s\n",
      "672:\tlearn: 0.4583511\ttest: 0.5183574\tbest: 0.5179668 (341)\ttotal: 4.4s\tremaining: 2.14s\n",
      "673:\tlearn: 0.4583511\ttest: 0.5183574\tbest: 0.5179668 (341)\ttotal: 4.4s\tremaining: 2.13s\n",
      "674:\tlearn: 0.4583511\ttest: 0.5183574\tbest: 0.5179668 (341)\ttotal: 4.41s\tremaining: 2.12s\n",
      "675:\tlearn: 0.4583511\ttest: 0.5183590\tbest: 0.5179668 (341)\ttotal: 4.41s\tremaining: 2.12s\n",
      "676:\tlearn: 0.4583511\ttest: 0.5183592\tbest: 0.5179668 (341)\ttotal: 4.42s\tremaining: 2.11s\n",
      "677:\tlearn: 0.4583511\ttest: 0.5183592\tbest: 0.5179668 (341)\ttotal: 4.42s\tremaining: 2.1s\n",
      "678:\tlearn: 0.4583385\ttest: 0.5183526\tbest: 0.5179668 (341)\ttotal: 4.43s\tremaining: 2.1s\n",
      "679:\tlearn: 0.4583385\ttest: 0.5183526\tbest: 0.5179668 (341)\ttotal: 4.44s\tremaining: 2.09s\n",
      "680:\tlearn: 0.4583385\ttest: 0.5183526\tbest: 0.5179668 (341)\ttotal: 4.44s\tremaining: 2.08s\n",
      "681:\tlearn: 0.4583385\ttest: 0.5183526\tbest: 0.5179668 (341)\ttotal: 4.45s\tremaining: 2.07s\n",
      "682:\tlearn: 0.4583385\ttest: 0.5183526\tbest: 0.5179668 (341)\ttotal: 4.46s\tremaining: 2.07s\n",
      "683:\tlearn: 0.4583384\ttest: 0.5183541\tbest: 0.5179668 (341)\ttotal: 4.47s\tremaining: 2.06s\n",
      "684:\tlearn: 0.4583384\ttest: 0.5183541\tbest: 0.5179668 (341)\ttotal: 4.47s\tremaining: 2.06s\n",
      "685:\tlearn: 0.4583384\ttest: 0.5183541\tbest: 0.5179668 (341)\ttotal: 4.48s\tremaining: 2.05s\n",
      "686:\tlearn: 0.4583268\ttest: 0.5183594\tbest: 0.5179668 (341)\ttotal: 4.49s\tremaining: 2.04s\n",
      "687:\tlearn: 0.4583268\ttest: 0.5183594\tbest: 0.5179668 (341)\ttotal: 4.5s\tremaining: 2.04s\n",
      "688:\tlearn: 0.4583255\ttest: 0.5183648\tbest: 0.5179668 (341)\ttotal: 4.5s\tremaining: 2.03s\n",
      "689:\tlearn: 0.4583254\ttest: 0.5183653\tbest: 0.5179668 (341)\ttotal: 4.51s\tremaining: 2.03s\n",
      "690:\tlearn: 0.4583254\ttest: 0.5183653\tbest: 0.5179668 (341)\ttotal: 4.52s\tremaining: 2.02s\n",
      "691:\tlearn: 0.4583254\ttest: 0.5183653\tbest: 0.5179668 (341)\ttotal: 4.53s\tremaining: 2.02s\n",
      "692:\tlearn: 0.4583254\ttest: 0.5183667\tbest: 0.5179668 (341)\ttotal: 4.54s\tremaining: 2.01s\n",
      "693:\tlearn: 0.4583254\ttest: 0.5183667\tbest: 0.5179668 (341)\ttotal: 4.54s\tremaining: 2s\n",
      "694:\tlearn: 0.4583222\ttest: 0.5183771\tbest: 0.5179668 (341)\ttotal: 4.56s\tremaining: 2s\n",
      "695:\tlearn: 0.4583222\ttest: 0.5183771\tbest: 0.5179668 (341)\ttotal: 4.56s\tremaining: 1.99s\n",
      "696:\tlearn: 0.4583105\ttest: 0.5183843\tbest: 0.5179668 (341)\ttotal: 4.57s\tremaining: 1.99s\n",
      "697:\tlearn: 0.4583105\ttest: 0.5183843\tbest: 0.5179668 (341)\ttotal: 4.58s\tremaining: 1.98s\n",
      "698:\tlearn: 0.4583105\ttest: 0.5183843\tbest: 0.5179668 (341)\ttotal: 4.58s\tremaining: 1.97s\n",
      "699:\tlearn: 0.4582833\ttest: 0.5184494\tbest: 0.5179668 (341)\ttotal: 4.59s\tremaining: 1.97s\n",
      "700:\tlearn: 0.4582828\ttest: 0.5184500\tbest: 0.5179668 (341)\ttotal: 4.6s\tremaining: 1.96s\n",
      "701:\tlearn: 0.4582828\ttest: 0.5184500\tbest: 0.5179668 (341)\ttotal: 4.61s\tremaining: 1.96s\n",
      "702:\tlearn: 0.4582828\ttest: 0.5184500\tbest: 0.5179668 (341)\ttotal: 4.62s\tremaining: 1.95s\n",
      "703:\tlearn: 0.4582828\ttest: 0.5184500\tbest: 0.5179668 (341)\ttotal: 4.62s\tremaining: 1.94s\n",
      "704:\tlearn: 0.4582718\ttest: 0.5184585\tbest: 0.5179668 (341)\ttotal: 4.63s\tremaining: 1.94s\n",
      "705:\tlearn: 0.4582718\ttest: 0.5184585\tbest: 0.5179668 (341)\ttotal: 4.63s\tremaining: 1.93s\n",
      "706:\tlearn: 0.4582718\ttest: 0.5184585\tbest: 0.5179668 (341)\ttotal: 4.64s\tremaining: 1.92s\n",
      "707:\tlearn: 0.4582718\ttest: 0.5184585\tbest: 0.5179668 (341)\ttotal: 4.64s\tremaining: 1.92s\n",
      "708:\tlearn: 0.4582718\ttest: 0.5184585\tbest: 0.5179668 (341)\ttotal: 4.65s\tremaining: 1.91s\n",
      "709:\tlearn: 0.4582718\ttest: 0.5184585\tbest: 0.5179668 (341)\ttotal: 4.66s\tremaining: 1.9s\n",
      "710:\tlearn: 0.4582263\ttest: 0.5184808\tbest: 0.5179668 (341)\ttotal: 4.66s\tremaining: 1.9s\n",
      "711:\tlearn: 0.4582263\ttest: 0.5184808\tbest: 0.5179668 (341)\ttotal: 4.67s\tremaining: 1.89s\n",
      "712:\tlearn: 0.4582263\ttest: 0.5184808\tbest: 0.5179668 (341)\ttotal: 4.68s\tremaining: 1.88s\n",
      "713:\tlearn: 0.4582263\ttest: 0.5184808\tbest: 0.5179668 (341)\ttotal: 4.69s\tremaining: 1.88s\n",
      "714:\tlearn: 0.4582252\ttest: 0.5184798\tbest: 0.5179668 (341)\ttotal: 4.7s\tremaining: 1.87s\n",
      "715:\tlearn: 0.4582166\ttest: 0.5184956\tbest: 0.5179668 (341)\ttotal: 4.71s\tremaining: 1.87s\n",
      "716:\tlearn: 0.4582166\ttest: 0.5184956\tbest: 0.5179668 (341)\ttotal: 4.71s\tremaining: 1.86s\n",
      "717:\tlearn: 0.4582157\ttest: 0.5185007\tbest: 0.5179668 (341)\ttotal: 4.72s\tremaining: 1.85s\n",
      "718:\tlearn: 0.4581945\ttest: 0.5185315\tbest: 0.5179668 (341)\ttotal: 4.73s\tremaining: 1.85s\n",
      "719:\tlearn: 0.4581945\ttest: 0.5185315\tbest: 0.5179668 (341)\ttotal: 4.73s\tremaining: 1.84s\n",
      "720:\tlearn: 0.4581945\ttest: 0.5185315\tbest: 0.5179668 (341)\ttotal: 4.74s\tremaining: 1.83s\n",
      "721:\tlearn: 0.4581945\ttest: 0.5185315\tbest: 0.5179668 (341)\ttotal: 4.74s\tremaining: 1.83s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722:\tlearn: 0.4581865\ttest: 0.5185487\tbest: 0.5179668 (341)\ttotal: 4.75s\tremaining: 1.82s\n",
      "723:\tlearn: 0.4581865\ttest: 0.5185487\tbest: 0.5179668 (341)\ttotal: 4.76s\tremaining: 1.81s\n",
      "724:\tlearn: 0.4581865\ttest: 0.5185488\tbest: 0.5179668 (341)\ttotal: 4.77s\tremaining: 1.81s\n",
      "725:\tlearn: 0.4581865\ttest: 0.5185488\tbest: 0.5179668 (341)\ttotal: 4.78s\tremaining: 1.8s\n",
      "726:\tlearn: 0.4581865\ttest: 0.5185488\tbest: 0.5179668 (341)\ttotal: 4.78s\tremaining: 1.79s\n",
      "727:\tlearn: 0.4581865\ttest: 0.5185488\tbest: 0.5179668 (341)\ttotal: 4.79s\tremaining: 1.79s\n",
      "728:\tlearn: 0.4581865\ttest: 0.5185488\tbest: 0.5179668 (341)\ttotal: 4.79s\tremaining: 1.78s\n",
      "729:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.8s\tremaining: 1.77s\n",
      "730:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.8s\tremaining: 1.77s\n",
      "731:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.81s\tremaining: 1.76s\n",
      "732:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.81s\tremaining: 1.75s\n",
      "733:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.82s\tremaining: 1.75s\n",
      "734:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.83s\tremaining: 1.74s\n",
      "735:\tlearn: 0.4581838\ttest: 0.5185587\tbest: 0.5179668 (341)\ttotal: 4.83s\tremaining: 1.73s\n",
      "736:\tlearn: 0.4581838\ttest: 0.5185588\tbest: 0.5179668 (341)\ttotal: 4.83s\tremaining: 1.73s\n",
      "737:\tlearn: 0.4581838\ttest: 0.5185588\tbest: 0.5179668 (341)\ttotal: 4.84s\tremaining: 1.72s\n",
      "738:\tlearn: 0.4581838\ttest: 0.5185588\tbest: 0.5179668 (341)\ttotal: 4.84s\tremaining: 1.71s\n",
      "739:\tlearn: 0.4581830\ttest: 0.5185637\tbest: 0.5179668 (341)\ttotal: 4.85s\tremaining: 1.7s\n",
      "740:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.86s\tremaining: 1.7s\n",
      "741:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.86s\tremaining: 1.69s\n",
      "742:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.87s\tremaining: 1.68s\n",
      "743:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.87s\tremaining: 1.68s\n",
      "744:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.87s\tremaining: 1.67s\n",
      "745:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.88s\tremaining: 1.66s\n",
      "746:\tlearn: 0.4581792\ttest: 0.5185720\tbest: 0.5179668 (341)\ttotal: 4.89s\tremaining: 1.66s\n",
      "747:\tlearn: 0.4581786\ttest: 0.5185768\tbest: 0.5179668 (341)\ttotal: 4.89s\tremaining: 1.65s\n",
      "748:\tlearn: 0.4581786\ttest: 0.5185769\tbest: 0.5179668 (341)\ttotal: 4.9s\tremaining: 1.64s\n",
      "749:\tlearn: 0.4581786\ttest: 0.5185769\tbest: 0.5179668 (341)\ttotal: 4.9s\tremaining: 1.63s\n",
      "750:\tlearn: 0.4581786\ttest: 0.5185769\tbest: 0.5179668 (341)\ttotal: 4.91s\tremaining: 1.63s\n",
      "751:\tlearn: 0.4581786\ttest: 0.5185769\tbest: 0.5179668 (341)\ttotal: 4.91s\tremaining: 1.62s\n",
      "752:\tlearn: 0.4581786\ttest: 0.5185768\tbest: 0.5179668 (341)\ttotal: 4.92s\tremaining: 1.61s\n",
      "753:\tlearn: 0.4581786\ttest: 0.5185768\tbest: 0.5179668 (341)\ttotal: 4.92s\tremaining: 1.61s\n",
      "754:\tlearn: 0.4581720\ttest: 0.5185917\tbest: 0.5179668 (341)\ttotal: 4.93s\tremaining: 1.6s\n",
      "755:\tlearn: 0.4581720\ttest: 0.5185917\tbest: 0.5179668 (341)\ttotal: 4.94s\tremaining: 1.59s\n",
      "756:\tlearn: 0.4581720\ttest: 0.5185918\tbest: 0.5179668 (341)\ttotal: 4.95s\tremaining: 1.59s\n",
      "757:\tlearn: 0.4581708\ttest: 0.5185907\tbest: 0.5179668 (341)\ttotal: 4.96s\tremaining: 1.58s\n",
      "758:\tlearn: 0.4581708\ttest: 0.5185907\tbest: 0.5179668 (341)\ttotal: 4.96s\tremaining: 1.58s\n",
      "759:\tlearn: 0.4581708\ttest: 0.5185907\tbest: 0.5179668 (341)\ttotal: 4.97s\tremaining: 1.57s\n",
      "760:\tlearn: 0.4581708\ttest: 0.5185907\tbest: 0.5179668 (341)\ttotal: 4.98s\tremaining: 1.56s\n",
      "761:\tlearn: 0.4581689\ttest: 0.5185960\tbest: 0.5179668 (341)\ttotal: 4.99s\tremaining: 1.56s\n",
      "762:\tlearn: 0.4581689\ttest: 0.5185960\tbest: 0.5179668 (341)\ttotal: 4.99s\tremaining: 1.55s\n",
      "763:\tlearn: 0.4581689\ttest: 0.5185960\tbest: 0.5179668 (341)\ttotal: 5s\tremaining: 1.54s\n",
      "764:\tlearn: 0.4581689\ttest: 0.5185960\tbest: 0.5179668 (341)\ttotal: 5s\tremaining: 1.54s\n",
      "765:\tlearn: 0.4581689\ttest: 0.5185960\tbest: 0.5179668 (341)\ttotal: 5.01s\tremaining: 1.53s\n",
      "766:\tlearn: 0.4581634\ttest: 0.5186048\tbest: 0.5179668 (341)\ttotal: 5.02s\tremaining: 1.52s\n",
      "767:\tlearn: 0.4581620\ttest: 0.5186094\tbest: 0.5179668 (341)\ttotal: 5.03s\tremaining: 1.52s\n",
      "768:\tlearn: 0.4581620\ttest: 0.5186094\tbest: 0.5179668 (341)\ttotal: 5.03s\tremaining: 1.51s\n",
      "769:\tlearn: 0.4581620\ttest: 0.5186094\tbest: 0.5179668 (341)\ttotal: 5.03s\tremaining: 1.5s\n",
      "770:\tlearn: 0.4581548\ttest: 0.5186214\tbest: 0.5179668 (341)\ttotal: 5.04s\tremaining: 1.5s\n",
      "771:\tlearn: 0.4581548\ttest: 0.5186214\tbest: 0.5179668 (341)\ttotal: 5.04s\tremaining: 1.49s\n",
      "772:\tlearn: 0.4581548\ttest: 0.5186214\tbest: 0.5179668 (341)\ttotal: 5.05s\tremaining: 1.48s\n",
      "773:\tlearn: 0.4581548\ttest: 0.5186214\tbest: 0.5179668 (341)\ttotal: 5.05s\tremaining: 1.48s\n",
      "774:\tlearn: 0.4581548\ttest: 0.5186215\tbest: 0.5179668 (341)\ttotal: 5.06s\tremaining: 1.47s\n",
      "775:\tlearn: 0.4581548\ttest: 0.5186215\tbest: 0.5179668 (341)\ttotal: 5.06s\tremaining: 1.46s\n",
      "776:\tlearn: 0.4581548\ttest: 0.5186215\tbest: 0.5179668 (341)\ttotal: 5.07s\tremaining: 1.45s\n",
      "777:\tlearn: 0.4581548\ttest: 0.5186215\tbest: 0.5179668 (341)\ttotal: 5.07s\tremaining: 1.45s\n",
      "778:\tlearn: 0.4581548\ttest: 0.5186215\tbest: 0.5179668 (341)\ttotal: 5.08s\tremaining: 1.44s\n",
      "779:\tlearn: 0.4581548\ttest: 0.5186215\tbest: 0.5179668 (341)\ttotal: 5.08s\tremaining: 1.43s\n",
      "780:\tlearn: 0.4581277\ttest: 0.5186661\tbest: 0.5179668 (341)\ttotal: 5.09s\tremaining: 1.43s\n",
      "781:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.09s\tremaining: 1.42s\n",
      "782:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.1s\tremaining: 1.41s\n",
      "783:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.1s\tremaining: 1.41s\n",
      "784:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.11s\tremaining: 1.4s\n",
      "785:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.12s\tremaining: 1.39s\n",
      "786:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.12s\tremaining: 1.39s\n",
      "787:\tlearn: 0.4581276\ttest: 0.5186668\tbest: 0.5179668 (341)\ttotal: 5.13s\tremaining: 1.38s\n",
      "788:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.13s\tremaining: 1.37s\n",
      "789:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.14s\tremaining: 1.36s\n",
      "790:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.15s\tremaining: 1.36s\n",
      "791:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.15s\tremaining: 1.35s\n",
      "792:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.16s\tremaining: 1.35s\n",
      "793:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.17s\tremaining: 1.34s\n",
      "794:\tlearn: 0.4581274\ttest: 0.5186672\tbest: 0.5179668 (341)\ttotal: 5.17s\tremaining: 1.33s\n",
      "795:\tlearn: 0.4581216\ttest: 0.5186780\tbest: 0.5179668 (341)\ttotal: 5.18s\tremaining: 1.33s\n",
      "796:\tlearn: 0.4581216\ttest: 0.5186780\tbest: 0.5179668 (341)\ttotal: 5.19s\tremaining: 1.32s\n",
      "797:\tlearn: 0.4581216\ttest: 0.5186786\tbest: 0.5179668 (341)\ttotal: 5.2s\tremaining: 1.31s\n",
      "798:\tlearn: 0.4581000\ttest: 0.5187139\tbest: 0.5179668 (341)\ttotal: 5.21s\tremaining: 1.31s\n",
      "799:\tlearn: 0.4581000\ttest: 0.5187139\tbest: 0.5179668 (341)\ttotal: 5.21s\tremaining: 1.3s\n",
      "800:\tlearn: 0.4581000\ttest: 0.5187139\tbest: 0.5179668 (341)\ttotal: 5.22s\tremaining: 1.3s\n",
      "801:\tlearn: 0.4580975\ttest: 0.5187256\tbest: 0.5179668 (341)\ttotal: 5.23s\tremaining: 1.29s\n",
      "802:\tlearn: 0.4580975\ttest: 0.5187256\tbest: 0.5179668 (341)\ttotal: 5.23s\tremaining: 1.28s\n",
      "803:\tlearn: 0.4580975\ttest: 0.5187256\tbest: 0.5179668 (341)\ttotal: 5.24s\tremaining: 1.28s\n",
      "804:\tlearn: 0.4580975\ttest: 0.5187256\tbest: 0.5179668 (341)\ttotal: 5.24s\tremaining: 1.27s\n",
      "805:\tlearn: 0.4580975\ttest: 0.5187256\tbest: 0.5179668 (341)\ttotal: 5.24s\tremaining: 1.26s\n",
      "806:\tlearn: 0.4580975\ttest: 0.5187256\tbest: 0.5179668 (341)\ttotal: 5.25s\tremaining: 1.25s\n",
      "807:\tlearn: 0.4580931\ttest: 0.5187354\tbest: 0.5179668 (341)\ttotal: 5.26s\tremaining: 1.25s\n",
      "808:\tlearn: 0.4580931\ttest: 0.5187354\tbest: 0.5179668 (341)\ttotal: 5.27s\tremaining: 1.24s\n",
      "809:\tlearn: 0.4580931\ttest: 0.5187354\tbest: 0.5179668 (341)\ttotal: 5.28s\tremaining: 1.24s\n",
      "810:\tlearn: 0.4580931\ttest: 0.5187354\tbest: 0.5179668 (341)\ttotal: 5.28s\tremaining: 1.23s\n",
      "811:\tlearn: 0.4580931\ttest: 0.5187364\tbest: 0.5179668 (341)\ttotal: 5.29s\tremaining: 1.23s\n",
      "812:\tlearn: 0.4580931\ttest: 0.5187364\tbest: 0.5179668 (341)\ttotal: 5.3s\tremaining: 1.22s\n",
      "813:\tlearn: 0.4580858\ttest: 0.5187525\tbest: 0.5179668 (341)\ttotal: 5.31s\tremaining: 1.21s\n",
      "814:\tlearn: 0.4580858\ttest: 0.5187525\tbest: 0.5179668 (341)\ttotal: 5.32s\tremaining: 1.21s\n",
      "815:\tlearn: 0.4580858\ttest: 0.5187525\tbest: 0.5179668 (341)\ttotal: 5.33s\tremaining: 1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816:\tlearn: 0.4580858\ttest: 0.5187525\tbest: 0.5179668 (341)\ttotal: 5.33s\tremaining: 1.2s\n",
      "817:\tlearn: 0.4580854\ttest: 0.5187568\tbest: 0.5179668 (341)\ttotal: 5.35s\tremaining: 1.19s\n",
      "818:\tlearn: 0.4580854\ttest: 0.5187568\tbest: 0.5179668 (341)\ttotal: 5.35s\tremaining: 1.18s\n",
      "819:\tlearn: 0.4580754\ttest: 0.5187502\tbest: 0.5179668 (341)\ttotal: 5.36s\tremaining: 1.18s\n",
      "820:\tlearn: 0.4580754\ttest: 0.5187502\tbest: 0.5179668 (341)\ttotal: 5.37s\tremaining: 1.17s\n",
      "821:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.38s\tremaining: 1.16s\n",
      "822:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.38s\tremaining: 1.16s\n",
      "823:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.39s\tremaining: 1.15s\n",
      "824:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.39s\tremaining: 1.14s\n",
      "825:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.4s\tremaining: 1.14s\n",
      "826:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.4s\tremaining: 1.13s\n",
      "827:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.41s\tremaining: 1.12s\n",
      "828:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.41s\tremaining: 1.12s\n",
      "829:\tlearn: 0.4580754\ttest: 0.5187503\tbest: 0.5179668 (341)\ttotal: 5.42s\tremaining: 1.11s\n",
      "830:\tlearn: 0.4580754\ttest: 0.5187502\tbest: 0.5179668 (341)\ttotal: 5.43s\tremaining: 1.1s\n",
      "831:\tlearn: 0.4580754\ttest: 0.5187502\tbest: 0.5179668 (341)\ttotal: 5.44s\tremaining: 1.1s\n",
      "832:\tlearn: 0.4580664\ttest: 0.5187448\tbest: 0.5179668 (341)\ttotal: 5.46s\tremaining: 1.09s\n",
      "833:\tlearn: 0.4580664\ttest: 0.5187448\tbest: 0.5179668 (341)\ttotal: 5.46s\tremaining: 1.09s\n",
      "834:\tlearn: 0.4580654\ttest: 0.5187491\tbest: 0.5179668 (341)\ttotal: 5.47s\tremaining: 1.08s\n",
      "835:\tlearn: 0.4580654\ttest: 0.5187491\tbest: 0.5179668 (341)\ttotal: 5.48s\tremaining: 1.07s\n",
      "836:\tlearn: 0.4580654\ttest: 0.5187491\tbest: 0.5179668 (341)\ttotal: 5.49s\tremaining: 1.07s\n",
      "837:\tlearn: 0.4580654\ttest: 0.5187491\tbest: 0.5179668 (341)\ttotal: 5.49s\tremaining: 1.06s\n",
      "838:\tlearn: 0.4580654\ttest: 0.5187491\tbest: 0.5179668 (341)\ttotal: 5.5s\tremaining: 1.05s\n",
      "839:\tlearn: 0.4580654\ttest: 0.5187486\tbest: 0.5179668 (341)\ttotal: 5.51s\tremaining: 1.05s\n",
      "840:\tlearn: 0.4580654\ttest: 0.5187486\tbest: 0.5179668 (341)\ttotal: 5.51s\tremaining: 1.04s\n",
      "841:\tlearn: 0.4580647\ttest: 0.5187479\tbest: 0.5179668 (341)\ttotal: 5.52s\tremaining: 1.03s\n",
      "842:\tlearn: 0.4580647\ttest: 0.5187479\tbest: 0.5179668 (341)\ttotal: 5.53s\tremaining: 1.03s\n",
      "843:\tlearn: 0.4580647\ttest: 0.5187479\tbest: 0.5179668 (341)\ttotal: 5.53s\tremaining: 1.02s\n",
      "844:\tlearn: 0.4580647\ttest: 0.5187479\tbest: 0.5179668 (341)\ttotal: 5.54s\tremaining: 1.01s\n",
      "845:\tlearn: 0.4580647\ttest: 0.5187473\tbest: 0.5179668 (341)\ttotal: 5.54s\tremaining: 1.01s\n",
      "846:\tlearn: 0.4580647\ttest: 0.5187473\tbest: 0.5179668 (341)\ttotal: 5.55s\tremaining: 1s\n",
      "847:\tlearn: 0.4580647\ttest: 0.5187473\tbest: 0.5179668 (341)\ttotal: 5.55s\tremaining: 995ms\n",
      "848:\tlearn: 0.4580647\ttest: 0.5187473\tbest: 0.5179668 (341)\ttotal: 5.56s\tremaining: 989ms\n",
      "849:\tlearn: 0.4580646\ttest: 0.5187482\tbest: 0.5179668 (341)\ttotal: 5.57s\tremaining: 983ms\n",
      "850:\tlearn: 0.4580646\ttest: 0.5187482\tbest: 0.5179668 (341)\ttotal: 5.58s\tremaining: 976ms\n",
      "851:\tlearn: 0.4580646\ttest: 0.5187482\tbest: 0.5179668 (341)\ttotal: 5.58s\tremaining: 969ms\n",
      "852:\tlearn: 0.4580646\ttest: 0.5187479\tbest: 0.5179668 (341)\ttotal: 5.59s\tremaining: 963ms\n",
      "853:\tlearn: 0.4580604\ttest: 0.5187522\tbest: 0.5179668 (341)\ttotal: 5.59s\tremaining: 957ms\n",
      "854:\tlearn: 0.4580604\ttest: 0.5187522\tbest: 0.5179668 (341)\ttotal: 5.6s\tremaining: 950ms\n",
      "855:\tlearn: 0.4580604\ttest: 0.5187522\tbest: 0.5179668 (341)\ttotal: 5.6s\tremaining: 943ms\n",
      "856:\tlearn: 0.4580552\ttest: 0.5187622\tbest: 0.5179668 (341)\ttotal: 5.61s\tremaining: 936ms\n",
      "857:\tlearn: 0.4580552\ttest: 0.5187622\tbest: 0.5179668 (341)\ttotal: 5.62s\tremaining: 929ms\n",
      "858:\tlearn: 0.4580475\ttest: 0.5187537\tbest: 0.5179668 (341)\ttotal: 5.62s\tremaining: 923ms\n",
      "859:\tlearn: 0.4580423\ttest: 0.5187621\tbest: 0.5179668 (341)\ttotal: 5.63s\tremaining: 916ms\n",
      "860:\tlearn: 0.4580423\ttest: 0.5187621\tbest: 0.5179668 (341)\ttotal: 5.63s\tremaining: 909ms\n",
      "861:\tlearn: 0.4580423\ttest: 0.5187621\tbest: 0.5179668 (341)\ttotal: 5.64s\tremaining: 903ms\n",
      "862:\tlearn: 0.4580423\ttest: 0.5187621\tbest: 0.5179668 (341)\ttotal: 5.64s\tremaining: 896ms\n",
      "863:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.65s\tremaining: 889ms\n",
      "864:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.65s\tremaining: 882ms\n",
      "865:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.66s\tremaining: 875ms\n",
      "866:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.66s\tremaining: 868ms\n",
      "867:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.67s\tremaining: 862ms\n",
      "868:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.67s\tremaining: 855ms\n",
      "869:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.67s\tremaining: 848ms\n",
      "870:\tlearn: 0.4580423\ttest: 0.5187626\tbest: 0.5179668 (341)\ttotal: 5.68s\tremaining: 841ms\n",
      "871:\tlearn: 0.4580423\ttest: 0.5187630\tbest: 0.5179668 (341)\ttotal: 5.68s\tremaining: 834ms\n",
      "872:\tlearn: 0.4580395\ttest: 0.5187695\tbest: 0.5179668 (341)\ttotal: 5.69s\tremaining: 828ms\n",
      "873:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.7s\tremaining: 821ms\n",
      "874:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.7s\tremaining: 814ms\n",
      "875:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.71s\tremaining: 808ms\n",
      "876:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.71s\tremaining: 801ms\n",
      "877:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.72s\tremaining: 794ms\n",
      "878:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.72s\tremaining: 788ms\n",
      "879:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.73s\tremaining: 781ms\n",
      "880:\tlearn: 0.4580317\ttest: 0.5187607\tbest: 0.5179668 (341)\ttotal: 5.73s\tremaining: 775ms\n",
      "881:\tlearn: 0.4580283\ttest: 0.5187694\tbest: 0.5179668 (341)\ttotal: 5.74s\tremaining: 769ms\n",
      "882:\tlearn: 0.4580283\ttest: 0.5187694\tbest: 0.5179668 (341)\ttotal: 5.75s\tremaining: 762ms\n",
      "883:\tlearn: 0.4580283\ttest: 0.5187694\tbest: 0.5179668 (341)\ttotal: 5.76s\tremaining: 756ms\n",
      "884:\tlearn: 0.4580283\ttest: 0.5187694\tbest: 0.5179668 (341)\ttotal: 5.76s\tremaining: 749ms\n",
      "885:\tlearn: 0.4580283\ttest: 0.5187694\tbest: 0.5179668 (341)\ttotal: 5.77s\tremaining: 742ms\n",
      "886:\tlearn: 0.4580283\ttest: 0.5187694\tbest: 0.5179668 (341)\ttotal: 5.78s\tremaining: 736ms\n",
      "887:\tlearn: 0.4580283\ttest: 0.5187692\tbest: 0.5179668 (341)\ttotal: 5.78s\tremaining: 729ms\n",
      "888:\tlearn: 0.4580256\ttest: 0.5187764\tbest: 0.5179668 (341)\ttotal: 5.79s\tremaining: 723ms\n",
      "889:\tlearn: 0.4580256\ttest: 0.5187764\tbest: 0.5179668 (341)\ttotal: 5.79s\tremaining: 716ms\n",
      "890:\tlearn: 0.4580256\ttest: 0.5187764\tbest: 0.5179668 (341)\ttotal: 5.8s\tremaining: 709ms\n",
      "891:\tlearn: 0.4580214\ttest: 0.5187861\tbest: 0.5179668 (341)\ttotal: 5.81s\tremaining: 703ms\n",
      "892:\tlearn: 0.4580214\ttest: 0.5187861\tbest: 0.5179668 (341)\ttotal: 5.81s\tremaining: 696ms\n",
      "893:\tlearn: 0.4580213\ttest: 0.5187866\tbest: 0.5179668 (341)\ttotal: 5.82s\tremaining: 690ms\n",
      "894:\tlearn: 0.4580213\ttest: 0.5187866\tbest: 0.5179668 (341)\ttotal: 5.82s\tremaining: 683ms\n",
      "895:\tlearn: 0.4580182\ttest: 0.5187949\tbest: 0.5179668 (341)\ttotal: 5.83s\tremaining: 676ms\n",
      "896:\tlearn: 0.4580182\ttest: 0.5187948\tbest: 0.5179668 (341)\ttotal: 5.83s\tremaining: 670ms\n",
      "897:\tlearn: 0.4580179\ttest: 0.5187985\tbest: 0.5179668 (341)\ttotal: 5.84s\tremaining: 663ms\n",
      "898:\tlearn: 0.4580151\ttest: 0.5188072\tbest: 0.5179668 (341)\ttotal: 5.85s\tremaining: 657ms\n",
      "899:\tlearn: 0.4580123\ttest: 0.5188149\tbest: 0.5179668 (341)\ttotal: 5.85s\tremaining: 650ms\n",
      "900:\tlearn: 0.4580096\ttest: 0.5188258\tbest: 0.5179668 (341)\ttotal: 5.86s\tremaining: 644ms\n",
      "901:\tlearn: 0.4580096\ttest: 0.5188258\tbest: 0.5179668 (341)\ttotal: 5.86s\tremaining: 637ms\n",
      "902:\tlearn: 0.4580096\ttest: 0.5188258\tbest: 0.5179668 (341)\ttotal: 5.87s\tremaining: 630ms\n",
      "903:\tlearn: 0.4579909\ttest: 0.5188056\tbest: 0.5179668 (341)\ttotal: 5.88s\tremaining: 624ms\n",
      "904:\tlearn: 0.4579909\ttest: 0.5188056\tbest: 0.5179668 (341)\ttotal: 5.88s\tremaining: 617ms\n",
      "905:\tlearn: 0.4579909\ttest: 0.5188056\tbest: 0.5179668 (341)\ttotal: 5.88s\tremaining: 611ms\n",
      "906:\tlearn: 0.4579909\ttest: 0.5188056\tbest: 0.5179668 (341)\ttotal: 5.89s\tremaining: 604ms\n",
      "907:\tlearn: 0.4579909\ttest: 0.5188056\tbest: 0.5179668 (341)\ttotal: 5.89s\tremaining: 597ms\n",
      "908:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.9s\tremaining: 590ms\n",
      "909:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.9s\tremaining: 584ms\n",
      "910:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.91s\tremaining: 577ms\n",
      "911:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.91s\tremaining: 570ms\n",
      "912:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.92s\tremaining: 564ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.92s\tremaining: 557ms\n",
      "914:\tlearn: 0.4579909\ttest: 0.5188055\tbest: 0.5179668 (341)\ttotal: 5.93s\tremaining: 551ms\n",
      "915:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.94s\tremaining: 545ms\n",
      "916:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.94s\tremaining: 538ms\n",
      "917:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.95s\tremaining: 532ms\n",
      "918:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.96s\tremaining: 525ms\n",
      "919:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.96s\tremaining: 518ms\n",
      "920:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.96s\tremaining: 512ms\n",
      "921:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.97s\tremaining: 505ms\n",
      "922:\tlearn: 0.4579885\ttest: 0.5188162\tbest: 0.5179668 (341)\ttotal: 5.97s\tremaining: 498ms\n",
      "923:\tlearn: 0.4579845\ttest: 0.5188259\tbest: 0.5179668 (341)\ttotal: 5.98s\tremaining: 492ms\n",
      "924:\tlearn: 0.4579845\ttest: 0.5188259\tbest: 0.5179668 (341)\ttotal: 5.99s\tremaining: 485ms\n",
      "925:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 5.99s\tremaining: 479ms\n",
      "926:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6s\tremaining: 472ms\n",
      "927:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6s\tremaining: 466ms\n",
      "928:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.01s\tremaining: 459ms\n",
      "929:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.01s\tremaining: 452ms\n",
      "930:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.01s\tremaining: 446ms\n",
      "931:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.02s\tremaining: 439ms\n",
      "932:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.02s\tremaining: 433ms\n",
      "933:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.03s\tremaining: 426ms\n",
      "934:\tlearn: 0.4579842\ttest: 0.5188293\tbest: 0.5179668 (341)\ttotal: 6.03s\tremaining: 419ms\n",
      "935:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.04s\tremaining: 413ms\n",
      "936:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.04s\tremaining: 406ms\n",
      "937:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.05s\tremaining: 400ms\n",
      "938:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.05s\tremaining: 393ms\n",
      "939:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.05s\tremaining: 387ms\n",
      "940:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.06s\tremaining: 380ms\n",
      "941:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.06s\tremaining: 373ms\n",
      "942:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.07s\tremaining: 367ms\n",
      "943:\tlearn: 0.4579615\ttest: 0.5188438\tbest: 0.5179668 (341)\ttotal: 6.07s\tremaining: 360ms\n",
      "944:\tlearn: 0.4579473\ttest: 0.5188386\tbest: 0.5179668 (341)\ttotal: 6.08s\tremaining: 354ms\n",
      "945:\tlearn: 0.4579453\ttest: 0.5188489\tbest: 0.5179668 (341)\ttotal: 6.09s\tremaining: 348ms\n",
      "946:\tlearn: 0.4579453\ttest: 0.5188489\tbest: 0.5179668 (341)\ttotal: 6.09s\tremaining: 341ms\n",
      "947:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.1s\tremaining: 335ms\n",
      "948:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.1s\tremaining: 328ms\n",
      "949:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.11s\tremaining: 321ms\n",
      "950:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.11s\tremaining: 315ms\n",
      "951:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.12s\tremaining: 309ms\n",
      "952:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.13s\tremaining: 302ms\n",
      "953:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.13s\tremaining: 296ms\n",
      "954:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.14s\tremaining: 289ms\n",
      "955:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.14s\tremaining: 283ms\n",
      "956:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.15s\tremaining: 276ms\n",
      "957:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.16s\tremaining: 270ms\n",
      "958:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.16s\tremaining: 263ms\n",
      "959:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.16s\tremaining: 257ms\n",
      "960:\tlearn: 0.4579322\ttest: 0.5188773\tbest: 0.5179668 (341)\ttotal: 6.17s\tremaining: 250ms\n",
      "961:\tlearn: 0.4579269\ttest: 0.5188926\tbest: 0.5179668 (341)\ttotal: 6.17s\tremaining: 244ms\n",
      "962:\tlearn: 0.4578962\ttest: 0.5189053\tbest: 0.5179668 (341)\ttotal: 6.18s\tremaining: 238ms\n",
      "963:\tlearn: 0.4578962\ttest: 0.5189053\tbest: 0.5179668 (341)\ttotal: 6.18s\tremaining: 231ms\n",
      "964:\tlearn: 0.4578962\ttest: 0.5189053\tbest: 0.5179668 (341)\ttotal: 6.19s\tremaining: 225ms\n",
      "965:\tlearn: 0.4578962\ttest: 0.5189053\tbest: 0.5179668 (341)\ttotal: 6.19s\tremaining: 218ms\n",
      "966:\tlearn: 0.4578962\ttest: 0.5189053\tbest: 0.5179668 (341)\ttotal: 6.2s\tremaining: 212ms\n",
      "967:\tlearn: 0.4578955\ttest: 0.5189099\tbest: 0.5179668 (341)\ttotal: 6.21s\tremaining: 205ms\n",
      "968:\tlearn: 0.4578955\ttest: 0.5189099\tbest: 0.5179668 (341)\ttotal: 6.21s\tremaining: 199ms\n",
      "969:\tlearn: 0.4578953\ttest: 0.5189090\tbest: 0.5179668 (341)\ttotal: 6.22s\tremaining: 192ms\n",
      "970:\tlearn: 0.4578953\ttest: 0.5189090\tbest: 0.5179668 (341)\ttotal: 6.22s\tremaining: 186ms\n",
      "971:\tlearn: 0.4578953\ttest: 0.5189090\tbest: 0.5179668 (341)\ttotal: 6.22s\tremaining: 179ms\n",
      "972:\tlearn: 0.4578953\ttest: 0.5189090\tbest: 0.5179668 (341)\ttotal: 6.23s\tremaining: 173ms\n",
      "973:\tlearn: 0.4578953\ttest: 0.5189090\tbest: 0.5179668 (341)\ttotal: 6.23s\tremaining: 166ms\n",
      "974:\tlearn: 0.4578935\ttest: 0.5189191\tbest: 0.5179668 (341)\ttotal: 6.24s\tremaining: 160ms\n",
      "975:\tlearn: 0.4578935\ttest: 0.5189191\tbest: 0.5179668 (341)\ttotal: 6.25s\tremaining: 154ms\n",
      "976:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.25s\tremaining: 147ms\n",
      "977:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.25s\tremaining: 141ms\n",
      "978:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.26s\tremaining: 134ms\n",
      "979:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.26s\tremaining: 128ms\n",
      "980:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.27s\tremaining: 121ms\n",
      "981:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.27s\tremaining: 115ms\n",
      "982:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.28s\tremaining: 109ms\n",
      "983:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.28s\tremaining: 102ms\n",
      "984:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.29s\tremaining: 95.7ms\n",
      "985:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.29s\tremaining: 89.3ms\n",
      "986:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.29s\tremaining: 82.9ms\n",
      "987:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.3s\tremaining: 76.5ms\n",
      "988:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.31s\tremaining: 70.1ms\n",
      "989:\tlearn: 0.4578933\ttest: 0.5189215\tbest: 0.5179668 (341)\ttotal: 6.31s\tremaining: 63.8ms\n",
      "990:\tlearn: 0.4578559\ttest: 0.5189367\tbest: 0.5179668 (341)\ttotal: 6.32s\tremaining: 57.4ms\n",
      "991:\tlearn: 0.4578543\ttest: 0.5189467\tbest: 0.5179668 (341)\ttotal: 6.33s\tremaining: 51.1ms\n",
      "992:\tlearn: 0.4578543\ttest: 0.5189471\tbest: 0.5179668 (341)\ttotal: 6.34s\tremaining: 44.7ms\n",
      "993:\tlearn: 0.4578543\ttest: 0.5189471\tbest: 0.5179668 (341)\ttotal: 6.35s\tremaining: 38.3ms\n",
      "994:\tlearn: 0.4578543\ttest: 0.5189471\tbest: 0.5179668 (341)\ttotal: 6.35s\tremaining: 31.9ms\n",
      "995:\tlearn: 0.4578530\ttest: 0.5189448\tbest: 0.5179668 (341)\ttotal: 6.36s\tremaining: 25.5ms\n",
      "996:\tlearn: 0.4578530\ttest: 0.5189447\tbest: 0.5179668 (341)\ttotal: 6.36s\tremaining: 19.1ms\n",
      "997:\tlearn: 0.4578530\ttest: 0.5189448\tbest: 0.5179668 (341)\ttotal: 6.37s\tremaining: 12.8ms\n",
      "998:\tlearn: 0.4578515\ttest: 0.5189545\tbest: 0.5179668 (341)\ttotal: 6.38s\tremaining: 6.38ms\n",
      "999:\tlearn: 0.4578498\ttest: 0.5189629\tbest: 0.5179668 (341)\ttotal: 6.38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5179667595\n",
      "bestIteration = 341\n",
      "\n",
      "Shrink model to first 342 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f7f6c5ea690>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_catboost.fit(train_PYTORCH_Features, y_train_,eval_set=(eval_PYTORCH_Features, y_test_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "phantom-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get intermediate layer first from pytorch\n",
    "test_intermediate=test_data.X_data.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.layer_6.register_forward_hook(get_activation('layer_6'))\n",
    "output = model(test_intermediate)\n",
    "activation['layer_6']\n",
    "\n",
    "test_PYTORCH_Features = activation['layer_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "humanitarian-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_PYTORCH_Features=test_PYTORCH_Features.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "healthy-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of intermediate layer\n",
    "pred = model_catboost.predict_proba(test_PYTORCH_Features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "sought-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2738712 , 0.7261288 ],\n",
       "       [0.72080675, 0.27919325],\n",
       "       [0.24654621, 0.75345379],\n",
       "       ...,\n",
       "       [0.32154811, 0.67845189],\n",
       "       [0.37167184, 0.62832816],\n",
       "       [0.16078052, 0.83921948]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "beautiful-polish",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "imf82bbP4RJvb4IVIYql",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "preds= np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "advised-margin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "promotional-washer",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "V5TaJ9n7tWqjDI9NyVcG",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "preds=[\"TRUE\" if x==1 else 'FALSE' for x in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "opposite-orleans",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jhWGzj0sBu54vLay6S3n",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "other-agenda",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "5CFVhiwNNwGI3lhrVPXb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission['Labels']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "optional-indonesia",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "OdTRVCYV3TiqQ679hsKU",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "aSbfhd9TQR3FB9dBJksJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ids</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6992a84_2020-11-25_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e68e62f4_2020-11-29_20</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2e68e81a4_2020-11-27_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2e69eec04_2020-11-24_7</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2e698e4a4_2020-11-27_8</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2e68dd414_2020-11-26_5</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2e698541c_2020-11-24_22</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2e69e8e0c_2020-11-24_10</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2e699a1cc_2020-11-24_18</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2e698d804_2020-11-25_19</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Ids Labels\n",
       "0      2e6992a84_2020-11-25_18   TRUE\n",
       "1      2e68e62f4_2020-11-29_20  FALSE\n",
       "2      2e68e81a4_2020-11-27_10   TRUE\n",
       "3       2e69eec04_2020-11-24_7   TRUE\n",
       "4       2e698e4a4_2020-11-27_8  FALSE\n",
       "...                        ...    ...\n",
       "13836   2e68dd414_2020-11-26_5   TRUE\n",
       "13837  2e698541c_2020-11-24_22  FALSE\n",
       "13838  2e69e8e0c_2020-11-24_10   TRUE\n",
       "13839  2e699a1cc_2020-11-24_18   TRUE\n",
       "13840  2e698d804_2020-11-25_19   TRUE\n",
       "\n",
       "[13841 rows x 2 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "worthy-paradise",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jq3zH3Yvk7k0W3NUKXjb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission.to_csv('TORCH_TRANSFER_CATBOOST_4features.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-magic",
   "metadata": {},
   "source": [
    "# Hyper Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "killing-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "streaming-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"used_ram_limit\": \"5gb\",\n",
    "    }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    gbm = CatBoostClassifier(**param)\n",
    "\n",
    "    gbm.fit(train_PYTORCH_Features, y_train_,eval_set=(eval_PYTORCH_Features, y_test_), verbose=0, early_stopping_rounds=100)\n",
    "\n",
    "    preds = gbm.predict(eval_PYTORCH_Features)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(y_test_, pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "interracial-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:08:55,607]\u001b[0m A new study created in memory with name: no-name-cf5269fe-bca1-4eca-9f77-df9d3dc1f9e8\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:08:57,326]\u001b[0m Trial 0 finished with value: 0.7495794785534062 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07975931848299937, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8047179404095212}. Best is trial 0 with value: 0.7495794785534062.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:08:58,850]\u001b[0m Trial 1 finished with value: 0.7476170451359686 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.012514168602873497, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.7495794785534062.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.35GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:00,684]\u001b[0m Trial 2 finished with value: 0.749439304737875 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.045088144521224276, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4650913139190711}. Best is trial 0 with value: 0.7495794785534062.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:04,920]\u001b[0m Trial 3 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0878588702310883, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.7496495654611719.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:09:06,787]\u001b[0m Trial 4 finished with value: 0.7497897392767031 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09728092503803056, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.1608209938999297}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:09,779]\u001b[0m Trial 5 finished with value: 0.746215306980656 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.03684779632384889, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.4362695698209438}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.36GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:15,675]\u001b[0m Trial 6 finished with value: 0.7483880011213905 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.041731557064848386, 'depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7163983597951771}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:20,017]\u001b[0m Trial 7 finished with value: 0.7482478273058593 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.034002174415744706, 'depth': 2, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.950480966563822}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:21,115]\u001b[0m Trial 8 finished with value: 0.748668348752453 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.03707202892817402, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4268233050073643}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:21,722]\u001b[0m Trial 9 finished with value: 0.7477572189514998 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08837176142831515, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 5.044743221443827}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:22,742]\u001b[0m Trial 10 finished with value: 0.7492991309223437 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07206233369399635, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.12721374029030308}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:26,328]\u001b[0m Trial 11 finished with value: 0.7490888701990468 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0977242719647721, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.37GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:30,329]\u001b[0m Trial 12 finished with value: 0.7495794785534062 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09922172256918028, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:09:32,057]\u001b[0m Trial 13 finished with value: 0.7489486963835156 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06934224658251262, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:33,347]\u001b[0m Trial 14 finished with value: 0.748668348752453 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09990546470677818, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.772916968319393}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:35,778]\u001b[0m Trial 15 finished with value: 0.7493692178301093 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06028875832804771, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:38,839]\u001b[0m Trial 16 finished with value: 0.746986262966078 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08703542088178493, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.203611883705673}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:39,685]\u001b[0m Trial 17 finished with value: 0.7492991309223437 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08804056358319162, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:09:40,584]\u001b[0m Trial 18 finished with value: 0.7483880011213905 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.05757049746871269, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.656757031735324}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:44,168]\u001b[0m Trial 19 finished with value: 0.7497897392767031 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07864369820834084, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:45,956]\u001b[0m Trial 20 finished with value: 0.7483179142136249 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07538208825149374, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:49,119]\u001b[0m Trial 21 finished with value: 0.7492991309223437 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09276109255013269, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 0.7497897392767031.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:09:52,732]\u001b[0m Trial 22 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08126869273291329, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:09:57,009]\u001b[0m Trial 23 finished with value: 0.7490187832912812 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06432268664686813, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:01,222]\u001b[0m Trial 24 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07675269996085893, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:06,821]\u001b[0m Trial 25 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08134270552765585, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:11,587]\u001b[0m Trial 26 finished with value: 0.7497196523689375 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0804667199578326, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:12,814]\u001b[0m Trial 27 finished with value: 0.7471264367816092 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09368398388136374, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.868376988324445}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:10:15,686]\u001b[0m Trial 28 finished with value: 0.7469161760583123 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06621007737798196, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.411430791457775}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:20,673]\u001b[0m Trial 29 finished with value: 0.7490187832912812 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.05180773320538749, 'depth': 3, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:21,369]\u001b[0m Trial 30 finished with value: 0.7483179142136249 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08351441096511586, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.10398118052532102}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:24,747]\u001b[0m Trial 31 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0808571376731775, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:28,337]\u001b[0m Trial 32 finished with value: 0.7490187832912812 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09405868495514105, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:10:34,027]\u001b[0m Trial 33 finished with value: 0.748668348752453 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.021218886225170486, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:37,747]\u001b[0m Trial 34 finished with value: 0.7498598261844688 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07948764325302984, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:41,202]\u001b[0m Trial 35 finished with value: 0.749439304737875 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07247412055697582, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:44,645]\u001b[0m Trial 36 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08228857738411618, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 0.7502102607232969.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:47,442]\u001b[0m Trial 37 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08445348018951108, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:10:50,794]\u001b[0m Trial 38 finished with value: 0.749439304737875 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0860835001129319, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:54,476]\u001b[0m Trial 39 finished with value: 0.7477572189514998 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06481683681900471, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1084046034256253}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:10:59,097]\u001b[0m Trial 40 finished with value: 0.7484580880291561 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09162998096550874, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:04,164]\u001b[0m Trial 41 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08236061421334118, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:07,956]\u001b[0m Trial 42 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08379670922724869, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:11:14,615]\u001b[0m Trial 43 finished with value: 0.7497196523689375 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07336824363810629, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:17,568]\u001b[0m Trial 44 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08400621430292313, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:20,544]\u001b[0m Trial 45 finished with value: 0.7492991309223437 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08482380157405728, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:23,827]\u001b[0m Trial 46 finished with value: 0.7485982618446874 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09076277769765886, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.38GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:27,054]\u001b[0m Trial 47 finished with value: 0.7492290440145781 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07040678765217345, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9314902101084626}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:11:29,909]\u001b[0m Trial 48 finished with value: 0.7492290440145781 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09628042964658398, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:34,230]\u001b[0m Trial 49 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07580177084705594, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:38,221]\u001b[0m Trial 50 finished with value: 0.7492290440145781 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0896988510565739, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:41,178]\u001b[0m Trial 51 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08368397850969535, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:43,807]\u001b[0m Trial 52 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0839371871675919, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:11:46,745]\u001b[0m Trial 53 finished with value: 0.749439304737875 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08570418816888191, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:49,764]\u001b[0m Trial 54 finished with value: 0.7493692178301093 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09705875907738552, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:53,624]\u001b[0m Trial 55 finished with value: 0.7500700869077657 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06775362971804583, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:11:57,271]\u001b[0m Trial 56 finished with value: 0.7495093916456406 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08870539912220944, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:01,136]\u001b[0m Trial 57 finished with value: 0.7495093916456406 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07791642814232923, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:12:07,398]\u001b[0m Trial 58 finished with value: 0.7495794785534062 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07430375359717377, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:11,360]\u001b[0m Trial 59 finished with value: 0.7489486963835156 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08539581010388599, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:15,083]\u001b[0m Trial 60 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06130914268889548, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:20,125]\u001b[0m Trial 61 finished with value: 0.7498598261844688 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07952975027644386, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:24,474]\u001b[0m Trial 62 finished with value: 0.7495093916456406 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0886240732538969, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:12:27,482]\u001b[0m Trial 63 finished with value: 0.7499299130922343 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08298176452664854, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:33,088]\u001b[0m Trial 64 finished with value: 0.7495093916456406 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.04956625196434725, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:36,513]\u001b[0m Trial 65 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07714758870580193, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:39,791]\u001b[0m Trial 66 finished with value: 0.7471965236893748 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.06307214200672265, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.28191875531754285}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:42,974]\u001b[0m Trial 67 finished with value: 0.7491589571068125 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09513274747785737, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:12:45,841]\u001b[0m Trial 68 finished with value: 0.7497196523689375 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09968967516806239, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:47,698]\u001b[0m Trial 69 finished with value: 0.7481777403980936 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.043323220535446114, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:51,458]\u001b[0m Trial 70 finished with value: 0.7501401738155312 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07056471813702384, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:54,464]\u001b[0m Trial 71 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08121206806566263, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:12:57,086]\u001b[0m Trial 72 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0836103414450067, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:12:59,677]\u001b[0m Trial 73 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0842679866219315, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:02,645]\u001b[0m Trial 74 finished with value: 0.749439304737875 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08698836284448713, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:03,900]\u001b[0m Trial 75 finished with value: 0.748668348752453 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.09296460728103513, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:07,556]\u001b[0m Trial 76 finished with value: 0.7465657415194842 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08366199287893185, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.887505019048163}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:12,407]\u001b[0m Trial 77 finished with value: 0.7492290440145781 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0903904671556481, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:13:15,748]\u001b[0m Trial 78 finished with value: 0.7497897392767031 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07838722119188118, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:18,336]\u001b[0m Trial 79 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0832886107018087, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:22,876]\u001b[0m Trial 80 finished with value: 0.749439304737875 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0865279037459839, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:27,480]\u001b[0m Trial 81 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08132528027043315, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:30,306]\u001b[0m Trial 82 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08338411851495062, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:13:32,935]\u001b[0m Trial 83 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08439695111951726, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:35,958]\u001b[0m Trial 84 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08804200331157155, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:39,585]\u001b[0m Trial 85 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07560484266885317, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:41,026]\u001b[0m Trial 86 finished with value: 0.7489486963835156 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09189735359673168, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:44,323]\u001b[0m Trial 87 finished with value: 0.7492991309223437 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08462113543194316, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.976524672974241}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:13:49,873]\u001b[0m Trial 88 finished with value: 0.748668348752453 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.029504364086705002, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:51,191]\u001b[0m Trial 89 finished with value: 0.7485281749369218 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07912177975848661, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:55,756]\u001b[0m Trial 90 finished with value: 0.7448836557331091 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0901292325997772, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.9476040229734615}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:13:59,400]\u001b[0m Trial 91 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08419164541551968, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:14:01,998]\u001b[0m Trial 92 finished with value: 0.7502803476310625 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08394549838614608, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:14:04,939]\u001b[0m Trial 93 finished with value: 0.749439304737875 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08689896645181745, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:14:07,907]\u001b[0m Trial 94 finished with value: 0.7502102607232969 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08239320187133199, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:14:11,373]\u001b[0m Trial 95 finished with value: 0.7497196523689375 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07316453366152803, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:14:14,818]\u001b[0m Trial 96 finished with value: 0.7496495654611719 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07702885070234607, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:14:20,176]\u001b[0m Trial 97 finished with value: 0.7498598261844688 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.07979809466083865, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-19 21:14:24,307]\u001b[0m Trial 98 finished with value: 0.7495093916456406 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08861607976942863, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(321920) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(57068) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14272) > ResourceQuota(0)\n",
      "CatBoost is using more CPU RAM (6.39GiB) than the limit (5GiB)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "Resource CPU RAM: functionWithResourceUsage.ResourceUsage(14268) > ResourceQuota(0)\n",
      "\u001b[32m[I 2021-03-19 21:14:27,104]\u001b[0m Trial 99 finished with value: 0.7489486963835156 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08516798526325142, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 37 with value: 0.7502803476310625.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "canadian-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.7502803476310625\n",
      "  Params: \n",
      "    objective: CrossEntropy\n",
      "    colsample_bylevel: 0.08445348018951108\n",
      "    depth: 7\n",
      "    boosting_type: Ordered\n",
      "    bootstrap_type: MVS\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "consolidated-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'CrossEntropy',\n",
       " 'colsample_bylevel': 0.08445348018951108,\n",
       " 'depth': 7,\n",
       " 'boosting_type': 'Ordered',\n",
       " 'bootstrap_type': 'MVS'}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "romantic-movement",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-5fb9830a69b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(X_train_)):\n",
    "    x_tr = x_train.loc[train_index]\n",
    "    y_tr = y_train.loc[train_index]\n",
    "    x_te = x_train.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "sorted-bernard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64557</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.288459</td>\n",
       "      <td>106.952093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16662</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.193291</td>\n",
       "      <td>106.972755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62922</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.956332</td>\n",
       "      <td>107.581583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.906395</td>\n",
       "      <td>107.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17177</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.276950</td>\n",
       "      <td>106.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21762</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.404998</td>\n",
       "      <td>106.757375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64388</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.898450</td>\n",
       "      <td>107.614134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69948</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.428860</td>\n",
       "      <td>106.733784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28491</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.888380</td>\n",
       "      <td>107.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32161</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.263309</td>\n",
       "      <td>107.017036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57068 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour  day  latitude   longitude\n",
       "64557    15    0 -6.288459  106.952093\n",
       "16662    22    0 -6.193291  106.972755\n",
       "62922    10    6 -6.956332  107.581583\n",
       "6597     21    2 -6.906395  107.608215\n",
       "17177    12    6 -6.276950  106.913727\n",
       "...     ...  ...       ...         ...\n",
       "21762    10    0 -6.404998  106.757375\n",
       "64388    14    0 -6.898450  107.614134\n",
       "69948    16    4 -6.428860  106.733784\n",
       "28491     9    5 -6.888380  107.608215\n",
       "32161    17    0 -6.263309  107.017036\n",
       "\n",
       "[57068 rows x 4 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-geology",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "historical-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59682 entries, 0 to 59681\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   road_type      59682 non-null  int64  \n",
      " 1   street         59682 non-null  int64  \n",
      " 2   city           59682 non-null  int64  \n",
      " 3   reliability    59682 non-null  float64\n",
      " 4   report_rating  59682 non-null  float64\n",
      " 5   confidence     59682 non-null  float64\n",
      " 6   type           59682 non-null  int64  \n",
      " 7   subtype        59682 non-null  int64  \n",
      " 8   longitude      59682 non-null  float64\n",
      " 9   latitude       59682 non-null  float64\n",
      " 10  hour           59682 non-null  int64  \n",
      " 11  day            59682 non-null  int64  \n",
      "dtypes: float64(5), int64(7)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "all_train_data=pd.read_csv('Datasets_Merge/Normalized/train_data_meta_norm.csv')\n",
    "all_train_data=all_train_data.drop(columns=['Unnamed: 0'])\n",
    "all_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "fatty-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59682 entries, 0 to 59681\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Labels  59682 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 466.4 KB\n"
     ]
    }
   ],
   "source": [
    "y_train_all=pd.read_csv('Datasets_Merge/Normalized/label_meta.csv')\n",
    "y_train_all=y_train_all.drop(columns=['Unnamed: 0'])\n",
    "y_train_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "polished-prairie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13841 entries, 0 to 13840\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   road_type      13841 non-null  int64  \n",
      " 1   street         13841 non-null  int64  \n",
      " 2   city           13841 non-null  int64  \n",
      " 3   reliability    13841 non-null  float64\n",
      " 4   report_rating  13841 non-null  float64\n",
      " 5   confidence     13841 non-null  float64\n",
      " 6   type           13841 non-null  int64  \n",
      " 7   subtype        13841 non-null  int64  \n",
      " 8   longitude      13841 non-null  float64\n",
      " 9   latitude       13841 non-null  float64\n",
      " 10  hour           13841 non-null  int64  \n",
      " 11  day            13841 non-null  int64  \n",
      "dtypes: float64(5), int64(7)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "all_test_data=pd.read_csv('Datasets_Merge/Normalized/test_data_norm.csv')\n",
    "all_test_data=all_test_data.drop(columns=['Unnamed: 0'])\n",
    "all_test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "specialized-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Starter based on Allstate Faron's Script\n",
    "#https://www.kaggle.com/mmueller/allstate-claims-severity/stacking-starter/run/390867\n",
    "# Preprocessing from ogrellier\n",
    "#https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import sqrt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import gc\n",
    "\n",
    "NFOLDS = 3\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "\n",
    "\n",
    "ntrain = all_train_data.shape[0]\n",
    "ntest = all_test_data.shape[0]\n",
    "\n",
    "# excluded_feats = ['SK_ID_CURR']\n",
    "features = np.where(all_train_data.dtypes != float)[0]\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "honey-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:33:16] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:33:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:33:17] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:33:17] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:33:19] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:33:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 8.08ms\tremaining: 1.61s\n",
      "1:\ttotal: 18.5ms\tremaining: 1.83s\n",
      "2:\ttotal: 27.2ms\tremaining: 1.78s\n",
      "3:\ttotal: 36.1ms\tremaining: 1.77s\n",
      "4:\ttotal: 45.8ms\tremaining: 1.79s\n",
      "5:\ttotal: 57.2ms\tremaining: 1.85s\n",
      "6:\ttotal: 69.3ms\tremaining: 1.91s\n",
      "7:\ttotal: 82.6ms\tremaining: 1.98s\n",
      "8:\ttotal: 95.1ms\tremaining: 2.02s\n",
      "9:\ttotal: 105ms\tremaining: 2s\n",
      "10:\ttotal: 114ms\tremaining: 1.96s\n",
      "11:\ttotal: 125ms\tremaining: 1.95s\n",
      "12:\ttotal: 135ms\tremaining: 1.94s\n",
      "13:\ttotal: 144ms\tremaining: 1.91s\n",
      "14:\ttotal: 149ms\tremaining: 1.83s\n",
      "15:\ttotal: 155ms\tremaining: 1.78s\n",
      "16:\ttotal: 159ms\tremaining: 1.71s\n",
      "17:\ttotal: 163ms\tremaining: 1.65s\n",
      "18:\ttotal: 171ms\tremaining: 1.62s\n",
      "19:\ttotal: 174ms\tremaining: 1.57s\n",
      "20:\ttotal: 178ms\tremaining: 1.51s\n",
      "21:\ttotal: 182ms\tremaining: 1.47s\n",
      "22:\ttotal: 185ms\tremaining: 1.43s\n",
      "23:\ttotal: 188ms\tremaining: 1.38s\n",
      "24:\ttotal: 192ms\tremaining: 1.34s\n",
      "25:\ttotal: 196ms\tremaining: 1.31s\n",
      "26:\ttotal: 199ms\tremaining: 1.28s\n",
      "27:\ttotal: 203ms\tremaining: 1.25s\n",
      "28:\ttotal: 206ms\tremaining: 1.22s\n",
      "29:\ttotal: 211ms\tremaining: 1.19s\n",
      "30:\ttotal: 214ms\tremaining: 1.16s\n",
      "31:\ttotal: 216ms\tremaining: 1.14s\n",
      "32:\ttotal: 220ms\tremaining: 1.11s\n",
      "33:\ttotal: 223ms\tremaining: 1.09s\n",
      "34:\ttotal: 226ms\tremaining: 1.06s\n",
      "35:\ttotal: 228ms\tremaining: 1.04s\n",
      "36:\ttotal: 239ms\tremaining: 1.05s\n",
      "37:\ttotal: 247ms\tremaining: 1.05s\n",
      "38:\ttotal: 254ms\tremaining: 1.05s\n",
      "39:\ttotal: 262ms\tremaining: 1.05s\n",
      "40:\ttotal: 270ms\tremaining: 1.04s\n",
      "41:\ttotal: 279ms\tremaining: 1.05s\n",
      "42:\ttotal: 289ms\tremaining: 1.05s\n",
      "43:\ttotal: 293ms\tremaining: 1.04s\n",
      "44:\ttotal: 296ms\tremaining: 1.02s\n",
      "45:\ttotal: 307ms\tremaining: 1.03s\n",
      "46:\ttotal: 311ms\tremaining: 1.01s\n",
      "47:\ttotal: 314ms\tremaining: 995ms\n",
      "48:\ttotal: 317ms\tremaining: 977ms\n",
      "49:\ttotal: 320ms\tremaining: 959ms\n",
      "50:\ttotal: 323ms\tremaining: 944ms\n",
      "51:\ttotal: 327ms\tremaining: 930ms\n",
      "52:\ttotal: 330ms\tremaining: 916ms\n",
      "53:\ttotal: 333ms\tremaining: 901ms\n",
      "54:\ttotal: 337ms\tremaining: 887ms\n",
      "55:\ttotal: 342ms\tremaining: 879ms\n",
      "56:\ttotal: 346ms\tremaining: 868ms\n",
      "57:\ttotal: 353ms\tremaining: 864ms\n",
      "58:\ttotal: 359ms\tremaining: 857ms\n",
      "59:\ttotal: 362ms\tremaining: 846ms\n",
      "60:\ttotal: 370ms\tremaining: 842ms\n",
      "61:\ttotal: 373ms\tremaining: 831ms\n",
      "62:\ttotal: 377ms\tremaining: 819ms\n",
      "63:\ttotal: 381ms\tremaining: 810ms\n",
      "64:\ttotal: 387ms\tremaining: 803ms\n",
      "65:\ttotal: 390ms\tremaining: 792ms\n",
      "66:\ttotal: 394ms\tremaining: 782ms\n",
      "67:\ttotal: 397ms\tremaining: 770ms\n",
      "68:\ttotal: 400ms\tremaining: 760ms\n",
      "69:\ttotal: 404ms\tremaining: 750ms\n",
      "70:\ttotal: 407ms\tremaining: 740ms\n",
      "71:\ttotal: 414ms\tremaining: 736ms\n",
      "72:\ttotal: 422ms\tremaining: 735ms\n",
      "73:\ttotal: 431ms\tremaining: 735ms\n",
      "74:\ttotal: 439ms\tremaining: 732ms\n",
      "75:\ttotal: 447ms\tremaining: 729ms\n",
      "76:\ttotal: 455ms\tremaining: 727ms\n",
      "77:\ttotal: 462ms\tremaining: 723ms\n",
      "78:\ttotal: 472ms\tremaining: 723ms\n",
      "79:\ttotal: 481ms\tremaining: 722ms\n",
      "80:\ttotal: 490ms\tremaining: 719ms\n",
      "81:\ttotal: 498ms\tremaining: 716ms\n",
      "82:\ttotal: 506ms\tremaining: 714ms\n",
      "83:\ttotal: 518ms\tremaining: 716ms\n",
      "84:\ttotal: 524ms\tremaining: 709ms\n",
      "85:\ttotal: 532ms\tremaining: 705ms\n",
      "86:\ttotal: 535ms\tremaining: 694ms\n",
      "87:\ttotal: 538ms\tremaining: 685ms\n",
      "88:\ttotal: 542ms\tremaining: 676ms\n",
      "89:\ttotal: 545ms\tremaining: 667ms\n",
      "90:\ttotal: 549ms\tremaining: 658ms\n",
      "91:\ttotal: 552ms\tremaining: 649ms\n",
      "92:\ttotal: 555ms\tremaining: 638ms\n",
      "93:\ttotal: 559ms\tremaining: 630ms\n",
      "94:\ttotal: 562ms\tremaining: 621ms\n",
      "95:\ttotal: 566ms\tremaining: 613ms\n",
      "96:\ttotal: 569ms\tremaining: 604ms\n",
      "97:\ttotal: 573ms\tremaining: 596ms\n",
      "98:\ttotal: 576ms\tremaining: 588ms\n",
      "99:\ttotal: 583ms\tremaining: 583ms\n",
      "100:\ttotal: 587ms\tremaining: 575ms\n",
      "101:\ttotal: 590ms\tremaining: 567ms\n",
      "102:\ttotal: 593ms\tremaining: 558ms\n",
      "103:\ttotal: 596ms\tremaining: 551ms\n",
      "104:\ttotal: 600ms\tremaining: 543ms\n",
      "105:\ttotal: 604ms\tremaining: 535ms\n",
      "106:\ttotal: 607ms\tremaining: 528ms\n",
      "107:\ttotal: 611ms\tremaining: 520ms\n",
      "108:\ttotal: 616ms\tremaining: 514ms\n",
      "109:\ttotal: 619ms\tremaining: 506ms\n",
      "110:\ttotal: 622ms\tremaining: 499ms\n",
      "111:\ttotal: 626ms\tremaining: 492ms\n",
      "112:\ttotal: 630ms\tremaining: 485ms\n",
      "113:\ttotal: 637ms\tremaining: 481ms\n",
      "114:\ttotal: 643ms\tremaining: 476ms\n",
      "115:\ttotal: 648ms\tremaining: 469ms\n",
      "116:\ttotal: 651ms\tremaining: 462ms\n",
      "117:\ttotal: 655ms\tremaining: 455ms\n",
      "118:\ttotal: 658ms\tremaining: 448ms\n",
      "119:\ttotal: 662ms\tremaining: 441ms\n",
      "120:\ttotal: 665ms\tremaining: 434ms\n",
      "121:\ttotal: 669ms\tremaining: 428ms\n",
      "122:\ttotal: 673ms\tremaining: 421ms\n",
      "123:\ttotal: 675ms\tremaining: 414ms\n",
      "124:\ttotal: 679ms\tremaining: 407ms\n",
      "125:\ttotal: 682ms\tremaining: 401ms\n",
      "126:\ttotal: 686ms\tremaining: 394ms\n",
      "127:\ttotal: 690ms\tremaining: 388ms\n",
      "128:\ttotal: 693ms\tremaining: 382ms\n",
      "129:\ttotal: 697ms\tremaining: 375ms\n",
      "130:\ttotal: 700ms\tremaining: 369ms\n",
      "131:\ttotal: 704ms\tremaining: 363ms\n",
      "132:\ttotal: 707ms\tremaining: 356ms\n",
      "133:\ttotal: 711ms\tremaining: 350ms\n",
      "134:\ttotal: 715ms\tremaining: 344ms\n",
      "135:\ttotal: 718ms\tremaining: 338ms\n",
      "136:\ttotal: 721ms\tremaining: 332ms\n",
      "137:\ttotal: 725ms\tremaining: 326ms\n",
      "138:\ttotal: 727ms\tremaining: 319ms\n",
      "139:\ttotal: 730ms\tremaining: 313ms\n",
      "140:\ttotal: 734ms\tremaining: 307ms\n",
      "141:\ttotal: 738ms\tremaining: 301ms\n",
      "142:\ttotal: 741ms\tremaining: 295ms\n",
      "143:\ttotal: 745ms\tremaining: 290ms\n",
      "144:\ttotal: 748ms\tremaining: 284ms\n",
      "145:\ttotal: 752ms\tremaining: 278ms\n",
      "146:\ttotal: 755ms\tremaining: 272ms\n",
      "147:\ttotal: 759ms\tremaining: 267ms\n",
      "148:\ttotal: 761ms\tremaining: 261ms\n",
      "149:\ttotal: 765ms\tremaining: 255ms\n",
      "150:\ttotal: 769ms\tremaining: 249ms\n",
      "151:\ttotal: 772ms\tremaining: 244ms\n",
      "152:\ttotal: 776ms\tremaining: 238ms\n",
      "153:\ttotal: 778ms\tremaining: 232ms\n",
      "154:\ttotal: 783ms\tremaining: 227ms\n",
      "155:\ttotal: 786ms\tremaining: 222ms\n",
      "156:\ttotal: 790ms\tremaining: 216ms\n",
      "157:\ttotal: 793ms\tremaining: 211ms\n",
      "158:\ttotal: 796ms\tremaining: 205ms\n",
      "159:\ttotal: 799ms\tremaining: 200ms\n",
      "160:\ttotal: 803ms\tremaining: 195ms\n",
      "161:\ttotal: 807ms\tremaining: 189ms\n",
      "162:\ttotal: 810ms\tremaining: 184ms\n",
      "163:\ttotal: 813ms\tremaining: 178ms\n",
      "164:\ttotal: 818ms\tremaining: 173ms\n",
      "165:\ttotal: 821ms\tremaining: 168ms\n",
      "166:\ttotal: 825ms\tremaining: 163ms\n",
      "167:\ttotal: 827ms\tremaining: 158ms\n",
      "168:\ttotal: 831ms\tremaining: 152ms\n",
      "169:\ttotal: 835ms\tremaining: 147ms\n",
      "170:\ttotal: 839ms\tremaining: 142ms\n",
      "171:\ttotal: 843ms\tremaining: 137ms\n",
      "172:\ttotal: 846ms\tremaining: 132ms\n",
      "173:\ttotal: 859ms\tremaining: 128ms\n",
      "174:\ttotal: 867ms\tremaining: 124ms\n",
      "175:\ttotal: 873ms\tremaining: 119ms\n",
      "176:\ttotal: 875ms\tremaining: 114ms\n",
      "177:\ttotal: 879ms\tremaining: 109ms\n",
      "178:\ttotal: 881ms\tremaining: 103ms\n",
      "179:\ttotal: 885ms\tremaining: 98.3ms\n",
      "180:\ttotal: 887ms\tremaining: 93.1ms\n",
      "181:\ttotal: 890ms\tremaining: 88ms\n",
      "182:\ttotal: 899ms\tremaining: 83.5ms\n",
      "183:\ttotal: 903ms\tremaining: 78.5ms\n",
      "184:\ttotal: 906ms\tremaining: 73.5ms\n",
      "185:\ttotal: 910ms\tremaining: 68.5ms\n",
      "186:\ttotal: 913ms\tremaining: 63.5ms\n",
      "187:\ttotal: 916ms\tremaining: 58.5ms\n",
      "188:\ttotal: 919ms\tremaining: 53.5ms\n",
      "189:\ttotal: 922ms\tremaining: 48.5ms\n",
      "190:\ttotal: 925ms\tremaining: 43.6ms\n",
      "191:\ttotal: 927ms\tremaining: 38.6ms\n",
      "192:\ttotal: 931ms\tremaining: 33.8ms\n",
      "193:\ttotal: 934ms\tremaining: 28.9ms\n",
      "194:\ttotal: 937ms\tremaining: 24ms\n",
      "195:\ttotal: 939ms\tremaining: 19.2ms\n",
      "196:\ttotal: 943ms\tremaining: 14.4ms\n",
      "197:\ttotal: 946ms\tremaining: 9.56ms\n",
      "198:\ttotal: 950ms\tremaining: 4.77ms\n",
      "199:\ttotal: 952ms\tremaining: 0us\n",
      "0:\ttotal: 3.61ms\tremaining: 719ms\n",
      "1:\ttotal: 6.71ms\tremaining: 665ms\n",
      "2:\ttotal: 9.97ms\tremaining: 655ms\n",
      "3:\ttotal: 13.1ms\tremaining: 642ms\n",
      "4:\ttotal: 15.8ms\tremaining: 616ms\n",
      "5:\ttotal: 19.4ms\tremaining: 627ms\n",
      "6:\ttotal: 23ms\tremaining: 634ms\n",
      "7:\ttotal: 25.8ms\tremaining: 618ms\n",
      "8:\ttotal: 28.6ms\tremaining: 606ms\n",
      "9:\ttotal: 32.1ms\tremaining: 610ms\n",
      "10:\ttotal: 35.2ms\tremaining: 605ms\n",
      "11:\ttotal: 39.6ms\tremaining: 621ms\n",
      "12:\ttotal: 44.8ms\tremaining: 644ms\n",
      "13:\ttotal: 48.3ms\tremaining: 641ms\n",
      "14:\ttotal: 51.2ms\tremaining: 631ms\n",
      "15:\ttotal: 59.2ms\tremaining: 681ms\n",
      "16:\ttotal: 66.8ms\tremaining: 719ms\n",
      "17:\ttotal: 75.5ms\tremaining: 763ms\n",
      "18:\ttotal: 84.9ms\tremaining: 809ms\n",
      "19:\ttotal: 93.9ms\tremaining: 845ms\n",
      "20:\ttotal: 103ms\tremaining: 878ms\n",
      "21:\ttotal: 112ms\tremaining: 910ms\n",
      "22:\ttotal: 128ms\tremaining: 988ms\n",
      "23:\ttotal: 136ms\tremaining: 1000ms\n",
      "24:\ttotal: 144ms\tremaining: 1.01s\n",
      "25:\ttotal: 154ms\tremaining: 1.03s\n",
      "26:\ttotal: 163ms\tremaining: 1.04s\n",
      "27:\ttotal: 173ms\tremaining: 1.06s\n",
      "28:\ttotal: 182ms\tremaining: 1.07s\n",
      "29:\ttotal: 193ms\tremaining: 1.09s\n",
      "30:\ttotal: 205ms\tremaining: 1.11s\n",
      "31:\ttotal: 214ms\tremaining: 1.12s\n",
      "32:\ttotal: 224ms\tremaining: 1.13s\n",
      "33:\ttotal: 233ms\tremaining: 1.14s\n",
      "34:\ttotal: 243ms\tremaining: 1.14s\n",
      "35:\ttotal: 251ms\tremaining: 1.14s\n",
      "36:\ttotal: 264ms\tremaining: 1.16s\n",
      "37:\ttotal: 271ms\tremaining: 1.16s\n",
      "38:\ttotal: 279ms\tremaining: 1.15s\n",
      "39:\ttotal: 289ms\tremaining: 1.16s\n",
      "40:\ttotal: 298ms\tremaining: 1.15s\n",
      "41:\ttotal: 307ms\tremaining: 1.16s\n",
      "42:\ttotal: 316ms\tremaining: 1.15s\n",
      "43:\ttotal: 325ms\tremaining: 1.15s\n",
      "44:\ttotal: 334ms\tremaining: 1.15s\n",
      "45:\ttotal: 344ms\tremaining: 1.15s\n",
      "46:\ttotal: 353ms\tremaining: 1.15s\n",
      "47:\ttotal: 356ms\tremaining: 1.13s\n",
      "48:\ttotal: 360ms\tremaining: 1.11s\n",
      "49:\ttotal: 364ms\tremaining: 1.09s\n",
      "50:\ttotal: 368ms\tremaining: 1.07s\n",
      "51:\ttotal: 373ms\tremaining: 1.06s\n",
      "52:\ttotal: 377ms\tremaining: 1.05s\n",
      "53:\ttotal: 384ms\tremaining: 1.04s\n",
      "54:\ttotal: 388ms\tremaining: 1.02s\n",
      "55:\ttotal: 391ms\tremaining: 1.01s\n",
      "56:\ttotal: 395ms\tremaining: 991ms\n",
      "57:\ttotal: 404ms\tremaining: 990ms\n",
      "58:\ttotal: 408ms\tremaining: 975ms\n",
      "59:\ttotal: 412ms\tremaining: 961ms\n",
      "60:\ttotal: 420ms\tremaining: 957ms\n",
      "61:\ttotal: 424ms\tremaining: 943ms\n",
      "62:\ttotal: 427ms\tremaining: 929ms\n",
      "63:\ttotal: 431ms\tremaining: 916ms\n",
      "64:\ttotal: 435ms\tremaining: 903ms\n",
      "65:\ttotal: 439ms\tremaining: 892ms\n",
      "66:\ttotal: 447ms\tremaining: 888ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67:\ttotal: 456ms\tremaining: 886ms\n",
      "68:\ttotal: 462ms\tremaining: 877ms\n",
      "69:\ttotal: 470ms\tremaining: 874ms\n",
      "70:\ttotal: 479ms\tremaining: 870ms\n",
      "71:\ttotal: 487ms\tremaining: 866ms\n",
      "72:\ttotal: 496ms\tremaining: 863ms\n",
      "73:\ttotal: 506ms\tremaining: 862ms\n",
      "74:\ttotal: 515ms\tremaining: 858ms\n",
      "75:\ttotal: 523ms\tremaining: 854ms\n",
      "76:\ttotal: 532ms\tremaining: 850ms\n",
      "77:\ttotal: 550ms\tremaining: 860ms\n",
      "78:\ttotal: 557ms\tremaining: 853ms\n",
      "79:\ttotal: 565ms\tremaining: 847ms\n",
      "80:\ttotal: 573ms\tremaining: 842ms\n",
      "81:\ttotal: 582ms\tremaining: 838ms\n",
      "82:\ttotal: 591ms\tremaining: 833ms\n",
      "83:\ttotal: 600ms\tremaining: 828ms\n",
      "84:\ttotal: 606ms\tremaining: 820ms\n",
      "85:\ttotal: 615ms\tremaining: 815ms\n",
      "86:\ttotal: 623ms\tremaining: 809ms\n",
      "87:\ttotal: 631ms\tremaining: 803ms\n",
      "88:\ttotal: 639ms\tremaining: 797ms\n",
      "89:\ttotal: 650ms\tremaining: 794ms\n",
      "90:\ttotal: 658ms\tremaining: 788ms\n",
      "91:\ttotal: 666ms\tremaining: 782ms\n",
      "92:\ttotal: 674ms\tremaining: 775ms\n",
      "93:\ttotal: 687ms\tremaining: 774ms\n",
      "94:\ttotal: 695ms\tremaining: 768ms\n",
      "95:\ttotal: 703ms\tremaining: 762ms\n",
      "96:\ttotal: 710ms\tremaining: 754ms\n",
      "97:\ttotal: 720ms\tremaining: 749ms\n",
      "98:\ttotal: 729ms\tremaining: 743ms\n",
      "99:\ttotal: 737ms\tremaining: 737ms\n",
      "100:\ttotal: 745ms\tremaining: 731ms\n",
      "101:\ttotal: 752ms\tremaining: 722ms\n",
      "102:\ttotal: 762ms\tremaining: 718ms\n",
      "103:\ttotal: 771ms\tremaining: 712ms\n",
      "104:\ttotal: 779ms\tremaining: 705ms\n",
      "105:\ttotal: 787ms\tremaining: 698ms\n",
      "106:\ttotal: 800ms\tremaining: 695ms\n",
      "107:\ttotal: 809ms\tremaining: 689ms\n",
      "108:\ttotal: 818ms\tremaining: 683ms\n",
      "109:\ttotal: 827ms\tremaining: 676ms\n",
      "110:\ttotal: 839ms\tremaining: 673ms\n",
      "111:\ttotal: 843ms\tremaining: 662ms\n",
      "112:\ttotal: 846ms\tremaining: 652ms\n",
      "113:\ttotal: 850ms\tremaining: 641ms\n",
      "114:\ttotal: 853ms\tremaining: 631ms\n",
      "115:\ttotal: 857ms\tremaining: 621ms\n",
      "116:\ttotal: 861ms\tremaining: 611ms\n",
      "117:\ttotal: 864ms\tremaining: 601ms\n",
      "118:\ttotal: 868ms\tremaining: 591ms\n",
      "119:\ttotal: 872ms\tremaining: 581ms\n",
      "120:\ttotal: 876ms\tremaining: 572ms\n",
      "121:\ttotal: 880ms\tremaining: 562ms\n",
      "122:\ttotal: 883ms\tremaining: 553ms\n",
      "123:\ttotal: 887ms\tremaining: 544ms\n",
      "124:\ttotal: 891ms\tremaining: 534ms\n",
      "125:\ttotal: 894ms\tremaining: 525ms\n",
      "126:\ttotal: 897ms\tremaining: 516ms\n",
      "127:\ttotal: 901ms\tremaining: 507ms\n",
      "128:\ttotal: 905ms\tremaining: 498ms\n",
      "129:\ttotal: 909ms\tremaining: 490ms\n",
      "130:\ttotal: 914ms\tremaining: 481ms\n",
      "131:\ttotal: 918ms\tremaining: 473ms\n",
      "132:\ttotal: 921ms\tremaining: 464ms\n",
      "133:\ttotal: 925ms\tremaining: 456ms\n",
      "134:\ttotal: 928ms\tremaining: 447ms\n",
      "135:\ttotal: 932ms\tremaining: 438ms\n",
      "136:\ttotal: 935ms\tremaining: 430ms\n",
      "137:\ttotal: 939ms\tremaining: 422ms\n",
      "138:\ttotal: 943ms\tremaining: 414ms\n",
      "139:\ttotal: 945ms\tremaining: 405ms\n",
      "140:\ttotal: 949ms\tremaining: 397ms\n",
      "141:\ttotal: 953ms\tremaining: 389ms\n",
      "142:\ttotal: 956ms\tremaining: 381ms\n",
      "143:\ttotal: 960ms\tremaining: 373ms\n",
      "144:\ttotal: 964ms\tremaining: 366ms\n",
      "145:\ttotal: 967ms\tremaining: 358ms\n",
      "146:\ttotal: 971ms\tremaining: 350ms\n",
      "147:\ttotal: 974ms\tremaining: 342ms\n",
      "148:\ttotal: 977ms\tremaining: 335ms\n",
      "149:\ttotal: 980ms\tremaining: 327ms\n",
      "150:\ttotal: 984ms\tremaining: 319ms\n",
      "151:\ttotal: 987ms\tremaining: 312ms\n",
      "152:\ttotal: 991ms\tremaining: 304ms\n",
      "153:\ttotal: 994ms\tremaining: 297ms\n",
      "154:\ttotal: 998ms\tremaining: 290ms\n",
      "155:\ttotal: 1s\tremaining: 283ms\n",
      "156:\ttotal: 1s\tremaining: 275ms\n",
      "157:\ttotal: 1.01s\tremaining: 268ms\n",
      "158:\ttotal: 1.01s\tremaining: 261ms\n",
      "159:\ttotal: 1.02s\tremaining: 254ms\n",
      "160:\ttotal: 1.02s\tremaining: 247ms\n",
      "161:\ttotal: 1.02s\tremaining: 240ms\n",
      "162:\ttotal: 1.02s\tremaining: 233ms\n",
      "163:\ttotal: 1.03s\tremaining: 226ms\n",
      "164:\ttotal: 1.03s\tremaining: 219ms\n",
      "165:\ttotal: 1.04s\tremaining: 212ms\n",
      "166:\ttotal: 1.04s\tremaining: 206ms\n",
      "167:\ttotal: 1.04s\tremaining: 199ms\n",
      "168:\ttotal: 1.05s\tremaining: 192ms\n",
      "169:\ttotal: 1.05s\tremaining: 185ms\n",
      "170:\ttotal: 1.05s\tremaining: 179ms\n",
      "171:\ttotal: 1.06s\tremaining: 172ms\n",
      "172:\ttotal: 1.06s\tremaining: 165ms\n",
      "173:\ttotal: 1.06s\tremaining: 159ms\n",
      "174:\ttotal: 1.06s\tremaining: 152ms\n",
      "175:\ttotal: 1.07s\tremaining: 146ms\n",
      "176:\ttotal: 1.07s\tremaining: 139ms\n",
      "177:\ttotal: 1.07s\tremaining: 133ms\n",
      "178:\ttotal: 1.08s\tremaining: 126ms\n",
      "179:\ttotal: 1.08s\tremaining: 120ms\n",
      "180:\ttotal: 1.08s\tremaining: 114ms\n",
      "181:\ttotal: 1.09s\tremaining: 107ms\n",
      "182:\ttotal: 1.1s\tremaining: 102ms\n",
      "183:\ttotal: 1.1s\tremaining: 95.6ms\n",
      "184:\ttotal: 1.1s\tremaining: 89.5ms\n",
      "185:\ttotal: 1.11s\tremaining: 83.4ms\n",
      "186:\ttotal: 1.11s\tremaining: 77.3ms\n",
      "187:\ttotal: 1.11s\tremaining: 71.1ms\n",
      "188:\ttotal: 1.12s\tremaining: 65ms\n",
      "189:\ttotal: 1.12s\tremaining: 59ms\n",
      "190:\ttotal: 1.13s\tremaining: 53.2ms\n",
      "191:\ttotal: 1.14s\tremaining: 47.4ms\n",
      "192:\ttotal: 1.15s\tremaining: 41.6ms\n",
      "193:\ttotal: 1.16s\tremaining: 35.8ms\n",
      "194:\ttotal: 1.17s\tremaining: 29.9ms\n",
      "195:\ttotal: 1.17s\tremaining: 23.9ms\n",
      "196:\ttotal: 1.18s\tremaining: 18ms\n",
      "197:\ttotal: 1.19s\tremaining: 12.1ms\n",
      "198:\ttotal: 1.2s\tremaining: 6.04ms\n",
      "199:\ttotal: 1.21s\tremaining: 0us\n",
      "0:\ttotal: 4.2ms\tremaining: 835ms\n",
      "1:\ttotal: 12.3ms\tremaining: 1.22s\n",
      "2:\ttotal: 20.9ms\tremaining: 1.37s\n",
      "3:\ttotal: 31.5ms\tremaining: 1.54s\n",
      "4:\ttotal: 40.2ms\tremaining: 1.57s\n",
      "5:\ttotal: 47.6ms\tremaining: 1.54s\n",
      "6:\ttotal: 58.3ms\tremaining: 1.61s\n",
      "7:\ttotal: 65.3ms\tremaining: 1.57s\n",
      "8:\ttotal: 74.3ms\tremaining: 1.57s\n",
      "9:\ttotal: 81.4ms\tremaining: 1.55s\n",
      "10:\ttotal: 89.7ms\tremaining: 1.54s\n",
      "11:\ttotal: 103ms\tremaining: 1.61s\n",
      "12:\ttotal: 112ms\tremaining: 1.61s\n",
      "13:\ttotal: 120ms\tremaining: 1.6s\n",
      "14:\ttotal: 128ms\tremaining: 1.57s\n",
      "15:\ttotal: 138ms\tremaining: 1.59s\n",
      "16:\ttotal: 147ms\tremaining: 1.58s\n",
      "17:\ttotal: 156ms\tremaining: 1.58s\n",
      "18:\ttotal: 165ms\tremaining: 1.57s\n",
      "19:\ttotal: 177ms\tremaining: 1.59s\n",
      "20:\ttotal: 185ms\tremaining: 1.57s\n",
      "21:\ttotal: 194ms\tremaining: 1.57s\n",
      "22:\ttotal: 203ms\tremaining: 1.56s\n",
      "23:\ttotal: 214ms\tremaining: 1.57s\n",
      "24:\ttotal: 222ms\tremaining: 1.55s\n",
      "25:\ttotal: 228ms\tremaining: 1.53s\n",
      "26:\ttotal: 233ms\tremaining: 1.49s\n",
      "27:\ttotal: 238ms\tremaining: 1.46s\n",
      "28:\ttotal: 242ms\tremaining: 1.43s\n",
      "29:\ttotal: 246ms\tremaining: 1.39s\n",
      "30:\ttotal: 250ms\tremaining: 1.36s\n",
      "31:\ttotal: 253ms\tremaining: 1.33s\n",
      "32:\ttotal: 257ms\tremaining: 1.3s\n",
      "33:\ttotal: 261ms\tremaining: 1.27s\n",
      "34:\ttotal: 264ms\tremaining: 1.24s\n",
      "35:\ttotal: 268ms\tremaining: 1.22s\n",
      "36:\ttotal: 275ms\tremaining: 1.21s\n",
      "37:\ttotal: 281ms\tremaining: 1.2s\n",
      "38:\ttotal: 286ms\tremaining: 1.18s\n",
      "39:\ttotal: 294ms\tremaining: 1.18s\n",
      "40:\ttotal: 298ms\tremaining: 1.15s\n",
      "41:\ttotal: 301ms\tremaining: 1.13s\n",
      "42:\ttotal: 305ms\tremaining: 1.11s\n",
      "43:\ttotal: 308ms\tremaining: 1.09s\n",
      "44:\ttotal: 312ms\tremaining: 1.07s\n",
      "45:\ttotal: 315ms\tremaining: 1.05s\n",
      "46:\ttotal: 320ms\tremaining: 1.04s\n",
      "47:\ttotal: 324ms\tremaining: 1.02s\n",
      "48:\ttotal: 327ms\tremaining: 1.01s\n",
      "49:\ttotal: 330ms\tremaining: 989ms\n",
      "50:\ttotal: 333ms\tremaining: 973ms\n",
      "51:\ttotal: 335ms\tremaining: 954ms\n",
      "52:\ttotal: 339ms\tremaining: 940ms\n",
      "53:\ttotal: 343ms\tremaining: 926ms\n",
      "54:\ttotal: 346ms\tremaining: 913ms\n",
      "55:\ttotal: 351ms\tremaining: 904ms\n",
      "56:\ttotal: 355ms\tremaining: 891ms\n",
      "57:\ttotal: 359ms\tremaining: 878ms\n",
      "58:\ttotal: 363ms\tremaining: 866ms\n",
      "59:\ttotal: 366ms\tremaining: 854ms\n",
      "60:\ttotal: 375ms\tremaining: 853ms\n",
      "61:\ttotal: 382ms\tremaining: 851ms\n",
      "62:\ttotal: 391ms\tremaining: 850ms\n",
      "63:\ttotal: 399ms\tremaining: 849ms\n",
      "64:\ttotal: 409ms\tremaining: 848ms\n",
      "65:\ttotal: 418ms\tremaining: 849ms\n",
      "66:\ttotal: 428ms\tremaining: 849ms\n",
      "67:\ttotal: 437ms\tremaining: 848ms\n",
      "68:\ttotal: 446ms\tremaining: 846ms\n",
      "69:\ttotal: 456ms\tremaining: 846ms\n",
      "70:\ttotal: 465ms\tremaining: 844ms\n",
      "71:\ttotal: 474ms\tremaining: 842ms\n",
      "72:\ttotal: 483ms\tremaining: 840ms\n",
      "73:\ttotal: 495ms\tremaining: 842ms\n",
      "74:\ttotal: 503ms\tremaining: 839ms\n",
      "75:\ttotal: 511ms\tremaining: 834ms\n",
      "76:\ttotal: 519ms\tremaining: 829ms\n",
      "77:\ttotal: 526ms\tremaining: 822ms\n",
      "78:\ttotal: 536ms\tremaining: 821ms\n",
      "79:\ttotal: 545ms\tremaining: 818ms\n",
      "80:\ttotal: 554ms\tremaining: 814ms\n",
      "81:\ttotal: 563ms\tremaining: 810ms\n",
      "82:\ttotal: 567ms\tremaining: 799ms\n",
      "83:\ttotal: 572ms\tremaining: 790ms\n",
      "84:\ttotal: 577ms\tremaining: 780ms\n",
      "85:\ttotal: 581ms\tremaining: 770ms\n",
      "86:\ttotal: 585ms\tremaining: 760ms\n",
      "87:\ttotal: 594ms\tremaining: 756ms\n",
      "88:\ttotal: 604ms\tremaining: 753ms\n",
      "89:\ttotal: 612ms\tremaining: 749ms\n",
      "90:\ttotal: 619ms\tremaining: 742ms\n",
      "91:\ttotal: 624ms\tremaining: 733ms\n",
      "92:\ttotal: 628ms\tremaining: 722ms\n",
      "93:\ttotal: 632ms\tremaining: 713ms\n",
      "94:\ttotal: 636ms\tremaining: 703ms\n",
      "95:\ttotal: 640ms\tremaining: 693ms\n",
      "96:\ttotal: 643ms\tremaining: 683ms\n",
      "97:\ttotal: 647ms\tremaining: 673ms\n",
      "98:\ttotal: 651ms\tremaining: 664ms\n",
      "99:\ttotal: 654ms\tremaining: 654ms\n",
      "100:\ttotal: 658ms\tremaining: 645ms\n",
      "101:\ttotal: 661ms\tremaining: 636ms\n",
      "102:\ttotal: 665ms\tremaining: 627ms\n",
      "103:\ttotal: 669ms\tremaining: 618ms\n",
      "104:\ttotal: 673ms\tremaining: 609ms\n",
      "105:\ttotal: 677ms\tremaining: 600ms\n",
      "106:\ttotal: 681ms\tremaining: 592ms\n",
      "107:\ttotal: 688ms\tremaining: 586ms\n",
      "108:\ttotal: 695ms\tremaining: 581ms\n",
      "109:\ttotal: 699ms\tremaining: 572ms\n",
      "110:\ttotal: 703ms\tremaining: 564ms\n",
      "111:\ttotal: 707ms\tremaining: 556ms\n",
      "112:\ttotal: 711ms\tremaining: 547ms\n",
      "113:\ttotal: 714ms\tremaining: 539ms\n",
      "114:\ttotal: 718ms\tremaining: 530ms\n",
      "115:\ttotal: 721ms\tremaining: 522ms\n",
      "116:\ttotal: 725ms\tremaining: 514ms\n",
      "117:\ttotal: 728ms\tremaining: 506ms\n",
      "118:\ttotal: 732ms\tremaining: 498ms\n",
      "119:\ttotal: 736ms\tremaining: 491ms\n",
      "120:\ttotal: 740ms\tremaining: 483ms\n",
      "121:\ttotal: 744ms\tremaining: 475ms\n",
      "122:\ttotal: 748ms\tremaining: 468ms\n",
      "123:\ttotal: 751ms\tremaining: 460ms\n",
      "124:\ttotal: 755ms\tremaining: 453ms\n",
      "125:\ttotal: 759ms\tremaining: 446ms\n",
      "126:\ttotal: 762ms\tremaining: 438ms\n",
      "127:\ttotal: 766ms\tremaining: 431ms\n",
      "128:\ttotal: 770ms\tremaining: 424ms\n",
      "129:\ttotal: 772ms\tremaining: 416ms\n",
      "130:\ttotal: 776ms\tremaining: 409ms\n",
      "131:\ttotal: 779ms\tremaining: 401ms\n",
      "132:\ttotal: 783ms\tremaining: 394ms\n",
      "133:\ttotal: 787ms\tremaining: 387ms\n",
      "134:\ttotal: 790ms\tremaining: 380ms\n",
      "135:\ttotal: 794ms\tremaining: 373ms\n",
      "136:\ttotal: 797ms\tremaining: 367ms\n",
      "137:\ttotal: 802ms\tremaining: 360ms\n",
      "138:\ttotal: 809ms\tremaining: 355ms\n",
      "139:\ttotal: 816ms\tremaining: 350ms\n",
      "140:\ttotal: 819ms\tremaining: 343ms\n",
      "141:\ttotal: 822ms\tremaining: 336ms\n",
      "142:\ttotal: 826ms\tremaining: 329ms\n",
      "143:\ttotal: 832ms\tremaining: 324ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144:\ttotal: 839ms\tremaining: 318ms\n",
      "145:\ttotal: 843ms\tremaining: 312ms\n",
      "146:\ttotal: 852ms\tremaining: 307ms\n",
      "147:\ttotal: 861ms\tremaining: 303ms\n",
      "148:\ttotal: 870ms\tremaining: 298ms\n",
      "149:\ttotal: 876ms\tremaining: 292ms\n",
      "150:\ttotal: 884ms\tremaining: 287ms\n",
      "151:\ttotal: 888ms\tremaining: 280ms\n",
      "152:\ttotal: 892ms\tremaining: 274ms\n",
      "153:\ttotal: 900ms\tremaining: 269ms\n",
      "154:\ttotal: 905ms\tremaining: 263ms\n",
      "155:\ttotal: 908ms\tremaining: 256ms\n",
      "156:\ttotal: 912ms\tremaining: 250ms\n",
      "157:\ttotal: 916ms\tremaining: 244ms\n",
      "158:\ttotal: 918ms\tremaining: 237ms\n",
      "159:\ttotal: 921ms\tremaining: 230ms\n",
      "160:\ttotal: 925ms\tremaining: 224ms\n",
      "161:\ttotal: 928ms\tremaining: 218ms\n",
      "162:\ttotal: 931ms\tremaining: 211ms\n",
      "163:\ttotal: 935ms\tremaining: 205ms\n",
      "164:\ttotal: 937ms\tremaining: 199ms\n",
      "165:\ttotal: 941ms\tremaining: 193ms\n",
      "166:\ttotal: 944ms\tremaining: 187ms\n",
      "167:\ttotal: 947ms\tremaining: 180ms\n",
      "168:\ttotal: 949ms\tremaining: 174ms\n",
      "169:\ttotal: 953ms\tremaining: 168ms\n",
      "170:\ttotal: 957ms\tremaining: 162ms\n",
      "171:\ttotal: 961ms\tremaining: 156ms\n",
      "172:\ttotal: 964ms\tremaining: 151ms\n",
      "173:\ttotal: 968ms\tremaining: 145ms\n",
      "174:\ttotal: 971ms\tremaining: 139ms\n",
      "175:\ttotal: 975ms\tremaining: 133ms\n",
      "176:\ttotal: 979ms\tremaining: 127ms\n",
      "177:\ttotal: 983ms\tremaining: 121ms\n",
      "178:\ttotal: 986ms\tremaining: 116ms\n",
      "179:\ttotal: 988ms\tremaining: 110ms\n",
      "180:\ttotal: 992ms\tremaining: 104ms\n",
      "181:\ttotal: 996ms\tremaining: 98.5ms\n",
      "182:\ttotal: 1000ms\tremaining: 92.9ms\n",
      "183:\ttotal: 1s\tremaining: 87.3ms\n",
      "184:\ttotal: 1.01s\tremaining: 81.7ms\n",
      "185:\ttotal: 1.01s\tremaining: 76.1ms\n",
      "186:\ttotal: 1.01s\tremaining: 70.6ms\n",
      "187:\ttotal: 1.02s\tremaining: 64.9ms\n",
      "188:\ttotal: 1.02s\tremaining: 59.3ms\n",
      "189:\ttotal: 1.02s\tremaining: 53.8ms\n",
      "190:\ttotal: 1.02s\tremaining: 48.3ms\n",
      "191:\ttotal: 1.03s\tremaining: 42.8ms\n",
      "192:\ttotal: 1.03s\tremaining: 37.4ms\n",
      "193:\ttotal: 1.04s\tremaining: 32.1ms\n",
      "194:\ttotal: 1.05s\tremaining: 26.8ms\n",
      "195:\ttotal: 1.05s\tremaining: 21.5ms\n",
      "196:\ttotal: 1.06s\tremaining: 16.2ms\n",
      "197:\ttotal: 1.07s\tremaining: 10.8ms\n",
      "198:\ttotal: 1.07s\tremaining: 5.4ms\n",
      "199:\ttotal: 1.08s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG-CV: 0.409771690830277\n",
      "ET-CV: 0.41107345748504565\n",
      "RF-CV: 0.40875499685880207\n",
      "CB-CV: 0.4565042881930303\n",
      "LG-CV: 0.40694823413336295\n",
      "(59682, 5),(13841, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "class CatboostWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "        \n",
    "class LightGBMWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['feature_fraction_seed'] = seed\n",
    "        params['bagging_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index,test_index) in enumerate(kf.split(all_train_data)):\n",
    "        x_tr = all_train_data.loc[train_index]\n",
    "        y_tr = y_train_all.loc[train_index]\n",
    "        x_te = all_train_data.loc[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(all_test_data)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "et_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'nrounds': 200\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.5,\n",
    "    'depth': 3,\n",
    "    'l2_leaf_reg': 40,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'subsample': 0.7,\n",
    "    'scale_pos_weight': 5,\n",
    "    'eval_metric': 'AUC',\n",
    "    'od_type': 'Iter',\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "    'n_estimators':200,\n",
    "    'learning_rate':0.1,\n",
    "    'num_leaves':123,\n",
    "    'colsample_bytree':0.8,\n",
    "    'subsample':0.9,\n",
    "    'max_depth':15,\n",
    "    'reg_alpha':0.1,\n",
    "    'reg_lambda':0.1,\n",
    "    'min_split_gain':0.01,\n",
    "    'min_child_weight':2    \n",
    "}\n",
    "\n",
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params)\n",
    "lg = LightGBMWrapper(clf = LGBMClassifier, seed = SEED, params = lightgbm_params)\n",
    "\n",
    "xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)\n",
    "cb_oof_train, cb_oof_test = get_oof(cb)\n",
    "lg_oof_train, lg_oof_test = get_oof(lg)\n",
    "\n",
    "print(\"XG-CV: {}\".format(sqrt(mean_squared_error(y_train_all, xg_oof_train))))\n",
    "print(\"ET-CV: {}\".format(sqrt(mean_squared_error(y_train_all, et_oof_train))))\n",
    "print(\"RF-CV: {}\".format(sqrt(mean_squared_error(y_train_all, rf_oof_train))))\n",
    "print(\"CB-CV: {}\".format(sqrt(mean_squared_error(y_train_all, cb_oof_train))))\n",
    "print(\"LG-CV: {}\".format(sqrt(mean_squared_error(y_train_all, lg_oof_train))))\n",
    "\n",
    "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train, cb_oof_train,lg_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test, cb_oof_test,lg_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(x_train,y_train_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "alike-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=logistic_regression.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "technical-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "guilty-advocate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "similar-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[\"TRUE\" if x==1 else 'FALSE' for x in preds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "prompt-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " ...]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "similar-winter",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jhWGzj0sBu54vLay6S3n",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "detailed-growing",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "5CFVhiwNNwGI3lhrVPXb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission['Labels']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "clear-jacksonville",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "OdTRVCYV3TiqQ679hsKU",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "aSbfhd9TQR3FB9dBJksJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRUE     10168\n",
       "FALSE     3673\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "breeding-parliament",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jq3zH3Yvk7k0W3NUKXjb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission.to_csv('Ensemble_Catboost_HyperParams_withMeta.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "posted-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'CrossEntropy',\n",
       " 'colsample_bylevel': 0.08445348018951108,\n",
       " 'depth': 7,\n",
       " 'boosting_type': 'Ordered',\n",
       " 'bootstrap_type': 'MVS'}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-median",
   "metadata": {},
   "source": [
    "# Using Fast AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "moral-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "corporate-albania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.393565</td>\n",
       "      <td>106.792766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.317464</td>\n",
       "      <td>106.925531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.369516</td>\n",
       "      <td>106.745579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.618644</td>\n",
       "      <td>106.816363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.307827</td>\n",
       "      <td>106.984562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71331</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.369921</td>\n",
       "      <td>106.810463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71332</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.611847</td>\n",
       "      <td>106.789816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71333</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.266825</td>\n",
       "      <td>106.910776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71334</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.898450</td>\n",
       "      <td>107.614134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71335</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.917925</td>\n",
       "      <td>107.575665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71336 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour  day  latitude   longitude\n",
       "0        13    5 -6.393565  106.792766\n",
       "1        17    0 -6.317464  106.925531\n",
       "2        19    3 -6.369516  106.745579\n",
       "3        15    2 -6.618644  106.816363\n",
       "4        11    2 -6.307827  106.984562\n",
       "...     ...  ...       ...         ...\n",
       "71331    10    1 -6.369921  106.810463\n",
       "71332    12    5 -6.611847  106.789816\n",
       "71333    14    2 -6.266825  106.910776\n",
       "71334     9    6 -6.898450  107.614134\n",
       "71335    12    3 -6.917925  107.575665\n",
       "\n",
       "[71336 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "latin-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fastai=all_train_data\n",
    "train_fastai['target']=y_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "progressive-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    " #1: If the target variable data type is left as a numeric value, FastAI/PyTorch will treat it as such and yield a runtime err\n",
    "\n",
    "train_fastai['target']=train_fastai['target'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "endless-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Features\n",
    "CAT_NAMES = ['hour', 'day'] \n",
    "# Continuous Features\n",
    "CONT_NAMES = ['latitude', 'longitude'] \n",
    "# Target Variable\n",
    "TARGET = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "surface-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processors\n",
    "procs = [Categorify, FillMissing, Normalize] \n",
    "# Training/Validation Dataset 80:20 Split \n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(train_fastai)) \n",
    "dls = TabularDataLoaders.from_df(train_fastai,                                         \n",
    "                                 y_names=TARGET,                                  \n",
    "                                 cat_names=CAT_NAMES,                                 \n",
    "                                 cont_names=CONT_NAMES,                                 \n",
    "                                 procs=procs,                                 \n",
    "                                 splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "otherwise-integral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13079</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.997727</td>\n",
       "      <td>-0.431171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59213</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0.519463</td>\n",
       "      <td>-0.110358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63940</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.455071</td>\n",
       "      <td>-1.210868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68430</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.281098</td>\n",
       "      <td>-0.994386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44526</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.209633</td>\n",
       "      <td>1.408912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33048</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1.025171</td>\n",
       "      <td>-0.439841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62970</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1.024817</td>\n",
       "      <td>-0.448511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32335</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.414221</td>\n",
       "      <td>1.426274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26982</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>-0.959729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497624</td>\n",
       "      <td>-1.080997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57069 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hour  day  latitude  longitude\n",
       "13079    14    6  0.997727  -0.431171\n",
       "59213    17    4  0.519463  -0.110358\n",
       "63940    16    3  0.455071  -1.210868\n",
       "68430    16    5 -0.281098  -0.994386\n",
       "44526    11    4 -1.209633   1.408912\n",
       "...     ...  ...       ...        ...\n",
       "33048    12    2  1.025171  -0.439841\n",
       "62970    17    5  1.024817  -0.448511\n",
       "32335    10    7 -1.414221   1.426274\n",
       "26982    16    3  0.493333  -0.959729\n",
       "347      18    1  0.497624  -1.080997\n",
       "\n",
       "[57069 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "encouraging-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_df = train_fastai.groupby(TARGET).count() \n",
    "n_0, n_1 = class_count_df.iloc[0, 0], class_count_df.iloc[1, 0] \n",
    "w_0 = (n_0 + n_1) / (2.0 * n_0)\n",
    "w_1 = (n_0 + n_1) / (2.0 * n_1)\n",
    "\n",
    "#2: Ensure that the class weights are converted to a float tensor and that cuda operations are enabled via .cuda(). Otherwise, you will get a type error.\n",
    "class_weights=torch.FloatTensor([w_0, w_1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "whole-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: For binary class labels, use RocAucBinary() and NOT RocAuc() in order to avoid a value error.\n",
    "\n",
    "roc_auc = RocAucBinary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "governing-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Use the FastAI cross entropy loss function as opposed to the PyTorch equivalent of torch.nn.CrossEntropyLoss() in order to avoid errors. The FastAI loss functions are listed here. Using the PyTorch cross entropy loss gave me the following runtime error.\n",
    "loss_func = CrossEntropyLossFlat(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "civic-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, \n",
    "                        layers=[1000, 800],    \n",
    "                        loss_func=loss_func, \n",
    "                        metrics=roc_auc\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fatty-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of CrossEntropyLoss()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "casual-arthritis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11' class='' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.50% [11/200 01:26<24:42]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.664003</td>\n",
       "      <td>0.668365</td>\n",
       "      <td>0.596265</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663156</td>\n",
       "      <td>0.661517</td>\n",
       "      <td>0.613740</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>0.662932</td>\n",
       "      <td>0.609346</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.662497</td>\n",
       "      <td>0.660528</td>\n",
       "      <td>0.613454</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.663853</td>\n",
       "      <td>0.667323</td>\n",
       "      <td>0.608065</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.663098</td>\n",
       "      <td>0.663609</td>\n",
       "      <td>0.608852</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.657117</td>\n",
       "      <td>0.661349</td>\n",
       "      <td>0.614186</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.661123</td>\n",
       "      <td>0.612442</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.661829</td>\n",
       "      <td>0.661677</td>\n",
       "      <td>0.612016</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.656020</td>\n",
       "      <td>0.661529</td>\n",
       "      <td>0.616214</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.660953</td>\n",
       "      <td>0.658077</td>\n",
       "      <td>0.617851</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='769' class='' max='891' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      86.31% [769/891 00:05<00:00 0.6612]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6683646440505981.\n",
      "Better model found at epoch 1 with valid_loss value: 0.6615174412727356.\n",
      "Better model found at epoch 3 with valid_loss value: 0.6605277061462402.\n",
      "Better model found at epoch 10 with valid_loss value: 0.6580771207809448.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-daedf2174236>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSaveModelCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevery_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fastai_best\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\callback\\schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[0;32m    110\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[0;32m    111\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m# Cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'before_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_cancel_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'after_{event_type}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\data\\load.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'it'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mcompose_tfms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;34mf\"Pipeline: {' -> '.join([f.name for f in self.fs if f.name != 'noop'])}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36mcompose_tfms\u001b[1;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtfms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_enc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;34m\"A transform that always take tuples as items\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0m_retain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__call__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36m_call1\u001b[1;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retain\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_get_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encodes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decodes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;34mf'{self.name}:\\nencodes: {self.encodes}decodes: {self.decodes}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_idx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\transform.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'returns'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastcore\\dispatch.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minst\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\tabular\\core.py\u001b[0m in \u001b[0;36mencodes\u001b[1;34m(self, to)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_cont\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_names\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\fastai\\torch_core.py\u001b[0m in \u001b[0;36mtensor\u001b[1;34m(x, *rest, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m            \u001b[1;32melse\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__array__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m            else _array2tensor(array(x), **kwargs))\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(200,cbs=[SaveModelCallback(monitor='valid_loss',every_epoch=False,fname=\"fastai_best\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"fastai_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test data\n",
    "all_test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl =dls.test_dl(all_test_data)\n",
    "pred_prob = learn.get_preds(dl=test_dl)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "reliable-hollywood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4368, 0.5632],\n",
       "        [0.5398, 0.4602],\n",
       "        [0.7314, 0.2686],\n",
       "        ...,\n",
       "        [0.5009, 0.4991],\n",
       "        [0.8444, 0.1556],\n",
       "        [0.4495, 0.5505]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "centered-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob= pred_prob[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "mathematical-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5632, 0.4602, 0.2686,  ..., 0.4991, 0.1556, 0.5505])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fitted-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[\"TRUE\" if x>0.37 else 'FALSE' for x in pred_prob]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "urban-folder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'FALSE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " 'TRUE',\n",
       " ...]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "adult-passion",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jhWGzj0sBu54vLay6S3n",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "straight-trout",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "5CFVhiwNNwGI3lhrVPXb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "submission['Labels']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "entitled-seeking",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "OdTRVCYV3TiqQ679hsKU",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     },
     "outputId": {
      "block": "aSbfhd9TQR3FB9dBJksJ",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 2
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRUE     11100\n",
       "FALSE     2741\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "light-berlin",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "jq3zH3Yvk7k0W3NUKXjb",
      "project": "CX99abAmoFUHBLWDvSoS",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "#generating submission csv\n",
    "# submission = pd.DataFrame(preds)\n",
    "#save the file to your directory\n",
    "submission.to_csv('FastAI_with_balancing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-mayor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "iooxa": {
   "id": {
    "block": "i6KIb73AeQCScK0ETruX",
    "project": "CX99abAmoFUHBLWDvSoS",
    "version": 3
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
